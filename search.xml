<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[【置顶】Learning Load Balance 目录]]></title>
    <url>%2Flb%2F20180107-learning-load-balance%2F</url>
    <content type="text"><![CDATA[Vagrant由于会用到很多机器做实验，故推荐使用Vagrant来批量创建虚拟机。 ✔Vagrant–快速搭建实验环境利器✔自制的 Vagrant box —— longdream/centos7 LVS ✔LVS原理 ✔LVS/NAT实验 ✔LVS/DR实验 Nginx ✔01-Nginx简介 ✔02-IO模型 ✔03-Nginx的主配置文件 ✔04-Nginx的默认http配置 ✔05-ngx_http_core_module详解 ✔06-Nginx的HTTP相关的杂项模块 ✔07-ngx_http_proxy_module详解 ✔08-ngx_http_fastcgi_module详解 ✔09-ngx_http_upstream_module详解 ✔10-ngx_stream*_module详解 HAProxy ✔01-HAProxy简介 ✔02-HAProxy简单配置和基本用法 ✔03-HAProxy 具体配置参数 ✔04-HAProxy统计页面 未完待续]]></content>
      <categories>
        <category>lb</category>
      </categories>
      <tags>
        <tag>Python3</tag>
        <tag>TOC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【置顶】Learning Linux目录]]></title>
    <url>%2Flinux%2F20171111-learning-linux-toc%2F</url>
    <content type="text"><![CDATA[这里存放的我的Linux笔记，供自己随时搜索和使用，同时共享给需要的人。系统采用的是CentOS7.3（主要使用，2017.9.18日之后更换为CentOS7.4)和CentOS6.9（少量使用）。每篇文章都可以评论，使用GitHub、微信、QQ、微博等均可登录评论。 ✔：代表已完成。 ✘：代表未完成。 近期调整目录结构，如果跳转链接有问题，请留言给我进行调整。 前言： ✔文章所使用的markdown语法 ✔本文章集合所遵循的开源协议以及开源协议介绍(GPL,LGPL,BSD,MIT,Apache,CC) ✔工欲善其事必先利其器 —— Xmanager Enterprise 5 和 RealVNC 5/6介绍 ✔学会科学上网 —— 用搬瓦工和Shadowsocks搭梯子 第一章 Linux 基础Linux简介 ✔Linux发行版时间线2017年版本 Linux安装 ✔CentOS 6 安装步骤 ✔CentOS 7 安装步骤 Linux基础命令 ✔01-命令基本格式 ✔02-查看命令帮助 ✔03-命令信息相关命令 ✔04-别名的使用方法 ✔05-关机重启命令 ✔06-日期时间相关命令 ✔07-回显命令 ✔08-换行（LF）和回车（CR）详解 ✔09-延伸小技巧screen、script、scriptreplay ✔10-基础命令练习题 Linux文件和目录管理 ✔01-Linux系统层级结构标准 ✔02-历史命令用法 ✔03-bash快捷键 ✔04-Linux文件类型和文件相关命令 ✔05-inode、软硬链接 IO重定向和管道 ✔01-IO重定向 ✔02-管道 ✔03-IO重定向和管道练习题 用户用户组管理 ✔01-什么是用户和组 ✔02-用户和组文件 ✔03-用户和用户组的管理命令 ✔04-用户和组练习题 ✔05-实践：Linux用户、组和密码相关文件被破坏如何恢复系统 权限和ACL访问控制 ✔01-权限 ✔02-特殊权限 ✔03-访问控制列表（ACL） ✔04-权限和ACL练习题 文本处理和正则表达式 ✔01-文本处理工具(cut、sort、tr、grep等) ✔02-正则表达式 ✔03-文本处理练习题 vim用法 ✔01-vim简明教程(附快速记忆方法) rpm、yum、编译安装程序 ✔01-程序包管理工具rpm ✔02-程序包管理工具yum ✔03-打包压缩命令tar、zip、split ✔04-编译安装make Shell基础 ✔01-全局变量和局部变量 ✔02-位置变量和退出码 ✘03-运算 ✔04-条件测试 ✔05-bash配置相关 第一章测试题 ✔第一阶段测试题 第二章 Linux磁盘、网络、进程管理磁盘管理 ✔磁盘分区管理 ✔磁盘阵列（RAID） ✔HPE x86服务器硬RAID做法 ✔逻辑卷管理（LVM） 网络管理 ✔网络模型 ✔CentOS6网络命令 ✔CentOS6网络配置 ✔CentOS7网络配置 ✔网卡绑定bonding 进程管理 ✔进程 ✔kill命令 ✔计划任务at、cron shell进阶 ✔流程 ✔函数 ✔数组和关联数组 ✔字符串处理 ✔sed ▬awk 推荐看《AWK程序设计语言》的中文开源翻译 20170704——练习题 ✔Shell流程练习题 ✔Shell函数练习题 第三章 LFS编译安装Linux启动流程 ✔CentOS5、CentOS6启动流程 ✘CentOS7启动流程 待更新 ✔破坏实验–破坏5的initrd、6和7的initramfs文件，然后恢复 LFS编译安装 ✔Linux From Scratch 8 之一–构建前准备主机系统 ✔Linux From Scratch 8 之二–创建LFS的分区，下载源码包 未完待续 第四章 Linux安全管理SELinux 待更新 OpenSSL ✔CA认证和证书 SSH ✔SSH客户端命令 ✔SSH转发 ✔SSH服务端 Sudo ✔Sudo TCP_Wrapper ✔TCP_Wrapper应用级防火墙 PAM ✔PAM安全认证模块 第五章 Linux自动化安装 ✘Kickstart详解 ✔自制Kickstart光盘 ✔DHCP服务 ✔TFTP服务和PXE功能 ✔Cobbler——无人值守安装多种版本多种配置操作系统 ✔Cobbler——添加网络同步仓库（Reposync用法) 第六章 Linux基础服务DNS服务（bind的使用） ✔01-什么是DNS ✔02-DNS如何工作 ✔03-DNS记录类型 ✔04-bind配置文件 ✔05-bind辅助工具 ✔06-bind主从复制 ✔07-DNS实战配置指南（转载） 第七章 负载均衡和高可用集群服务Tomcat ✔01-Tomcat基础知识 ✔02-Tomcat设置管理页面 ✘Tomcat基本配置 ✘Tomcat高级配置 Keepalived ✔01-Keepalived介绍 ✔02-Keepalived配置 ✔03-Keepalived各种模式配置 ✔04-单网络双活模式的Keepalived+LVS配置 ✔05-双网络双活模式的Keepalived+Nginx配置 第八章 缓存、消息队列Memcached Memcached简介Memcached配置详解✘Tomcat搭配Memcached Varnish ✘Varnish原理 ✘Varnish配置 RabbitMQ**✘ 第九章 数据库SQL基础 ✔01-数据库和SQL简介 ✔02-MariaDB安装 ✔03-SQL语句简单示例 ✔04-SELECT语句 ✔05-INSERT、DELETE、UPDATE语句 MySQL基础 ✘数据管理系统基础 ✘MySQL存储引擎 ✘MySQL事务和隔离级别 ✘MYSQL账号和权限管理 ✘MySQL索引 ✘MySQL日志 ✔ MySQL备份恢复（mysqldump、xtrabackup） ✘MySQL扩展机制概述 ✘MySQL复制实践 ✘MySQL复制及读写分离 ✘MySQL主节点高可用 OracleMongoDBRedis第十章 自动化部署Git、GitHub、GitLab ✔Git和GitHub笔记） JekinsAnsible ✘Ansible简介✘Ansible Roles Puppet ✘ 第十一章 监控Zabbix ✔01-Zabbix Server安装指南） ✔02-Zabbix Agent 安装指南和 Zabbix Server 设置自动发现 ✔03-Zabbix Server设置主机监控 ✔04-Zabbix Web 中文字体显示问题 ✔05-Zabbix trigger（触发器）设置 ✔06-Zabbix Actions(动作）设置 ✘Zabbix SNMP 监控设置 ✘Zabbix JMX 监控设置 ✘Zabbix IPMI 监控设置 ✘Zabbix Proxy 设置 ✘Zabbix自定义监控脚本 Open-FalconElastic Stack第十二章 虚拟化KVMOpenStack✘KVM ✔OpenStack简介 ✔01-OpenStack(Pike)安装实战——环境准备 LXCDockerKubernetes]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>TOC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【置顶】Learning Python3 目录]]></title>
    <url>%2Fpython%2F20171111-learning-python3-toc%2F</url>
    <content type="text"><![CDATA[**此文章集合是一个笔记，记录了我在学习Python3中学到的东西。 所有文章代码如无特殊说明，Python 版本均用 3.6.2。 ✔：表示已更新完毕 第一部分 Python基础第1章 环境搭建 ✔1.1 macOS下Python多版本控制软件的安装：pyenv、pyenv-virtualenv ✔1.2 CentOS下Python多版本控制软件的安装：pyenv、pyenv-virtualenv ✔1.3 开发环境配置 第2章 基础语法 ✔2.1 变量与命名规则 ✔2.2 运算符 ✔2.3 程序控制结构 第3章 内置数据结构 ✔3.1 数字（Numbers） ✔3.2 列表（Lists） ✔3.3 元组（Tuples） ✔3.4 字符串（Strings） ✔3.5 切片（Slice） ✔3.6 解包（Unpacking） ✔3.7 格式化（Formatting） ✔3.8 集合（Sets） ✔3.9 字典（Dictionarys） ✔3.10 bytes和bytearray ✔ 3.11 解析式（Comprehensions) ✔ 3.12 简单了解 可迭代对象(Iterables)、迭代器(Iterators)、生成器(Generators) ✔ 3.13 详解 可迭代对象(Iterables)、迭代器(Iterators)、生成器(Generators) 第4章 函数 ✔ 4.1 函数的基本定义与函数调用 ✔ 4.2 函数的执行过程 ✔ 4.3 函数的参数 ✔ 4.4 函数注解（类型示意） ✔ 4.5 递归函数 ✔ 4.6 生成器函数 ✔ 4.7 高阶函数、闭包、偏函数、柯里化、匿名函数 ✔ 4.8 装饰器 第二部分 Python高级第5章 面向对象和类 ✔ 5.1 类（Class）的定义 ✔ 5.2 OOP的三大特征：封装、继承、多态 ✔ 5.3 多继承与MRO算法 ✔5.4 魔术方法/特殊方法(Magic Methods) 第6章 异常处理 ✔6.1 异常（Exception） 第7章 模块化 ✔7.1 模块化（Modularization） 第8章 数据结构 ✔8.1 单链表（Singly Linked List） ✔8.2 栈（stack） ✔8.3 stack应用–表达式解析 ✔8.4 stack应用-规则解析 ✔8.5 队列（queue） ✔8.6 哈希（hash） ✔8.7 树（tree） ✔8.8 堆（heap） ——— 华丽分割线 2017.10.16 ———- 第三章 Web开发第9章 实现一个简单的Web框架]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>Python3</tag>
        <tag>TOC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[06-Zabbix Actions(动作）设置]]></title>
    <url>%2Flinux%2F20170927-06-zabbix-actions-config%2F</url>
    <content type="text"><![CDATA[当我们触发器触发了问题，要通知运维人员去解决问题，动作（Actions)就是用来通知运维人员的设置。 动作分为几个定义块： （1）触发动作的条件：（这里的条件是：1 不在维护状态；2 触发了触发器 “网络进站包数&gt;10000”) （2）触发了动作后，相应的操作：（通过MyEmail(zabbix@yulongjun.com)发送给用户Admin（ops@yulongjun.com)。（此段邮箱设置，在第一节Zabbix Server安装指南上有） 测试一下效果： 1hping 192.168.0.10 右上角有报警提示，并且有报警音： 仪表盘上也有报警信息，还可以看到报警邮件已经发送： 去邮箱查看，确实有报警邮件：（因为阀值设置的比较大，hping一会达到阀值，一会儿不到阈值，所以会看到问题和解决两种邮件。）]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[05-Zabbix trigger（触发器）设置]]></title>
    <url>%2Flinux%2F20170927-05-zabbix-triggers-config%2F</url>
    <content type="text"><![CDATA[设置一个监控项–进站包数，当进站包数&gt;50触发器报警。 先设置一个进站包数的监控项（item)： 针对进站包数设置触发器（tragger），&gt;5000为警告，&gt;10000为严重： 设置图形（graph） 记得勾选查看触发器，我们预览一下，可以看到两条虚线，就是触发器的阈值线，黄色的是上面定义的告警线，红色的是严重线。 测试一下效果： 1hping --flood 192.168.0.10 我们可以看到有问题告警： 停掉hping，问题告警变绿，变成已解决：]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[04-Zabbix Web 中文字体显示问题]]></title>
    <url>%2Flinux%2F20170927-04-zabbix-chinese-display%2F</url>
    <content type="text"><![CDATA[Zabbix中文字体问题，我们可以通过拷贝中文字体文件到zabbix的目录来实现。 上传一个中文字体文件到/usr/share/zabbix/fonts下，这里我拷贝的是windows下的微软雅黑msyh.ttf。 tips：只能支持ttf格式的字体文件，不能支持ttc的，本来copy了macOS下的一个苹方简体（PingFang.ttc)，结果不支持ttc类型的字体文件，最后换成微软雅黑（msyh.ttf)字体 原来配置文件里面配置的是graphfont.ttf，我们grep一下配置文件/usr/share/zabbix/include/defines.inc.php发现有两条记录： 1cat /usr/share/zabbix/include/defines.inc.php |grep graphfont 把这两个替换了就好： 1sed -i &apos;s/graphfont/msyh/g&apos; /usr/share/zabbix/include/defines.inc.php OK，替换完毕，可以grep验证一下： 刷新一下页面，即可看到中文正常显示：]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[03-Zabbix Server设置主机监控]]></title>
    <url>%2Flinux%2F20170927-03-zabbix-host-monitor-config%2F</url>
    <content type="text"><![CDATA[设置主机的监控项(1) 设置CPU用户使用率，键值为sys.cpu.util[all,sys,avg1] 由于用的百分号作为单位，所以要在进程里改为100倍： (2)设置CPU用户使用率，同上，只是把键值变为sys.cpu.util[all,user,avg1] 可以看到创建的两个监控项： 创建监控图形（grah)创建如macOS上的iStat Menus的效果： 设置： 最终效果： tips：图中中文出现乱码，是由于字体库的原因，具体解决方法可以查看下一节。http://www.yulongjun.com/linux/20170927-04-zabbix-chinese-display/]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[02-Zabbix Agent 安装指南和 Zabbix Server 设置自动发现]]></title>
    <url>%2Flinux%2F20170927-02-zabbix-agent-installation%2F</url>
    <content type="text"><![CDATA[Zabbix Agent分为两种模式，被动模式（Passive)和主动模式（ 我们实验在node1.yulongjun.com 和node2.yulongjun.com上分别配置Zabbix Agent。 yum 安装 Zabbix Agent123rpm -ivh http://repo.zabbix.com/zabbix/3.4/rhel/7/x86_64/zabbix-release-3.4-1.el7.centos.noarch.rpmyum install -y zabbix-agent 如果不能联网，可以去官网下载rpm包安装。repo地址：http://repo.zabbix.com/zabbix/可以找到当前你所用的版本的agent。写这篇文章的时候，Zabbix的最新版本是3.4.2：CentOS7的相关包下载地址：http://repo.zabbix.com/zabbix/3.4/rhel/7/x86_64/zabbix-agent-3.4.2-1.el7.x86_64.rpm如果后续有更新，可以自行查找。 Agent可以设置被动检查模式或者主动检查模式： node1上，vim /etc/zabbix/zabbix_agentd.conf： 123456789101112131415161718192021##### Passive checks related 被动模式检查相关# Zabbix Server地址,如果想被Zabbix Proxy发现，可以添加zabbix-proxy的地址。Server=zabbix.yulongjun.com#Server=zabbix.yulongnjun.com, zabbix-proxy.yulongjun.com# 监听端口，默认10050ListenPort=10050# 限定Server可以监控的IP地址，可以用逗号隔开多个。默认0.0.0.0，即监控所有ip地址。# ListenIP=0.0.0.0# 代理进程并发数，如果监控的选项比较多，可以改大StartAgents=3##### Active checks related 主动模式检查相关## Zabbix Server地址ServerActive=zabbix.yulongjun.com#ServerActive=zabbix.yulongjun.com,zabbix-proxy.yulongjun.com## 本机主机名，也是在Zabbix Server上显示的名字Hostname=node1.yulongjun.com node2的配置，更改相应的设置为node2.yulongjun.com和192.168.0.20 启动服务，下次开启自启动： 12systemctl start zabbix-agent.servicesystemctl enable zabbix-agent.service 配置服务器的自动发现功能配置–&gt;自动发现，我们看到默认有一个默认本地网段（Local Network)的规则，我们直接用就可以了，，点状态那里打开为启用： 在dashboard上就可以看到有发现两台主机： 点开上图Local network可以看到主机： 发现的主机，我们要添加到主机信息里，需要设置每一台主机的监控项。 设置主机组，添加主机node1和node2分别安装Nginx，我们就对Nginx进行监控： 123yum install nginxsystemctl start nginxsystemctl enable nginx 在配置–&gt;主机选项卡，点右上角创建主机：]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[01-Zabbix Server安装指南]]></title>
    <url>%2Flinux%2F20170927-01-zabbix-server-installation%2F</url>
    <content type="text"><![CDATA[安装 Zabbix 的 yum 仓库在所有机器上安装zabbix的yum仓库文件： 1rpm -ivh http://repo.zabbix.com/zabbix/3.4/rhel/7/x86_64/zabbix-release-3.4-3.el7.centos.noarch.rpm 安装配置MariaDB数据库并启动数据库可以装在和 Zabbix Server 同一台机器上（zabbix.yulongjun.com)，也可以装在不同的机器上，这里直接装在同一台机器上了： 123yum install -y mariadb-serversystemctl start mariadbsystemctl enable mariadb 在 Zabbix Server 上创建数据库zabbix、用户zabbix、运行建库脚本schema.sql、schema.sql、images.sql、data.sql（如果是Zabbix Proxy，就不用运行后两个） 123456789# shell下运行：shell&gt; mysql -uroot# mysql命令行里运行：mysql&gt; create database zabbix character set utf8 collate utf8_bin;mysql&gt; grant all privileges on zabbix.* to zabbix@localhost identified by 'zabbix';mysql&gt; quit;# shell下运行：shell&gt; cd /usr/share/doc/zabbix-server-mysql-3.4.2shell&gt; zcat create.sql.gz | mysql -uroot zabbix # zcat出来的脚本写入zabbix库 安装配置Zabbix Server并启动Server后端在zabbix.yulongjun.com节点上,安装Zabbix Server相关： 1yum install zabbix-server-mysql zabbix-web-mysql zabbix-get Zabbix 的配置主要分为下面几段： 12345grep "^#####" /etc/zabbix/zabbix_server.conf############ GENERAL PARAMETERS ############################# ADVANCED PARAMETERS ####################### LOADABLE MODULES ############## TLS-RELATED PARAMETERS ####### 通用参数、高级参数、加载的模块、TLS加密通信相关配置 12cp /etc/zabbix/zabbix_server.conf&#123;,.bak&#125;vim /etc/zabbix/zabbix_server.conf 主要更改通用参数（GENERAL PARAMETERS）： 下面是通用参数的说明： 12345678910111213141516171819############ GENERAL PARAMETERS #################ListenPort=10051 # trapper监听端口，一般不变SourceIP=192.168.0.222 # 对外服务ip，这里要设置一下，要不会开放给所有ipLogType=file # 日志格式，默认为file，可设置为system（syslog）、file（需要定义LogFile参数）、console（标准输出）LogFile=/var/log/zabbix/zabbix_server.log # 上面定义为LogFile，这里就要定义路径了。LogFileSize=50 # 日志到多大滚动，0表示不滚动，一般需要设置下，最大为1024（MB)PidFile=/var/run/zabbix/zabbix_server.pid # pid对应的文件位置和名字DBHost=localhost # 数据库地址DBName=zabbix # 数据库名字DBUser=zabbix # 数据库用户DBPassword=zabbix # 数据库密码SocketDir=/var/run/zabbix # Zabbix的IPC socket目录DebugLevel=3 # debug 级别，默认为3，一般不动，需要详细日志是可设置为5DBHost=localhost # 不变，因为zabbix用户就是授权到地址localhost了DBName=zabbix # 不变，当时创建的数据库名就是zabbixDBUser=zabbix # 不变，当时创建的用户就是zabbixDBPassword=zabbix # 这条原来没设置，设置为上面定义的密码DBSocket=/var/lib/mysql/mysql.sock # DBSocket文件路径默认为`/tmp/mysql.sock`，所以这条需要设置数据库的sock文件所在位置；或者 `ln -sv /var/lib/mysql/mysql.sock /tmp/`，这样不用改配置也能用DBPort=3306 # 数据库端口 其实主要改的就这几项，其余的如果不一样再修改： 123SourceIP=192.168.0.222DBPassword=zabbixDBSocket=/var/lib/mysql/mysql.sock 启动zabbix-server并设置下次开机自动开启 1systemctl start zabbix-server 编辑Zabbix前端PHP配置，并启动Zabbix的Web服务只要把httpd配置文件/etc/httpd/conf.d/zabbix.conf中的php_value date.timezone启用并设置为当前时区： 1php_value date.timezone Asia/Shanghai 或者是，把/etc/php.ini里的date.timezone =启用，并设置为当前时区： 1date.timezone = Asia/Shanghai 上述两种方法均可。 启动Apache Web服务： 12systemctl start httpdsystemctl enable httpd 设置Zabbix Server在浏览器输入zabbix.yulongjun.com/zabbix即可登录Web页面，然后开始进一步的设置： 点击Next step 配置，进入检查阶段，全部OK可以进入下一步配置： 输入密码，其他的如果有自己更改过的可以自行更改： 输入主机名或者ip地址、端口、还有名字 安装摘要，点下一步开始安装： 安装成功： 可以登录了，默认用户名admin, 密码zabbix： 进入页面： 可以更换页面风格和语言： Administration –&gt; General –&gt; 选择Dark主题–&gt;Update 可以更改密码，语言（支持中文哦）： 看一下中文界面： 设置media类型（报警媒介类型）由于某些原因，无法使用自带的一些媒介，所以使用自定义的邮箱设置 自带的Media，国内无法使用： 点击右上角创建媒体类型创建自定义的媒介，这里的媒介指的是出现报警后，用什么媒介来报警，这里设置的一个zabbix@yulongjun.com来负责发送报警邮件。 在Admin用户的设置里设置报警媒介，即出现报警后发送给谁，这里设置的ops@yulongjun.com。如果出现报警，则可以设置通过MyEmail(zabbix@yulongjun.com),向用户Admin设置的邮箱ops@yulongjun.com发送报警。 这里设置里仅设置了警告以上级别： 如果触发了triggers（触发器）的阈值，如果设定了相应的发送报警信息的Actions（行动），则会通过定义的规则来发送信息。 还可以设置页面的报警音（右上角人头–&gt;正在发送消息） 其他设置dashboard页面可以定义每个仪表盘的刷新时间： 监控模板网站在https://share.zabbix.com/，提供了各种各样的监控模板，可以自行搜索，套用。 下一节根据具体Agent来设置监控]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7上简单安装部署GitLab]]></title>
    <url>%2Fcloud%2F20170922-gitlab%2F</url>
    <content type="text"><![CDATA[安装：在安装gitlab之前，记得要安装postfix来作为发送邮件通知的邮件服务： 123yum install postfixsystemctl enable postfixsystemctl start postfix GitLab-CE 可以用脚本一键安装repo文件： 1curl -s https://packages.gitlab.com/install/repositories/runner/gitlab-ci-multi-runner/script.rpm.sh | bash 也可以手动编写repo文件： vim /etc/yum.repos.d/gitlab-ce.repo 12345[gitlab-ce]name=Gitlab CE Repositorybaseurl=https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el7/gpgcheck=0enabled=1 之后yum安装即可： 1yum install gitlab-ce 简单配置启动根据提示来配置： vim /etc/gitlab/gitlab.rb 找到external_url那项，改为可用的主机名(我的是gitlab.yulongjun.com，并且已做好解析）： 1external_url gitlab.yulongjun.com tips：可以使用sed替换 —— sed -i.bak &quot;s#external_url &#39;http://gitlab.example.com&#39;#external_url &#39;http://gitlab.yulongjun.com&#39;#g&quot; /etc/gitlab/gitlab.rb 修改完后，启动gitlab实例： 1gitlab-ctl reconfigure 设置下次开机自启动： 1systemctl enable gitlab-runsvdir.service 登录浏览器输入gitlab.yulongjun.com。 第一次登录需要更改密码： 然后使用新密码登录，用户名为root： 登录成功后的界面： 设置禁止注册一般公司内部使用的话，是禁止注册的，用的话单独开设账号。 root登录后，在Admin area里可以关掉注册： 去掉勾选 Sign-up enabled： 如果需要注册很多人，而且都是一个公司的邮箱后缀，可以开启邮箱验证功能，并且设置白名单区域，只允许本公司的邮箱后缀的人注册。 详细设置1. 设置时区修改时区为Asia/Shanghai1sed -i &quot;s@# gitlab_rails[&apos;time_zone&apos;] = &apos;UTC&apos;@gitlab_rails[&apos;time_zone&apos;] = &apos;Asia/Shanghai&apos;@g&quot; /etc/gitlab/gitlab.rb 验证是否修改成功： 2. 设置]]></content>
      <categories>
        <category>cloud</category>
      </categories>
      <tags>
        <tag>GitLab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git和GitHub笔记]]></title>
    <url>%2Fcloud%2F20170922-git%2F</url>
    <content type="text"><![CDATA[git安装1. macOS 下安装 GitMac上已经安装了git了 12[yulongjun@MBP ~]$ git --versiongit version 2.13.5 (Apple Git-94) 我们可以用brew命令来更新到最新版。brew命令类似于RHEL的yum和ubuntu的apt-get命令。 OS X没有自带brew，登陆Homebrew网站，找到ruby代码来安装brew目前的安装代码是： 1ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)" 安装好brew后，就可以用brew来安装git的最新版本了，而且会自动下载依赖包： 1$ brew install git 2. Linux 下安装 GitCentOS/RHEL： 1sudo yum install git Debian/Ubuntu： 1sudo apt install git 3. Windows 下安装Git谁会在Windows下用Git? 还是不写了，官网下个包，下一步下一步傻瓜安装就行了。 https://git-scm.com/ Git初始全局设置1. 设置姓名和邮箱地址终端输入： 12$ git config --global user.name &quot;Firstname Lastname&quot;$ git config --global user.email &quot;your_email@your_example.com&quot; 我用我的名字和邮箱来设置的，命令会在~/.gitconfig文件里生成以下内容： 123[user]name = Yu Longjunemail = tianshoulong@sina.com 2. 高亮命令输出的文字（可选）把color.ui设置成auto 1$ git config --global color.ui auto ~/.gitconfig会增加下面一行： 12[color]ui = auto GitHub设置1. 注册GitHub登陆https://github.com 注册并设置个人信息（这个就不写了） 2. 设置ssh key123456789101112131415[yulongjun@MBP ~]$ ssh-keygen -t rsa -C &quot;me@yulongjun.com&quot;Generating public/private rsa key pair.Enter file in which to save the key (/Users/yulongjun/.ssh/id_rsa): `按回车键`Enter passphrase (empty for no passphrase): `输入密码,可以不填直接回车`Enter same passphrase again: `再次输入密码，可以不填直接回车`Your identification has been saved in /Users/yulongjun/.ssh/id_rsa.Your public key has been saved in /home/yulongjun/.ssh/id_rsa.pub.The key fingerprint is:28:15:a9:38:93:c5:3f:36:b1:6f:76:3f:af:28:45:77 me@yulongjun.comThe key&apos;s randomart image is:+--[ RSA 2048]----+| . .. || o o. || + o.o |`略` 3. 把本机生成的公开密钥添加到github中12$ cat ~/.ssh/id_rsa.pubssh-rsa AAAAB3NzaC1...Rrjx6t33i5 me@yulongjun.com 打开github登陆后，点击自己头像下箭头，找到settings（设置），在左边栏目里面选择SSH keys,然后点击Add SSH key，随便填一个Title，把上面把cat出来的内容全部(是全部内容，包括前面的ssh-rsa和后面的邮箱）添加到key文本框里，然后点击add key。 添加成功后，创建github时用到的邮箱会收到GitHub发的一个&quot;A new public key was add to your account&quot;的邮件。 4. 使用私人密钥与GitHub进行认证和通信1234567$ ssh -T git@github.comThe authenticity of host &apos;github.com (192.30.252.130)&apos; can&apos;t be established.RSA key fingerprint is 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added &apos;github.com,192.30.252.130&apos; (RSA) to the list of known hosts.Enter passphrase for key &apos;/Users/yulongjun/.ssh/id_rsa&apos;: #输入3.1步骤中的密码，没有设置可以直接回车` 出现如下结果，表示成功： 1Hi yulongjun! You've successfully authenticated, but GitHub does not provide shell access. Git基本命令和操作1. git int（初始化仓库）1234$ mkdir Git-GitHub-Note$ cd Git-GitHub-note$ git initInitialized empty Git repository in /Users/yulongjun/Git-GitHub-Note/.git/ 2. git status（查看仓库状态）1234567$ git statusOn branch master #在master分支Initial commit #初始化提交nothing to commit(create/copy files and use "git add" to track) #没有文件提交（创建/复制文件 或者用git add 来添加文件） 创建一个README.md文件后，再查看状态： 123456789101112131415$ touch README.md$ git statusOn branch master #在master分支Initial commit #初始化提交Untracked files: #未追踪的文件： (use "git add &lt;file&gt;..." to include in what will be committed) #用 "git add &lt;file&gt;..."去添加用来提交的文件 README.md nothing added to commit but untracked files present (use "git add" to track)#没有文件添加到提交，但是有未跟踪的文件（用"git add"来追踪） 3. git add（向暂存区中添加文件）把4.2中的untracked files添加到暂存区 123456789101112$ git add README.md$ git statusOn branch master #在master分支Initial commit #初始化提交Changes to be committed: #提交改变： (use "git rm --cached &lt;file&gt;..." to unstage) # 用"git rm --cache &lt;file&gt;..."来去掉暂存文件 new file: README.md #新文件：README.md 4. git commit(提交仓库的历史记录）git commit 后跟的-m的意思是message，意味着添加一段描述性文字描述此次提交。 12345$ git commit -m "First commit"[master (root-commit) 7919beb] First commit 1 file changed, 0 insertions(+), 0 deletions(-) create mode 100644 README.md 提交完后看状态： 12345$ git statusOn branch master #在master分支nothing to commit, working directory clean#无东西提交，工作目录干净的。 5. git log（查看提交日志）1234567$ git logcommit 7919bebdb5a7635238719556dfc9e2a0d1Author: Yu Longjun &lt;tianshoulong@sina.com&gt;#作者Date: Thu Jul 30 15:35:25 2015 +0800 #日期 第一次提交 单独查看某个文件或某个目录的权限，比如只查看README.md的日志 1$ git log README.md 想查看提交前后的改动，可以用下面命令： 1$ git log -p 当然，单独某个文件或文件夹，也可以查看改动 1$ git log -p README.md 6. git diff（查看更改前后的不同）更改了文件后，未git add，也未git commit，此时用git diff命令可以查看不同之处。 12345678$ git diffdiff --git a/README.md b/README.mdindex e69de29..74ab05b 100644--- a/README.md+++ b/README.md@(Git&amp;GitHub)@ -0,0 +1 @@+Git 教程 更改了文件后，用git add添加到缓存区了，但是未git commit，此时用git diff HEAD命令可以查看不同之处。 12345678$ git diff HEADdiff --git a/README.md b/README.mdindex e69de29..74ab05b 100644--- a/README.md+++ b/README.md@@ -0,0 +1 @@+Git 教程 把图中红框的SSH clone URL复制一下，URL的格式为：git@github.com:用户名/仓库名。 在终端输入git clone+复制内容，就把此仓库clone下来了 例如： 123456789$ git clone git@github.com:yulongjun/A-Byte-of-Markdown.gitCloning into 'A-Byte-of-Markdown'...remote: Counting objects: 33, done.remote: Compressing objects: 100% (31/31), done.remote: Total 33 (delta 13), reused 0 (delta 0), pack-reused 0Receiving objects: 100% (33/33), 25.87 KiB | 6.00 KiB/s, done.Resolving deltas: 100% (13/13), done.Checking connectivity... done. git分支操作1. git branch（显示分支一览表或者创建一个新分支）1234567891011$ git branch* master#显示分支一览表，当前只有一个分支master$ git branch feature-A#创建分支feature-A$ git branch feature-A* master# 显示分支一览表，有两个分支，当前处于master分支 * 分支表示当前所处的分支。 2. git checkout （切换、创建分支）1234567891011121314151617181920212223$ git checkout feature-AM README.mdSwitched to branch 'feature-A'#切换到 ‘feature-A’分支$ git branch* feature-A master#显示当前分支一览表，切换到了‘feature-A’分支$ git checkout -b fix-BM README.mdSwitched to a new branch 'fix-B'#新建并切换到‘fix-B’$ git branch feature-A* fix-B master 让我们看看切换分支编辑的效果 1234567891011121314151617181920212223242526272829303132333435363738$ git checkout feature-AM README.mdSwitched to branch 'feature-A'#切换到分支`feature-A`$ git branch* feature-A fix-B master #查看当前分支一览表 $ vim README.md #在文档里添加一行`- feature-A`$ git add README.md #添加`README.md`到暂存区$ git commit -m "Add feature-A"[feature-A 944df3c] Add feature-A 1 file changed, 1 insertions(+)#提交更改$ git checkout masterSwitched to branch 'master'#切换到`master`分支$ cat README.mdGit教程只显示原来的哪一行$ git checkout -#切换至上一个分支，即分支`feature-A` 3. git merge（合并分支）12345678910$ git checkout master#切换到`master`主干分支$ git merge --no-ff feature-A# `master`分支合并`feature-A`分支,出现的填写信息框，`：wq`保存退出就合并完成，如果想写点合并的原因，可以自行编辑。#出现以下内容就表示合并完毕Merge made by the &apos;recursive&apos; strategy.#用递归策略合并 README.md | 1 + 1 file changed, 1 insertion(+) 4. git log –graph （以图标的形式查看分支）1234567891011121314151617181920212223242526$ git log --graph* commit 64d2d5e9f8f32e890b04ba3c684f803767e650e1|\ Merge: 6ba50f6 399cae8| | Author: Yu Longjun &lt;tianshoulong@sina.com&gt;| | Date: Thu Jul 30 21:56:05 2015 +0800| | | | Merge branch &apos;feature-A&apos;| | | * commit 399cae80e4f5a1ec3a24b697c5222d89763c08a8|/ Author: Yu Longjun &lt;tianshoulong@sina.com&gt;| Date: Thu Jul 30 21:44:57 2015 +0800| | Add feature-A| * commit 6ba50f6beddfa8cc5d0d2c6ead46c8dd293a8f20| Author: Yu Longjun &lt;tianshoulong@sina.com&gt;| Date: Thu Jul 30 21:41:17 2015 +0800| | Add index| * commit a357886ac799f3e7d2ccff329ab1b7ef2a9a9f70 Author: Yu Longjun &lt;tianshoulong@sina.com&gt; Date: Thu Jul 30 21:39:43 2015 +0800 First commit 更改提交的操作1. git reset（回溯历史版本）看上面最后一个git log --graph的图标，我们要把先回溯到feature-A分支创建前，然后创建一个fix-B分支。 回退到“Add index”时候的状态，用git reset --hard 哈希值 123$ git reset --hard 6ba50f6beddfa8cc5d0d2c6ead46c8dd293a8f20HEAD is now at 6ba50f6 Add index 创建fix-B分支创建特性分支fix-B。 12$ git checkout -b fix-BSwitched to a new branch &apos;fix-B&apos; 修改READ.md文件，添加一行- fix-B。 12Git教程- fix-B 提交READ.md文件 12345$ git add README.md $ git commit -m &quot;fix-B&quot;[fix-B 767957a] fix-B 1 file changed, 1 insertion(+) 推进至feature-A分支合并后的状态 git log 只能查看当前状态为终点的历史日志。要查看整个仓库的所有操作日志，要用git reflog，找到回溯历史之前的哈希值，通过git reset --hard来恢复到回溯之前的状态。 123456789101112131415$ git reflog767957a HEAD@&#123;0&#125;: commit: fix-B6ba50f6 HEAD@&#123;1&#125;: checkout: moving from master to fix-B6ba50f6 HEAD@&#123;2&#125;: reset: moving to 6ba50f6beddfa8cc5d0d2c6ead46c8dd293a8f2064d2d5e HEAD@&#123;3&#125;: merge feature-A: Merge made by the &apos;recursive&apos; strategy.6ba50f6 HEAD@&#123;4&#125;: checkout: moving from feature-A to master399cae8 HEAD@&#123;5&#125;: checkout: moving from master to feature-A6ba50f6 HEAD@&#123;6&#125;: checkout: moving from feature-A to master399cae8 HEAD@&#123;7&#125;: commit: Add feature-A6ba50f6 HEAD@&#123;8&#125;: checkout: moving from master to feature-A6ba50f6 HEAD@&#123;9&#125;: checkout: moving from feature-B to master6ba50f6 HEAD@&#123;10&#125;: checkout: moving from master to feature-B6ba50f6 HEAD@&#123;11&#125;: commit: Add indexa357886 HEAD@&#123;12&#125;: commit (initial): First commit 看到第四行64d2d5e HEAD@{3}: merge feature-A: Merge made by the &#39;recursive&#39; strategy.,是feature-A特性分支合并后的状态，对应的哈希值是64d2d5e，我们将HEAD、暂存区、工作树恢复到这个时间点的状态。 12345$ git checkout master$ git reset --hard 64d2d5eHEAD is now at 64d2d5e Merge branch &apos;feature-A&apos; 2. 消除冲突 合并fix-B分支,发现README.md出现冲突 12345$ git merge --no-ff fix-BAuto-merging README.mdCONFLICT (content): Merge conflict in README.mdAutomatic merge failed; fix conflicts and then commit the result. 查看冲突并解决 查看README.md,发现变成这个样子 Git教程&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD- feature-A\=======- fix-B>&gt;&gt;&gt;&gt;&gt;&gt; fix-B> 我们在编辑器将其编程想要的样子 Git教程- feature-A- fix-B 提交结果 12345$ git add README.md $ git commit -m &quot;Fix conflict&quot;[master 3df8965] Fix conflict 3. git commit –amend（修改提交信息）上次提交commit，信息记为”Fix conflict”，不妥，其实是fix-B分支的合并，解决冲突只是过程之一，标记不妥，修改一下 1git commit --amend 执行上述命令后，编辑器启动,出现以下内容 Fix conflict# Please enter the commit message for your changes. Lines starting# with ‘#’ will be ignored, and an empty message aborts the commit.## Date: Fri Jul 31 10:49:28 2015 +0800## On branch master# Changes to be committed:# modified: README.md 修改第一行为Merge branch &#39;fix-B&#39;,保存退出。终端出现以下内容表示修改该信息成功 12 [master 5759a34] Merge branch &apos;fix-B&apos;Date: Fri Jul 31 10:49:28 2015 +0800 4. 远程仓库操作 添加远程仓库 首先在GitHub上创建一个空仓库： 复制GitHub上的仓库路径git@github.com:yulongjun/Git-GitHub-Note.git 运行命令： 1$ git remote add origin git@github.com:yulongjun/Git-GitHub-Note.git 添加远程仓库并把远程仓库设置成origin标识符。 把master推送至远程仓库 1$ git push -u origin master 推送master以外的分支。 12$ git checkout -b feature-D #新建一个feature-D分支$ git push -u origin feature-D #推送feature-D到origin远程仓库]]></content>
      <categories>
        <category>cloud</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>GitHub</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[05-双网络双活模式的Keepalived+Nginx配置]]></title>
    <url>%2Flb%2F20170904-05-keepalived-nginx%2F</url>
    <content type="text"><![CDATA[Vagrant配置实验环境Vagrantfile： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546# -*- mode: ruby -*-# vi: set ft=ruby :Vagrant.configure("2") do |config| # Vagrant Global Config # `longdream/centos7` is a custom centos7 box made by YuLongjun. config.vm.box = "longdream/centos7" # If this box is add online, set true will check update. # Also set `false` will not update it. # If this box is added locally, this setting is invalid. config.vm.box_check_update = false # you need `vagrant plugin install vagrant-vbguest` # You also need `vagrant plugin install vagrant-hostmanager` config.hostmanager.enabled = true # Allow update `/etc/hosts` file in VMs. config.hostmanager.manage_guest = true # Allow update `/etc/hosts` file in Hosts. config.hostmanager.manage_host = true # Create VM ka1. config.vm.define "ka1" do |ka1| ka1.vm.network "public_network", ip: "172.16.111.10", bridge: "en0: Wi-Fi (AirPort)" ka1.vm.network "private_network", ip: "192.168.111.10" ka1.vm.hostname = "ka1" end # Create VM ka2. config.vm.define "ka2" do |ka2| ka2.vm.network "public_network", ip: "172.16.111.20", bridge: "en0: Wi-Fi (AirPort)" ka2.vm.network "private_network", ip: "192.168.111.20" ka2.vm.hostname = "ka2" end # Create VM web1. config.vm.define "web1" do |web1| web1.vm.network "private_network", ip: "192.168.111.30" web1.vm.hostname = "web1" end # Create VM web2 config.vm.define "web2" do |web2| web2.vm.network "private_network", ip: "192.168.111.40" web2.vm.hostname = "web2" endend vagrant up启动4台虚拟机。 配置Keepalived初始设置（1）时间同步，略（2）关闭SELinux和防火墙，略（3）互相之间/etc/hosts文件添加对方主机名，略（4）确认接口支持多播（组播），略，基本新的网卡都支持。 打开ka1和ka2的ip_forward12echo "net.ipv4.ip_forward=1" &gt;&gt;/etc/sysctl.confecho 1 &gt; /proc/sys/net/ipv4/ip_forward 配置ka1123yum install -y keepalivedsystemctl enable keepalivedcp /etc/keepalived/keepalived.conf&#123;,.bak&#125; vim /etc/keepalived/keepalived.conf： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283global_defs &#123; notification_email &#123; root@localhost &#125; notification_email_from ka1@localhost smtp_server 127.0.0.1 smtp_connect_timeout 30 vrrp_mcast_group4 224.111.111.111&#125;vrrp_instance External_1 &#123; state MASTER interface eth1 virtual_router_id 171 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 1402b1b5 &#125; virtual_ipaddress &#123; 172.16.111.100 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault" &#125;vrrp_instance External_2 &#123; state BACKUP interface eth1 virtual_router_id 172 priority 95 advert_int 1 authentication &#123; auth_type PASS auth_pass 9d3d15d5 &#125; virtual_ipaddress &#123; 172.16.111.200 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault" &#125;vrrp_instance Internal_1 &#123; state MASTER interface eth2 virtual_router_id 191 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 0702f7ab &#125; virtual_ipaddress &#123; 192.168.111.100 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault" &#125;vrrp_instance Internal_2 &#123; state BACKUP interface eth2 virtual_router_id 192 priority 95 advert_int 1 authentication &#123; auth_type PASS auth_pass 85c9a27b &#125; virtual_ipaddress &#123; 192.168.111.200 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault" &#125; 配置ka2123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081global_defs &#123; notification_email &#123; root@localhost &#125; notification_email_from ka2@localhost smtp_server 127.0.0.1 smtp_connect_timeout 30 vrrp_mcast_group4 224.111.111.111&#125;vrrp_instance External_1 &#123; state BACKUP interface eth1 virtual_router_id 171 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 1402b1b5 &#125; virtual_ipaddress &#123; 172.16.111.100 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault" &#125; vrrp_instance External_2 &#123; state MASTER interface eth1 virtual_router_id 172 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 9d3d15d5 &#125; virtual_ipaddress &#123; 172.16.111.200 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault" &#125; vrrp_instance Internal_1 &#123; state BACKUP interface eth2 virtual_router_id 191 priority 95 advert_int 1 authentication &#123; auth_type PASS auth_pass 0702f7ab &#125; virtual_ipaddress &#123; 192.168.111.100 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault" &#125;vrrp_instance Internal_2 &#123; state MASTER interface eth2 virtual_router_id 192 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 85c9a27b &#125; virtual_ipaddress &#123; 192.168.111.200 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault" &#125; ka1和ka2分别放一个同样的脚本：/etc/keepalived/notify.sh，实现切换通知功能。 vim /etc/keepalived/notify.sh： 1234567891011121314151617181920212223242526#!/bin/bash#contact='root@localhost' notify() &#123; local mailsubject="$(hostname) to be $1, vip floating" local mailbody="$(date +'%F %T'): vrrp transition, $(hostname) changed to be $1" echo "$mailbody" | mail -s "$mailsubject" $contact&#125; case $1 inmaster) notify master ;;backup) notify backup systemctl start nginx # 此处配置后，Nginx服务挂了能自动启动 ;;fault) notify fault ;;*) echo "Usage: $(basename $0) &#123;master|backup|fault&#125;" exit 1 ;;esac 测试keepalived功能ka1： 123systemctl start keepalived.servicesystemctl status keepalived.serviceip a 在ka2没启动前，ka1添加了4个ip192.168.111.100、192.168.111.200、172.16.111.100、172.16.111.200 ka2： 123systemctl start keepalived.servicesystemctl status keepalived.serviceip a ka2一启动，ka1就移除了192.168.111.200、172.16.111.200，ka2就添加了192.168.111.200、172.16.111.200 我们停掉ka1： ka1移除了了192.168.111.100和172.16.111.100 ka2添加了192.168.111.100和172.16.111.100 ,然后拥有了4个vip。 我们还可以通过tcpdump命令来分别查看组播状态。 ka1和ka2都可运行下面命令来查看组播地址检查心跳的状态。 12tcpdump -nn -i eth1 host 224.111.111.111tcpdump -nn -i eth2 host 224.111.111.111 tips：在虚拟机软件里，关闭网卡物理连接，ip也是可以漂移的。 至此，vrrp的的高可用测试完毕。我们继续配置Nginx服务。 安装后端Web服务器web1和web2分别安装httpd或者nginx作为http服务，这里安装的httpd： web1： 1234yum install -y httpdecho "&lt;h1&gt;Real Server 1&lt;/h1&gt;" &gt; /var/www/html/index.htmlsystemctl start httpdsystemctl enable httpd web2： 1234yum install -y httpdecho "&lt;h1&gt;Real Server 2&lt;/h1&gt;" &gt; /var/www/html/index.htmlsystemctl start httpdsystemctl enable httpd 实验环境为了显示不同，故意设置成不同的页面，实际生产中获取的内容应该一致。 测试httpd功能： ka1或ka2上： 12curl 192.168.111.30curl 192.168.111.40 配置Nginx在ka1和ka2上分别yum安装Nginx最新稳定版： 1234567891011121314151617181920212223242526cat &gt; /etc/yum.repos.d/nginx.repo &lt;&lt;EOF[nginx]name=nginx repobaseurl=http://nginx.org/packages/centos/\$releasever/\$basearch/gpgcheck=0enabled=1EOFyum install -y nginx mv /etc/nginx/conf.d/default.conf&#123;,.bak&#125; cat &gt;/etc/nginx/conf.d/vhost1.conf &lt;&lt;EOFupstream websrvs &#123; server 192.168.111.30:80; server 192.168.111.40:80;&#125;server &#123; location / &#123; proxy_pass http://websrvs; &#125;&#125;EOFsystemctl start nginx 分别在ka1和ka2上测试： 1for i in `seq 10`; do curl 192.168.111.10; done 至此，Nginx功能也实现了。我们接下来把Nginx和Keepalived结合起来，使Nginx支持高可用。 配置Keepalived使Nginx实现高可用在ka1和ka2的/etc/keepalived/keepalived.conf的全局配置块global_defs下方配置vrrp_script块： 1234567vrrp_script chk_nginx &#123; script &quot;killall -0 nginx&quot; interval 2 weight -10 fall 2 rise 2&#125; 在所有vrrp_instance实例块里，添加track_script块： 123track_script &#123; chk_nginx&#125; 配置完后，重启ka1和ka2的keepalived服务。 12systemctl stop keepalivedsystemctl start keepalived 一开始……实验并未成功 警告：此处测试没有成功，o(╯□╰)o，Keepalived正常，但是停掉Nginx后，不会降权，查了好久配置……，最后准备自己写个脚本shell自检测Nginx的时候，写完脚本运行时候发现，没装killall命令！所以不会降权！……坑啊！ 安装psmisc包，包含killall命令。 1yum install psmisc 安装完killall后，测试完美开一个循环，查看效果：1while True;do curl 172.16.111.100; curl 172.16.111.200;sleep 0.5; done 关闭任意一个Keepalived服务，不受影响。 在Keepalived服务启动的时候，停掉Nginx服务，过一会儿，会自行恢复，如下： 完整配置文件附录附上所有完整配置文件的下载链接：(用的七牛云存储，点击即可下载，或者右键“链接另存为”下载） 实验环境的Vagrant配置文件Vagrantfile：Vagrantfile ka1的Keepalived配置文件/etc/keepalived/keepalived.conf：keepalived.conf(ka1) ka2的Keepalived配置文件/etc/keepalived/keepalived.conf： keepalived.conf(ka2) ka1和ka2的Keepalived调用的通知脚本/etc/keepalived/notify.sh：notify.sh ka1和ka2的Nginx配置文件/etc/nginx/conf.d/vhost1.conf：vhost1.conf]]></content>
      <categories>
        <category>lb</category>
      </categories>
      <tags>
        <tag>VRRP</tag>
        <tag>Keepalived+Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[04-单网络双活模式的Keepalived+LVS-DR配置]]></title>
    <url>%2Flb%2F20170904-04-keepalived-lvs%2F</url>
    <content type="text"><![CDATA[Vagrant配置实验环境Vagrantfile： 1234567891011121314151617181920212223242526272829303132333435363738394041424344# -*- mode: ruby -*-# vi: set ft=ruby :Vagrant.configure("2") do |config| # Vagrant Global Config # `longdream/centos7` is a custom centos7 box made by YuLongjun. config.vm.box = "longdream/centos7" # If this box is add online, set true will check update. # Also set `false` will not update it. # If this box is added locally, this setting is invalid. config.vm.box_check_update = false # you need `vagrant plugin install vagrant-vbguest` # You also need `vagrant plugin install vagrant-hostmanager` config.hostmanager.enabled = true # Allow update `/etc/hosts` file in VMs. config.hostmanager.manage_guest = true # Allow update `/etc/hosts` file in Hosts. config.hostmanager.manage_host = true # Create VM ka1. config.vm.define "ka1" do |ka1| ka1.vm.network "private_network", ip: "192.168.111.10" ka1.vm.hostname = "ka1" end # Create VM ka2. config.vm.define "ka2" do |ka2| ka2.vm.network "private_network", ip: "192.168.111.20" ka2.vm.hostname = "ka2" end # Create VM web1. config.vm.define "web1" do |web1| web1.vm.network "private_network", ip: "192.168.111.30" web1.vm.hostname = "web1" end # Create VM web2 config.vm.define "web2" do |web2| web2.vm.network "private_network", ip: "192.168.111.40" web2.vm.hostname = "web2" endend vagrant up启动4台虚拟机。 配置Keepalived初始设置（1）时间同步，略（2）关闭SELinux和防火墙，略（3）互相之间/etc/hosts文件添加对方主机名，略（4）确认接口支持多播（组播），略，基本新的网卡都支持。 配置ka1的keepalived服务12yum install -y keepalivedsystemctl enable keepalived vim /etc/keepalived/keepalived.conf 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647global_defs &#123; notification_email &#123; root@localhost &#125; notification_email_from ka1@localhost smtp_server 127.0.0.1 smtp_connect_timeout 60 vrrp_mcast_group4 224.111.111.111&#125;vrrp_instance VI_1 &#123; state MASTER interface eth1 virtual_router_id 191 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 0702f7ab &#125; virtual_ipaddress &#123; 192.168.111.100 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault" &#125;vrrp_instance VI_2 &#123; state BACKUP interface eth1 virtual_router_id 192 priority 95 advert_int 1 authentication &#123; auth_type PASS auth_pass 85c9a27b &#125; virtual_ipaddress &#123; 192.168.111.200 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault" &#125; 配置ka212yum install -y keepalivedsystemctl enable keepalived vim /etc/keepalived/keepalived.conf 123456789101112131415161718192021222324252627282930313233343536373839404142434445global_defs &#123; notification_email &#123; root@localhost &#125; notification_email_from ka2@localhost smtp_server 127.0.0.1 smtp_connect_timeout 60 vrrp_mcast_group4 224.111.111.111&#125;vrrp_instance VI_1 &#123; state BACKUP interface eth1 virtual_router_id 191 priority 95 advert_int 1 authentication &#123; auth_type PASS auth_pass 0702f7ab &#125; virtual_ipaddress &#123; 192.168.111.100 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault" &#125;vrrp_instance VI_2 &#123; state MASTER interface eth1 virtual_router_id 192 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 85c9a27b &#125; virtual_ipaddress &#123; 192.168.111.200 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault" &#125; ka1和ka2分别放一个同样的脚本：/etc/keepalived/notify.sh，实现切换通知功能。 vim /etc/keepalived/notify.sh 12345678910111213141516171819202122232425#!/bin/bash#contact='root@localhost' notify() &#123; local mailsubject="$(hostname) to be $1, vip floating" local mailbody="$(date +'%F %T'): vrrp transition, $(hostname) changed to be $1" echo "$mailbody" | mail -s "$mailsubject" $contact&#125; case $1 inmaster) notify master ;;backup) notify backup ;;fault) notify fault ;;*) echo "Usage: $(basename $0) &#123;master|backup|fault&#125;" exit 1 ;;esac 测试keepalived功能ka1： 123systemctl start keepalived.servicesystemctl status keepalived.serviceip a 在ka2没启动前，ka1先添加了ip192.168.111.100，监测不到192.168.111.200，又添加了192.168.111.200。 ka2： 123systemctl start keepalived.servicesystemctl status keepalived.serviceip a ka2一启动，ka1就移除了192.168.111.200，ka2就添加了192.168.111.200 我们停掉ka1的keepalived服务： ka1就移除了了192.168.111.100ka2就添加了192.168.111.100 我们还可以通过tcpdump命令来分别查看组播状态。 ka1和ka2都可运行下面命令来查看组播地址检查心跳的状态: 1tcpdump -nn -i eth1 host 224.111.111.111 tips：在虚拟机软件里，关闭网卡物理连接，ip也是可以漂移的。 至此，vrrp的的高可用测试完毕。我们继续配置LVS相关的配置。 配置LVS相关的配置。配置VS(Virtual Server,也叫Director)我们分别在ka1(ka1也是vs1)和ka2(ka2也是vs2)上安装lvs，然后停止keepalived服务，添加VS配置： 1systemctl stop keepalived 分别修改/etc/keepalived/keepalived.conf,在后面添加Virtual Server相关的配置： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465virtual_server 192.168.111.100 80 &#123; delay_loop 3 lb_algo rr lb_kind DR protocol TCP sorry_server 127.0.0.1 80 real_server 192.168.111.30 80 &#123; weight 1 HTTP_GET &#123; url &#123; path / status_code 200 &#125; connect_timeout 1 nb_get_retry 3 delay_before_retry 1 &#125; &#125; real_server 192.168.111.40 80 &#123; weight 1 HTTP_GET &#123; url &#123; path / status_code 200 &#125; connect_timeout 1 nb_get_retry 3 delay_before_retry 1 &#125; &#125;&#125;virtual_server 192.168.111.200 80 &#123; delay_loop 3 lb_algo rr lb_kind DR protocol TCP sorry_server 127.0.0.1 80 real_server 192.168.111.30 80 &#123; weight 1 HTTP_GET &#123; url &#123; path / status_code 200 &#125; connect_timeout 1 nb_get_retry 3 delay_before_retry 1 &#125; &#125; real_server 192.168.111.40 80 &#123; weight 1 HTTP_GET &#123; url &#123; path / status_code 200 &#125; connect_timeout 1 nb_get_retry 3 delay_before_retry 1 &#125; &#125;&#125; 上述keepalived设置中的设置了sorry_server为本地的http服务，即要在ka1和ka2上做一个Sorry Server，所以分别提供一个web服务（可采用httpd或者apache都行，这里采用的是httpd）对外say sorry： ka1： 123456yum install -y httpdecho "&lt;h1&gt;Sorry Server@ka1&lt;/h1&gt;" &gt; /var/www/html/index.htmlsystemctl start httpdsystemctl enable httpdsystemctl start keepalivedsystemctl enable keepalived ka2： 123456yum install -y httpdecho "&lt;h1&gt;Sorry Server@ka2&lt;/h1&gt;" &gt; /var/www/html/index.htmlsystemctl start httpdsystemctl enable httpdsystemctl start keepalivedsystemctl enable keepalived 实验环境为了显示不同，故意设置成不同的页面，实际生产获取的内容应该保持一致。 配置RS(Real Server)web1和web2web1和web2分别安装httpd或者nginx作为http服务，这里安装的httpd： web1： 1234yum install -y httpdecho "&lt;h1&gt;Real Server 1&lt;/h1&gt;" &gt; /var/www/html/index.htmlsystemctl start httpdsystemctl enable httpd web2： 1234yum install -y httpdecho "&lt;h1&gt;Real Server 2&lt;/h1&gt;" &gt; /var/www/html/index.htmlsystemctl start httpdsystemctl enable httpd 实验环境为了显示不同，故意设置成不同的页面，实际生产中获取的内容应该一致。 web1 和web2 上添加脚本set_rs.sh： vim ~/set_rs.sh 1234567891011121314151617181920212223242526272829#!/bin/bashvip1=192.168.111.100vip2=192.168.111.200dev1=lo:1dev2=lo:2case $1 instart) echo 1 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo 1 &gt; /proc/sys/net/ipv4/conf/lo/arp_ignore echo 2 &gt; /proc/sys/net/ipv4/conf/all/arp_announce echo 2 &gt; /proc/sys/net/ipv4/conf/lo/arp_announce ifconfig $dev1 $vip1 netmask 255.255.255.255 broadcast $vip1 up ifconfig $dev2 $vip2 netmask 255.255.255.255 broadcast $vip2 up echo "VS Server is Ready!" ;;stop) ifconfig $dev down echo 0 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo 0 &gt; /proc/sys/net/ipv4/conf/lo/arp_ignore echo 0 &gt; /proc/sys/net/ipv4/conf/all/arp_announce echo 0 &gt; /proc/sys/net/ipv4/conf/lo/arp_announce echo "VS Server is Cancel!" ;;*) echo "Usage `basename $0` start|stop" exit 1 ;;esac 分别运行bash set_rs.sh start。 总体测试测试代码： 1234for i in `seq 5`; do curl 192.168.111.100 curl 192.168.111.200done 全部开启的情况下测试： 关闭web2的httpd服务： 关闭ka2的keepalived服务： 关闭 web1的httpd服务： 完整配置文件附录附上所有完整配置文件的下载链接：(用的七牛云存储，点击即可下载，或者右键“链接另存为”下载） 实验环境的Vagrant配置文件Vagrantfile：Vagrantfile ka1的Keepalived配置文件/etc/keepalived/keepalived.conf：keepalived.conf(ka1) ka2的Keepalived配置文件/etc/keepalived/keepalived.conf： keepalived.conf(ka2) ka1和ka2的Keepalived调用的通知脚本/etc/keepalived/notify.sh：notify.sh]]></content>
      <categories>
        <category>lb</category>
      </categories>
      <tags>
        <tag>VRRP</tag>
        <tag>Keepalived+LVS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[03-Keepalived各种模式配置]]></title>
    <url>%2Flb%2F20170904-03-keepalived-models%2F</url>
    <content type="text"><![CDATA[由于图片花费很长时间制作，本文图片转载或使用请务必加上原文链接，图片中的作者信息也请勿删除，谢谢！ 下面仅仅是Keepalived配置里只关于Keepalived部分的相关的配置。从最简单的单网络单主模式，一直到双网络同步漂移的双主模式。 单网络的Master-Backup主备模式（单主模式） ka1 的/etc/keepalived/keepalived.conf配置： 1234567891011121314151617181920212223242526272829global_defs &#123; notification_email &#123; root@localhost &#125; notification_email_from ka1@localhost smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id ka1 vrrp_mcast_group4 224.111.111.111&#125;vrrp_instance VG_1 &#123; state MASTER interface eth2 virtual_router_id 191 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 0702f7ab &#125; virtual_ipaddress &#123; 192.168.111.100 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault" &#125; ka2 的/etc/keepalived/keepalived.conf配置： 1234567891011121314151617181920212223242526272829global_defs &#123; notification_email &#123; root@localhost &#125; notification_email_from ka1@localhost smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id ka1 vrrp_mcast_group4 224.111.111.111&#125;vrrp_instance VG_1 &#123; state BACKUP interface eth2 virtual_router_id 191 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 0702f7ab &#125; virtual_ipaddress &#123; 192.168.111.100 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault" &#125; 单网络的Active-Active双活模式（双主模式） ka1 的/etc/keepalived/keepalived.conf配置： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748global_defs &#123; notification_email &#123; root@localhost &#125; notification_email_from ka1@localhost smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id ka1 vrrp_mcast_group4 224.111.111.111&#125;vrrp_instance VG_1 &#123; state MASTER interface eth2 virtual_router_id 191 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 0702f7ab &#125; virtual_ipaddress &#123; 192.168.111.100 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault" &#125;vrrp_instance VG_2 &#123; state BACKUP interface eth2 virtual_router_id 192 priority 95 advert_int 1 authentication &#123; auth_type PASS auth_pass 85c9a27b &#125; virtual_ipaddress &#123; 192.168.111.200 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault" &#125; ka2 的/etc/keepalived/keepalived.conf配置： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748global_defs &#123; notification_email &#123; root@localhost &#125; notification_email_from ka1@localhost smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id ka1 vrrp_mcast_group4 224.111.111.111&#125;vrrp_instance VG_1 &#123; state BACKUP interface eth2 virtual_router_id 191 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 0702f7ab &#125; virtual_ipaddress &#123; 192.168.111.100 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault" &#125;vrrp_instance VG_2 &#123; state MASTER interface eth2 virtual_router_id 192 priority 95 advert_int 1 authentication &#123; auth_type PASS auth_pass 85c9a27b &#125; virtual_ipaddress &#123; 192.168.111.200 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault"&#125; 双网络（内外网）非同步漂移的Master-Backup主备模式（单主模式）一般生产环境内外网是分开的，所以一般有两个网络，一个内网网络，一个外网网络，内网网络和外网网络不用同步漂移，比如Keepalived+LVS-DR、Keepalived+Nginx、Keepalived+HAProxy，都是不用同步漂移的。（Keepalived+LVS-NAT是需要同步漂移的。） ka1 的/etc/keepalived/keepalived.conf配置： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354global_defs &#123; notification_email &#123; root@localhost &#125; notification_email_from ka1@localhost smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id ka1 vrrp_mcast_group4 224.111.111.111&#125;vrrp_sync_group VG_1 &#123; group &#123; External_1 Internal_1 &#125;&#125;vrrp_instance External_1 &#123; state MASTER interface eth1 virtual_router_id 171 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 1402b1b5 &#125; virtual_ipaddress &#123; 172.16.111.100 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault"&#125;vrrp_instance Internal_1 &#123; state MASTER interface eth2 virtual_router_id 191 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 0702f7ab &#125; virtual_ipaddress &#123; 192.168.111.100 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault"&#125; ka2 的/etc/keepalived/keepalived.conf配置： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647global_defs &#123; notification_email &#123; root@localhost &#125; notification_email_from ka1@localhost smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id ka1 vrrp_mcast_group4 224.111.111.111&#125;vrrp_instance External_1 &#123; state BACKUP interface eth1 virtual_router_id 171 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 1402b1b5 &#125; virtual_ipaddress &#123; 172.16.111.100 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault"&#125;vrrp_instance Internal_1 &#123; state BACKUP interface eth2 virtual_router_id 191 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 0702f7ab &#125; virtual_ipaddress &#123; 192.168.111.100 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault"&#125; 双网络（内外网）同步漂移的Master-Backup主备模式（单主模式）一般生产环境内外网是分开的，所以一般有两个网络，一个内网网络，一个外网网络，而且内网网络和外网网络要实现同步漂移，比如Keepalived+LVS-NAT模式，那么就用到vrrp_sync_group来设置同步漂移组 ka1 的/etc/keepalived/keepalived.conf配置： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354global_defs &#123; notification_email &#123; root@localhost &#125; notification_email_from ka1@localhost smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id ka1 vrrp_mcast_group4 224.111.111.111&#125;vrrp_sync_group VG_1 &#123; group &#123; External_1 Internal_1 &#125;&#125;vrrp_instance External_1 &#123; state MASTER interface eth1 virtual_router_id 171 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 1402b1b5 &#125; virtual_ipaddress &#123; 172.16.111.100 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault"&#125;vrrp_instance Internal_1 &#123; state MASTER interface eth2 virtual_router_id 191 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 0702f7ab &#125; virtual_ipaddress &#123; 192.168.111.100 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault"&#125; ka2 的/etc/keepalived/keepalived.conf配置： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354global_defs &#123; notification_email &#123; root@localhost &#125; notification_email_from ka1@localhost smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id ka1 vrrp_mcast_group4 224.111.111.111&#125;vrrp_sync_group VG_1 &#123; group &#123; External_1 Internal_1 &#125;&#125;vrrp_instance External_1 &#123; state BACKUP interface eth1 virtual_router_id 171 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 1402b1b5 &#125; virtual_ipaddress &#123; 172.16.111.100 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault"&#125;vrrp_instance Internal_1 &#123; state BACKUP interface eth2 virtual_router_id 191 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 0702f7ab &#125; virtual_ipaddress &#123; 192.168.111.100 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault"&#125; 双网络（内外网）非同步漂移的Active-Active双活模式（双主模式）一般生产环境内外网是分开的，所以一般有两个网络，一个内网网络，一个外网网络，内网网络和外网网络不用同步漂移，比如Keepalived+LVS-DR、Keepalived+Nginx、Keepalived+HAProxy，都是不用同步漂移的。（Keepalived+LVS-NAT是需要同步漂移的。） ka1 的/etc/keepalived/keepalived.conf配置： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384global_defs &#123; notification_email &#123; root@localhost &#125; notification_email_from ka1@localhost smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id ka1 vrrp_mcast_group4 224.111.111.111&#125;vrrp_instance External_1 &#123; state MASTER interface eth1 virtual_router_id 171 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 1402b1b5 &#125; virtual_ipaddress &#123; 172.16.111.100 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault"&#125;vrrp_instance External_2 &#123; state BACKUP interface eth1 virtual_router_id 172 priority 95 advert_int 1 authentication &#123; auth_type PASS auth_pass 9d3d15d5 &#125; virtual_ipaddress &#123; 172.16.111.200 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault"&#125;vrrp_instance Internal_1 &#123; state MASTER interface eth2 virtual_router_id 191 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 0702f7ab &#125; virtual_ipaddress &#123; 192.168.111.100 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault"&#125;vrrp_instance Internal_2 &#123; state BACKUP interface eth2 virtual_router_id 192 priority 95 advert_int 1 authentication &#123; auth_type PASS auth_pass 85c9a27b &#125; virtual_ipaddress &#123; 192.168.111.200 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault"&#125; ka2 的/etc/keepalived/keepalived.conf配置： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283global_defs &#123; notification_email &#123; root@localhost &#125; notification_email_from ka1@localhost smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id ka1 vrrp_mcast_group4 224.111.111.111&#125;vrrp_instance External_1 &#123; state BACKUP interface eth1 virtual_router_id 171 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 1402b1b5 &#125; virtual_ipaddress &#123; 172.16.111.100 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault"&#125;vrrp_instance External_2 &#123; state MASTER interface eth1 virtual_router_id 172 priority 95 advert_int 1 authentication &#123; auth_type PASS auth_pass 9d3d15d5 &#125; virtual_ipaddress &#123; 172.16.111.200 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault"&#125;vrrp_instance Internal_1 &#123; state BACKUP interface eth2 virtual_router_id 191 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 0702f7ab &#125; virtual_ipaddress &#123; 192.168.111.100 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault"&#125;vrrp_instance Internal_2 &#123; state MASTER interface eth2 virtual_router_id 192 priority 95 advert_int 1 authentication &#123; auth_type PASS auth_pass 85c9a27b &#125; virtual_ipaddress &#123; 192.168.111.200 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault"&#125; 双网络（内外网）同步漂移的Active-Active双活模式（双主模式）一般生产环境内外网是分开的，所以一般有两个网络，一个内网网络，一个外网网络，而且内网网络和外网网络要实现同步漂移，比如Keepalived+LVS-NAT模式，那么就用到vrrp_sync_group来设置同步漂移组，如果要做双活，那么就分别两端加两个vip，互为主备。 ka1 的/etc/keepalived/keepalived.conf配置： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798global_defs &#123; notification_email &#123; root@localhost &#125; notification_email_from ka1@localhost smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id ka1 vrrp_mcast_group4 224.111.111.111&#125;vrrp_sync_group VG_1 &#123; group &#123; External_1 Internal_1 &#125;&#125;vrrp_sync_group VG_2 &#123; group &#123; External_2 Internal_2 &#125;&#125;vrrp_instance External_1 &#123; state MASTER interface eth1 virtual_router_id 171 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 1402b1b5 &#125; virtual_ipaddress &#123; 172.16.111.100 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault"&#125;vrrp_instance External_2 &#123; state BACKUP interface eth1 virtual_router_id 172 priority 95 advert_int 1 authentication &#123; auth_type PASS auth_pass 9d3d15d5 &#125; virtual_ipaddress &#123; 172.16.111.200 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault"&#125;vrrp_instance Internal_1 &#123; state MASTER interface eth2 virtual_router_id 191 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 0702f7ab &#125; virtual_ipaddress &#123; 192.168.111.100 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault"&#125;vrrp_instance Internal_2 &#123; state BACKUP interface eth2 virtual_router_id 192 priority 95 advert_int 1 authentication &#123; auth_type PASS auth_pass 85c9a27b &#125; virtual_ipaddress &#123; 192.168.111.200 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault"&#125; ka2 的/etc/keepalived/keepalived.conf配置： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697global_defs &#123; notification_email &#123; root@localhost &#125; notification_email_from ka1@localhost smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id ka1 vrrp_mcast_group4 224.111.111.111&#125;vrrp_sync_group VG_1 &#123; group &#123; External_1 Internal_1 &#125;&#125;vrrp_sync_group VG_2 &#123; group &#123; External_2 Internal_2 &#125;&#125;vrrp_instance External_1 &#123; state BACKUP interface eth1 virtual_router_id 171 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 1402b1b5 &#125; virtual_ipaddress &#123; 172.16.111.100 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault"&#125;vrrp_instance External_2 &#123; state MASTER interface eth1 virtual_router_id 172 priority 95 advert_int 1 authentication &#123; auth_type PASS auth_pass 9d3d15d5 &#125; virtual_ipaddress &#123; 172.16.111.200 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault"&#125;vrrp_instance Internal_1 &#123; state BACKUP interface eth2 virtual_router_id 191 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 0702f7ab &#125; virtual_ipaddress &#123; 192.168.111.100 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault"&#125;vrrp_instance Internal_2 &#123; state MASTER interface eth2 virtual_router_id 192 priority 95 advert_int 1 authentication &#123; auth_type PASS auth_pass 85c9a27b &#125; virtual_ipaddress &#123; 192.168.111.200 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault"&#125; notfiy.sh脚本内容见上一节。]]></content>
      <categories>
        <category>lb</category>
      </categories>
      <tags>
        <tag>Keepalived</tag>
        <tag>VRRP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[02-Keepalived配置]]></title>
    <url>%2Flb%2F20170904-02-keepalived-configuration%2F</url>
    <content type="text"><![CDATA[Keepalived HA cluster的配置前提(1) 各节点时间必须同步：可以使用ntp(CentOS6&amp;7)或者chrony(CentOS 7)。(2) 确保iptables及selinux不会成为阻碍。(3) 各节点之间可通过主机名互相通信（对KA并非必须）：建议使用/etc/hosts文件实现(DNS服务如果有问题，还不如hosts文件好用）(4) 确保各节点的用于集群服务的接口支持MULTICAST通信：多播或叫组播，使用D类地址(224-239)。（多播地址最好不要使用默认的，手动修改一下。因为如果好多个集群服务都是用默认的，虽然有认证机制，但是也会互相发送信息，虽然因为认证机制丢弃掉了，但也影响性能，也会产生无用的日志。） （1）所有服务器都要做时间服务器同步。 第一种方法： ntp 1ntpdate TIME_SERVER_IP TIME_SERVER_IP换成时间服务器IP。 第二种方法：chrony vim /etc/chrony.conf 12345#server 0.centos.pool.ntp.org iburst#server 1.centos.pool.ntp.org iburst#server 2.centos.pool.ntp.org iburst#server 3.centos.pool.ntp.org iburstserver TIME_SERVER_IP iburst TIME_SERVER_IP换成时间服务器IP。 systemctl restart chronyd.service chrony sources可以查看同步时间情况。TIME_SERVER_IP换成时间服务器IP。 （2）iptables、SELinux、/etc/hosts自行设定。 （3）Keepalived集群的组播地址不采用系统默认的。 组播地址定为224.111.111.111。 Keepalived配置详解Keepalived的配置文件：/etc/keepalived/keepalived.conf man keepalived.conf可以查看配置详情解析。 配置分为三大项配置块： Global configuration，全局配置，包含两个子配置块： 全局定义：global_defs。 静态地址和路由：static_ipaddress、static_routes VRRP configuration，VRRP配置，包含两个子配置块： VRRP同步组：vrrp_sync_group。 VRRP实例：vrrp_instance。 LVS configuration，LVS配置。如果要用Keepalived+LVS的话，需要使用这段配置，如果是用其他的如Keepalived+Nginx的话，是不需要配置的。LVS的话，包含两个子配置块： 虚拟服务器组： virtual_server_group。可选项,大型LVS集群才会用。 虚拟服务器：virtual_server。每个虚拟服务器里面又包含多个真实服务器real_server。 Global Configuration12345678910global_defs &#123; notification_email &#123; root@localhost &#125; notification_email_from ka1@localhost smtp_server 127.0.0.1 smtp_connect_timeout 30 # 前面这几段随意配置，一般不会用邮件通知，一般会有监控软件来监控 router_id ka1 vrrp_mcast_group4 224.111.111.111 # 多播地址段，最好自定义，不要用系统默认的&#125; VRRP ConfigurationVRRP同步组配置块：vrrp_sync_group定义一个vrrp同步组，当同步组内的instance挂了一个，组内的所有instance都Failover（故障转移）到另外一个节点。 123456vrrp_sync_group GROUP_NAME &#123; group &#123; INSTANCE_NAME INSTANCE_NAME &#125;&#125; 常见的一个案例是，在有连接外网的地址和内网的地址都有，并且两个VIP做了ip_forward，需要两个VIP同时漂移。如下面例子，External_1为外网的VRRP实例，Internal_2为内网的VRRP实例。 123456vrrp_sync_group VG_1 &#123; group &#123; External_1 Internal_2 &#125;&#125; VRRP实例配置块：vrrp_instance定义vrrp实例。 12345678910111213141516171819202122232425262728293031323334353637383940vrrp_instance INSTANCE_NAME &#123; state MASTER|BACKUP # 当前节点在此虚拟路由器上的初始状态；只能有一个是MASTER，余下的都应该为BACKUP； interface IFACE_NAME # 绑定为当前虚拟路由器使用的物理接口；IFACE_NAME是网卡名，如`eth0` virtual_router_id VRID # 当前虚拟路由器的惟一标识，VRID代表一个数字，范围是0-255； priority PRI # 当前主机在此虚拟路径器中的优先级；PRI范围是1-254； advert_int INT # vrrp通告的时间间隔；INT单位为秒，比如`1`，代表通告间隔为1秒 # 认证模块，同一个实例的主和备，要用同一个认证方式和密码 authentication &#123; auth_type AH|PASS # 认证方式：PASS为简单字符串密码，推荐使用；AH为IPSEC方式，不推荐使用 auth_pass &lt;PASSWORD&gt; # 密码，只有8个字符被使用，写多了会截取前8位 &#125; # 虚拟地址，即Floating IP virtual_ipaddress &#123; # 格式为：&lt;IPADDR&gt;/&lt;MASK&gt; brd &lt;IPADDR&gt; dev &lt;STRING&gt; scope &lt;SCOPE&gt; label &lt;LABEL&gt; # 可以简写为单个地址，系统会默认计算掩码和设备，也可以写label别名。 192.168.200.15 # 192.168.200.16/24 # 192.168.200.17/24 dev eth1 # 192.168.200.18/24 dev eth2 label eth2:1 &#125; # 配置要监控的网络接口，一旦配置中的一个接口出现故障，这个实例就转为FAULT状态 track_interface &#123; eth0 eth1 ... &#125; # 抢占模式相关配置 nopreempt # 定义工作模式为非抢占模式 preempt_delay 300 # 抢占式模式下，节点上线后触发新选举操作的延迟时长（在没有nopreempt的时候才能使用） # 定义通知脚本 notify_master &lt;STRING&gt;|&lt;QUOTED-STRING&gt; # 当前节点成为主节点时触发的脚本 notify_backup &lt;STRING&gt;|&lt;QUOTED-STRING&gt; # 当前节点转为备节点时触发的脚本 notify_fault &lt;STRING&gt;|&lt;QUOTED-STRING&gt; # 当前节点转为“失败”状态时触发的脚本 notify &lt;STRING&gt;|&lt;QUOTED-STRING&gt; # 通用格式的通知触发机制，一个脚本可完成以上三种状态的转换时的通知&#125; 下面为一段通用格式的通知脚本： 12345678910111213141516171819202122232425#!/bin/bash#contact='root@localhost' notify() &#123; local mailsubject="$(hostname) to be $1, vip floating" local mailbody="$(date +'%F %T'): vrrp transition, $(hostname) changed to be $1" echo "$mailbody" | mail -s "$mailsubject" $contact&#125; case $1 inmaster) notify master ;;backup) notify backup ;;fault) notify fault ;;*) echo "Usage: $(basename $0) &#123;master|backup|fault&#125;" exit 1 ;;esac 在vrrp_instance配置块里定义通知脚本的方法： 123notify_master "/etc/keepalived/notify.sh master"notify_backup "/etc/keepalived/notify.sh backup"notify_fault "/etc/keepalived/notify.sh fault" 检测机制程序自带的检测示例： cat /usr/share/doc/keepalived-1.2.13/samples/keepalived.conf.vrrp.localcheck 1234567891011121314151617181920212223242526272829303132333435363738394041424344vrrp_script chk_sshd &#123; script "killall -0 sshd" # cheaper than pidof interval 2 # check every 2 seconds weight -4 # default prio: -4 if KO fall 2 # require 2 failures for KO rise 2 # require 2 successes for OK&#125;vrrp_script chk_http_port &#123; script "&lt;/dev/tcp/127.0.0.1/80" # connects and exits interval 1 # check every second weight -2 # default prio: -2 if connect fails&#125;# .............vrrp_instance VI_1 &#123; interface eth0 state MASTER virtual_router_id 51 priority 100 virtual_ipaddress &#123; 192.168.200.18/25 &#125; track_interface &#123; eth1 weight 2 # prio = +2 if UP eth2 weight -2 # prio = -2 if DOWN eth3 # no weight, fault if down &#125; track_script &#123; chk_sshd # use default weight from the script chk_haproxy weight 2 # +2 if process is present chk_http_port chk_https_port chk_smtp_port &#125;&#125;track_script &#123; chk_sshd # use default weight from the script chk_haproxy weight 2 # +2 if process is present # ......... &#125;# ............... 检测分为两个地方：vrrp_script(示例里通过track_script调用定义的vrrp_script)和track_interface： vrrp_script，跟踪脚本返回值： script &quot;SCRIPT&quot;，这里写检测脚本。返回值是0，不执行后续操作，返回值是1，执行后续操作。 例子1：script &quot;killall -0 sshd&quot;。是检测服务是否存在，如果服务存在，返回值是0，无操作；服务不存在，返回值是1，执行后续操作。 例子2：script &quot;&lt;/dev/tcp/127.0.0.1/80&quot; 检测端口80是否打开，如果端口打开，返回值是0，无操作；端口未打开，返回值是1，执行后续操作。 interval 2， 检测间隔为2秒。 weight -4，如果检测返回值为1（失败），则权重-4 weight 2，如果检测返回值为0，则权重+2 fall 2，需要2次失败才认为是失败 rise 2，需要2次成功能认为是成功 track_script，定义调用哪个vrrp_script： chk_sshd,直接使用脚本里的默认权重。 # use default weight from the script chk_haproxy weight 2，自定义权重，如果进程存在，则权重+2 # +2 if process is present 有了vrrp_script，我们就可以基于服务层面来做Floating IP了，也就能实现其他服务，如Nginx或HAProxy的高可用。 track_interface，跟踪网卡状态： eth1 weight 2，如果是up状态，则权重+2(prio = +2 if UP)。 eth2 weight -2，如果是down状态，则权重-2(prio = -2 if DOWN)。 eth3，没有写权重的话，如果是down状态，则失败(no weight, fault if down)。 下一节我们来具体配置Keepalived的各种模式，包含： 单网络的Master-Backup主备模式（单主模式） 单网络的Active-Active双活模式（双主模式） 双网络（内外网）的Master-Backup主备模式（单主模式） 双网络（内外网）的Active-Active双活模式（双主模式）]]></content>
      <categories>
        <category>lb</category>
      </categories>
      <tags>
        <tag>Keepalived</tag>
        <tag>VRRP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[01-Keepalived介绍]]></title>
    <url>%2Flb%2F20170904-01-keepalived-introduction%2F</url>
    <content type="text"><![CDATA[HA（高可用，High availability）里的几个概念SPOF(single point of failure)单点故障 MTBF(Mean Time Between Failures)：平均故障间隔MTTR(Mean Time To Repair)：平均修复时间A(Availability)：可用性A=MTBF/(MTBF+MTTR)：99%、99.9%、99.99%、99.999%、99.9999% 用高可用的方案可以减少无故障时间。 Failover(故障转移)：即当活动的服务或应用意外终止时，快速启用冗余或备用的服务器、系统、硬件或者网络接替它们工作。Failback(故障恢复)：是将系统，组件，服务恢复到故障之前的组态。 解决高可用中网络分区的方法两节点集群容易出现网络分区（Network Partition）。网络分区是一种在系统的任何两个组之间的所有网络连接同时发生故障后所出现的情况。发生这种情况时，分裂的系统双方都会从对方一侧重新启动应用程序，进而导致重复服务或脑裂（Brain Split）。如果一个群集中配置的两个独立系统具有对指定资源（通常是文件系统或卷）的独占访问权限，则会发生裂脑情况。由网络分裂造成的最为严重的问题是它会影响共享磁盘上的数据。 在两节点集群中（偶数节点也有这种情况，也要考虑），由于网络分区导致集群的节点之间无法正常通信，无法判断对方是否故障，各持有一票无法裁决。这时候就需要引入观察者，一个拥有投票权，但不拥有被投票权的设备。 我们可以引入前端路由作为观察者，能跟前端路由通信的就获得一票，那么能通讯的集群节点就对外服务，前端的路由也叫做一个ping node(ping节点，只用来做探测和投票的，没有被投票权）。 我们可以引入一个仲裁盘（quorum disk），活动节点周期性的写入磁盘，备用节点接受心跳，并能周期性的读到磁盘上的写入的数据。如果不能接受到心跳，也无法读到周期性的数据，那么就可以认为活动节点挂了，这时候就可以让备用节点变为活动节点对外服务。 多节点集群，只有一个对外服务，会导致资源大量的浪费（尤其节点很多的情况下），为了避免资源浪费，那么我们就可以让多个主机同时工作起来。但是需要故障时候，ip地址可以漂移到另外一个节点。这种方式叫做双主模型。 STONITH（shoot the other node in the head）： Heartbeat软件包里提供了这样的一个STONITH组件，它允许使用一个远程或“智能的”连接到健康服务器的电源设备自动重启失效服务器的电源，stonith设备可以关闭电源并响应软件命令，运行Heartbeat的服务器可以通过串口线或网线向stonith设备发送命令，它控制高可用服务器对中其他服务器的电力供应，换句话说，主服务器可以复位备用服务器的电源，备用服务器也可以复位主服务器的电源。 HA Cluster实现方案：VRRP协议的实现：KeepalivedAIS（完备HA集群）：RHCS(corosync + pacemaker)、heartbeat VRRP协议VRRP：Virtual Router redundancy Protocol(虚拟路由器冗余协议) 相关术语： 虚拟路由器(Virtual Router)：由一个 Master 路由器和多个 Backup 路由器组成。主机将虚拟路由器当作默认网关。 VRID：虚拟路由器的标识。 有相同 VRID 的一组路由器构成一个虚拟路由器。 Master 路由器：虚拟路由器中承担报文转发任务的路由器。 Backup 路由器：Master 路由器出现故障时，能够代替 Master 路由器工作的路由器。 虚拟 IP 地址(VIP: Virtual IP)：虚拟路由器的 IP 地址。一个虚拟路由器可以拥有一个或多个IP 地址。 IP 地址拥有者：接口 IP 地址与虚拟 IP 地址相同的路由器被称为 IP 地址拥有者。 虚拟 MAC 地址(VMAC: Virutal MAC)：一个虚拟路由器拥有一个虚拟 MAC 地址。虚拟 MAC 地址的格式为 00-00-5E-00-01-{VRID}。通常情况下，虚拟路由器回应 ARP 请求使用的是虚拟 MAC 地址，只有虚拟路由器做特殊配置的时候，才回应接口的真实 MAC 地址。 优先级(Priority)：VRRP 根据优先级来确定虚拟路由器中每台路由器的地位。 VRRP详细内容可见：VRRP技术白皮书需要细读一下。了解VRRP工作原理。 VRRP工作模式VRRP全称 Virtual Router Redundancy Protocol，即 虚拟路由冗余协议。可以认为它是实现路由器高可用的容错协议，即将N台提供相同功能的路由器组成一个路由器组(Router Group)，这个组里面有一个master和多个backup，但在外界看来就像一台一样，构成虚拟路由器，拥有一个虚拟IP（vip，也就是路由器所在局域网内其他机器的默认路由），占有这个IP的master实际负责ARP相应和转发IP数据包，组中的其它路由器作为备份的角色处于待命状态。master会发组播消息，当backup在超时时间内收不到vrrp包时就认为master宕掉了，这时就需要根据VRRP的优先级来选举一个backup当master，保证路由器的高可用。 在VRRP协议实现里，虚拟路由器使用 00-00-5E-00-01-XX 作为虚拟MAC地址，XX就是唯一的 VRID （Virtual Router IDentifier），这个地址同一时间只有一个物理路由器占用。在虚拟路由器里面的物理路由器组里面通过多播IP地址 224.0.0.18 来定时发送通告消息。每个Router都有一个 1-255 之间的优先级别，级别最高的（highest priority）将成为主控（master）路由器。通过降低master的优先权可以让处于backup状态的路由器抢占（pro-empt）主路由器的状态，两个backup优先级相同的IP地址较大者为master，接管虚拟IP。 单主模式（主备模式）： 单主模式仅仅一个虚拟IP，仅实现高可用。 多活模式（或叫多主模式、负载均衡的高可用模式）： 对外表现为多个虚拟IP，这样就可以同时实现负载均衡和高可用。 上面两图是针对正向代理的，不过和反向代理的原理一样，大家只要理解VRRP原理就可以了，不比纠结于图示。 Heartbeat、Corosync、Keepalived对比Heartbeat、Corosync、Keepalived这三个集群组件我们到底选哪个好，首先我想说明的是，Heartbeat、Corosync是属于同一类型，Keepalived与Heartbeat、Corosync，根本不是同一类型的。Keepalived使用的vrrp协议方式，虚拟路由冗余协议 (Virtual Router Redundancy Protocol，简称VRRP)；Heartbeat或Corosync是基于主机或网络服务的高可用方式；简单的说就是，Keepalived的目的是模拟路由器的高可用，Heartbeat或Corosync的目的是实现Service的高可用。 所以一般Keepalived是实现前端高可用，常用的前端高可用的组合有，就是我们常见的LVS+Keepalived、Nginx+Keepalived、HAproxy+Keepalived。而Heartbeat或Corosync是实现服务的高可用，常见的组合有Heartbeat v3(Corosync)+Pacemaker+NFS+Httpd 实现Web服务器的高可用、Heartbeat v3(Corosync)+Pacemaker+NFS+MySQL 实现MySQL服务器的高可用。总结一下，Keepalived中实现轻量级的高可用，一般用于前端高可用，且不需要共享存储，一般常用于两个节点的高可用。而Heartbeat(或Corosync)一般用于服务的高可用，且需要共享存储，一般用于多节点的高可用。这个问题我们说明白了。 又有博友会问了，那heartbaet与corosync我们又应该选择哪个好啊，我想说我们一般用corosync，因为corosync的运行机制更优于heartbeat，就连从heartbeat分离出来的pacemaker都说在以后的开发当中更倾向于corosync，所以现在corosync+pacemaker是最佳组合。 KeepalivedKeepalived是一个基于VRRP协议来实现的服务高可用方案，可以利用其来避免IP单点故障。 一个WEB服务至少会有2台服务器运行Keepalived，一台为主服务器（Master），一台为备份服务器（Backup），但是对外表现为一个虚拟IP，主服务器会发送特定的消息给备份服务器，当备份服务器收不到这个消息的时候，即主服务器宕机的时候，备份服务器就会接管虚拟IP，继续提供服务，从而保证了高可用性(主备模式）。当然，也可以对外表现为多个虚拟IP，这样就可以同时实现负载均衡和高可用。（两台的话叫主主模式，或者叫双活模式） 但是它一般不会单独出现，而是与其它负载均衡技术（如LVS、HAProxy、Nginx）一起工作来达到集群的高可用。 Keepalive是vrrp协议的软件实现，原生设计的目的为了高可用ipvs（LVS、Nginx、HAProxy）服务： 基于vrrp协议完成地址流动(IP Floating)。 为集群内的所有的节点生成ipvs规则（在配置文件中预先定义）。 为ipvs集群的各RS做健康状态检测。 基于脚本调用接口通过执行脚本完成脚本中定义的功能，进而影响集群事务。 组件： 核心组件： vrrp stack：VRRP协议的实现 ipvs wrapper：为集群内的所有的节点生成ipvs规则 checkers：为ipvs集群的各RS做健康状态检测。 控制组件：配置文件分析器 IO复用器 内存管理组件]]></content>
      <categories>
        <category>lb</category>
      </categories>
      <tags>
        <tag>Keepalived</tag>
        <tag>VRRP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Keepalived系列文章]]></title>
    <url>%2Flb%2F20170904-00-keepalived-content%2F</url>
    <content type="text"><![CDATA[✔01-Keepalived介绍 ✔02-Keepalived配置 ✔03-Keepalived各种模式配置 ✔04-单网络双活模式的Keepalived+LVS-DR配置 ✔05-双网络双活模式的Keepalived+Nginx配置]]></content>
      <categories>
        <category>lb</category>
      </categories>
      <tags>
        <tag>Keepalived</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat主配置详解]]></title>
    <url>%2Flinux%2F20170830-03-tomcat-server-config%2F</url>
    <content type="text"><![CDATA[/etc/tomcat/server.xmlserver.xml是Tomcat的主配置文件。我们来看一下配置文件里各个条目的意义： &lt;Server port=&quot;8005&quot; shutdown=&quot;SHUTDOWN&quot;&gt;一个Server代表tomcat instance，即表现出的一个java进程；监听在8005端口，只接收“SHUTDOWN”。各server监听的端口不能相同，因此，在同一物理主机启动多个实例时，需要修改其监听端口为不同的端口。 通常我们把这个关闭：&lt;Server port=&quot;-1&quot; shutdown=&quot;480f5eca50a06b1e063165c5e30ab0c3415dd5e0&quot;&gt; tips：那串字符串是通过openssl rand -hex 20生成的。 &lt;listener className=&quot;xxxxx&quot;&gt;侦听器，监视资源的改变，并做相应的操作，多数情况不需要改变。 &lt;GlobalNamingResources&gt;全局命名资源。 子项&lt;Resource&gt;就是一个个的资源信息。指向了资源的路径(pathname)。 系统默认提供了一个认证用的资源信息,名为UserDatabase, 后面的Realm会调用这个资源： 12345&lt;Resource name=&quot;UserDatabase&quot; auth=&quot;Container&quot; type=&quot;org.apache.catalina.UserDatabase&quot; description=&quot;User database that can be updated and saved&quot; factory=&quot;org.apache.catalina.users.MemoryUserDatabaseFactory&quot; pathname=&quot;conf/tomcat-users.xml&quot; /&gt; &lt;Service name=&quot;Catalina&quot;&gt;提供的服务名，默认为Catalina。可以用来实现一个或多个Connector关联至一个engine组件。 Connector负责接收客户端请求。常见有3类：HTTP连接器，HTTPs连接器，AJP连接器。 进入tomcat的请求可分为两类：(1) standalone : 请求来自于客户端浏览器；(2) 由其它的web server反代：来自前端的反代服务器。前端反代又分为以下几种模式： nginx –&gt; http connector –&gt; tomcat httpd(proxy_http_module) –&gt; http connector –&gt; tomcat httpd(proxy_ajp_module) –&gt; ajp connector –&gt; tomcat httpd(mod_jk) –&gt; ajp connector –&gt; tomcat 默认配置里有几项示例： HTTP connector： 普通HTTP连接器： 123&lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; /&gt; 使用共享线程池的http连接器： 1234&lt;Connector executor=&quot;tomcatThreadPool&quot; port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; /&gt; HTTPs connector 123&lt;Connector port=&quot;8443&quot; protocol=&quot;org.apache.coyote.http11.Http11Protocol&quot; maxThreads=&quot;150&quot; SSLEnabled=&quot;true&quot; scheme=&quot;https&quot; secure=&quot;true&quot; clientAuth=&quot;false&quot; sslProtocol=&quot;TLS&quot; /&gt; AJP connector 1&lt;Connector port=&quot;8009&quot; protocol=&quot;AJP/1.3&quot; redirectPort=&quot;8443&quot; /&gt; 上述例子没有的几项属性参数： address：监听的IP地址；默认为本机所有可用地址。 maxThreads：最大并发连接数，默认为200。 enableLookups：是否启用DNS查询功能。 acceptCount：等待队列的最大长度。 EngineServlet实例，即servlet引擎，其内部可以一个或多个host组件来定义站点； 通常需要通过defaultHost来定义默认的虚拟主机。 &lt;Engine name=&quot;Catalina&quot; defaultHost=&quot;localhost&quot;&gt; 内部有个相应的Host是localhost 如果要设置负载均衡，要加一个jvmRoute Realm认证模块，这里调用的GlobalNamingResources里名为UserDatabase的Resourse。用来给Manager和Host-Manager提供认证服务。 1234&lt;Realm className=&quot;org.apache.catalina.realm.LockOutRealm&quot;&gt; &lt;Realm className=&quot;org.apache.catalina.realm.UserDatabaseRealm&quot; resourceName=&quot;UserDatabase&quot;/&gt;&lt;/Realm&gt; Host位于engine内部用于接收请求并进行相应处理的主机或虚拟主机。 示例： 123&lt;Host name=&quot;localhost&quot; appBase=&quot;webapps&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt;&lt;/Host&gt; 常用属性说明： (1) appBase：此Host的webapps的默认存放目录，指存放非归档的web应用程序的目录或归档的WAR文件目录路径；可以使用基于$CATALINA_BASE变量所定义的路径的相对路径；(2) autoDeploy：在Tomcat处于运行状态时，将某webapp放置于appBase所定义的目录中时，是否自动将其部署至tomcat； 示例： 12345# 事先创建好目录# mkdir -pv /appdata/webapps# mkdir -pv /appdata/webapps/ROOT/&#123;lib,classes,WEB-INF&#125;# touch /appdata/webapps/ROOT/index.jsp# 添加测试内容 index.jsp： 123456789101112131415161718&lt;%@ page language=&quot;java&quot; %&gt;&lt;html&gt; &lt;head&gt;&lt;title&gt;TomcatA&lt;/title&gt;&lt;/head&gt; &lt;body&gt; &lt;h1&gt;&lt;font color=&quot;red&quot;&gt;TomcatA.yulongjun.com&lt;/font&gt;&lt;/h1&gt; &lt;table align=&quot;centre&quot; border=&quot;1&quot;&gt; &lt;tr&gt; &lt;td&gt;Session ID&lt;/td&gt; &lt;% session.setAttribute(&quot;yulongjun.com&quot;,&quot;yulongjun.com&quot;); %&gt; &lt;td&gt;&lt;%= session.getId() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Created on&lt;/td&gt; &lt;td&gt;&lt;%= session.getCreationTime() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/body&gt;&lt;/html&gt; 修改server.xml： 123&lt;Host name=&quot;tc1.yulongjun.com&quot; appBase=&quot;/appdata/webapps&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt;&lt;/Host&gt; 浏览器访问tc1.yulongjun.com:8080即可访问到这个页面（记得hosts文件里要添加对应的ip，要么部署dns服务） Context包含在Host标签里。 如果在一个主机上部署多个app的话，Context就可以用来定义不同app对应的路径。 1&lt;Context path=&quot;/PATH&quot; docBase=&quot;/PATH/TO/SOMEDIR&quot; reloadable=&quot;&quot;/&gt; 把/PATH/TO/SOMEDIR映射到 request URI /PATH 如果/PATH/TO/SOMEDIR不带/，则是相对路径，相对的是Host的appBase。 如果/PATH/TO/SOMEDIR带/，则是操作系统的绝对路径。 reloadable：是否支持主机装载。 关于reloadable：http://blog.csdn.net/blueheart20/article/details/40074115 如果在上面Host tc1.yulongjun.com 内部加入一个Context： 12345&lt;Host name=&quot;tc1.yulongjun.com&quot; appBase=&quot;/appdata/webapps&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt; &lt;Context path=&quot;/test1&quot; docBase=&quot;test1&quot; reloadable=&quot;&quot;/&gt; &lt;Context path=&quot;/app1&quot; docBase=&quot;/app/app1&quot; reloadable=&quot;&quot;/&gt;&lt;/Host&gt; ValveValve存在多种类型： 定义访问日志：org.apache.catalina.valves.AccessLogValve 定义访问控制：org.apache.catalina.valves.RemoteAddrValve 123&lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot; directory=&quot;logs&quot; prefix=&quot;localhost_access_log.&quot; suffix=&quot;.txt&quot; pattern=&quot;%h %l %u %t &amp;quot;%r&amp;quot; %s %b&quot; /&gt; &quot;%h %l %u %t &amp;quot;%r&amp;quot; %s %b&quot;为日志格式，&amp;quot表示的是引号。 1&lt;Valve className=&quot;org.apache.catalina.valves.RemoteAddrValve&quot; deny=&quot;172\.16\.100\.67&quot;/&gt;]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat管理页面]]></title>
    <url>%2Flinux%2F20170830-02-tomcat-manage%2F</url>
    <content type="text"><![CDATA[在http:tomcat_ip:8080页面，我们可以看到3个按钮，分别的功用为： Server Status：tomcat服务器状态，包括内存信息，进程信息等等。manager App：Web App的管理页面，可以开、关、重载、部署、卸载 Web AppHost Manager：虚拟主机的管理页面，可以对虚拟主机进行添加删除修改操作。 Tomcat Web Application Manager （简称 manager）这个工具Tomcat里一个启动（Start）\关闭(Stop)\重载(Reload)\部署(Deploy)\卸载(Undeploy) Web App的一个非常好用的工具，可以实现热部署。 但是点开会提示权限禁止，需要配置： manager-gui - allows access to the HTML GUI and the status pages manager-script - allows access to the text interface and the status pages manager-jmx - allows access to the JMX proxy and the status pages manager-status - allows access to the status pages only 我们可以看到，要增加页面的manger权限，需要manager-gui角色，然后赋予相应的用户这个角色，这个角色同事也支持状态页，也就是页面上的Server status。 vim $CATALINA_BASE/conf/tomcat-users.xml,在tomcat-userstag里写如下内容： 12&lt;role rolename="manager-gui"/&gt;&lt;user username="tomcat" password="LongDream" roles="manager-gui"/&gt; tomcat 7里不需要再修改任何东西就可以访问，tocmat 8 做了权限控制，只有tomcat本机才能访问，所以还需要去相应的manager的context.xml中的valve的权限选项：vim $CATALINA_HOME/webapps/manager/META-INF/context.xml修改其中的Valve阀门中的allow=&quot;127\.\d+\.\d+\.\d+|::1|0:0:0:0:0:0:0:1&quot;为allow=&quot;192\.168+\.111+\.\d+|::1|0:0:0:0:0:0:0:1&quot;context.xml修改完之后的全部的内容为： 123456&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;Context antiResourceLocking="false" privileged="true" &gt; &lt;Valve className="org.apache.catalina.valves.RemoteAddrValve" allow="192\.168+\.111+\.\d+|::1|0:0:0:0:0:0:0:1" /&gt; &lt;Manager sessionAttributeValueClassNameFilter="java\.lang\.(?:Boolean|Integer|Long|Number|String)|org\.apache\.catalina\.filters\.CsrfPreventionFilter\$LruCache(?:\$1)?|java\.util\.(?:Linked)?HashMap"/&gt;&lt;/Context&gt; 重启tomcat，systemd管理的tomcat 7 ，重启用systemctl restart tomcat 手动安装的tomcat 8.5.x，可以catalina.sh stop 然后 catalina.sh start来重启。 下面就是 Manager的界面： Tomcat Virtual Host Manager （简称 host manager）可以实现虚拟主机的热管理。 vim $CATALINA_BASE/conf/tomcat-users.xml,在tomcat-userstag里再添加一条，如下： 123&lt;role rolename="manager-gui"/&gt;&lt;role rolename="admin-gui"&lt;user username="tomcat" password="LongDream" roles="manager-gui,admin"/&gt; Server Status上面个两个配置任意一个配置好了后，都可以启用Server Status的GUI界面： JVM Memory StatusMAX memory：大约为服务器最大内存的四分之一左右。可以自定义，最大不超过32G。 Heap 内存区分为：Eden Space（伊甸园）、Survivor Space(幸存者区)、Tenured Gen（老年代-养老区）。 非Heap 内存区分为：Code Cache（代码缓存区）、Compressed Class Space（压缩的类区）、Metaspace（源数据区） AJP 服务 和HTTP服务（默认HTTPS服务没有启用）AJP(默认监听在8009端口）、HTTP（默认监听在8080端口） 服务阶段（Stage）P: Parse and prepare request （解析和准备请求）S: Service （服务中）F: Finishing （完成服务）R: Ready （准备好）K: Keepalive（保持连接）]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat基础知识]]></title>
    <url>%2Flinux%2F20170830-01-tomcat-basic%2F</url>
    <content type="text"><![CDATA[介绍Tomcat之前先介绍下Java相关的知识。 JavaJava简介Java代码的运行： *.java(source code) –&gt; javac –&gt; *.class(bytecode) –&gt; JVM *.java源代码经过javac编译之后，生成字节码*.class，然后发送给JVM来运行。 JVM（Java Virtual Machine）：class loader，加载程序的类文件，及程序的类文件依赖到的其它的类文件而后运行； 整个运行表现为一个jvm进程。 Java Applet 、Java Servlet、在浏览器或客户端运行的Java程序就叫：Java Applet 在服务端运行的的Java程序就叫：Java Servlet Applet和Servlet都不是独立的程序，都需要Java运行环境。 JSPJava Server Pages(JSP)是一种实现普通静态HTML和动态HTML混合编码的技术，JSP并没有增加任何本质上不能用Servlet实现的功能。但是，在 JSP中编写静态HTML更加方便，不必再用println语句来输出每一行HTML代码。更重要的是，借助内容和外观的分离，页面制作中不同性质的任务可以方便地分开：比如，由页面设计者进行HTML设计，同时留出供Servlet程序员插入动态内容的空间。 此段转载自：http://blog.csdn.net/yasi_xi/article/details/22071099如果想要详细了解，可以阅读原文。 jasperjasper程序的功能，就是把JVM不认识的JSP文件解析成java文件，然后由javac程序编译成class文件提供使用。目前有很多的JSP解析引擎，Tomcat中使用的是Jasper。如下： *.jsp –&gt; jasper –&gt; *.java –&gt; javac –&gt; *.class –&gt; JVM JDKJDK（Java Development Kits）：Java 开发套件，一共分为两种： OpenJDK Oracle JDK 安装 OpenJDK 1.8yum list|grep openjdk发现包含1.6、1.7、1.8，我们可以过滤一下，只看1.8的x86_64版本的： 1yum list|grep java-1.8.0-openjdk.*x86_64 openjdk是The OpenJDK runtime environment，只有运行环境; openjdk-devel是The OpenJDK development tools,是开发工具包组。所以我们来安装openjdk-devel，这样有一系列的开发工具包组可供使用。 1yum install -y java-1.8.0-openjdk-devel 这条命令会安装java-1.8.0、java-1.8.0-poenjdk-devel、java-1.8.0-openjdk-headless以及其他相关依赖。 java -version可以看到java版本： 安装 Oracle 的 JDK 8Oracle 官方也有对应的JRE和JDK。可以去官网下载安装：http://www.oracle.com/technetwork/java/javase/downloads/index.html 包含3个版本，这里选择JDK版本下载，包格式选择rpm 用rpm命令进行安装： 这里单独下载安装的JDK的rpm，是无法用rpm -ql查询的，我们可以在/usr/java下找到： 默认latest指向jdk的版本的文件夹，default指向latest文件夹，如果后来升级了，可以把指向自行更换。 我们还需要写一下环境变量，让系统可以找到java程序1234567# 写到环境变量里，下次启动生效。cat &gt; /etc/profile.d/java.sh &lt;&lt;EOFexport JAVA_HOME=/usr/java/latestexport PATH=\$JAVA_HOME/bin:\$PATHEOF# source一下，在当前环境下立即生效。source /etc/profile.d/java.sh 这里推荐用OpenJDK，免去了配置环境变量的操作。而且JDK属于Oracle公司未开源产品，万一你公司做大了，Oracle像告谷歌一样告你呢？:-D TomcatTomcat简介Tomcat 服务器是一个免费的开放源代码的Web 应用服务器，Tomcat是Apache 软件基金会（Apache Software Foundation）的Jakarta 项目中的一个核心项目：tomcat.apache.org，它的项目名称为catalina，后来由Apache、Sun 和其他一些公司及个人共同开发而成，因为在O’Reilly家出的书的封面是一只汤姆猫，所以软件更名为Tomcat。Tomcat 是一个小型的轻量级应用服务器，在中小型系统和并发访问用户不是很多的场合下被普遍使用，是开发和调试JSP 程序的首选，因为Tomcat 技术先进、性能稳定，成为目前比较流行的Web 应用服务器。Tomcat是应用（java）服务器，它只是一个servlet容器，是Apache的扩展，但它是独立运行的。 Tomcat架构 图片来自于：http://www.blogjava.net/honzeland/archive/2010/05/10/320458.html 它由一组嵌套的层次和组件组成，一般可分为以下四类： 顶级组件：位于配置层次的顶级，并且彼此间有着严格的对应关系。Server 服务类组件：位于Server的下一级。Service 连接器组件：连接客户端（可以是浏览器或Web服务器）请求至Servlet容器。http，https， ajp 容器类组件：包含一组其它组件。Engine，Host，Context 被嵌套的组件：位于一个容器当中，但不能包含其它组件。valve，loger，realm，loader，manager，… 集群类组件： listener，cluster，… 各常见组件： 1、服务器(server)：Tomcat的一个实例，通常一个JVM只能包含一个Tomcat实例；因此，一台物理服务器上可以在启动多个JVM的情况下在每一个JVM中启动一个Tomcat实例，每个实例分属于一个独立的管理端口。这是一个顶级组件。 2、服务(service)：一个服务组件通常包含一个引擎和与此引擎相关联的一个或多个连接器。给服务命名可以方便管理员在日志文件中识别不同服务产生的日志。一个server可以包含多个service组件，但通常情下只为一个service指派一个server。连接器类组件： 3、连接器(connectors)：负责连接客户端（可以是浏览器或Web服务器）请求至Servlet容器内的Web应用程序，通常指的是接收客户发来请求的位置及服务器端分配的端口。默认端口通常是HTTP协议的8080，管理员也可以根据自己的需要改变此端口。还可以支持HTTPS ，默认HTTPS端口为8443。同时也支持AJP，即（A）一个引擎可以配置多个连接器，但这些连接器必须使用不同的端口。默认的连接器是基于HTTP/1.1的Coyote。同时，Tomcat也支持AJP、JServ和JK2连接器。 容器类组件： 4、引擎(Engine)：引擎通是指处理请求的Servlet引擎组件，即Catalina Servlet引擎，它检查每一个请求的HTTP首部信息以辨别此请求应该发往哪个host或context，并将请求处理后的结果返回的相应的客户端。严格意义上来说，容器不必非得通过引擎来实现，它也可以是只是一个容器。如果Tomcat被配置成为独立服务器，默认引擎就是已经定义好的引擎。而如果Tomcat被配置为Apache Web服务器的提供Servlet功能的后端，默认引擎将被忽略，因为Web服务器自身就能确定将用户请求发往何处。一个引擎可以包含多个host组件。 5、主机(Host)：主机组件类似于Apache中的虚拟主机，但在Tomcat中只支持基于FQDN的“虚拟主机”。一个引擎至少要包含一个主机组件。 6、上下文(Context)：Context组件是最内层次的组件，它表示Web应用程序本身。配置一个Context最主要的是指定Web应用程序的根目录，以便Servlet容器能够将用户请求发往正确的位置。Context组件也可包含自定义的错误页，以实现在用户访问发生错误时提供友好的提示信息。 被嵌套类(nested)组件： 这类组件通常包含于容器类组件中以提供具有管理功能的服务，它们不能包含其它组件，但有些却可以由不同层次的容器各自配置。 7、阀门(Valve)：用来拦截请求并在将其转至目标之前进行某种处理操作，类似于Servlet规范中定义的过滤器。Valve可以定义在任何容器类的组件中。Valve常被用来记录客户端请求、客户端IP地址和服务器等信息，这种处理技术通常被称作请求转储(request dumping)。请求转储valve记录请求客户端请求数据包中的HTTP首部信息和cookie信息文件中，响应转储valve则记录响应数据包首部信息和cookie信息至文件中。 8、日志记录器(Logger)：用于记录组件内部的状态信息，可被用于除Context之外的任何容器中。日志记录的功能可被继承，因此，一个引擎级别的Logger将会记录引擎内部所有组件相关的信息，除非某内部组件定义了自己的Logger组件。 9、领域(Realm)：用于用户的认证和授权；在配置一个应用程序时，管理员可以为每个资源或资源组定义角色及权限，而这些访问控制功能的生效需要通过Realm来实现。Realm的认证可以基于文本文件、数据库表、LDAP服务等来实现。Realm的效用会遍及整个引擎或顶级容器，因此，一个容器内的所有应用程序将共享用户资源。同时，Realm可以被其所在组件的子组件继承，也可以被子组件中定义的Realm所覆盖。 此段来自于：http://www.ttlsa.com/tomcat/tomcat-install-and-configure/ 安装Tomcat安装好OpenJDK或JDK之后，就可以安装tomcat了。 yum 安装方式1yum install tomcat-lib tomcat tomcat-admin-webapps tomcat-webapps tomcat-docs-webapp tomcat-webapps 依赖的tomcat-libs、tomcat api和其他组件会自动安装上。 CentOS7 默认安装的tomcat版本是7： 1systemctl start tomcat 浏览器打开http://tomcat_ip:8080，这里的tomcat_ip换成你tomcat服务器的ip 手动安装过程看官方版本图：http://tomcat.apache.org/whichversion.html 我们可以看到，在目前来说，8.0.x属于superseded(废弃）状态，9.0.x属于alpha版，不考虑,8.5.x是目前的主流版本，故下载8.5.x版本，目前版本是8.5.20，笔者到清华镜像下载的。 123456789101112131415wget https://mirrors.tuna.tsinghua.edu.cn/apache/tomcat/tomcat-8/v8.5.20/bin/&#123;apache-tomcat-8.5.20.tar.gz,apache-tomcat-8.5.20-fulldocs.tar.gz,apache-tomcat-8.5.20-deployer.tar.gz&#125;tar -xvf apache-tomcat-8.5.20.tar.gz -C /usr/localcd /usr/locallink -sv apache-tomcat-8.5.20 tomcatcat &gt; /etc/profile.d/tomcat.sh &lt;&lt; EOFexport CATALINA_BASE=/usr/local/tomcatexport PATH=\$CATALINA_BASE/bin:\$PATHEOF. /etc/profile.d/tomcat.shuseradd -r tomcatchown -R tomcat:tomcat /usr/local/tomcat/su - tomcat -c &apos;catalina.sh start&apos; 手动安装的话，设置完环境变量后，手动安装的版本可以使用catlina.sh来进行各种操作。 catalina.sh start 后，浏览器打开http://tomcat_ip:8080，这里的tomcat_ip换成你tomcat服务器的ip: Tomcat 目录结构tomcat的目录结构： bin：脚本，及启动时用到的类。 conf：配置文件目录。 lib：库文件，Java类库，jar。 logs：日志文件目录。 temp：临时文件目录。 webapps：webapp的默认目录。 work：工作目录。存放编译后的字节码文件。 tomcat的配置目录文件构成： server.xml：主配置文件； web.xml：每个webapp只有“部署”后才能被访问，它的部署方式通常由web.xml进行定义，其存放位置为WEB-INF/目录中；此文件为所有的webapps提供默认部署相关的配置； context.xml：每个webapp都可以专用的配置文件，它通常由专用的配置文件context.xml来定义，其存放位置为WEB-INF/目录中；此文件为所有的webapps提供默认配置； tomcat-users.xml：用户认证的账号和密码文件； catalina.policy：当使用-security选项启动tomcat时，用于为tomcat设置安全策略； catalina.properties：Java属性的定义文件，用于设定类加载器路径，以及一些与JVM调优相关参数； logging.properties：日志系统相关的配置。 JSP Webapp的组织结构： webapps的根目录： index.jsp：主页； WEB-INF/：当前webapp的私有资源路径；通常用于存储当前webapp的web.xml和context.xml配置文件； META-INF/：类似于WEB-INF/； classes/：类文件，当前webapp所提供的类； lib/：类文件，当前webapp所提供的类，被打包为jar格式； webapp归档格式： .war：webapp .jar：EJB的类打包文件； .rar：资源适配器类打包文件； .ear：企业级webapp；]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自制的 Vagrant box —— longdream/centos7]]></title>
    <url>%2Fcloud%2F20170829-vagrant-custom-box%2F</url>
    <content type="text"><![CDATA[自己做了一个Vagrant镜像，上传到Vagrant官方的Vagrant Cloud上，方便自己和读者使用。 目前为2.0.0版本。 项目地址：longdream/centos7 Vagrant可以使用下面命令安装： 1vagrant box add longdream/centos7 关于Vagrant使用，可参考：Vagrant–快速搭建实验环境利器。 In English:longdream/centos7 Change Log@Version 2.0.0 change CentOS official box centos/7 1707.1 to centos/7 1708.1(CentOS’s Version is updated from 7.3.1611 to 7.4.1708)。 Modify /etc/ssh/sshd_config：PasswordAuthentication no –&gt;PasswordAuthentication no (To enable argument Login with Password). add useful tools: expect. longdream/centos7 IntroductionBase on CentOS official box centos/7 1708.1. the following changes have been made: Disabled SELinux. yum updateupdate to the latest version. Modify /etc/ssh/sshd_config：PasswordAuthentication no –&gt;PasswordAuthentication no (To Open Login with Password). Some useful tools: vim, tree, wget ,bash-completion, net-tools ,tcpdump ,ab, expect. CentOS-Base.repo and epel.repo change to aliyun’s repos(which more fast in China). Add VirtualBox Guest in box. (Need plugin vagrant-vbguest in Host：vagrant plugin install vagrant-vbguest.) 中文：longdream/centos7 变更日志@Version 2.0.0 更改CentOS官方boxcentos/7 1707.1 到 centos/7 1708.1（CentOS的版本从7.3.1611 更新为7.4.1708）。 修改/etc/ssh/sshd_config：PasswordAuthentication no –&gt;PasswordAuthentication no （打开密码登录参数）。 添加有用的工具: expect。 longdream/centos7 介绍基于CentOS官方box centos/7 1708.1。做了如下的更改： 禁用了SElinux。 加了一些有用的工具：vim、 tree、 wget 、bash-completion、 net-tools 、tcpdump 、ab、expect。 yum update更新到最新版。 修改/etc/ssh/sshd_config：PasswordAuthentication no –&gt;PasswordAuthentication no (为了打开密码登录)。 CentOS-Base.repo 和 epel.repo 更换为 阿里云的 repo （国内更快） 在box里添加了VirtualBox的虚机客户端。（需要在宿主机上安装插件vagrant-vbguest：vagrant plugin install vagrant-vbguest。）]]></content>
      <categories>
        <category>cloud</category>
      </categories>
      <tags>
        <tag>Vagrant</tag>
        <tag>Vagrant Cloud</tag>
        <tag>Vagrant box</tag>
        <tag>longdream/centos7</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[04-HAProxy 统计页面]]></title>
    <url>%2Flb%2F20170828-04-haproxy-stats%2F</url>
    <content type="text"><![CDATA[HAProxy的统计页面，可以定义在frontend listen backend中，不过一般都定义在listen段中，专门开辟一个端口作为监听端口，然后对外提供状态页面。 12345678listen stats mode http bind 192.168.20.222:9999 stats enable stats hide-version log global stats uri /haproxy-stats stats auth haadmin:haadmin123 重启服务，systemctl restart haproxy，输入统计页地址192.168.20.222:9999/haproxy-stats，输入上面定义的用户名和密码： 如果在添加一个参数：stats admin，可以提供后端主机的管理功能，还可以限定只允许某台主机进行管理： 1stats admin &#123; if | unless &#125; &lt;cond&gt; 例如不设置限制：1stats admin if TRUE # 任何主机都可以管理 设置完重启服务，可以看到每个服务器前面会多一个勾选用的复选框，可以直接设置服务器状态： 还可以设置页面自动刷新间隔： 1stats refresh 15s]]></content>
      <categories>
        <category>lb</category>
      </categories>
      <tags>
        <tag>HAProxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[03-HAProxy 具体配置参数]]></title>
    <url>%2Flb%2F20170828-03-haproxy-params%2F</url>
    <content type="text"><![CDATA[具体配置参数可以查看这里： HAProxy 1.5：http://cbonte.github.io/haproxy-dconv/1.5/configuration.html HAProxy 1.7：http://cbonte.github.io/haproxy-dconv/1.7/configuration.html 下面捡一些用的比较多的参数来说明： server：后端具体服务器1server &lt;name&gt; &lt;address&gt;[:[port]] [param*] name：跟服务器相关的内部名称，会出现在log日志和报警里。 [:[port]]：具体服务器ip地址和端口，不指定端口话默认为80。[param*]：参数有很多，如backup、check inter fall rise等。 1234567frontend myweb bind *:80 default_backend websrvsbackend websrvs server nginx-web1 192.168.20.10:80 check server nginx-web2 192.168.20.20:80 check backup：标记为备用主机标记为backup的主机，不负载均衡，在服务器全挂了的时候才会调用，一般用来做sorry Server。 1server sorry-server 192.168.20.44 backup balance：负载均衡算法12balance &lt;algorithm&gt; [ &lt;arguments&gt; ]balance url_param &lt;param&gt; [check_post] 负载均衡算法有以下几种： roundrobin：(动态)轮询。可运行时调整权重，支持慢启动，最多支持4095个后端主机。（不过这种限制不算是限制了，已经很大了） static-rr：静态轮询。运行时不可调整权重，不支持慢启动，无后端主机数量限制。 leastconn：最少连接，按最少连接来调度，此处是加权最少连接，支持指定权重，是动态的，所以也就支持权重的运行时调整和慢启动。 first：制定先调度至一个主机，主机连接限制到了，再调度到另外一台。 source：source ip hash，源地址hash。根据请求的源地址进行hash，同一个来源ip调度到同一台主机。 uri：uri hash。根据请求的uri的hash值调度，这样可以提高缓存的命中率。 url_param：根据url里的某个参数的hash来调度。读取url地址里给定的参数的hash值，来调度。 hdr(&lt;name&gt;)：根据HTTP header 的hash值进行调度。如果name不存在，或者如果不包含任何值，则采用roundrobin算法。 上述的source、 uri、 url_param、 hdr(&lt;name&gt;)采用的默认hash算法都是map-based，。还可以更改为另外一种算法consistent。 map-based: 静态映射，可以分配权重，但是一旦服务启动后，无法动态调整权重，也不支持慢启动。而且一旦服务器发生变动，影响是全局的，不适合用来做缓存代理。这种算法虽然不好，但是占用系统资源少。consistent: 一致性hash，服务器发生变动，只影响局部有限的服务器，可以运行中动态调整权重，支持慢启动。这种算法很好用，但是占用系统资源多。 举几个例子： 1、想要对缓存比较友好，缓存命中率更高，使用基于uri的一致性hash算法。同一个uri地址，无论请求地址是多少，返回的信息始终来自于同一个后端主机： 123456789frontend myweb bind *:80 default_backend websrvsbackend websrvs balance uri server nginx-web1 192.168.20.10:80 check server nginx-web2 192.168.20.20:80 check hash-type consistent 2、想要基于HTTP 头信息的浏览器来分类： 123456789frontend myweb bind *:80 default_backend websrvsbackend websrvs balance header(User-Agent) server nginx-web1 192.168.20.10:80 check server nginx-web2 192.168.20.20:80 check hash-type consistent compression：压缩12compression algo &lt;algorithm&gt;compression type &lt;mime type&gt; 用在前段的例子例子： 1234567891011frontend myweb bind *:80 default_backend websrvs compression algo gzip compression type text/html text/plain application/xml application/javascriptbackend websrvs balance source server nginx-web1 192.168.20.10:80 check server nginx-web2 192.168.20.20:80 check hash-type consistent mode：负载模式（四层TCP或7层HTTP）负载模式： tcp：默认模式，四层TCP负载均衡，被用于四层基于端口的协议，可以用来转发各种端口。 http：七层HTTP负载均衡，这是HAProxy的价值所在，可以做很多比较复杂的七层策略。 123frontend myweb bind 192.168.20.111:80 mode http default_backend websrvs backend websrvs mode http balance source server nginx-web1 192.168.20.10:80 check server nginx-web2 192.168.20.20:80 check server 中的params1. check、inter、fail、raise：（健康检查相关） check：是否启用健康检查。不写则默认不启用健康检查。 addr：可以不占用服务器主用的ip，换一个ip进行检测。 port：同样，端口也可以换一个。 inter &lt;delay&gt;：两个连续的检查之间的延时，默认为2000ms。 fall &lt;count&gt;：在连续的几次健康检查中失败，则视为dead（当机），默认为3次。 rise &lt;count&gt;：在连续的几次健康检查中成功，则视为operational（可操作的），默认为2次。 123frontend myweb bind 192.168.20.111:443 mode http default_backend websrvs backend websrvs mode http balance source server nginx-web1 192.168.20.10:443 check port 80 inter 1000 fall 3 rise 5 server nginx-web2 192.168.20.20:443 check port 80 inter 1000 fall 3 rise 5 option httpcheck：基于http协议做健康检查可以指定method、uri、version 1234option httpchkoption httpchk &lt;uri&gt;option httpchk &lt;method&gt; &lt;uri&gt;option httpchk &lt;method&gt; &lt;uri&gt; &lt;version&gt; 例子： 123456# Relay HTTPS traffic to Apache instance and check service availability# using HTTP request &quot;OPTIONS * HTTP/1.1&quot; on port 80.backend https_relay mode tcp option httpchk OPTIONS * HTTP/1.1\r\nHost:\ www server apache1 192.168.1.1:443 check port 80 还有 smtpchk、mysql-check、pgsql-check 、ssl-hello-chk不做赘述，也是应用层的复杂检测方法。 maxconn：最大并发连接数 maxqueue：最大队列数12maxconn &lt;maxconn&gt;maxqueue &lt;maxqueue&gt; 可以指定单台后端服务器的最大并发连接数。 1server nginx-web1 192.168.20.10:80 check maxconn 10000 maxqueue 2000 redir ：302临时重定向到另外一台服务器。123frontend myweb bind 192.168.20.111:443 mode http default_backend websrvs backend websrvs mode http balance source server nginx-web1 192.168.20.10:443 check port 80 inter 1000 fall 3 rise 5 server nginx-web2 192.168.20.20:443 check port 80 inter 1000 fall 3 rise 5 redir http:///www.baidu.com 对192.168.20.10的访问，临时重定向到http://www.baidu.com weight：权重服务器的权重]]></content>
      <categories>
        <category>lb</category>
      </categories>
      <tags>
        <tag>HAProxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[02-HAProxy简单配置和基本用法]]></title>
    <url>%2Flb%2F20170828-02-haproxy-simple-configuration%2F</url>
    <content type="text"><![CDATA[环境一台HAProxy，两个Nginx Web Server。 Vagrantfile配置如下： 123456789101112131415161718192021222324252627# -*- mode: ruby -*-# vi: set ft=ruby :Vagrant.configure("2") do |config| config.vm.box = "longdream/centos7" config.vm.box_check_update = false config.hostmanager.enabled = true config.hostmanager.manage_guest = true config.hostmanager.manage_host = true # Create VM haproxy config.vm.define "haproxy" do |node| node.vm.network "private_network", ip: "192.168.20.222" node.vm.hostname = "haproxy.yulongjun.com" end # Create VM nginx-web1 config.vm.define "nginx-web1" do |node| node.vm.network "private_network", ip: "192.168.20.10" node.vm.hostname = "nginx-web1.yulongjun.com" end # Create VM nginx-web2 config.vm.define "nginx-web2" do |node| node.vm.network "private_network", ip: "192.168.20.20" node.vm.hostname = "nginx-web2.yulongjun.com" endend 配置web服务器端1yum install nginx 更改两个服务器的/usr/share/nginx/html/index.html文件： nginx-web1更改内容为： 1Backend Server 1 nginx-web2更改内容为： 1Backend Server 2 这样做事为了区分开两个服务器显示页面，生产环境下一般是两台都是一样的内容。 在浏览器上访问下http://nginx-web1.yulongjun.com/和http://nginx-web2.yulongjun.com,如果能访问成功，证明没问题。 配置HAProxy1yum install -y haproxy 程序环境： 主程序：/usr/sbin/haproxy 主配置文件：/etc/haproxy/haproxy.cfg Unit file：/usr/lib/systemd/system/haproxy.service 配置文件/etc/haproxy/haproxy.cfg的结构主要分为全局配置段和代理配置端： global：全局配置段 进程及安全配置相关的参数 性能调整相关参数 Debug参数 用户列表 peers proxies：代理配置段 defaults：为frontend, listen, backend提供默认配置 fronted：前端，相当于nginx, server {} backend：后端，相当于nginx, upstream {} listen：同时拥前端和后端 1. 配置日志在/etc/haproxy/haproxy.cfg里，日志定义为： 1log 127.0.0.1 local2 所以我们要开启rsyslog，并且添加local2的定义项： vim /etc/rsyslog.conf： 1234567# Provides UDP syslog reception$ModLoad imudp$UDPServerRun 514# Save boot messages also to boot.loglocal7.* /var/log/boot.loglocal2.* /var/log/haproxy.log 重启rsyslog服务，并且确保udp的514端口打开：12systemctl restart rsyslogss -unlp |grep rsyslogd # 确保514端口处于监听状态 HAProxy的基本用法（简单配置）默认的全部注释掉： 然后开始手动添加： 12345678frontend myweb bind *:80 default_backend websrvsbackend websrvs balance roundrobin server nginx-web1 192.168.20.10:80 check server nginx-web2 192.168.20.20:80 check 测试一下： 1234567891011[root@haproxy ~]# for i in `seq 10`;do curl 192.168.20.222;done&lt;h1&gt;Backend Server 1&lt;/h1&gt;&lt;h1&gt;Backend Server 2&lt;/h1&gt;&lt;h1&gt;Backend Server 1&lt;/h1&gt;&lt;h1&gt;Backend Server 2&lt;/h1&gt;&lt;h1&gt;Backend Server 1&lt;/h1&gt;&lt;h1&gt;Backend Server 2&lt;/h1&gt;&lt;h1&gt;Backend Server 1&lt;/h1&gt;&lt;h1&gt;Backend Server 2&lt;/h1&gt;&lt;h1&gt;Backend Server 1&lt;/h1&gt;&lt;h1&gt;Backend Server 2&lt;/h1&gt;]]></content>
      <categories>
        <category>lb</category>
      </categories>
      <tags>
        <tag>HAProxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[01-HAProxy简介]]></title>
    <url>%2Flb%2F20170828-01-haproxy-introduction%2F</url>
    <content type="text"><![CDATA[我们yum info haproxy可以看到HAProxy的描述，翻译一下： 摘要：HAProxy是在高可用环境下提供TCP/HTTP proxy和Load Balance的工具。描述：HAProxy 是一个适用于HA环境的 TCP/HTTP reverse proxy（译者注：本身没有HA功能，但是有proxy和LB功能，可以这样理解，HA的proxy…… ），HAProxy可以： 路由依赖静态分配cookies的HTTP请求。 在多个服务器之间扩展负载，同时确保通过使用HTTP cookie来保持服务器的持久性。 在主服务器fail时候，可以切换到备用服务器。 接受连接到特定端口的专用服务监控 在不断开已有的链接的情况下，停止接受新的链接请求。 双向添加，修改，删除HTTP headers。 锁定匹配特定模式的请求。 从一个被应用解析的URI来报告详细状态给认证过的用户（译者注：相当方便和强大） HAProxy是一个纯粹的reverse proxy，能够实现基于TCP的4层和基于HTTP的7层负载均衡功能，但是和Nginx不一样，是没有Web Server功能的，所以HAProxy后端通常会接Nginx或Apache httpd等Web Server。 通常HAproxy会和Keepalived配合使用，实现高可用的负载均衡(Keepalived后面会讲到）： 更多详细的介绍可以看官方文档：Introduction to HAProxy 下一节，我们来简单配置一个HAProxy的集群。]]></content>
      <categories>
        <category>lb</category>
      </categories>
      <tags>
        <tag>HAProxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10-ngx__stream_*_module详解]]></title>
    <url>%2Flb%2F20170823-10-ngx_stream_module%2F</url>
    <content type="text"><![CDATA[Nginx的ngx_stream_module提供了伪四层代理功能。但是功能不强，用的不多。 捡几个常用的模块说明一下作用，就不做详细展开，想研究的可以详细的去看官方文档。 http://nginx.org/en/docs/ ngx_stream_core_module ：核心模块listen 监听的端口。默认为tcp协议，加上udp就监听udp协议的端口。 stream stream段里面定义一个个的server的具体信息。（每个sever监听一个端口） ngx_stream_proxy_module四层代理功能proxy_pass定义的每个端口的server对应的后端主机或主机组。 proxy_connect_timeout和被代理的服务器建立连接的超时时间。 proxy_next_upstream当代理服务器和后端服务器不能建立时，是否把客户端连接转移到到下一个后端服务器。默认打开 proxy_next_upstream_timeout转移到下一个服务器的连接的限制时间，如果设置了值，过了这个值，就会再次转移到下一个服务器。如果不设置，那么默认为0，即不限制，一直要求建立连接。 proxy_next_upstream_tries在超时后，尝试的次数，超过这个次数，会转移到下一台。默认为0，无限制尝试。 proxy_timeout 代理服务器处理客户端和后端服务器两次读或写成功的之间的时间内，超过多少时间，就断开连接。默认为10分钟。（即建立连接后，10分钟内没有数据交互，则断开连接） ngx_stream_upstream_moduleupstream stream的upstream和http的upstream没什么区别，都可以设置多个后端服务器，也可以设置备份后端服务器，还可以设置权重和算法。 123456upstream backend &#123; hash $remote_addr consistent; server backend1.example.com:12345 weight=5; server 127.0.0.1:12345 max_fails=3 fail_timeout=30s; server unix:/tmp/backend3;&#125; ngx_stream_ssl_module和http的ssl相似。 12345678910111213141516171819worker_processes auto;stream &#123; ... server &#123; listen 12345 ssl; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers AES128-SHA:AES256-SHA:RC4-SHA:DES-CBC3-SHA:RC4-MD5; ssl_certificate /usr/local/nginx/conf/cert.pem; ssl_certificate_key /usr/local/nginx/conf/cert.key; ssl_session_cache shared:SSL:10m; ssl_session_timeout 10m; ... &#125;&#125; ngx_stream_log_modulelog_format，是日志格式，可以定义多种，写在stream段。access_log可以用在stream和server段（使用log_format）。 如下，定义一个名为basic 的log_format，access_log调用basic的日志格式 1234log_format basic &apos;$remote_addr [$time_local] &apos; &apos;$protocol $status $bytes_sent $bytes_received &apos; &apos;$session_time&apos;;access_log /spool/logs/nginx-access.log basic buffer=32k; ngx_stream_access_module同http的访问控制模块。 例子： 12345678server &#123; ... deny 192.168.1.1; allow 192.168.1.0/24; allow 10.1.1.0/16; allow 2001:0db8::/32; deny all;&#125; ngx_stream_geo_module： 自定义ip地理位置。 用的少，一般用geoip，是有ip地址库的,见下。 `ngx_stream_geoip_moduleyum install yum install GeoIP GeoIP-datageoip是库文件，geoip-data是具体的数据文件。不过不是最新版，要想要最新版还是要到官方网站去下载：官方提供免费版和付费版，官网地址:www.maxmind.com。 rpm -ql GeoIP-data： 1234/usr/share/GeoIP/GeoIPASNum-initial.dat/usr/share/GeoIP/GeoIPASNumv6-initial.dat/usr/share/GeoIP/GeoIPCity-initial.dat/usr/share/GeoIP/GeoIPCityv6-initial.dat 123456789101112stream &#123; geoip_country /usr/share/GeoIP/GeoIPASNum-initial.dat; geoip_city /usr/share/GeoIP/GeoIPCity-initial.dat; map $geoip_city_continent_code $nearest_server &#123; default example.com; EU eu.example.com; NA na.example.com; AS as.example.com; &#125; ...&#125; 官方的一个示例： 1234567891011121314151617181920212223242526272829303132333435363738394041worker_processes auto;error_log /var/log/nginx/error.log info;events &#123; worker_connections 1024;&#125;stream &#123; upstream backend &#123; hash $remote_addr consistent; server backend1.example.com:12345 weight=5; server 127.0.0.1:12345 max_fails=3 fail_timeout=30s; server unix:/tmp/backend3; &#125; upstream dns &#123; server 192.168.0.1:53535; server dns.example.com:53; &#125; server &#123; listen 12345; proxy_connect_timeout 1s; proxy_timeout 3s; proxy_pass backend; &#125; server &#123; listen 127.0.0.1:53 udp; proxy_responses 1; proxy_timeout 20s; proxy_pass dns; &#125; server &#123; listen [::1]:12345; proxy_pass unix:/tmp/stream.socket; &#125;&#125;]]></content>
      <categories>
        <category>lb</category>
      </categories>
      <tags>
        <tag>Nginx FastCGI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[09-ngx_http_upstream_module详解]]></title>
    <url>%2Flb%2F20170823-09-ngx_http_upstream_module%2F</url>
    <content type="text"><![CDATA[LB Cluster（负载均衡集群）方案： 硬件： F5公司：BigIP Citrix公司：NetScaler A10公司：A10 软件： 四层调度：lvs, nginx(stream module), haproxy(mode tcp) 七层调度：nginx(http_upstream module), haproxy(mode http), httpd, ats, … 这节我们学习Nginx的七层调度模块ngx_http_upstream_module。 我们可以构建一个后端服务器组(Backend Server Group),里面包含多个相同作用的服务器，通过Nginx的负载均衡功能，可以实现调度。 ngx_http_upstream_module模块用来定义服务器组，这个服务器组可以被proxy_pass、fastcgi_pass、uwsgi_pass、scgi_pass和memcached_pass等指令引用。实现负载均衡的调度功能。 默认算法为randrobin，另外支持least_conn、ip_hash算法，nginx plus还支持更多的调度算法，这里不做讨论。 指令upstream upstream只能在http上下文里，定义了一组上游服务器组。 server server字段只能在在upstream上下文里，定义一个个的上游服务器，也叫后端服务器（Backend）. 参数有很多： weight=number：设置服务器的权重，默认情况下为1。 fail_timeout=time：与后端服务器通信失败的超时时间，超过时间，则算一次失败。 max_fails=number：设置与服务器通讯的最大失败次数，超过此数将不再调度。 backup：将服务器标记为备份服务器。当一个组里所有非备份的服务器都挂了的时候，将会反代备份服务器对外服务。 down：将备份服务器标记为不可用；通常在维护服务器的时候使用，比如蓝绿发布的时候。（配置为down，然后reload Nginx服务，维护好了，再去掉down，再reload Nginx服务） resolve：当后端服务器地址写的是域名的时候，如果修改了ip地址，可以自动监控修改 蓝绿发布：https://www.v2ex.com/t/344341 调度算法(默认不写是wrr)least_conn、ip_hash、hash 最少连接算法 源地址哈希算法：同一个ip绑定在一个服务器上 hash自定义的key。该key可以包含文本，变量，以及它们的组合,consistent表示是否启用一致性hash算法。 例如hash $request_uri consistent，就是根据request URI来做调度，即意味着无论哪个客户端，访问同一个资源，都会到固定的后端服务区上去找。如果后端是缓存服务器，可以提高缓存命中率。 关于一致性hash算法，可以看这里详细了解：http://www.jianshu.com/p/e8fb89bb3a61 实验基础虚拟机环境一个proxy负责前端调度，后面接两个backend做负载均衡，一个作为backup。 proxy反代服务器：192.168.1.200backend1后端服务器：192.168.1.101backend2后端服务器：192.168.1.102backup备份后端服务器：192.168.1.103 Vagrant的Vagrantfile配置文件： 1234567891011121314151617181920212223242526272829303132333435363738394041424344# -*- mode: ruby -*-# vi: set ft=ruby :Vagrant.configure("2") do |config| # Vagrant Global Config # `longdream/centos7` is a custom centos7 box made by YuLongjun. config.vm.box = "longdream/centos7" # If this box is add online, set true will check update. # Also set `false` will not update it. # If this box is added locally, this setting is invalid. config.vm.box_check_update = false # you need `vagrant plugin install vagrant-vbguest` # You also need `vagrant plugin install vagrant-hostmanager` config.hostmanager.enabled = true # Allow update `/etc/hosts` file in VMs. config.hostmanager.manage_guest = true # Allow update `/etc/hosts` file in Hosts. config.hostmanager.manage_host = true # Create VM `proxy`. config.vm.define "proxy" do |proxy| proxy.vm.network "private_network", ip: "192.168.1.200" proxy.vm.hostname = "proxy" end # Create VM `backend1`. config.vm.define "backend1" do |backend1| backend1.vm.network "private_network", ip: "192.168.1.101" backend1.vm.hostname = "backend1" end # Create VM `backend2`. config.vm.define "backend2" do |backend2| backend2.vm.network "private_network", ip: "192.168.1.102" backend2.vm.hostname = "backend2" end # Create VM `backup`. config.vm.define "backup" do |backup| backup.vm.network "private_network", ip: "192.168.1.103" backup.vm.hostname = "backup" endend 安装Nginxproxy的Nginx程序作为反向代理服务，backend1、backend2、backup的Nginx程序作为HTTP服务。 分别安装Nginx软件： 写一个install_nginx.sh脚本，在四台机器上运行： 123456789101112131415#!/bin/bash## set up yum repo.cat &gt;/etc/yum.repos.d/nginx.repo &lt;&lt;EOF[nginx]name=nginx repobaseurl=http://nginx.org/packages/centos/\$releasever/\$basearch/gpgcheck=0enabled=1EOF# installyum install -y nginx [ $? -eq 0 ]&amp;&amp;echo -e "\033[32;1mInstall nginx successfully.\033[0m"||echo -e "\033[31;1mInstall nginx failed. Please check the Network.\033[0m" 配置各个服务器backend1: 1234mv /usr/share/nginx/html/index.html&#123;,.bak&#125;echo "&lt;h1&gt;Backend Web Server 1&lt;/h1&gt;" &gt; /usr/share/nginx/html/index.htmlsystemctl enable nginxsystemctl start nginx backend2: 1234mv /usr/share/nginx/html/index.html&#123;,.bak&#125;echo "&lt;h1&gt;Backend Web Server 2&lt;/h1&gt;" &gt; /usr/share/nginx/html/index.htmlsystemctl enable nginxsystemctl start nginx backup： 1234mv /usr/share/nginx/html/index.html&#123;,.bak&#125;echo "&lt;h1&gt;Backup Server&lt;/h1&gt;" &gt; /usr/share/nginx/html/index.htmlsystemctl enable nginxsystemctl start nginx proxy： 123456789101112131415161718mv /etc/nginx/conf.d/default.conf&#123;,.bak&#125;cat &gt; /etc/nginx/conf.d/upstream1.conf &lt;&lt;EOFupstream backend &#123; server 192.168.1.101; weight=2 max_fails=2 fail_timeout=3; server 192.168.1.102:80 weight=1 max_fails=2 fail_timeout=3; server 192.168.1.103 backup;&#125;server &#123; location / &#123; proxy_pass http://backend; &#125;&#125;EOFsystemctl enable nginxsystemctl start nginx 测试1for i in `seq 10`;do curl 192.168.1.200;done down掉backend1，只能访问到backend2 down掉backend1和backend2，就负载均衡到backup备份服务器上了：]]></content>
      <categories>
        <category>lb</category>
      </categories>
      <tags>
        <tag>Nginx FastCGI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[08-ngx_http_fastcgi_module详解]]></title>
    <url>%2Flb%2F20170823-08-ngx_http_fastcgi_module%2F</url>
    <content type="text"><![CDATA[有两种Web架构： LNMP( Linux+Nginx+MySQL+PHP-FPM+MySQL)：需要FastCGI模块 LNAMP(Nginx+HTTPD+MySQL+PHP_Module)：需要HTTP相关模块 LNMP是使用的php的fpm功能，而不再是一个依赖httpd的库模块。LNAMP里面，是httpd+php库模块。 ngx_http_fastcgi_module和ngx_http_proxy_module很像，在proxy里的用的proxy_pass，在fastcgi里就变成了fastcgi_pass，定义缓存也换成了是fastcgi_cache_path，调用缓存也换成了fastcgi_cache等等。基本用法都差不多。 这里给出一个示例1： 在192.168.10.40上安装php-fpm 1yum install -y php-fpm 修改/etc/php-fpm.d/www.conf 12345678listen = 0.0.0.0:9000# listen.allowed_clients = 127.0.0.1 # 注释掉，让Nginx可以连接到php-fpmpm = dynamic # 可以修改为静态# 下面的参数生产中都会调大。pm.max_children = 50 # 最大子进程数pm.start_servers = 5 # 起始子进程数pm.min_spare_servers = 5 # 最小空闲子进程数pm.max_spare_servers = 35 # 最大空闲子进程数 在Nginx(192.168.10.10)上的/etc/nginx/config.d/里在上一节的基础之上设置vhost1.conf： 12345678910111213141516171819202122232425262728293031323334353637383940server &#123; server_name www.yulongjun.com; listen 80; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; location / &#123; root /usr/share/nginx/html; # 此处增加php index index.php index.html index.htm; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root /usr/share/nginx/html; &#125; location /blog/ &#123; proxy_pass http://192.168.10.20/; &#125; location /bbs/ &#123; proxy_pass http://192.168.10.30/; &#125; location ~* \.(jpg|gif|png|jpeg|svg)$ &#123; proxy_pass http://192.168.10.40; proxy_cache pgcache; proxy_cache_key $request_uri proxy_cache_valid 200 302 10m; proxy_cache_valid 301 1h; proxy_cache_valid any 1m; proxy_cache_use_state error timeout invalid_header; &#125; location ~* \.php$ &#123; fastcgi_pass 172.16.0.69:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /data/fpm/$fastcgi_script_name; include fastcgi_params; &#125;&#125; 配置示例2：通过/pm_status和/ping来获取fpm server状态信息； 12345location ~* ^/(pm_status|ping)$ &#123; include fastcgi_params; fastcgi_pass 127.0.0.1:9000; fastcgi_param SCRIPT_FILENAME $fastcgi_script_name;&#125; 访问下列不同地址，可以看到不同格式和内容的状态信息： www.yulongjun.com/pm_statuswww.yulongjun.com/pm_status?fullwww.yulongjun.com/pm_status?jsonwww.yulongjun.com/pm_status?xml ngx_http_uwsgi_module和fastcgi接口一样，uwsgi也是一种Web服务器网关接口。它是一个Web服务器（如nginx，uWSGI等服务器）与web应用（如Python的Flask、Django、Tornado等框架写的程序）通信的一种规范。Nginx的ngx_http_uwsgi_module实现了跟uwsgi服务器的通信。 ngx_http_scgi_module同上，也是一种Web服务器网关接口，略]]></content>
      <categories>
        <category>lb</category>
      </categories>
      <tags>
        <tag>Nginx FastCGI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[07-ngx_http_proxy_module详解]]></title>
    <url>%2Flb%2F20170823-07-ngx_http_proxy_module%2F</url>
    <content type="text"><![CDATA[ngx_http_proxy_module 里面包含反向代理(Reverse Proxy)相关指令和缓存(Cache)相关指令。 proxy_pass前端代理服务器Nginx：192.168.10.10后端准备两个被代理的服务器192.168.10.20和192.168.10.30，开启httpd服务 192.168.10.20上： 123456789yum install httpdcat &gt;/var/www/html/index.html &lt;&lt;EOF&lt;h1&gt;BLOG Server&lt;/h1&gt;&lt;h2&gt;Upsteam Server 1&lt;/h2&gt;&lt;h3&gt;IP: 192.168.10.20&lt;/h3&gt;EOFsystemctl start httpd 192.168.10.30上： 123456789yum install httpdcat &gt;/var/www/html/index.html &lt;&lt;EOF&lt;h1&gt;BBS Server&lt;/h1&gt;&lt;h2&gt;Upsteam Server 2&lt;/h2&gt;&lt;h3&gt;IP: 192.168.10.30&lt;/h3&gt;EOFsystemctl start httpd 192.168.10.10上 mv /etc/nginx/confi.d/{,.bak} vim /etc/nginx/conf.d/vhost1.conf 12345678server_name www.yulongjun.com;listen location /blog/ &#123; proxy_pass http://192.168.10.20/;&#123;location /bbs/ &#123; proxy_pass http://192.168.10.30/;&#125; 在proxy_pass 后面的url，加斜线和不加斜线是有区别的：如果加了斜线，如/bbs/ --&gt; http://192.168.10.20/ 指的就是访问www.yulongjun.com/bbs/即访问的http://192.167.10.20/。如果不加斜线，如/bbs/ --&gt; http://192.168.10.20，指的就是访问www.yulongjun.com/bbs/即访问的http://192.168.10.20/bbs。如果location定义其uri时使用了正则表达式的模式，或在if语句或limt_execept中使用proxy_pass指令，则proxy_pass之后必须不能使用uri; 用户请求时传递的uri将直接附加代理到的服务的之后: 123location ~* \.(jpg|gif|png|jpeg|svg)$ &#123; proxy_pass http://192.168.10.40;&#125; 如果我们访问http://www.yulongjun.com/img/bluesky.jpg即访问http://192.168.0.40/img/sky.jpg proxy_set_header 设定发往后端主机的请求报文的请求首部的值。 proxy_set_header X-Real-IP $remote_addr; # 真实client地址proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; # 代理服务器代理的真实地址 定义各个段用的Cache之前，要先在http 上下文定义缓存路径： proxy_cache_path 定义的keys_zone的名字，要被嵌套的各个子段所引用，即各子段缓存都定义在这个缓存路径下。 1234http&#123; proxy_cache_path /data/nginx/cache levels=1:2 keys_zone=one:10m; ...&#125; 记得创建目录mkdir -pv /data/nginx/cache /data/nginx/cache为缓存路径。 levels=1:2的意思是一级目录为hash值的倒数第一个数，二级目录再切两个数字。 keys_zone=one:10m：one为缓存的名字,10m为缓存的大小 那么，缓存的里的文件名就类似于这样： /data/nginx/cache/c/29/b7f54b2df7773722d382f4809d65029c proxy_cacheproxy_cache定义在哪，就在哪生效，在server里写，就对server生效，在location里写，就对location生效。 proxy_cache_valid设置不同的响应码的缓存时间。 123proxy_cache_valid 200 302 10m;proxy_cache_valid 301 1h;proxy_cache_valid any 1m; proxy_cache_use_stalestale(腐烂，过时） 在后端服务器出故障或找不到的时候，哪些情况可能会使用过时缓存进行相应。 1proxy_cache_use_stale error timeout invalid_header; proxy_cache_methods proxy_hide_header隐藏响应首部的filed，默认隐藏了“Date”，“Server”，“X-Pad”和“X-Accel -…”，如果还想加隐藏项，就可以写在这里。 proxy_pass_header正好相反，想要传递客户端的header里的某些field，可以在这个字段添加。 proxy_set_header设定发往后端主机的请求header添加某些字段。 1proxy_set_header X-Real-IP $remote_addr; 修改后端服务器的日志格式： 1LogFormat &quot;%h %l %u %t \&quot;%r\&quot; %&gt;s %b \&quot;%&#123;Referer&#125;i\&quot; \&quot;%&#123;User-Agent&#125;i\&quot;&quot; combined 为1LogFormat &quot;%h %l %u %t \&quot;%r\&quot; %&gt;s %b \&quot;%&#123;Referer&#125;i\&quot; \&quot;%&#123;User-Agent&#125;i\&quot; %&#123;X-Real-IP&#125;i&quot; combined 或者这样修改： 1proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 延伸知识，X-forwarded-For可以记录多层代理的信息，如：X-Forwarded-For: 1.1.1.1, 2.2.2.2, 3.3.3.3而X-Real-IP只能记录单层代理的上一级Client的信息，多级只会记录隔一级的代理。详细区别可见：http://www.cnblogs.com/mypath/articles/5239687.html proxy_connect_timeout代理服务器与后端服务器建立连接的超时时间。应该注意的是，这个超时通常不能超过75秒。 proxy_read_timeout代理服务器从后端服务器读取响应的超时时长。超时仅在两个连续读操作之间设置，而不是传输整个响应。如果后端服务器在此时间内没有传输任何内容，则连接被关闭。 proxy_send_timeout请求发送给后端服务器的超市是长。超时仅在两个连续写操作之间设置，而不是传输整个响应。如果后端服务器在此时间内没有传输任何内容，则连接被关闭。 proxy_limit_rate限制从后端服务器读取相应的速度。 总的配置实例：mkdir -pv /data/nginx/cache vim /etc/nginx/nginx.conf 在httpd段里添加：proxy_cache_path /data/nginx/cache levels=1:2 keys_zone=one:10m; 全部配置为： 1234567891011121314151617181920212223242526272829303132user nginx;worker_processes 1;error_log /var/log/nginx/error.log warn;pid /var/run/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include /etc/nginx/mime.types; default_type application/octet-stream; proxy_cache_path /data/nginx/cache levels=1:2 keys_zone=one:10m; log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf;&#125; 移走默认的/etc/nginx/config.d/default.conf ，以免造成干扰 mv /etc/nginx/config.d/default.conf{,.bak} 添加vhost1.confvim /etc/nginx/config.d/vhost1.conf 123456789101112131415161718192021222324252627282930313233server &#123; server_name www.yulongjun.com; listen 80; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; location / &#123; root /usr/share/nginx/html; index index.html index.htm; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root /usr/share/nginx/html; &#125; location /blog/ &#123; proxy_pass http://192.168.10.20/; &#125; location /bbs/ &#123; proxy_pass http://192.168.10.30/; &#125; location ~* \.(jpg|gif|png|jpeg|svg)$ &#123; proxy_pass http://192.168.10.40; proxy_cache pgcache; proxy_cache_key $request_uri proxy_cache_valid 200 302 10m; proxy_cache_valid 301 1h; proxy_cache_valid any 1m; proxy_cache_use_state error timeout invalid_header; &#125;&#125;]]></content>
      <categories>
        <category>lb</category>
      </categories>
      <tags>
        <tag>Nginx Reverse Proxy</tag>
        <tag>Nginx Cache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[06-Nginx的HTTP相关的杂项模块]]></title>
    <url>%2Flb%2F20170823-06-ngx-http-other-modules%2F</url>
    <content type="text"><![CDATA[主要介绍下面几个模块： ngx_http_access_modulehttp_access_module包含了http的访问权限控制的一个模块，前面一节的limit_except指令里用过，还可以用在http, server, location等地方。 allow deny 示例： 1234567location /admin &#123; deny 192.168.1.1; allow 192.168.1.0/24; allow 10.1.1.0/16; allow 2001:0db8::/32; deny all;&#125; ngx_http_auth_basic_module实现基于用户的访问控制，使用basic机制进行用户认证 auth_basic auth_basic_user_file 示例： 123yum install -y http-tools # htpasswd工具在这个包里htpasswd -c -m /etc/nginx/.htpasswd admin1 # 之后输入admin1的两次密码htpasswd -m /etc/nginx/.htpasswd admin2 # 之后设置admin2 的密码 修改nginx的配置文件： 1234location /admin &#123; auth_basic &quot;Admin Area&quot;; auth_basic_user_file /etc/nginx/.htpasswd;&#125; ngx_sub_status_module用于输出nginx的基本状态信息。 stub_status 1234567location/basic_status &#123; stub_status; allow 172.16.0.0/16; deny all;&#125; Active connections: 291server accepts handled requests 16630948 16630948 31070465Reading: 6 Writing: 179 Waiting: 106 Active connections: 活动状态的连接数 accepts：已经接受的客户端请求的总数 handled：已经处理完成的客户端请求的总数 requests：客户端发来的总的请求数 Reading：正在读取客户端请求报文首部的连接的连接数 Writing：正在向客户端发送响应报文过程中的连接数 Waiting：正在等待客户端发出请求的空闲连接数 ngx_http_log_module指定http访问日志格式和路径的模块。 log_format string可以使用nginx核心模块及其它模块内嵌的变量。Nginx内嵌变量：http://nginx.org/en/docs/varindex.html 我们可以看到/etc/nginx/nginx.conf的默认的format格式： 123log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; 具体分析一下： $remote_addr：指的就是客户端地址。 $remote_user：Basic认证时候的用户名 [$time_local]： 中括号括起来的本地时间(通用的日志格式的那种） $request：request URI $status：响应码 body_bytes_sent：返回的body大小 http_referer：跳转链接，从哪个网页跳转过来，可以用来看外链。 http_user_agent：用户浏览器类型 http_x_forwarded_for：简称XFF头，它代表客户端，也就是HTTP的请求端真实的IP，在通过了HTTP 代理或者负载均衡服务器时会添加该项。 httpd的日志格式默认使用的combined模式，combined格式的默认定义为：LogFormat &quot;%h %l %u %t \&quot;%r\&quot; %&gt;s %b \&quot;%{Referer}i\&quot; \&quot;%{User-Agent}i\&quot;&quot; combined这里写了各种参数代表的意义：http://blog.csdn.net/hytfly/article/details/11209909官方详细参数解析：http://httpd.apache.org/docs/2.4/mod/mod_log_config.html#formats access_log 可以在不同的区域自定义访问日志文件路径和文件名，还有日志格式，以及相关的缓冲的配置： buffer=size flush=time open_log_file_cache 缓存各日志文件相关的元数据信息。 max：缓存的最大文件描述符数量 min_uses：在inactive指定的时长内访问大于等于此值方 可被当作活动项 inactive：非活动时长 valid：验正缓存中各缓存项是否为活动项的时间间隔 ngx_gzip_modulegzip 是否开启gzip。 gzip_comp_level gzip压缩级别。级别1-9。 gzip disable 禁止IE6之类的浏览器压缩。 gzip_min_length 不能多大的文件都压缩吧，那样效率很低，这里规定了gzip压缩的最小响应报文大小。 gzip_buffers 支持实现压缩功能时为其配置的缓冲区数量及每个缓存区的大小。 gzip_proxied nginx作为代理服务器接收到从被代理服务器发送的响应报文后，在何种条件下启用压缩功能的。 off：对代理的请求不启用。no-cache, no-store，private：表示从被代理服务器收到的响应报文首部的Cache-Control的值为此三者中任何一个，则启用压缩功能。 gzip_types mime-type 压缩过滤器，仅对此处设定的MIME类型的内容启用压缩功能。 示例： 12345gzip on;gzip_comp_level 6;gzip_min_length 64;gzip_proxied any;gzip_types text/xml text/css application/javascript; ngx_http_ssl_modulessl 开启或关闭ssl。 ssl_certificate 当前虚拟主机使用PEM格式的证书文件。 ssl_certificate_key 当前虚拟主机上与其证书匹配的私钥文件。 ssl_protocols 支持ssl协议版本，默认为1、1.1、1.2，为了安全可以改为1.3，1.2是有安全漏洞的。 ssl_session_cache builtin[:size]：使用OpenSSL内建的缓存，此缓存为每worker进程私有。[shared:name:size]：在各worker之间使用一个共享的缓存。 ssl_session_timeout 客户端一侧的连接可以复用ssl session cache中缓存的ssl参数的有效时长。 ngx_http_ssl_module参数示例： 生成自签名证书123456789101112cd /etc/pki/CAopenssl genrsa -out private/cakey.pem 4096chmod go= private/cakey.pemopenssl req -new -x509 -key private/cakey.pem -out cacert.pem -days 365touch index.txtecho 01&gt; serialcd /etc/nginxmkdir sslcd ssl(umask 077; openssl genrsa -out nginx.key 2048)openssl req -new -key nginx.key -out nginx.csropenssl ca -in nginx.csr -out nginx.crt 配置ssl模块1234567891011server &#123; listen 443 ssl; server_name www.yulongjun.com; root /vhosts/ssl/htdocs; ssl on; ssl_certificate /etc/nginx/ssl/nginx.crt; ssl_certificate_key /etc/nginx/ssl/nginx.key; ssl_session_cache shared:sslcache:20m; ssl_session_timeout 600s; &#125; ngx_http_rewrite_module（URL重写）有下面几种url重写： http://bbs.yulongjun.com/ –&gt; http://www.yulongjun.com/bbs/http://www.yulongjun.com/ –&gt; https://www.yulongjun.com/http://www.yulongjun.com/login.php;username=tom –&gt; http://www.yulongjun.com/tom/ http://www.yulongjun.io/bbs/ –&gt; http://bbs.yulongjun.io/ 将用户请求的URI基于regex所描述的模式进行检查，而后完成替换。 rewrite 将用户请求的URI基于regex所描述的模式进行检查，匹配到时将其替换为replacement指定的新的URI。 注意：如果在同一级配置块中存在多个rewrite规则，那么会自下而下逐个检查；被某条件规则替换完成后，会重新一轮的替换检查，因此，隐含有循环机制；[flag]所表示的标志位用于控制此循环机制。 如果replacement是以http://或https://开头，则替换结果会直接以重定向返回给客户端。 [flag]： last：重写完成后停止对当前URI在当前location中后续的其它重写操作，而后对新的URI启动新一轮重写检查；提前重启新一轮循环(类似于continue)； break：重写完成后停止对当前URI在当前location中后续的其它重写操作，而后直接跳转至重写规则配置块之后的其它配置；结束循环； redirect：重写完成后以临时重定向方式(302 Moved Temprarily)直接返回重写后生成的新URI给客户端，由客户端重新发起请求；不能以http://或https://开头； permanent：重写完成后以永久重定向方式(301 Moved Permanently)直接返回重写后生成的新URI给客户端，由客户端重新发起请求； 12rewrite /(.*)$ https://www.yulongjun.io/$1;rewrite /bbs return 停止处理，然后返回一个特殊响应码给客户端。还可以指定返回的url页面。 rewrite_log 是否开启重写日志 if 引入一个新的配置上下文 ；条件满足时，执行配置块中的配置指令。只支持在server, location。 condition： 比较操作符： == != ~：模式匹配，区分字符大小写； ~*：模式匹配，不区分字符大小写； !~：模式不匹配，区分字符大小写； !~*：模式不匹配，不区分字符大小写； 文件及目录存在性判断：-e, !-e-f, !-f-d, !-d-x, !-x 示例： 12345678910111213141516171819if ($http_user_agent ~ MSIE) &#123; rewrite ^(.*)$ /msie/$1 break;&#125;if ($http_cookie ~* &quot;id=([^;]+)(?:;|$)&quot;) &#123; set $id $1;&#125;if ($request_method = POST) &#123; return 405;&#125;if ($slow) &#123; limit_rate 10k;&#125;if ($invalid_referer) &#123; return 403;&#125; set ![](/images/15043208822285.jpg) 设置用户自定义变量。 ngx_http_referer_module访问有通过地址直接访问，或者从其他网站跳转过来。 用过滤referer头域的方法可以来防止盗链。 valid_referers 定义referer首部的合法 可用值。 none：请求报文首部没有referer首部。 blocked：请求报文的referer首部没有值。 server_names：参数，其可以有值作为主机名或主机名模式。 arbitrary_string：直接字符串，但可使用*作通配符。 regular expression：被指定的正则表达式模式匹配到的字符串；要使用~打头，例如 ~.*\.yulongjun\.com。 示例： 12345valid_referers none block server_names *.yulongjun.com yulongjun.* ~\.yulongjun\.;if($invalid_referer) &#123; return http://www.yulongjun.com/invalid.jpg;&#125; 1234567valid_referers none blocked server_names *.example.com example.* www.example.org/galleries/ ~\.google\.;if ($invalid_referer) &#123; return 403;&#125;]]></content>
      <categories>
        <category>lb</category>
      </categories>
      <tags>
        <tag>Nginx ACL</tag>
        <tag>Nginx Status</tag>
        <tag>Nginx Log</tag>
        <tag>Nginx Gzip</tag>
        <tag>Nginx SSL</tag>
        <tag>Nginx Rewrite</tag>
        <tag>Nginx Upstream</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[05-ngx_http_core_module详解]]></title>
    <url>%2Flb%2F20170821-05-ngx_http_core_module%2F</url>
    <content type="text"><![CDATA[ngx_http_core_module,规定了一些http功能相关的核心配置。 与套接字相关配置1、server设置虚拟服务器全局配置 配置一个虚拟主机的全局配置 12345server &#123;listen address[:PORT]|PORT;server_name SERVER_NAME;root /PATH/TO/DOCUMENT_ROOT;&#125; 2、listen设置监听端口和IP default_server：设定为默认虚拟主机 ssl：限制仅能够通过ssl连接提供服务 backlog=NUMBER 设置调用中限制挂起连接队列的最大长度的backlog参数 listen()。默认情况下， backlog在FreeBSD，DragonFly BSD和macOS上设置为-1，在其他平台上设置为511。 rcvbuf=SIZE 设置所监听端口的接收缓存大小（SO_RCVBUF选项） sndbuf=SIZE 设置所监听端口的发送缓存大小（SO_SNDBUF选项） 注意：(1) 基于port：listen PORT指令监听在不同的端口(2) 基于hostname：server_name指令指向不同的主机名(3) 基于ip的虚拟主机listen IP:PORT&gt; IP 地址不同 例如： 1234567listen 192.168.0.100:8000; # 监听192.168.0.100的8000端口listen 192.168.0.100; # 监听192.168.0.100，不写端口则默认为80端口listen 8000; # 监听本地8000端口listen *:8000; # 同上listen localhost:8000; # 同上listen [::]:8000; # 监听本地的ipv6的8000端口listen [::1]; # 监听本地的ipv6地址，不写端口则默认为80 3、server_name设置虚拟服务器名字 虚拟主机的主机名称后可跟多个由空白字符分隔的字符串。 支持*通配任意长度的任意字符 server_name *.yulongjun.com www.yulongjun.* 支持~起始的字符做正则表达式模式匹配 1server_name ~^www\d+\.yulongjun\.com$ \d 表示 [0-9] 匹配机制: 首先是字符串精确匹配 如:www.yulongjun.com 左侧*通配符 如:*.yulongjun.com 侧*通配符 如:www.yulongjun.* 正则表达式 如: ~^.*\.yulongjun\.com$ 都没写，则匹配default_server 4、tcp_nodelay on | off; 在keepalived模式下的连接是否启用TCP_NODELAY选项。off时，延迟发送，合并多个请求后再发送 默认On时，不延迟发送。 5、sendfile 零拷贝是否开启 是否启用sendfile零拷贝功能，即在内核中封装报文直接发送。默认Off。 定义路径相关的配置1、root 设置web资源的路径映射;用于指明请求的URL所对应的文档 的目录路径，可用于http, server, location, if in location ```server { …root /data/www/vhost1;}1234567891011 &gt; 例如：网络上`http://www.yulongjun.com/images/logo.jpg`,实际是服务器上的`/data/www/vhosts/images/logo.jpg`### 2、`location`![](/images/15034969496035.jpg) 在一个server中location配置段可存在多个，用于实现从uri到 文件系统的路径映射;ngnix会根据用户请求的URI来检查定义的所有 location，并找出一个最佳匹配，而后应用其配置 示例:``` server &#123;... server_name www.yulongjun.com; location /images/ &#123; root /data/imgs/; &#125; &#125; 例如：网络上的http://www.yulongjun.com/images/logo.jpg，实际是服务器上的/data/imgs/images/logo.jpg =：对URI做精确匹配。 1location = / &#123; ... &#125; 可以匹配http://www.yulongjun.com/ ，不能匹配http://www.yulongjun.com/index.html ~：对URI做正则表达式模式匹配，区分字符大小写 ~*：对URI做正则表达式模式匹配，不区分字符大小写 ^~：对URI的最左边部分做匹配检查，不区分字符大小写 不带符号：匹配起始于此uri的所有的uri 匹配优先级：=&gt;^~&gt; ～&gt; ～*&gt;不带符号。 示例： 1root /vhosts/www/htdocs/ http://www.yulongjun.com/index.html –&gt; /vhosts/www/htdocs/index.html 123456server &#123; root /vhosts/www/htdocs/ location /admin/ &#123; root /webapps/app1/data/ &#125;&#125; http://www.yulongjun.com/admin/index.html–&gt; /webapps/app1/data/admin/index.html 3、alias PATH; 路径别名，文档映射的另一种机制；仅能用于location上下文 示例： 123location /bbs/ &#123; alias /web/forum/;&#125; http://www.yulongjun.com/bbs/index.php–&gt; /web/forum/index.html 相比之下，root是这样的： 123location /bbs/ &#123; root /web/forum/;&#125; http://www.yulongjun.com/bbs/index.php–&gt; /web/forum/bbs/index.html 注意：location中使用root指令和alias指令的意义不同 (a) root，给定的路径对应于location中的/uri/左侧的/ (b) alias，给定的路径对应于location中的/uri/右侧的/ 4、index file指定默认网页资源，注意,这个是在ngx_http_index_module模块。 5、error_page 错误页404 12error_page 404 /404.html; error_page 500 502 503 504 /50x.html; 这将导致内部重定向到uri 客户端请求方法指定的内部重定向更改为“GET”（对于除“GET”和“HEAD” 之外的所有方法）。 此外，可以使用=response语法将响应代码更改为另一个，例如： 1error_page 404 = 200 /empty.gif; 如果代理服务器或FastCGI/uwsgi/SCGI服务器处理错误响应，并且服务器可能返回不同的响应代码（例如200、302、401或404），则可以使用返回的代码进行响应： 1error_page 404 = /404.php; 如果在内部重定向期间不需要更改URI和方法，则可以将错误处理传递到命名位置： 123456location / &#123; error_page 404 = @fallback; &#125; location @fallback &#123; proxy_pass http：//后端; 如果uri处理导致错误，则将最后发生的错误的状态代码返回给客户端。 还可以使用URL重定向进行错误处理： 12error_page 403 http://example.com/forbidden.html; error_page 404 = 301 http://example.com/notfound.html; 在这种情况下，默认情况下，将响应代码302返回给客户端。它只能更改为重定向状态代码之一（301,302,303,307和308）。当且仅当没有error_page 在当前级别上定义指令时，这些指令才能从上一级继承 。 6、try_files 以指定的顺序检查文件的存在，并使用第一个找到的文件进行请求处理; 该处理在当前上下文中执行。文件的路径是file根据根和别名指令的参数 构建的 。可以通过在名称末尾指定斜杠来检查目录的存在，例如“ $uri/”。如果没有找到任何文件，则会uri进行最后一个参数中指定的内部重定向 。例如： 1234567location /images/ &#123; try_files $uri /images/default.gif;&#125;location = /images/default.gif &#123; expires 30s;&#125; 最后一个参数也可以指向一个命名的位置，如下面的例子所示。从0.7.51版本开始，最后一个参数也可以是 code： 123location / &#123; try_files $uri $uri/index.html $uri.html =404;&#125; Drupal/FastCGI示例： 12345678910111213141516171819202122232425location / &#123; try_files $uri $uri/ @drupal;&#125;location ~ \.php$ &#123; try_files $uri @drupal; fastcgi_pass ...; fastcgi_param SCRIPT_FILENAME /path/to$fastcgi_script_name; fastcgi_param SCRIPT_NAME $fastcgi_script_name; fastcgi_param QUERY_STRING $args; ... other fastcgi_param&apos;s&#125;location @drupal &#123; fastcgi_pass ...; fastcgi_param SCRIPT_FILENAME /path/to/index.php; fastcgi_param SCRIPT_NAME /index.php; fastcgi_param QUERY_STRING q=$uri&amp;$args; ... other fastcgi_param&apos;s&#125; 在上面的例子中， 123location / &#123; try_files $uri $uri/ @drupal;&#125; 该try_files指令相当于下面两端代码的结合： 1234location / &#123; error_page 404 = @drupal; log_not_found off;&#125; 123456789location ~ \.php$ &#123; try_files $uri @drupal; fastcgi_pass ...; fastcgi_param SCRIPT_FILENAME /path/to$fastcgi_script_name; ...&#125; try_files 在将请求传递给FastCGI服务器之前检查PHP文件的存在。 Wordpress和Joomla的示例： 12345678910111213141516171819location / &#123; try_files $uri $uri/ @wordpress;&#125;location ~ \.php$ &#123; try_files $uri @wordpress; fastcgi_pass ...; fastcgi_param SCRIPT_FILENAME /path/to$fastcgi_script_name; ... other fastcgi_param&apos;s&#125;location @wordpress &#123; fastcgi_pass ...; fastcgi_param SCRIPT_FILENAME /path/to/index.php; ... other fastcgi_param&apos;s&#125; 定义客户端请求的相关配置1、keepalive_timeout设定长连接的超时时长 第一个参数设置保持连接的超时时长，0表示禁止长连接。默认为75s，推荐120s 可选的第二个参数在“Keep-Alive：timeout = time”响应头域中设置一个值。两个参数可能不同。 Mozilla和Konqueror可以识别 Keep-Alive：timeout = time头域。MSIE在大约60秒内自行关闭保持连接。 2、keepalive_requests长连接允许请求的资源的最大数量 在一次长连接上所允许请求的资源的最大数量。默认为100 3、keepalive_disable对哪种浏览器禁用长连接 4、send_timeout设置用于向客户端发送响应的超时时间 设置用于向客户端发送响应的超时时间。超时仅在两个连续的写入操作之间设置，而不是传输整个响应。如果客户端在这段时间内没有收到任何内容，则连接被关闭。 5、client_body_buffer_size 设置读取客户端请求体的缓冲区大小。如果请求体大于缓冲区，则整个身体或仅将其部分写入 临时文件。默认情况下，缓冲区大小等于两个内存页面。这是x86上的8K，其他32位平台和x86-64。其他64位平台通常为16K。 6、client_body_temp_path定义用于存储持有客户机请求主体的临时文件的目录。最多可以在指定目录下使用三级子目录层次结构。例如，在以下配置中： 1client_body_temp_path /spool/nginx/client_temp 1 2; 临时文件hash： 85c9d32c3526a1bbb3996525ec80b3e0f7aa83dd 12ls /spool/nginx/client_temp/d/3d/a83/85c9d32c3526a1bbb3996525ec80b3e0f7aa83dd 我们可以看到就是逐级从右边截取hash值 目录名为16进制的数字； 1 1级目录占1位16进制，即2^4=16个目录 0-f 2 2级目录占2位16进制，即2^8=256个目录 00-ff 2 3级目录占2位16进制，即2^8=256个目录 00-ff 对客户端进行限制的相关配置1、limit_rate 限制响应给客户端的传输速率，单位是bytes/second 默认值0表示无限制 19、limit_except 限制客户端使用除了指定的请求方法之外的其它方法，只能用在location上下文。 Method:GET, HEAD, POST, PUT, DELETE MKCOL, COPY, MOVE, OPTIONS, PROPFIND, PROPPATCH, LOCK, UNLOCK, PATCH 12345limit_except GET HEAD POST &#123; deny 192.168.111.200 allow 192.168.111.0/24; deny all;&#125; 表示除了GET、HEAD、POST方法其他方法都限制，主机范围为：禁止192.168.111.200、允许192.168.111.0/24、禁止所有。即仅允许192.168.111.0网段访问，但是禁止192.168.111.200的地址访问。 文件操作优化的配置1. aio 是否启用Linux的aio功能。 2. directio 是否同步写磁盘，在Linux主机启用O_DIRECT标记，意味文件大于等于给定的大小时使用，例如directio 4m 3. open_file_cache nginx可以缓存以下三种信息： 文件元数据：文件的描述符、文件大小和最近一次的修改时间 打开的目录结构 没有找到的或者没有权限访问的文件的相关信息 max=N：可缓存的缓存项上限；达到上限后会使用LRU算法实现管理。inactive=time：缓存项的非活动时长，在此处指定的时长内未被命中的或命中的次数少于open_file_cache_min_uses指令所指定的次数的缓存项 即为非活动项，将被删除。 4. open_file_cache_errors 是否缓存查找时发生错误的文件一类的信息。 5. open_file_cache_min_uses open_file_cache指令的inactive参数指定的时长内，至少被命中此处指定的次数方可被归类为活动项。 6. open_file_cache_valid 缓存项有效性的检查频率。 综上来个例子： 123456aio on;directio 4m;open_file_cache max=1000 inactive=20s;open_file_cache_valid 30s;open_file_cache_min_uses 2;open_file_cache_errors on; 其他模块暂时没时间写，有时间再写。可以去查看官方文档的Module reference(模块参考），用的比较多的是NGINX主配置文件里讲到的那些模块，这里再次列出来。 核心模块： core module 常用的标准模块： HTTP modules： ngx_http_core_modules http核心功能模块（重要） ngx_http_ssl_module http信道加密模块（重要） ngx_http_upstream_module http定义服务器组模块（重要） ngx_http_fastcgi|uWSGI|SCGI_module http web api接口模块（重要） ngx_http_proxy_module http反向代理模块（重要） ngx_http_gzip_module http gzip压缩传输模块（次一级） ngx_http_log_module http日志模块（次一级） ngx_http_referer_modulehttp防盗链模块（次一级） ngx_http_rewrite_module http重定向模块（次一级） ngx_http_access_module http权限控制模块 ngx_http_auth_basic_module http认证模块 ngx_http_stub_status_module http状态模块 ngx_http_headers_module http首部信息模块 Mail modules： 用的少 Stream modules： ngx_stream_core_module http的伪四层负载均衡模块]]></content>
      <categories>
        <category>lb</category>
      </categories>
      <tags>
        <tag>Nginx HTTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[04-Nginx的默认http配置选项]]></title>
    <url>%2Flb%2F20170821-04-nginx-default-httpd-config%2F</url>
    <content type="text"><![CDATA[http配置结构http配置，可以写在/etc/nginx/nginx.conf的http配置字段里。也可以单独来写，一般是单独写在/etc/nginx/conf.d/xxx.conf文件里，不同的虚拟主机写在不同的配置文件里，清晰明了。 在http的配置文件里，和主配置一样，分为{}括起来的，我们称之为段，比如http{}、server{}、location {}、if CONDITION {} 12345678910111213141516171819202122http &#123; # http block: http/https 协议相关的公共配置块 ... server &#123; # server虚拟主机配置段，可以定义多个server # server block: 某一虚拟主机的详细配置块 ... location /URI1/ &#123; # 资源位置location的配置段，可以定义多个location # location block: 某一资源位置的详细配置块 if CONDITION &#123; # if in location block: 在location配置段里的if条件判断块。 &#125; ... &#125; location /URI2/ &#123; ... &#125; location ... # 多个location &#125; server &#123; &#125; server ... # 多个server &#125; http各种配置段的的详细配置选项信息见： http://nginx.org/en/docs/http/ngx_http_core_module.html 与http相关的配置指令仅能够放置于http,server,location,upstream,if CONDITION段里。而且每个指令都有对应的可以放的段，并不是所有段都可以放。 比如default_type配置指令，只支持http，server，location段： Syntax: default_type mime-type;Default: default_type text/plain;Context: http, server, location 通过默认的http配置来简单了解http配置文件。 1.10版本时候，http默认配置还是写在/etc/nginx/nginx.conf中，新版本（1.12）的http默认配置是在`/etc/nginx/conf.d/default.conf 我们通过理解nginx.conf里默认的http配置来管中窥豹。后续再去理解一些更精细的参数。 HTTP协议的配置： 123456789101112131415161718192021222324252627282930313233343536373839404142http &#123; # 日志格式 日志别名 log_format main '$remote_addr - $remote_user [$time_local] "$request" ' '$status $body_bytes_sent "$http_referer" ' '"$http_user_agent" "$http_x_forwarded_for"'; # 定义日志路径和使用的日志格式（用上面定义的别名） access_log /var/log/nginx/access.log main; sendfile on; # sendfile零拷贝 tcp_nopush on; # 在sendfile模式下，是否启用TCP_CORK选项 tcp_nodelay on; # 在keepalived模式下的连接是否启用TCP_NODELAY选项 keepalive_timeout 65; # 设定保持连接的超时时长，0表示禁止长连接；默认为65s types_hash_max_size 2048; include /etc/nginx/mime.types; # 支持的MIME类型文件 default_type application/octet-stream; # # Load modular configuration files from the /etc/nginx/conf.d directory. # See http://nginx.org/en/docs/ngx_core_module.html#include # for more information. include /etc/nginx/conf.d/*.conf; # 载入confi.d下的子配置文件 server &#123; listen 80 default_server; # 监听地址；default_server表示是设定为默认虚拟主机 listen [::]:80 default_server; # ipv6的监听地址 server_name _; # 列出所有服务器名称。 root /usr/share/nginx/html; # http服务器的根目录相对于系统的路径 # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; # 载入default.d下的配置文件 location / &#123; # 根据请求URI设置配置，这里请求的URI是/ &#125; error_page 404 /404.html; #设置404错误页面为/404.html, location = /40x.html &#123; # 这里又缩进了一层location，表示404的error_page实际指向是http root目录的40x.html,根据上文root路径，可得出是系统下/usr/share/nginx/html/40x.html &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125; 原理同上，是把500，502 503，504的error_page都定位到/50x.html上 &#125; HTTPS(HTTP with TLS) 12345678910111213141516171819202122232425262728293031# Settings for a TLS enabled server. server &#123; listen 443 ssl http2 default_server; # 端口为443，开启了ssl，协议为HTTP2.0标准，设置为默认服务器。 listen [::]:443 ssl http2 default_server; # ipv6的 server_name _; #服务器名字列表 root /usr/share/nginx/html; # https服务根目录 ssl_certificate "/etc/pki/nginx/server.crt"; # 服务器证书 ssl_certificate_key "/etc/pki/nginx/private/server.key"; # 服务器认证私钥 ssl_session_cache shared:SSL:1m; # SSL会话缓存模式为共享，时间为1分钟。 ssl_session_timeout 10m; # SSL会话超时时间10分钟 ssl_ciphers HIGH:!aNULL:!MD5; ssl_prefer_server_ciphers on; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; # 下同http，略 location / &#123; &#125; error_page 404 /404.html; location = /40x.html &#123; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125; &#125;&#125; 术语：关于sendfile零拷贝，见Linux网络编程–sendfile零拷贝高效率发送文件。]]></content>
      <categories>
        <category>lb</category>
      </categories>
      <tags>
        <tag>default http config</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[03-Nginx主配置文件]]></title>
    <url>%2Flb%2F20170821-03-nginx-global-config%2F</url>
    <content type="text"><![CDATA[Nginx的程序架构Nginx进程： 进程为为master/worker模式 一个master进程：负载加载和分析配置文件、管理worker进程、平滑升级 一个或多个worker进程：处理并响应用户请求 缓存相关的进程： cache loader：载入缓存对象 cache manager：管理缓存对象 Nginx模块： 高度模块化，但其模块早期不支持DSO机制；近期版本支持动态装载和卸载； 模块分类： 核心模块： core module 常用的标准模块： HTTP modules： ngx_http_core_modules http核心功能模块（重要） ngx_http_ssl_module http信道加密模块（重要） ngx_http_upstream_module http定义服务器组模块（重要） ngx_http_fastcgi|uWSGI|SCGI_module http web api接口模块（重要） ngx_http_proxy_module http反向代理模块（重要） ngx_http_gzip_module http gzip压缩传输模块（次一级） ngx_http_log_module http日志模块（次一级） ngx_http_referer_module http防盗链模块（次一级） ngx_http_rewrite_module http重定向模块（次一级） ngx_http_access_module http权限控制模块 ngx_http_auth_basic_module http认证模块 ngx_http_stub_status_module http状态模块 ngx_http_headers_module http首部信息模块 Mail modules： 用的少 Stream modules： ngx_stream_core_module http的伪四层负载均衡模块 第三方模块 Nginx的功用： 静态的web资源服务器；(图片服务器，或js/css/html/txt等静态资源服务器) 结合FastCGI/uwSGI/SCGI等协议反代动态资源请求； http/https协议的反向代理； imap4/pop3协议的反向代理； tcp/udp协议的请求转发； Nginx的安装yum安装最新稳定版： vim /etc/yum.repos.d/nginx.repo 12345[nginx]name=nginx repobaseurl=http://nginx.org/packages/centos/$releasever/$basearch/gpgcheck=0enabled=1 yum install -y nginx epel源安装次新的稳定版： yum install epel-release这是安装的官方的epel源地址。 也可以安装国内的epel镜像源： 如阿里： 12mv /etc/yum.repos.d/epel.repo /etc/yum.repos.d/epel.repo.backupwget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo NGINX程序组成 主程序文件：/usr/sbin/nginx systemd服务：nginx.service 配置文件(/etc/nginx下）： 主配置文件：nginx.conf（include了conf.d/*.conf） fastcgi， uwsgi，scgi等协议相关的配置文件：fastcgi_params、uwsgi_params、scgi_params 支持的MIME类型配置文件：mime.types NGINX主配置文件/etc/nginx/nginx.conf 主配置文件各种配置段的的详细配置选项信息见： http://nginx.org/en/docs/ngx_core_module.html 我们要来理解配置文件的结构： 段：如http{} 、event{}、server{}、location{}等，段可以并列，也可以嵌套。 块：指的就是在段里定义的一组directives（配置指令）。 directive：指的就是块里的一条条配置指令。指令定义方法：directive value [value2 ...];。 注意：(1) 指令必须以分号结尾。(2)嵌套的段是有层级结构的，比如http段里，遵循http{}–&gt;server{}–&gt;location{}这种嵌套结构。(3) 支持使用配置变量： 内建变量：由Nginx模块引入，可直接引用。 自定义变量：由用户使用set命令定义。 定义变量：set variable_name value;。 引用变量：$variable_name 主配置文件结构： 1234567891011121314151617181920212223# main block：主配置段，也即全局配置段...events &#123; # 事件驱动相关的配置段 ...&#125; http &#123; # http block：http/https 协议相关的公共配置段 server &#123; # server block：虚拟主机公共相关配置段 location /xxx &#123; # location block：资源位置相关公共配置段 &#125; ... # 其他location &#125; ... # 其他server&#125; mail &#123; ...&#125;stream &#123; ...&#125; main block主配置段，也即全局配置段main block常见配置指令分类： 正常运行必备的配置 优化性能相关的配置 用于调试及定位问题相关的配置 事件驱动相关的配置 正常运行必备的配置： 1、 user USERNAME; 指定worker进程的运行身份，如组不指定，默认和用户名同名。如果不写user字段，默认为nobody用户和nobody组。 2、pid /PATH/TO/PID_FILE; 指定存储nginx主进程进程号码的文件路径 3、 include file | mask; 指明包含进来的其它配置文件片断 4、load_module file /usr/share/nginx/modules/*.conf 指明要装载的动态模块路径。例如geoip.conf文件里：load_module &quot;/usr/lib64/nginx/modules/ngx_http_geoip_module.so&quot;; 性能优化相关的配置： 1、worker_processes NUMBER | auto; worker进程的数量；NUMBER通常应该等于小于当前主机的cpu的物理核心数。auto：自动为当前主机物理CPU核心数。例如：worker_processes 4 2、worker_cpu_affinity cpumask ...; worker_cpu_affinity auto |CPUMASK;nginx进程的CPU亲缘性，配置cpumask可以指定绑定CPU 123456CPU MASK：0000 0001：0号CPU0000 0010：1号CPU0000 0100：2号CPU... ...0000 0011：0和1号CPU 例如如果nginx进程为4个的话，worker_cpu_affinity 0001 0010 0100 1000;就是把4个nginx进程分别绑在0123号cpu上。例如如果nginx进程为4个的话，worker_cpu_affinity 0101 1010;就是把第一个nginx进程绑在0和2号cpu上，第二个cpu进程绑在1和3号cpu上 3、worker_priority NUMBER; 指定worker进程的nice值，设定worker进程优先级：[-20,20] 4、worker_rlimit_nofile NUMBER; 单个worker进程所能够打开的文件数量上限,如65535 调试、定位问题相关配置： 1、daemon on|off; 是否以守护进程方式运行nignx，默认是on，守护进程方式 2、master_process on|off; 是否以master/worker模型运行nginx；默认为on，off将不启动worker 3、error_log PATH/TO/LOGFILE [LEVEL]; PATH/TO/LOGFILE 为日志文件路径LEVEL为日志级别,一般不修改，出于调试需要，可设定为debug。系统默认为：error_log /var/log/nginx/error.log; 事件驱动相关的配置: 写在events里面 events { ... } 1、worker_connections number; 每个worker进程所能够打开的最大并发连接数数量，如 10240总最大并发数：worker_processes * worker_connections 2、use METHOD 指明并发连接请求的处理方法 ,一般不用设置，Nginx会默认自动选择适合系统的最优方法。 如果系统是Linux，会自动使用epoll方法；如果是FreeBSD和macOS，会自动使用kqueue；如果是Solaris和HP/UX，会自动使用/dev/poll。有两个普通方法select和poll，已经被淘汰，不做讨论。 3、accept_mutex on | off 是否接受互斥。指的是处理新的连接请求的方法；on指由各个worker轮流处理新请求 ，Off指每个新请求的到达都会通知(唤醒)所有的worker进程，但 只有一个进程可获得连接，造成“惊群”，影响性能，默认on]]></content>
      <categories>
        <category>lb</category>
      </categories>
      <tags>
        <tag>IO model</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[02-IO模型]]></title>
    <url>%2Flb%2F20170821-02-io-model%2F</url>
    <content type="text"><![CDATA[转载自：我本善良 几大模型： Blocking IO（阻塞型IO） Non-Blocking IO（非阻塞型IO） IO multiplexing（IO复用型）：select，poll signal driven I/O（事件驱动型IO）：epoll（Linux）、Kqueue（BSD）、/dev/poll（Solaris） Asynchronous I/O（异步IO） 概括来说，一个IO操作可以分为两个部分：发出请求、结果完成。如果从发出请求到结果返回，一直Block，那就是Blocking IO；如果发出请求就可以返回（结果完成不考虑），就是non-blocking IO；如果发出请求就返回，结果返回是Block在select或者poll上的，则其只能称为IO multiplexing；如果发出请求就返回，结果返回通过Call Back的方式被处理，就是AIO。 Blocking IO这个最好理解了，在Blocking IO模式下，函数调用只有在操作完成后才会返回。下图是它调用过程的图示： 重点解释下上图，下面例子都会讲到。首先application调用 recvfrom()转入kernel，注意kernel有2个过程，wait for data和copy data from kernel to user。直到最后copy complete后，recvfrom()才返回。此过程一直是阻塞的。 Non-Blocking IONon-Blocking 是Blocking的反，也就是说，即使操作没有完成，函数也可以返回。调用过程如下： 可以看见，如果直接操作它，那就是个轮询。。直到内核缓冲区有数据 AIO也是这样啊？对！这是Non-Blocking IO 和AIO的共同点。其实从概念层面来说Non-Blocking IO 就是AIO，他们没有什么区别。但是Non-Blocking IO是对文件描述符（*nix）或者Handle（Windows）的设置，在执行操作时不需要特殊的数据结构。Non-Blocking IO提交请求后只能通过提交的操作函数来查询操作是否完成，这是一个很大的限制。而AIO往往会提供多种通知或者查询机制，也就是说用Non-Blocking IO时只能轮询，而AIO有更多选择。所以是否支持轮询外的其他机制是AIO和Non-Blocking IO的区别。 Non-Blocking IO和Blocking IO的区别仅仅在操作是否能够立刻完成，如果能够立刻完成，IO函数的行为是一样的；如果不能立刻完成，Non-Blocking IO会返回EAGAIN或者EWOULDBLOCK，而Blocking IO会一直阻塞。 IO multiplexing (select and poll)最常见的I/O复用模型，select。 select先阻塞，有活动套接字才返回。与blocking I/O相比，select会有两次系统调用，但是select能处理多个套接字。 signal driven IO (SIGIO) 与I/O multiplexing (select and poll)相比，它的优势是，免去了select的阻塞与轮询，当有活跃套接字时，由注册的handler处理。 Asynchronous IOAIO让应用发起一个操作请求，让这个请求被异步地执行。应用可以选择在操作完成时被通知到或者不被通知。所以通知机制并不是AIO的核心，但是需要提供几种方案的选择。 完全异步的I/O复用机制，因为纵观上面其它四种模型，至少都会在由kernel copy data to application时阻塞。而该模型是当copy完成后才通知application，可见是纯异步的。 Nginx官方并没有实现AIO模块，Linux官方提供了AIO库函数来实现AIO，但是用的很少。目前有很多开源的AIO库，如libevent、libev、libuv都很不错。 下面是以上五种模型的比较 可以看出，越往后，阻塞越少，理论上效率也是最优。 下面可以把select,epoll,iocp,kqueue按号入座。 select和iocp分别对应第3种与第5种模型，那么epoll与kqueue呢？其实也于select属于同一种模型，只是更高级一些，可以看作有了第4种模型的某些特性，如callback机制。 那么，为什么epoll,kqueue比select高级？ 答案是，他们无轮询。因为他们用callback取代了。想想看，当套接字比较多的时候，每次select()都要通过遍历FD_SETSIZE个Socket来完成调度,不管哪个Socket是活跃的,都遍历一遍。这会浪费很多CPU时间。如果能给套接字注册某个回调函数，当他们活跃时，自动完成相关操作，那就避免了轮询，这正是epoll与kqueue做的。 提供一致的接口，IO Design Patterns 实际上，不管是哪种模型，都可以抽象一层出来，提供一致的接口，广为人知的有ACE,Libevent这些，他们都是跨平台的，而且他们自动选择最优的I/O复用机制，用户只需调用接口即可。说到这里又得说说2个设计模式，Reactor and Proactor。有一篇经典文章http://www.artima.com/articles/io_design_patterns.html值得阅读，Libevent是Reactor模型，ACE提供Proactor模型。实际都是对各种I/O复用机制的封装。 总结一些重点： 只有IOCP是asynchronous I/O，其他机制或多或少都会有一点阻塞。 select低效是因为每次它都需要轮询，但低效也是相对的，视情况而定，也可通过良好的设计改善。 epoll, kqueue是Reacor模式，IOCP是Proactor模式。]]></content>
      <categories>
        <category>lb</category>
      </categories>
      <tags>
        <tag>IO model</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[01-Nginx简介]]></title>
    <url>%2Flb%2F20170821-01-nginx-introduction%2F</url>
    <content type="text"><![CDATA[Nginx （是engine x的缩写） 是一个HTTP server（HTTP服务器）和HTTP reverse proxy server（HTTP反向代理服务器），一个mail proxy server（邮件代理服务器）, 一个 通用 TCP/UDP proxy server（TCP/UDP反向代理服务器）。 Nginx工作在OSI模型的七层，也可以提供伪四层负载均衡。 Nginx是一个scalable event-driven（asynchronous）architecture，即可伸缩的事件驱动型（异步）架构。 国内的基于Nginx的二次开发版本： Tengine OpenResty Nginx三大核心功能： http Web服务器（类似于httpd的功能） HTTP reverse proxy Server（httpd也有类似的功能） mail Mail proxy server，支持icmp/pop3/smtp stream TCP/UDP proxy server（类似于lvs，不过是伪四层代理，效率没有lvs高） HTTP的几个概念术语URI统一资源定位符（Uniform Resource Identifier） scheme:[//[user[:password]@]host[:port]][/path][?query][#fragment] 例子： fragment,可以通过访问下面网站来实验： PV、UVPV: Page ViewUV: User View http事务：request&lt;–&gt;response Headers: 通用头部（General Headers） 请求头部（Response Headers） 回应头部（Request Headers） Method：GET/HEAD/POST(常用）, PUT/DELETE, TRACE, OPTIONS 常用Status Code(状态码）： 2xx：成功类响应码，200（OK）等 3xx：重定向类的响应码，301（永久重定向,permenent）、302（临时重定向,termina）、304（Not Modified，从上次访问后未发生改变） 4xx：客户端错误：403(Forbidden)，404(Not Found) 5xx：服务器端错误，502(Bad Gateway)、503 （Service Unavailable） 认证（Auth）： 基于IP认证 基于用户认证：basic（基于htpasswd生成的用户文件认证）/digest（摘要认证） httpd MPM： prefork：进程模型，两级结构，主进程master负责生成prefork子进程，每个子进程相应一个请求。 worker：线程模型，三级结构，主进程master负责生成子进程worker，每个worker子进程负责生成多个worker线程，每个worker线程相应一个请求。 event：主进程master负责生成子进程event，每个event子进程基于事件驱动机制相应多个请求。 文件描述符（file descriptor，简写fd）内核（kernel）利用文件描述符（file descriptor）来访问文件。文件描述符是非负整数。打开现存文件或新建文件时，内核会返回一个文件描述符。读写文件也需要使用文件描述符来指定待读写的文件。 在设备读写（IO）、网络通信、进程通信，fd可谓是关键中的关键。 IO类型“阻塞”与”非阻塞”与”同步”与“异步”不能简单的从字面理解，提供一个从分布式系统角度的回答。 1.同步(Synchronous)与异步(Asynchronous)同步和异步关注的是消息通信机制 (synchronous communication/ asynchronous communication)所谓同步，就是在发出一个调用时，在没有得到结果之前，该调用就不返回。但是一旦调用返回，就得到返回值了。 换句话说，就是由调用者主动等待这个调用的结果。 而异步则是相反，调用在发出之后，这个调用就直接返回了，但是没有返回最终结果。换句话说，当一个异步过程调用发出后，调用者不会立刻得到结果。而是在调用发出后，被调用者通过状态、通知来通知调用者，或通过回调函数处理这个调用。 典型的异步编程模型比如Node.js，Python的asyncio。 举个通俗的例子：你打电话问书店老板有没有《分布式系统》这本书，如果是同步通信机制，书店老板会说，你稍等，我查一下”，然后开始查啊查，等查好了（可能是5秒，也可能是一天）告诉你结果（返回结果）。而异步通信机制，书店老板直接告诉你我查一下啊，查好了打电话给你，然后直接挂电话了（不返回结果）。然后查好了，他会主动打电话给你。在这里老板通过“回电”这种方式来回调。 2. 阻塞(Blocking）与非阻塞IO(Non-Blocking)阻塞和非阻塞关注的是程序在等待调用结果（消息，返回值）时的状态。 阻塞调用是指调用结果返回之前，当前线程会被挂起。调用线程只有在得到结果之后才会返回。 非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程。 还是上面的例子:你打电话问书店老板有没有《分布式系统》这本书，你如果是阻塞式调用，你会一直把自己“挂起”，直到得到这本书有没有的结果，如果是非阻塞式调用，你不管老板有没有告诉你，你自己先一边去玩了， 当然你也要偶尔过几分钟check一下老板有没有返回结果。在这里阻塞与非阻塞与是否同步异步无关。跟老板通过什么方式回答你结果无关。 3. 同步阻塞、同步非阻塞、异步阻塞、异步非阻塞 老张爱喝茶，废话不说，煮开水。出场人物：老张，水壶两把（普通水壶，简称水壶；会响的水壶，简称响水壶）。 （1）老张把水壶放到火上，立等水开。（同步阻塞）老张觉得自己有点傻。 （2）老张把水壶放到火上，去客厅看电视，时不时去厨房看看水开没有。（同步非阻塞）老张还是觉得自己有点傻，于是变高端了，买了把会响笛的那种水壶。水开之后，能大声发出嘀~~~~的噪音。 （3）老张把响水壶放到火上，立等水开。（异步阻塞）老张觉得这样傻等意义不大。 （4）老张把响水壶放到火上，去客厅看电视，水壶响之前不再去看它了，响了再去拿壶。（异步非阻塞）老张觉得自己聪明了。 所谓同步异步，只是对于水壶而言。普通水壶，同步；响水壶，异步。虽然都能干活，但响水壶可以在自己完工之后，提示老张水开了。这是普通水壶所不能及的。同步只能让调用者去轮询自己（情况2中），造成老张效率的低下。 所谓阻塞非阻塞，仅仅对于老张而言。立等的老张，阻塞；看电视的老张，非阻塞。 情况1和情况3中老张就是阻塞的，媳妇喊他都不知道。虽然3中响水壶是异步的，可对于立等的老张没有太大的意义。所以一般异步是配合非阻塞使用的，这样才能发挥异步的效用。 – 来自知乎：怎样理解阻塞非阻塞与同步异步的区别？ 下一节我们来了解一下IO模型，IO模型不光Nginx有设计，其他服务也会涉及。]]></content>
      <categories>
        <category>lb</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx系列文章]]></title>
    <url>%2Flb%2F20170821-00-nginx-content%2F</url>
    <content type="text"><![CDATA[✔01-Nginx简介 ✔02-IO模型 ✔03-Nginx的主配置文件 ✔04-Nginx的默认http配置 ✔05-ngx_http_core_module详解 ✔06-Nginx的HTTP相关的杂项模块 ✔07-ngx_http_proxy_module详解 ✔08-ngx_http_fastcgi_module详解 ✔09-ngx_http_upstream_module详解 ✔10-ngx_stream*_module详解]]></content>
      <categories>
        <category>lb</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LVS/NAT实验]]></title>
    <url>%2Flb%2F20170819-03-lvs-nat%2F</url>
    <content type="text"><![CDATA[LVS/NAT模式，在VS和RS之间有路由。 上图中，假设172.16.111.0网段都是外网。 实验采用Vagrant配置网络和主机信息。Vagrant的用法可参考Vagrant–快速搭建实验环境利器。 服务器 IP client 172.16.111.123（假装是外网） vs 172.16.111.200（假装是外网）/192.168.111.200（内网） rs1 192.168.111.101（内网，网关指向vs） rs2 192.168.111.102（内网，网关指向vs） Vagrantfile配置文件： 12345678910111213141516171819202122232425262728293031323334353637Vagrant.configure("2") do |config| # config为全局配置文件 config.vm.box = "longdream/centos7" # 这里是我自定义的centos7模板 config.hostmanager.enabled = true # 启用hostmanager插件 config.hostmanager.manage_guest = true # 允许更新虚拟机上的hosts文件 config.hostmanager.manage_host = true # 允许更新主机上的hosts文件 # 定义Client config.vm.define "client" do |client| client.vm.network "private_network", ip: "172.16.111.123" client.vm.hostname = "client" client.vm.provision "shell", inline: "sudo bash /vagrant/client.sh" end # 定义VS config.vm.define "vs" do |vs| vs.vm.network "private_network", ip: "172.16.111.200" vs.vm.network "private_network", ip: "192.168.111.200" vs.vm.hostname = "vs" vs.vm.provision "shell", inline: "sudo bash /vagrant/vs.sh" end # 定义RS1 config.vm.define "rs1" do |rs1| rs1.vm.network "private_network", ip: "192.168.111.101" rs1.vm.hostname = "rs1" rs1.vm.provision "shell", inline: "sudo bash /vagrant/rs1.sh" end # 定义RS2 config.vm.define "rs2" do |rs2| rs2.vm.network "private_network", ip: "192.168.111.102" rs2.vm.hostname = "rs2" rs2.vm.provision "shell", inline: "sudo bash /vagrant/rs2.sh" endend Vagrantfile里每一台机器都运行了相应的脚本。 Client: client.sh 1234#!/bin/bashecho &gt;&gt; /etc/sysconfig/network-scripts/ifconfig-eth1 &lt;&lt;EOFGATEWAY=172.16.111.200EOF VS: vs.sh 12345#!/bin/bashecho "net.ipv4.ip_forward=1" &gt;&gt; /etc/sysctl.confecho 1 &gt; /proc/sys/net/ipv4/ip_forwardyum install -y ipvsadmbash /vagrant/vs-nat-rr.sh start vs.sh引用的vs-nat-rr.sh来启动VS。 vs-nat-rr.sh： 123456789101112131415161718192021#!/bin/bashvip=172.16.111.200mode=m # m为NAT模式，g为DR模式，i为tun模式schdule=rrrip1=192.168.111.101rip2=192.168.111.102case $1 instart) ipvsadm -A -t $vip:80 -s $schdule ipvsadm -a -t $vip:80 -r $rip1 -$mode ipvsadm -a -t $vip:80 -r $rip2 -$mode ;;stop) ipvsadm -C ;;*) echo "Usage: `basename $0` start|stop" exit 1 ;;esac RS1 rs1.sh： 123456789101112#!/bin/bashecho 'GATEWAY=192.168.111.200' &gt;&gt; /etc/sysconfig/network-scripts/ifcfg-eth1ifdown eth1 &amp;&amp; ifup eth1yum install -y httpdcat &gt;/var/www/html/index.html&lt;&lt;EOFReal Server 1EOFsystemctl enable httpdsystemctl start httpd RS2 rs2.sh： 123456789101112#!/bin/bashecho 'GATEWAY=192.168.111.200' &gt;&gt; /etc/sysconfig/network-scripts/ifcfg-eth1ifdown eth1 &amp;&amp; ifup eth1yum install -y httpdcat &gt;/var/www/html/index.html&lt;&lt;EOFReal Server 2EOFsystemctl enable httpdsystemctl start httpd vagrant up启动所有机器后，在Virtualbox里关掉所有虚机的eth0（vagrant创建虚机时候，默认的一个NAT网络，默认在eth0上，关闭它以防止对实验造成影响）： 1ifdown eth0 然后从Client虚机里运行： bash /vagrant/client-test.sh进行测试： 1234567#!/bin.bash# 测试LVSvip=172.16.111.200for i in `seq 100`;do curl --connect-timeout 1 $vip sleep 1done]]></content>
      <categories>
        <category>lb</category>
      </categories>
      <tags>
        <tag>LVS</tag>
        <tag>LVS/NAT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LVS/DR实验]]></title>
    <url>%2Flb%2F20170819-02-lvs-dr%2F</url>
    <content type="text"><![CDATA[LVS/DR模式,数据流来的时候走VS，回去的时候调度到RS上，然后用VIP的作为源地址返回回去。 实验采用Vagrant配置网络和主机信息。Vagrant的用法可参考Vagrant–快速搭建实验环境利器。 Vagrantfile配置文件： 1234567891011121314151617181920212223242526272829303132333435363738394041424344Vagrant.configure("2") do |config| # config为全局配置文件 config.vm.box = "longdream/centos7" # 这里是我自定义的centos7模板 config.hostmanager.enabled = true # 启用hostmanager插件 config.hostmanager.manage_guest = true # 允许更新虚拟机上的hosts文件 config.hostmanager.manage_host = true # 允许更新主机上的hosts文件 # 定义Client config.vm.define "client" do |client| client.vm.network "private_network", ip: "172.16.111.123" client.vm.hostname = "client" client.vm.provision "shell", inline: "sudo bash /vagrant/client.sh" end # 定义Router config.vm.define "router" do |router| router.vm.network "private_network", ip: "172.16.111.222" router.vm.network "private_network", ip: "192.168.111.222" router.vm.hostname = "router" router.vm.provision "shell", inline: "sudo bash /vagrant/router.sh" end # 定义VS config.vm.define "vs" do |vs| vs.vm.network "private_network", ip: "192.168.111.100" vs.vm.hostname = "vs" vs.vm.provision "shell", inline: "sudo bash /vagrant/vs.sh" end # 定义RS1 config.vm.define "rs1" do |rs1| rs1.vm.network "private_network", ip: "192.168.111.101" rs1.vm.hostname = "rs1" rs1.vm.provision "shell", inline: "sudo bash /vagrant/rs1.sh" end # 定义RS2 config.vm.define "rs2" do |rs2| rs2.vm.network "private_network", ip: "192.168.111.102" rs2.vm.hostname = "rs2" rs2.vm.provision "shell", inline: "sudo bash /vagrant/rs2.sh" endend Vagrantfile里每一台机器都运行了相应的脚本。 Client: client.sh 123#!/bin/bashecho "GATEWAY=172.16.111.222" &gt;&gt; /etc/sysconfig/network-scripts/ifcfg-eth1ifdown eth1 &amp;&amp; ifup eth1 Router: router.sh 123#!/bin/bashecho "net.ipv4.ip_forward=1" &gt;&gt;/etc/sysctl.confecho 1 &gt; /proc/sys/net/ipv4/ip_forward VS: vs.sh 12345#!/bin/bashecho "GATEWAY=192.168.111.222" &gt;&gt; /etc/sysconfig/network-scripts/ifcfg-eth1ifdown eth1 &amp;&amp; ifup eth1yum install -y ipvsadmbash /vagrant/vs-dr-wlc.sh start vs.sh引用的vs-dr-wlc.sh来启动VS。 vs-dr-wlc.sh： 123456789101112131415161718192021222324#!/bin/bashvip=192.168.111.200mode=g # m为NAT模式，g为DR模式，i为tun模式schdule=wlcrip1=192.168.111.101rip2=192.168.111.102dev=lo:1case $1 instart) ifconfig $dev $vip netmask 255.255.255.255 broadcast $vip up ipvsadm -A -t $vip:80 -s $schdule ipvsadm -a -t $vip:80 -r $rip1 -$mode -w 3 ipvsadm -a -t $vip:80 -r $rip2 -$mode -w 1 ;;stop) ipvsadm -C ifconfig $dev down ;;*) echo "Usage: `basename $0` start|stop" exit 1 ;;esac RS1 rs1.sh： 1234567891011121314#!/bin/bashecho "GATEWAY=192.168.111.222" &gt;&gt; /etc/sysconfig/network-scripts/ifcfg-eth1ifdown eth1 &amp;&amp; ifup eth1yum install -y httpdcat &gt;/var/www/html/index.html&lt;&lt;EOFReal Server 1EOFsystemctl enable httpdsystemctl start httpdbash /vagrant/rs-config.sh start RS2 rs2.sh： 1234567891011121314#!/bin/bashecho "GATEWAY=192.168.111.222" &gt;&gt; /etc/sysconfig/network-scripts/ifcfg-eth1ifdown eth1 &amp;&amp; ifup eth1yum install -y httpdcat &gt;/var/www/html/index.html&lt;&lt;EOFReal Server 2EOFsystemctl enable httpdsystemctl start httpdbash /vagrant/rs-config.sh start 两个RS都调用的一个脚本 rs-config.sh 12345678910111213141516171819202122232425#!/bin/bashvip=192.168.111.200dev=lo:1case $1 instart) echo 1 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo 1 &gt; /proc/sys/net/ipv4/conf/lo/arp_ignore echo 2 &gt; /proc/sys/net/ipv4/conf/all/arp_announce echo 2 &gt; /proc/sys/net/ipv4/conf/lo/arp_announce ifconfig $dev $vip netmask 255.255.255.255 broadcast $vip up echo "VS Server is Ready!" ;;stop) ifconfig $dev down echo 0 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo 0 &gt; /proc/sys/net/ipv4/conf/lo/arp_ignore echo 0 &gt; /proc/sys/net/ipv4/conf/all/arp_announce echo 0 &gt; /proc/sys/net/ipv4/conf/lo/arp_announce echo "VS Server is Cancel!" ;;*) echo "Usage `basename $0` start|stop" exit 1 ;;esac vagrant up启动所有机器后，在Virtualbox里关掉所有虚机的eth0（vagrant创建虚机时候，默认的一个NAT网络，默认在eth0上，关闭它以防止对实验造成影响）： 1ifdown eth0 然后从Client虚机里运行： bash /vagrant/client-test.sh进行测试： 1234567#!/bin.bash# 测试LVSvip=192.168.111.200for i in `seq 100`;do curl --connect-timeout 1 $vip sleep 1done]]></content>
      <categories>
        <category>lb</category>
      </categories>
      <tags>
        <tag>LVS</tag>
        <tag>LVS/DR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LVS原理、模式、调度算法]]></title>
    <url>%2Flb%2F20170817-01-lvs-introduction%2F</url>
    <content type="text"><![CDATA[我们先来讲一下集群和负载均衡。 一、集群和负载均衡1. scale up和scale out当业务量越来越大的时候，我们就要对系统进行扩展，扩展有两种方式： scale up: 纵向扩展，即增强服务器的性能。买买买！但是性能越好的服务器价格成几何倍数增长…… scale out: 线性扩展，即增加服务器的数量，然后用调度来解决分配资源，这就是集群（Cluster）的由来。 2. 集群和分布式集群（Cluster）定义：为解决某个特定问题将多台计算机组合起来形成的单个系统 Cluster类型： LB：Load Balancing，负载均衡。 HA：High Availiablity，高可用。 HPC：High-Performance Computing，高性能计算。（www.top500.org） 与集群相对应的是分布式系统（distributed system）。 集群和分布式的区别，简单来说就是： 集群：同一个业务，部署在多个服务器上。 分布式：一个业务分拆多个子业务，部署在不同的服务器上。 举个例子大家更能明白： 一个小饭店原来只有一个厨师，切菜洗菜备料炒菜全干。后来客人多了，厨房一个厨师忙不过来，又请了个厨师，两个厨师都能炒一样的菜，这两个厨师的关系是集群。为了让厨师专心炒菜，把菜做到极致，又请了个配菜师负责切菜，备菜，备料，厨师和配菜师的关系是分布式，一个配菜师也忙不过来了，又请了个配菜师，两个配菜师关系是集群链接。–本段文字来源。 3. 负载均衡集群负载均衡集群的实现： 硬件： F5: BIG-IP Citrix: NetScaler A10: A10 软件： LVS HAproxy Nginx ats(apache traffic server) perlbal 软件中，LVS, HAproxy, Nginx用的比较多，重点学习就是这3个。 我们重点学习头3种：LVS, HAproxy ,Nginx 关于这三种的优缺点可以看这篇文章：Nginx/LVS/HAProxy负载均衡软件的优缺点详解 本文主要讲集群中的负载均衡中的一个：lvs（Linux Virtual Server）,LVS基于ISO七层模型中的4层传输层。 二、LVS基本术语和组成1. LVS基本术语LVS集群类型中的术语： VS：Virtual Server，Director，Dispatcher(调度器)，Load Balancer RS：Real Server(lvs里)， upstream server(nginx里)，backend server(haproxy里)、Replica（副本） CIP：Client IP 客户端ip VIP: Virtual server IP VS外网的IP DIP: Director IP VS内网的IP RIP: Real server IP 2. LVS软件组成LVS 由2部分程序组成，包括 ipvs 和 ipvsadm。 ipvs(ip virtual server)：一段代码工作在内核空间，叫ipvs，是真正生效实现调度的代码。 ipvsadm：另外一段是工作在用户空间，叫ipvsadm，负责为ipvs内核框架编写规则，定义谁是集群服务，而谁是后端真实的服务器(Real Server)。 LVS基本工作原理 当用户向负载均衡调度器（VS或者叫LB）发起请求，调度器将请求发往至内核空间。 PREROUTING链首先会接收到用户请求，判断目标IP确定是本机IP，将数据包发往INPUT链。 IPVS是工作在INPUT链上的，当用户请求到达INPUT时，IPVS会将用户请求和自己已定义好的集群服务进行比对，如果用户请求的就是定义的集群服务，那么此时IPVS会强行修改数据包里的目标IP地址及端口，并将新的数据包发往POSTROUTING链。 POSTROUTING链接收数据包后发现目标IP地址刚好是自己的后端服务器，那么此时通过选路，将数据包最终发送给后端的服务器。 LVS各种模式原理lvs集群的类型： LVS/NAT： NAT模式。修改请求报文的目标IP,多目标IP的DNAT。 LVS/DR：DirectRouting（直接路由）。操纵封装新的MAC地址。 LVS/TUN：Tunneling（隧道）。在原请求IP报文之外新加一个IP首部。 LVS/FULLNAT：Full NAT。修改请求报文的源和目标IP。 1. LVS/NATLVS/NAT 最基本的LVS策略 如图: 客户端(Client) -&gt; LB（VS） -&gt; replica1(RS1),replica2(RS2),replica3(RS3) 详细的数据包的流转图： (a). 当用户请求到达Director Server，此时请求的数据报文会先到内核空间的PREROUTING链。 此时报文的源IP为CIP，目标IP为VIP(b). PREROUTING检查发现数据包的目标IP是本机，将数据包送至INPUT链(c). IPVS比对数据包请求的服务是否为集群服务，若是，修改数据包的目标IP地址为后端服务器IP，然后将数据包发至POSTROUTING链。 此时报文的源IP为CIP，目标IP为RIP(d). POSTROUTING链通过选路，将数据包发送给Real Server(e). Real Server比对发现目标为自己的IP，开始构建响应报文发回给Director Server。 此时报文的源IP为RIP，目标IP为CIP(f). Director Server在响应客户端前，此时会将源IP地址修改为自己的VIP地址，然后响应给客户端。 此时报文的源IP为VIP，目标IP为CIP 2. LVS/DR很多时候，相应流是比请求流大的，如下图： 所以有第二种方案，响应流不走LB，这就是LVS/DR模式： 详细的数据包的流转图： (a) 当用户请求到达Director Server，此时请求的数据报文会先到内核空间的PREROUTING链。 此时报文的源IP为CIP，目标IP为VIP(b) PREROUTING检查发现数据包的目标IP是本机，将数据包送至INPUT链(c) IPVS比对数据包请求的服务是否为集群服务，若是，将请求报文中的源MAC地址修改为DIP的MAC地址，将目标MAC地址修改RIP的MAC地址，然后将数据包发至POSTROUTING链。 此时的源IP和目的IP均未修改，仅修改了源MAC地址为DIP的MAC地址，目标MAC地址为RIP的MAC地址(d) 由于DS和RS在同一个网络中，所以是通过二层来传输。POSTROUTING链检查目标MAC地址为RIP的MAC地址，那么此时数据包将会发至Real Server。(e) RS发现请求报文的MAC地址是自己的MAC地址，就接收此报文。处理完成之后，将响应报文通过lo接口传送给eth0网卡然后向外发出。 此时的源IP地址为VIP，目标IP为CIP(f) 响应报文最终送达至客户端 LVS-DR模型的特性 特点1：保证前端路由将目标地址为VIP报文统统发给Director Server，而不是RS。 RS可以使用私有地址；也可以是公网地址，如果使用公网地址，此时可以通过互联网对RIP进行直接访问。 RS跟Director Server必须在同一个物理网络中。 所有的请求报文经由Director Server，但响应报文必须不能进过Director Server。 不支持地址转换，也不支持端口映射。 RS可以是大多数常见的操作系统。 RS的网关绝不允许指向DIP(因为我们不允许他经过director)。 RS上的lo接口配置VIP的IP地址。 缺陷：RS和DS必须在同一机房中。 特点1的解决方案： 在前端路由器做静态地址路由绑定，将对于VIP的地址仅路由到Director Server。 存在问题：用户未必有路由操作权限，因为有可能是运营商提供的，所以这个方法未必实用。 arptables：在arp的层次上实现在ARP解析时做防火墙规则，过滤RS响应ARP请求。这是由iptables提供的 修改RS上内核参数（arp_ignore和arp_announce）将RS上的VIP配置在lo接口的别名上，并限制其不能响应对VIP地址解析请求。 3. LVS/TUN在原有的IP报文外再次封装多一层IP首部，内部IP首部(源地址为CIP，目标IIP为VIP)，外层IP首部(源地址为DIP，目标IP为RIP) (a) 当用户请求到达Director Server，此时请求的数据报文会先到内核空间的PREROUTING链。 此时报文的源IP为CIP，目标IP为VIP 。(b) PREROUTING检查发现数据包的目标IP是本机，将数据包送至INPUT链。(c) IPVS比对数据包请求的服务是否为集群服务，若是，在请求报文的首部再次封装一层IP报文，封装源IP为为DIP，目标IP为RIP。然后发至POSTROUTING链。 此时源IP为DIP，目标IP为RIP 。(d) POSTROUTING链根据最新封装的IP报文，将数据包发至RS（因为在外层封装多了一层IP首部，所以可以理解为此时通过隧道传输）。 此时源IP为DIP，目标IP为RIP。(e) RS接收到报文后发现是自己的IP地址，就将报文接收下来，拆除掉最外层的IP后，会发现里面还有一层IP首部，而且目标是自己的lo接口VIP，那么此时RS开始处理此请求，处理完成之后，通过lo接口送给eth0网卡，然后向外传递。 此时的源IP地址为VIP，目标IP为CIP。(f) 响应报文最终送达至客户端。 LVS-TUN模型特性 RIP、VIP、DIP全是公网地址。 RS的网关不会也不可能指向DIP。 所有的请求报文经由Director Server，但响应报文必须不能进过Director Server。 不支持端口映射。 RS的系统必须支持隧道。 4. LVS/FULLNATlvs-fullnat：通过同时修改请求报文的源IP地址和目标IP地址进行转发: CIP –&gt; DIP VIP –&gt; RIP (1) VIP是公网地址，RIP和DIP是私网地址，且通常不在同一IP网络；因此，RIP的网关一般不会指向DIP。 (2) RS收到的请求报文源地址是DIP，因此，只需响应给DIP；但Director还要将其发往Client。 (3) 请求和响应报文都经由Director。 (4) 支持端口映射。 注意：此类型kernel默认不支持。 LVS工作模式总结 VS/NAT VS/TUN VS/DR server any tunneling non-arp device server network private LAN/WAN LAN server number low (10~20) high high server gateway load balancer own router own router LVS/NAT, LVS/FULLNAT：请求和响应报文都经由VS LVS/NAT：RIP的网关要指向DIP LVS/FULLNAT：RIP和DIP未必在同一IP网络，但要能通信 LVS/DR, LVS/TUN：请求报文要经由VS，但响应报文由RS直接发往Client LVS/DR：通过封装新的MAC首部实现，通过MAC网络转发 LVS/TUN：通过在原IP报文之外封装新的IP报文实现转发，支持远距离通信 其实企业中最常用的是 DR 实现方式，而 NAT 配置上比较简单和方便，后边实践中会总结 DR 和 NAT 具体使用配置过程。 LVS调度算法根据其调度时是否考虑各RS当前的负载状态，分为静态方法和动态方法。 静态方法：仅根据算法本身进行调度 RR：roundrobin，轮询。 WRR：Weighted RR，加权轮询。 SH：Source Hashing，实现session sticky，源IP地址hash；将来自于同一个IP地址的请求始终发往第一次挑中的RS，从而实现会话绑定。 DH：Destination Hashing；目标地址哈希，将发往同一个目标地址的请求始终转发至第一次挑中的RS，典型使用场景是正向代理缓存场景中的负载均衡，如：宽带运营商。 动态方法：主要根据每RS当前的负载状态及调度算法进行调度，Overhead=value较小的RS将被调度。 LC：least connections，最少连接，适用于长连接应用。Overhead=activeconns*256+inactiveconns WLC：Weighted LC，加权最少连接，默认调度方法。Overhead=(activeconns*256+inactiveconns)/weight SED：Shortest Expection Delay,初始连接高权重优先。Overhead=(activeconns+1)*256/weight NQ：Never Queue，第一轮均匀分配，后续SED。 LBLC：Locality-Based LC，动态的DH算法，使用场景： 根据负载状态实现正向代理。 LBLCR：LBLC with Replication，带复制功能的LBLC，解决LBLC负载不均衡问题，从负载重的复制到负载轻的RS。 部分内容转自：使用LVS实现负载均衡原理及安装配置详解图片部分来自：章文嵩博士和他背后的负载均衡帝国]]></content>
      <categories>
        <category>lb</category>
      </categories>
      <tags>
        <tag>LVS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[防火墙Netfilter/iptables]]></title>
    <url>%2Flinux%2F20170815-iptables%2F</url>
    <content type="text"><![CDATA[Netfilter/iptables原理 Netfilter组件： 内核空间，集成在linux内核中 扩展各种网络服务的结构化底层框架 内核中选取五个位置放了五个hook function（勾子函数）(INPUT、OUTPUT、FORWARD、PREROUTING、POSTROUTING)， 而这五个hook function向用户开放，用户可以通过一个命令工 具（iptables）向其写入规则。 由信息过滤表（table）组成，包含控制IP包处理的规则集（ rules），规则被分组放在链（chain）上 三种报文流向： 流入本机：PREROUTING –&gt; INPUT–&gt;用户空间进程 流出本机：用户空间进程 –&gt;OUTPUT–&gt; POSTROUTING 转发：PREROUTING –&gt; FORWARD –&gt; POSTROUTING iptables由四个表和五个链以及一些规则组成: 四个表(table)： filter:过滤规则表，根据预定义的规则过滤符合条件的数据包 nat:network address translation 地址转换规则表 mangle:修改数据标记位规则表 Raw:关闭NAT表上启用的连接跟踪机制，加快封包穿越防火墙速度 优先级由高到低的顺序为:raw–&gt;mangle–&gt;nat–&gt;filter 五个内置链(chain)： INPUT OUTPUT FORWARD PREROUTING POSTROUTING Netfilter/iptables Packet Flow： 内核中数据包的传输过程 当一个数据包进入网卡时，数据包首先进入PREROUTING链，内核根据数据包目的IP判断是否需要转送出去 如果数据包就是进入本机的，数据包就会沿着图向下移动，到达INPUT链。数据包到达INPUT链后，任何进程都会收到它。本机上运行的程序可以发送数据包，这些数据包经过OUTPUT链 ，然后到达POSTROTING链输出 如果数据包是要转发出去的，且内核允许转发，数据包就会向右移动，经过FORWARD链，然后到达POSTROUTING链输出 防火墙工具 iptables firewalld工具集 firewall-cmd 命令行工具 firewall-config 图形工具 我们主要以实验的方式介绍iptables的使用,firewalld的工具集自行了解下。 上图加粗部分是重点实验内容，包括： filter表中的INPUT和OUTPUT filter表中的FORWARD nat表中的PREROUTING和POSTROUTING 实验前要关闭防火墙自带的服务，来自行配置防火墙，而不是系统定义的防火墙策略。 CentOS6: 12service iptables stopchkconfig iptables off CentOS7: 12systemctl stop firewalld.service systemctl disable firewalld. service iptables命令语法格式 -t table指的是chain表，默认不写为filter表，还可以指定nat、mangle、raw等表。 -COMMANDS1. 查看防火墙规则参数常用选项：-vnL -v：verbose,详细信息。如果要更详细信息，-vv。 -n：numberic，以数字格式显示地址和端口号 -L：List列出指定链上所有规则，不指定链的话，只输出filter表上的链。此参数要写在最后。 -x：exactly，显示计数器结果的精确值,而非单位转换后的易读值。 --line-numbers：显示规则的序号。 常用组合： 123-vnL-vnL --line-numbers-vvnxL --line-numbers 2. 规则管理的参数 -A chain：Append，添加某chain的规则。 -C chain：Check，检查某chain的规则。 -D chain rulenum：Delete，删除某chian指定序号位置的规则。 -I chain [rulenum]：Insert，在某chain的指定序号位置插入规则，不写默认插在开头（第一个）。 -R chain rulenum：Replace，替换指定链上的指定规则编号。 -F [chain]：Flush，清空指定的链的所有规则，如果不指定链，默认清空所有链的所有规则。 -Z：Zero，计数器置零。iptables的每条规则都有两个计数器： 匹配到的报文的个数。 匹配到的所有报文的大小之和。 这里的chain指的是以下几种链：PREROUTING，INPUT，FORWARD，OUTPUT， POSTROUTING 3. 链管理的参数 -N chain ：New,自定义一条新的规则链。 -X [chain]：delete，删除自定义的空的规则链。如果不指定链，默认删除所有非内置链（所有自定义的链）。 -P [chain] target：Policy，设置指定链的默认策略（target），不写链的话默认指定表中所有的链。对filter表中的链而言，其默认策略（target）有： ACCEPT：接受 DROP：丢弃 REJECT：拒绝 -E old-chain new-chain：重命名自定义链。引用计数不为0的自定义链不能够被重命名，也不能被删除 规则定义（rule-specification）123rule-specification = [matches...] [target]match = -m matchname [per-match-options]target = -j targetname [per-target-options] 先说匹配条件（match），分为两种： 一种是基本匹配条件，无需加载模块，由iptables/netfilter自行提供。CentOS6和7都是通过man iptables可以查看匹配条件使用说明。 扩展匹配条件：需要加载扩展模块（/usr/lib64/xtables/*.so） ，方可生效。CentOS6还是在man iptables里查看模块的匹配条件使用说明，CentOS7可以通过man iptables-extensions来查看。 处理动作(target)，target可以是ACCEPT、DROP、REJECT、RETURN等内置target，也可以是自定义的链。 1. 匹配条件（match）基本匹配条件 [!] -s：source，源IP地址或范围。 [!] -d：destination，目标IP地址或范围。 [!] -p：protocol，指定协议。 [!] -i name：in-interface， 报文流入的接口名字；只能应用于数据报文流入环节，只应用于INPUT、FORWARD、PREROUTING链。 [!] -o name：out-interface，报文流出的接口名字；只能应用于数据报文流出的环节，只应用于FORWARD、OUTPUT、POSTROUTING链。 扩展匹配条件 (1)隐式扩展： 隐式扩展，在使用-p选项指明了特定的协议时，无需再用-m选项 指明扩展模块的扩展机制，不需要手动加载扩展模块。例如-t tcp、-t udp、-t icmp等等。 tcp协议的扩展选项 [!] -sport PORT：匹配报文源端口,例如-sport 22 可为端口范围，例如20:23 [!] -dport PORT：匹配报文目标端口,例如-dport 22可为范围，例如22:23 [!] -tcp-flag mask comp：tcp标志位（flag），在mask列表中必须为1的标志位列表，无指定则必须为0。例子： --tcp-flags SYN,ACK,FIN,RST SYN： 表示要检查的标志位为SYN,ACK,FIN,RST四个，其中SYN必须为1，余下的必须为0。 --tcp-flags SYN,ACK,FIN,RST SYN,ACK --tcp-flags ALL ALL 表示要检查的标志位为所有，所有的都要为1。 --tcp_flags ALL NONE表示要检查的标志位为所有，所有的都要为0。 [!] --syn：用于匹配第一次握手。相当于：--tcp-flags SYN,ACK,FIN,RST SYN Wireshark抓到的TCP的flags： udp协议的扩展选项： [!] -sport：匹配报文源端口,可为端口范围 [!] -dport：匹配报文源端口,可为端口范围 Wireshark抓到的UDP的port： icmp协议的扩展选项： [!] --icmp-type type[/code] type/code为： 8/0：echo-request icmp请求 0/0：echo-reply icmp应答 Wireshark抓到的icmp的request/replay： (2)显式扩展： 必须使用-m选项指明要调用的扩展模块的扩展机制，要手动加载扩展模块： 1[-m matchname [per-match-options]] multiport扩展 iprange扩展 string扩展 time扩展 connlimit扩展 limit扩展 state扩展 2. 处理动作1-j targetname [per-target-options] 简单： ACCEPT DROP 扩展： REJECT：--reject-with:icmp-port-unreachable默认动作选项 RETURN：返回调用链 REDIRECT：端口重定向 LOG：记录日志，dmesg MARK：做防火墙标记 DNAT：目标地址转换 SNAT：源地址转换 MASQUERADE：地址伪装 … 自定义链]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Netfilter</tag>
        <tag>iptables</tag>
        <tag>firewalld</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vagrant--快速搭建实验环境利器]]></title>
    <url>%2Fcloud%2F20170813-vagrant%2F</url>
    <content type="text"><![CDATA[Vagrant是一个虚拟机管理软件，需要结合虚拟机软件来使用。使用Vagrant能迅速创建批量虚拟机环境。对于做实验的同学来说，可以说是利器。 官网地址：www.vagrantup.com 一、下载与安装 Vagrant不能单独使用，需要依赖虚拟机软件如Virtualbox和Vmware，这里推荐Virtualbox，Vmware是需要收费的才能使用（序列号破解的不能用的）。 box镜像是网上别人做好的模板，CentOS官方、Ubuntu官方、Debian官方都有专门去制作做好了的模板（而且一直更新迭代），直接安装就可以用（可以使用命令安装，也可以离线下载安装。） VirtualBox下载地址：https://www.virtualbox.org/wiki/Downloads Vagrant支持四大主流操作系统，可以根据自己的操作系统进行下载安装，安装过程不赘述。 Vagrant下载地址：https://www.vagrantup.com/downloads.html Vagrant Boxes镜像名称和介绍：https://app.vagrantup.com/boxes/search tips: CentOS下需要sudo yum install kernel-devel，要不然vagrant up 虚拟机启动不了；同样的Ubuntu下需要sudo apt install linux-headers-generic。 二、基础命令查看vagrant帮助命令： 1vagrant --help 比较常用的一些命令： 123456789101112131415# 模板（box）相关命令vagrant box list # 列出虚机模板vagrant box add USERNAME/BOX_NAME # 添加别人做好的虚机，在线下载。vagrant box add PATH/TO/BOX # 添加本地离线下载好的boxvagrant box remove # 移除虚机# 虚机（vm）相关命令vagrant init BOX # 初始化一个Vagrantfile文件。BOX为虚机模板名vagrant status [VM_NAME] # 虚拟机状态。不跟参数默认查看所有虚机，指定虚机名字（VM_NAME）查看指定的虚机状态vagrant destroy [VM_NAME] # 删除虚机。不跟参数默认删除所有，指定虚机名字（VM_NAME）删除指定的虚机vagrant up [VM_NAME] # 启动虚机。不跟参数默认启动所有，指定虚机名字（VM_NAME）启动指定的虚机vagrant down [VM_NAME] # 关闭虚机。不跟参数默认关闭所有，指定虚机名字（VM_NAME）关闭指定的虚机vagrant suspend [VM_NAME] # 挂起虚机。不跟参数默认关闭所有，指定虚机名字（VM_NAME）挂起指定的虚机vagrant resume [VM_NAME] # 从挂起状态恢复运行。不跟参数默认恢复所有，指定虚机名字（VM_NAME）恢复指定的虚机vagrant reload [VM_NAME] # 从挂起状态恢复运行。不跟参数默认恢复所有，指定虚机名字（VM_NAME）恢复指定的虚机 下面详细讲解box的命令使用，还有虚机相关命令的使用。 三、下载安装box模板安装box模板有两种途径。一种是在线下载安装；一种是离线下载，然后添加进去。 1. 在线下载安装 vagrant box add username/boxname 添加vagrant云仓库里别人做好的box模板。https://app.vagrantup.com/boxes/search在这里可以搜索到，还可以看到详情信息。 例如CentOS官方的两个： 12vagrant box add centos/7vagrant box add centos/6 vagrant box remove xxx/yyy可以移除你安装的box模板。 在线下载安装的时候，会让你选择下哪种虚拟机软件的box模板，我们选择virtualbox版本的。 用vagrant命令在线下载完成后，会有一行绿色的Sucessfully显示成功： 2. 离线下载安装因为主机在国外，有时候网络环境不是，下载慢。那么就可以复制上上个图那里圈起来的链接。复制链接到浏览器下载。（其实我发现，那个地址有的是地址转换，如下图，我们可以看到是从cloud.centos.org下载的，文件名都变成CentOS-x-Vagrant-xxxx.Virtualbox.box这种长格式。而且地址是centos.org的地址说明这个景象是CentOS官方提供的）： 这里贴出目前最新的，你可以自己去用上述方法找到最新的： CentOS 7 :1708_01CentOS 6 :1708_01 我在百度云也存了一份（不更新，如果你看这篇文章的时候在之后的很长时间的话，还是用上述方法离线自行下载最新版）： 链接: https://pan.baidu.com/s/1i5oqW5n密码: 7grf 离线下载完成后，就可以用命令添加下载好的box模板，例如： 1vagrant box add ~/Downloads/CentOS-6-x86_64-Vagrant-1708_01.VirtualBox.box --name centos/6 –name 参数，是指定本地离线添加的文件导入vagrant程序后的名字。 3. 关于版本列出添加的box模板： 1vagrant box list 在线下载安装的，括号里会跟其他人制作时所定义版本号。本地添加的box，括号里默认版本号是0。 4. 常用的几个模板几个常用的官方在线box模板： centos/7 CentOS 7 x64 centos/6 CentOS 6 x64 ubuntu/xenial64 Ubuntu 16.04 LTS x64 ubuntu/trusty64 Ubuntu 14.04 LTS x64 四、安装和使用单台虚机 我们先以一台为例，介绍常用的几个命令的使用方法。 1. 用指定模板来初始化配置文件Vagrantfile（init）123mkdir test # 创建一个test项目目录cd test # 进入test目录vagrant init centos/7 # 用centos/7这个box模板进行初始化 我们可以看到在项目目录test下面，创建了一个VagrantFile的文件，这个就是虚拟机的配置文件。后续配置复杂多台虚机的时候我们会讲到这个文件的使用。我们先用默认的配置启动虚拟机，默认配置只启动一台。通通过一台的命令，我们来熟悉一些命令的使用。 2. 启动(up)、关闭(halt)、暂停(suspend)、恢复(resume)、重载(reload)虚机1vagrant up 第一次启动会从模板复制一份虚机到当前目录，然后进行一系列配置工作。 vagrant status 可以查看虚拟机状态： 我们可以看到下面有一行提示几个命令的作用： vagrant halt 关闭(halt)虚机 vagrant up 启动(up)虚机 vagrant suspend 暂停(suspend)虚机 还有两条用的也很多： vagrant resume 从暂停中恢复（resume）虚机 vagrant reload 重载(reload)虚拟机，也就是重启虚拟机(在Vmware类的软件里也叫做重置，都是一个意思）。如果修改了配置文件，reload会按照配置文件来更改虚拟机的一些配置。 3. 登录虚机vagrant ssh可以登录虚拟机，是以vagrant用户登录的，我们可以看vagrant init那张图，可以看到有生成秘钥对并上传公钥到虚拟机了，所以vagrant ssh可以无秘钥登录。 4. 销毁(destory)虚机vagrant destory tips: 上述的命令都是基于一台虚拟机的操作，所以相对比较简单，多台是在上述命令基础上加一些参数而已。 五、制作自己习惯用的模板通常我们会自定义一个虚机，配置成自己习惯用的状态，然后打包，打包命令是： 1vagrant package 下面通过一个例子来说明如何打包：（下文中直接用了官方镜像，然后安装了一些自己需要的包，关闭了selinux策略。记得要删除网卡的信息。） 在项目目录下面，登录已经up的一台虚机： 123456789vagrant ssh #sudo su -setenforce 0 # 关闭selinuxsed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/selinux/config # 永久禁止selinuxyum install -y vim tree wget bash-completion net-tools tcpdump ab expect# 安装一些需要的包，这里根据个人爱好。rm -rf /etc/udev/rules.d/70-persistent-net.rules # 删除网卡的信息，否则在其他地方启动会有问题mv /etc/yum.repos.d/CentOS-Base.repo&#123;,.bak&#125;curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repocurl -o /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo 退出虚机，运行下面命令： 12vagrant package # 关机并打包虚机，会在项目目录生成一个package.box模板文件vagrant box add longdream/centos7 package.box # 打包的虚机模板可以作为模板进行创建虚机。 六、Vagrantfile参数详解我们可以看到在项目目录下面有一个Vagrantfile文件，这个就是这个项目的配置文件，通过修改这个配置文件，我们可以来批量创建多个虚机并且有不同的配置，只要写好配置就可以实现。 config.xx.yyy指的是项目全局配置。NODE_NAME.xx.yyy指的是单独的节点的配置，需要比全局配置缩进一层。 下面来详解里面的配置选项，然后下一小节我们就实战来通过这个文件来搭一套测试环境。 1. config.vm.define定义多台主机123456config.vm.define "node1" do |node1|endconfig.vm.define "node2" do |node2|endconfig.vm.define "node3" do |node3|end 2. *.vm.network 虚拟机网络nat默认方式forwarded_port 端口转发private network 私有网络（仅主机模式）public network 公有网络（桥接模式） Vagrantfile自带的几个示例： 1234config.vm.network "forwarded_port", guest: 80, host: 8080config.vm.network "forwarded_port", guest: 80, host: 8080, host_ip: "127.0.0.1"config.vm.network "private_network", ip: "192.168.33.10"config.vm.network "public_network" 默认所有主机都会创建一个NAT网络作为eth0的网络，ip地址是自动分配的。 写了ip就是静态ip地址，没写ip就会dhcp自动分配一个地址。 如果写了多条网络配置，那么就是配置多个网络，服务器会自动多几个网卡。当然，默认的NAT网络的eth0还在（作为vagrant ssh命令登录使用的网络，还有yum更新的网络），自己写的配置文件，从上到下依次匹配eth1,eth2等。 例子： 123456789101112config.vm.define "node1" do |node1| node1.vm.network "private_network", ip: "192.168.33.11" node1.vm.network "public_network" end config.vm.define "node2" do |node2| node2.vm.network "private_network", ip: "192.168.33.12" end config.vm.define "node3" do |node3| node3.vm.network "private_network", ip: "192.168.33.13" end 3. *.vm.hostname 定义虚机主机名NODE_NAME.vm.hostname = HOSTNAME定义主机名，NODE_NAME为节点名，HOSTNAME为定义的主机名。 例子： 123456789101112131415config.vm.define "node1" do |node1| node1.vm.network "private_network", ip: "192.168.33.11" node1.vm.network "public_network" node1.vm.hostname = "node1.yulongjun.com" end config.vm.define "node2" do |node2| node2.vm.network "private_network", ip: "192.168.33.12" node2.vm.hostname = "node2.yulongjun.com" end config.vm.define "node3" do |node3| node3.vm.network "private_network", ip: "192.168.33.13" node3.vm.hostname = "node3.yulongjun.com" end 4. *.vm.synced_folder 宿主机与虚机共享同步目录默认宿主机项目目录和虚拟机下的/vagrant目录同步。 如果还想自定义共享目录，可以参照下面用法： 12config.vm.synced_folder "宿主机目录", "虚机机目录" create: true|false, owner: "用户", group: "用户组" 宿主机目录一般是写的相对路径。相对的路径是相对的项目根目录。例如项目目录为test，那么宿主机目录写&quot;www/&quot;指的就是就是test/www目录。 虚拟目录是虚拟机上目录，一般写绝对路径。 create: true|false指的是是否在虚拟机创建此目录。 owner: &quot;用户&quot;, group: &quot;用户组&quot;指的是指定目录的拥有者和拥有组。 12config.vm.synced_folder "www/", "/var/www/", create: true, owner: "root", group: "root" 七、插件插件安装方法： 1vagrant plugin install xxxx 1. 插件vagrant-hostmanager：用主机名访问（建议安装）可以实现虚机之间用主机名互相访问，也可以实现宿主机用主机名访问虚机。 安装： 1vagrant plugin install vagrant-hostmanager 修改Vagrantfile文件 123456789101112131415161718192021222324Vagrant.configure("2") do |config| config.vm.box = "centos/7" config.hostmanager.enabled = true # 启用hostmanager config.hostmanager.manage_guest = true # 允许更新虚拟机上的文件 config.hostmanager.manage_host = true # 允许更新主机上的文件 config.vm.define "node1" do |node1| node1.vm.network "private_network", ip: "192.168.33.11" node1.vm.network "public_network" node1.vm.hostname = "node1.yulongjun.com" end config.vm.define "node2" do |node2| node2.vm.network "private_network", ip: "192.168.33.12" node2.vm.hostname = "node2.yulongjun.com" end config.vm.define "node3" do |node3| node3.vm.network "private_network", ip: "192.168.33.13" node3.vm.hostname = "node3.yulongjun.com" endend 2. 插件vagrant-vbguest：安装VirtualBox 客户端（建议安装）有时候我们发现有些virtualbox无法使用自定义的共享目录，这时候就需要安装vbguest客户端（类似于VMware的client） 1vagrant plugin install vagrant-vbguest 这个是在虚拟机启动的时候实时添加的。其实如果不去添加，下次虚拟机启动的时候会默认去添加的。 每次启动虚机都会检查vbguest插件的更新，如果不想更新，修改Vgrantfilew文件，加上这样一条： 1config.vbguest.auto_update = false 3. 插件vagrant-bindfs 支持多种共享模式（可选）插件bindfs可以支持多种共享模式，如nfs，samba 命令行下输入： 1vagrant plugin install vagrant-bindfs 修改Vgrantfile文件： 123456config.vm.define "node1" do |node1| node1.vm.network "private_network", ip: "192.168.33.11" node1.vm.hostname="node1.yulongjun.com" node1.vm.synced_folder "./app" "/mnt/app-data", type: "nfs" node1.bindfs.bind_folder "/mnt/app-data" "/app" force_user: "root", force_group: "root", o: "noempty" 八、实验例子1. 搭建一个每台机器不同配置的实验环境。搭建一个LVS实验环境。（用自己做的镜像最好，首先是已经安装了一些常用的包；二是如果是初始镜像，一开始需要安装几个包（glibc、kernel -de），比较耽误时间，自己打包的镜像已经安装好了。） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# -*- mode: ruby -*-# vi: set ft=ruby :Vagrant.configure("2") do |config| # Vagrant Global Config # `longdream/centos7` is a custom centos7 box made by YuLongjun. config.vm.box = "longdream/centos7" # If this box is add online, set true will check update. # Also set `false` will not update it. # If this box is added locally, this setting is invalid. config.vm.box_check_update = false # you need `vagrant plugin install vagrant-vbguest` # You also need `vagrant plugin install vagrant-hostmanager` config.hostmanager.enabled = true # Allow update `/etc/hosts` file in VMs. config.hostmanager.manage_guest = true # Allow update `/etc/hosts` file in Hosts. config.hostmanager.manage_host = true # Define VM `client` config.vm.define "client" do |client| client.vm.network "private_network", ip: "172.16.111.123" client.vm.hostname = "client" end # Define VM `vs` config.vm.define "vs" do |vs| vs.vm.network "private_network", ip: "172.16.111.200" vs.vm.network "private_network", ip: "192.168.111.200" vs.vm.hostname = "vs" end # Define VM `rs1` config.vm.define "rs1" do |rs1| rs1.vm.network "private_network", ip: "192.168.111.101" rs1.vm.hostname = "rs1" rs1.vm.provision "shell", inline: " sudo echo 'GATEWAY=192.168.111.200' &gt;&gt; /etc/sysconfig/network-scripts/ifcfg-eth1" end # Define VM `rs2` config.vm.define "rs2" do |rs2| rs2.vm.network "private_network", ip: "192.168.111.102" rs2.vm.hostname = "rs2" rs2.vm.provision "shell", inline: "sudo echo 'GATEWAY=192.168.111.200' &gt;&gt; /etc/sysconfig/network-scripts/ifcfg-eth1" endend 2. 批量搭建一组服务器（20170829补充）1234567891011121314151617181920212223242526272829303132333435363738# -*- mode: ruby -*-# vi: set ft=ruby :Vagrant.configure("2") do |config| # Vagrant Global Config # `longdream/centos7` is a custom centos7 box made by YuLongjun. config.vm.box = "longdream/centos7" # If this box is add online, set true will check update. # Also set `false` will not update it. # If this box is added locally, this setting is invalid. config.vm.box_check_update = false # you need `vagrant plugin install vagrant-vbguest` # You also need `vagrant plugin install vagrant-hostmanager` config.hostmanager.enabled = true # Allow update `/etc/hosts` file in VMs. config.hostmanager.manage_guest = true # Allow update `/etc/hosts` file in Hosts. config.hostmanager.manage_host = true # define 10 VMs in batch. # you can up a VM:`vagrant up node1` # you can up all VMs:`vagrant up` # you can up some VMs:`vagrant up `node[1-4]` (1..9).each do |i| config.vm.define "node#&#123;i&#125;" do |node| node.vm.network "private_network", ip: "192.168.111.#&#123;i&#125;0" node.vm.hostname = "node#&#123;i&#125;" end end # Create a single VM. #config.vm.define "client" do |client| # client.vm.network "private_network", ip "192.168.0.123" # client.vm.hostname "client" # client.vm.provision "shell", inline: &lt;&lt;-SHELL # sudo yum install tcpdump ab # SHELLend]]></content>
      <categories>
        <category>cloud</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网站启用新logo和新头像]]></title>
    <url>%2Fessay%2F20170811-new-logo%2F</url>
    <content type="text"><![CDATA[新logo新气象，但是博客的笔记内容已经两周没更新了 -_—！ 红牛（强化型）已到货，鱼油在路上，看来得补充点能量顺便补下脑子了…… 懒筋谁给我抽一抽 ┐(ﾟ～ﾟ)┌ …… favicon favicon]]></content>
      <categories>
        <category>essay</category>
      </categories>
      <tags>
        <tag>logo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LAMP 一键安装脚本]]></title>
    <url>%2Flinux%2F20170804-lamp%2F</url>
    <content type="text"><![CDATA[项目地址： https://github.com/yulongjun/lamp LAMP各组件版本： L：CentOS 7.3 A：httpd 2.4.27 M：MariaDB 10.2.7 P：PHP 7.1.7 git方式安装(recommended)：123git clone https://github.com/yulongjun/lamp.gitcd lampbash install.sh curl方式安装：1curl -L http://ou5hkxl8l.bkt.clouddn.com/lamp-web-installer?attname= |bash 用的七牛云存储，域名备案中，暂时下载速度不快，只有100KB左右。（MariaDB除外，用的清华的yum源）]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使MWeb外部模式支持Hexo]]></title>
    <url>%2Fmacos%2F20170728-mweb-hexo%2F</url>
    <content type="text"><![CDATA[Command + E 打开外部模式。 右下角引入外部文件夹，然后选择自己Hexo博客目录下的source文件夹。 在source文件夹上点右键，选择“编辑”，然后如下图修改。 这时候MWeb就支持hexo的格式了。贴图直接就帮你转化了格式为网络模式，而且支持预览： 详细的关于MWeb外部模式帮助文档可以去官网查看： http://zh.mweb.im/mweb-1.4-add-floder-octpress-support.html]]></content>
      <categories>
        <category>macos</category>
      </categories>
      <tags>
        <tag>MWeb</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[05-INSERT、DELETE、UPDATE语句]]></title>
    <url>%2Fdatabase%2F20170727-05-sql-insert-delete-update%2F</url>
    <content type="text"><![CDATA[INSERT1INSERT INTO &lt;表名&gt; (列名1, 列名2, ...) Values (value1, value2, ...); 省略列名不写，就得写每一列的数据： 12INSERT INTO &lt;表名&gt;Values (value1, value2, ...); 非空约束的列，不能插入Null值，否则报错。 有默认值约束的列，在列的列表里可以不写，这样就会插入默认值。如果要列表里有列名，想设置默认值需要写DEFAULT。 可以从其他表中取数据： 1234INSERT INTO &lt;表名1&gt; (列名1, 列名2, ...) SELECT 列名a, 列名b, ... from &lt;表名2&gt; ...; -- 子select可以接WGHO DELETE清空表： 1DELETE FROM &lt; 表名 &gt;; 加条件： 1DELETE FROM &lt; 表名 &gt; WHERE &lt; 条件 &gt;; 截断表，速度快，DELETE相当于一条条删除，截断一下子就截断了： 1TRUNCATE &lt; 表名 &gt;; UPDATEUPDATE 语句的基本语法 12UPDATE &lt; 表名 &gt; SET &lt; 列名 &gt; = &lt; 表达式 &gt;; 指定条件的 UPDATE 语句（搜索型 UPDATE ） 123UPDATE &lt; 表名 &gt;SET &lt; 列名 &gt; = &lt; 表达式 &gt; WHERE &lt; 条件 &gt;; 使用NULL进行更新 123UPDATE ProductSET regist_date = NULL WHERE product_id = '0008'; 多列更新 方法①：代码清单4-19 将代码清单4-18的处理合并为一条 UPDATE 语句 1234-- 使用逗号对列进行分隔排列 UPDATE ProductSET sale_price = sale_price * 10, purchase_price = purchase_price / 2 WHERE product_type = ' 厨房用具 '; 方法②：代码清单4-20 将代码清单4-18的处理合并为一条 UPDATE 语句 方法②只可以在PostgreSQL和DB2中使用，MySQL和Oracle不支持。 1234-- 将列用 () 括起来的清单形式 UPDATE ProductSET (sale_price, purchase_price) = (sale_price * 10, purchase_price / 2) WHERE product_type = ' 厨房用具 ';]]></content>
      <categories>
        <category>database</category>
      </categories>
      <tags>
        <tag>SELECT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[04-SELECT语句]]></title>
    <url>%2Fdatabase%2F20170727-04-sql-select%2F</url>
    <content type="text"><![CDATA[可以看《SQL基础教程（第2版）》第二章，这本书是2017年5月出的最新版。 第二章内容： （下面内容请忽略，笔者已会SQL语句，下面内容是查漏补缺写的笔记） 聚合函数(Group Function) count() sum() max() min() GROUP BY使用 GROUP BY 子句可以像切蛋糕那样将表分割。通过使用聚合函数和 GROUP BY 子句，可以根据“商品种类”或者“登记日期”等将表分割后再 进行汇总。 聚合键中包含 NULL 时，在结果中会以“不确定”行（空行）的形式表现出来。 使用聚合函数和 GROUP BY 子句时需要注意以下4点。 ① 只能写在 SELECT 子句之中 ② GROUP BY 子句中不能使用 SELECT 子句中列的别名 ③ GROUP BY 子句的聚合结果是无序的 ④ WHERE 子句中不能使用聚合函数 GROUP BY 和 WHERE 并用时 SELECT 语句的执行顺：FROM → WHERE → GROUP BY → SELECT 所以这样使用会报错： 123SELECT product_type AS pt, COUNT(*) FROM Product GROUP BY pt; 在WHERE子句里不能使用聚合函数： 1234SELECT product_type, COUNT(*)FROM Product WHERE COUNT(*) = 2GROUP BY product_type; 上面这个会报错： 12ERROR 1111 (HY000): Invalid use of group function 想要在子句里使用聚合函数，可以用having子句。 GROUP BY和DISTINCT HAVING说到指定条件，估计大家都会首先想到 WHERE 子句。但是， WHERE 子句只能指定记录（行）的条件，而不能用来指定组的条件（例如，“聚合结果正好为2行的组”或者“平均值为500的组”等）。 HAVING 子句必须写在 GROUP BY 子句之后，其在 DBMS 内部的执行顺序也排在 GROUP BY 子句之后。 使用 HAVING 子句时 SELECT 语句的顺序： SELECT → FROM → WHERE → GROUP BY → HAVING sale_pricegroup by 后，count(*)大于2的显示出来： 1234SELECT product_type, COUNT(*) FROM Product GROUP BY product_type HAVING COUNT(*) = 2; sale_price group by 后，平均值大于2的显示出来： 1234SELECT product_type, AVG(sale_price) FROM Product GROUP BY product_type HAVING AVG(sale_price) &gt;= 2500; ORDER BY 子句的书写顺序：1. SELECT 子句 → 2. FROM 子句 → 3. WHERE 子句 → 4. GROUP BY 子句 → 5. HAVING 子句 → 6. ORDER BY 子句 默认是升序ASC（Ascendent），可以加DESC(Descendent)就变成降序。 可以指定多个排序键，那么就先排序第一个排序键，然后再第一个排序键有相同的值的情况下，第二个再排序。 NULL在ASC排序里是排在最后，DESC排序里排在最前面。 在 ORDER BY 子句中可以使用 SELECT 子句中未使用的列和聚合函数。 总的顺序：WGHO原则： 1234WHEREGROUP BYHAVINGORDER BY]]></content>
      <categories>
        <category>database</category>
      </categories>
      <tags>
        <tag>SELECT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[03-SQL语句简单示例]]></title>
    <url>%2Fdatabase%2F20170727-03-sql-language%2F</url>
    <content type="text"><![CDATA[简单的几个示例演示一下。 创建1. 数据库的创建（ CREATE DATABASE 语句）1CREATE DATABASE &lt;数据库名称&gt; ; 2. 表的创建（CREATE TABLE 语句）12345678CREATE TABLE &lt;表名&gt;(&lt;列名1&gt; &lt;数据类型&gt; &lt;该列所需约束&gt; ，&lt;列名2&gt; &lt;数据类型&gt; &lt;该列所需约束&gt; ， &lt;列名3&gt; &lt;数据类型&gt; &lt;该列所需约束&gt; ，&lt; 列名4&gt; &lt;数据类型&gt; &lt;该列所需约束&gt; ，...&lt;该表的约束1&gt; ， &lt;该表的约束2&gt; ，……）； 例子： 12345678CREATE TABLE Product(product_id CHAR(4) NOT NULL, -- 商品编号 product_name VARCHAR(100) NOT NULL, -- 商品名称 product_type VARCHAR(32) NOT NULL, -- 商品种类 sale_price INTEGER , -- 销售单价 purchase_price INTEGER , -- 进货单价 regist_date DATE , -- 登记日期 PRIMARY KEY (product_id)); 下面对上面内容进行分解： 3. 命名规则标准SQL命名规则： 标准SQL，只能使用半角英文字母、数字、下划线（_）作为数据库、表和列的名称。 标准SQL名称必须以半角英文字母开头。 名称不能重复。在同一个数据库中不能创建两个相同名称的表，在同一个表中也不能创建两个名称相同的列。 4. 列的数据类型数据类型表示数据的种类，包括数字型、字符型和日期型等。 上文中的几种数据类型： INTEGER：整数型 CHAR：定长字符型 VARCHAR：可变字符型 DATE：日期型 5. 约束设置 NOT NULL 非空约束：字段不能为空。 UNIQUE 唯一性约束：字段全列唯一，可以为空。 PRIMARY KEY 主键约束：NOT NULL和UNIQUE结合起来，即字段不能为空，而且唯一。 表的删除和更新1. 表的删除（ DROP TABLE 语句）1DROP TABLE &lt;表名&gt;; 2. 表定义的更新（ ALTER TABLE 语句）添加列的 ALTER TABLE 语句： 1ALTER TABLE &lt;表名&gt; ADD COLUMN &lt;列的定义&gt;； 删除列的 ALTER TABLE 语句 1ALTER TABLE &lt;表名&gt; DROP COLUMN &lt;列名&gt;； 插入数据 向 Product 表中插入数据的SQL语句 12345678910INSERT INTO Product VALUES (&apos;0001&apos;, &apos;T恤衫&apos;, &apos;衣服&apos;, 1000, 500, &apos;2009-09-20&apos;); INSERT INTO Product VALUES (&apos;0002&apos;, &apos;打孔器&apos;, &apos;办公用品&apos;, 500, 320, &apos;2009-09-11&apos;); INSERT INTO Product VALUES (&apos;0003&apos;, &apos;运动T恤&apos;, &apos;衣服&apos;, 4000, 2800, NULL); INSERT INTO Product VALUES (&apos;0004&apos;, &apos;菜刀&apos;, &apos;厨房用具&apos;, 3000, 2800, &apos;2009-09-20&apos;); INSERT INTO Product VALUES (&apos;0005&apos;, &apos;高压锅&apos;, &apos;厨房用具&apos;, 6800, 5000, &apos;2009-01-15&apos;); INSERT INTO Product VALUES (&apos;0006&apos;, &apos;叉子&apos;, &apos;厨房用具&apos;, 500, NULL, &apos;2009-09-20&apos;); INSERT INTO Product VALUES (&apos;0007&apos;, &apos;擦菜板&apos;, &apos;厨房用具&apos;, 880, 790, &apos;2008-04-28&apos;); INSERT INTO Product VALUES (&apos;0008&apos;, &apos;圆珠笔&apos;, &apos;办公用品&apos;, 100, NULL,&apos;2009-11-11&apos;);COMMIT;]]></content>
      <categories>
        <category>database</category>
      </categories>
      <tags>
        <tag>CREATE</tag>
        <tag>ALTER</tag>
        <tag>DROP</tag>
        <tag>INSERT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[02-MariaDB安装]]></title>
    <url>%2Fdatabase%2F20170727-02-mariadb-install%2F</url>
    <content type="text"><![CDATA[CentOS7中，iso镜像里就带有MariaDB，因此通过yum安装mariaDB就可以了，但是版本不是最新的。 如果想要在6或7上安装最新的MariaDB，可以设置yum generator来找到yum repo地址，来安装： yum generator：https://downloads.mariadb.org/mariadb/repositories/ 选择要安装的版本，这里我选的是目前最新的稳定版本10.2。 在/etc/yum.repos.d/下创建MariaDB.repo文件。 CentOS 7写入： 123456# MariaDB 10.2 CentOS repository list - created 2017-07-28 08:01 UTC# http://downloads.mariadb.org/mariadb/repositories/[mariadb]name = MariaDBbaseurl = http://yum.mariadb.org/10.2/centos7-amd64gpgcheck=0 CentOS 6写入： 123456# MariaDB 10.2 CentOS repository list - created 2017-07-28 08:04 UTC# http://downloads.mariadb.org/mariadb/repositories/[mariadb]name = MariaDBbaseurl = http://yum.mariadb.org/10.2/centos6-amd64gpgcheck=0 然后（6和7通用）： 1sudo yum install MariaDB-server MariaDB-client]]></content>
      <categories>
        <category>database</category>
      </categories>
      <tags>
        <tag>MariaDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[01-数据库和SQL简介]]></title>
    <url>%2Fdatabase%2F20170727-01-db-and-sql-introduction%2F</url>
    <content type="text"><![CDATA[上图为DB-ENGINES的数据库排行榜。 现在比较流行的数据库分为以下几种： Relational DBMS：如Oracle，MySQL/MariaDB，SQL Server，DB2。Document Store：如MongoDB，Amazon DynamoDB。Key-Value Store：如Redis。Search Engine：如Elasticsearch。 行（记录）、列（字段） 表的列（column）（垂直方向）称为字段(field)，它代表了保存在表中的数据项目。表的行（row）（水平方向）称为记录(record)，它相当于一条数据。关系数据库必须以行为单位进行数据读写。 SQL语句种类：DDLDDL（Data Definition Language，数据定义语言） 用来创建或者删除存储数据用的数据库以及数据库中的表等对象。DDL 包含以下几种指令。 CREATE ：创建数据库和表等对象DROP ： 删除数据库和表等对象ALTER ： 修改数据库和表等对象的结构 DMLDML（Data Manipulation Language，数据操纵语言） 用来查询或者变更 表中的记录。DML 包含以下几种指令。 SELECT ：查询表中的数据（Oracle算在DML里面，MySQL算在DQL（Data Query Language）里面）INSERT ：向表中插入新数据UPDATE ：更新表中的数据DELETE ：删除表中的数据 DCLDCL（Data Control Language，数据控制语言） 用来确认或者取消对数据库中的数据进行的变更。除此之外，还可以对 RDBMS 的用户是否有权限 操作数据库中的对象（数据库表等）进行设定。DCL 包含以下几种指令。 COMMIT ： 确认对数据库中的数据进行的变更ROLLBACK ：取消对数据库中的数据进行的变更GRANT ： 赋予用户操作权限 REVOKE ： 取消用户的操作权限 DDL和DCL是自带commit的，一旦使用，无法rollback。 实际使用的 SQL 语句当中有 90% 属于 DML。]]></content>
      <categories>
        <category>database</category>
      </categories>
      <tags>
        <tag>DB</tag>
        <tag>SQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[04-DNS主从复制]]></title>
    <url>%2Flinux%2F20170725-06-dns-slave%2F</url>
    <content type="text"><![CDATA[主DNS正向解析、从DNS正向解析，主DNS反向解析，从DNS反向解析。 正向解析和反向解析是两个完全不同的系统，可以分别来设置。 只有一个主，但是可以有多个从服务器，从服务器可以接从服务器（不一定接主服务器)。 一个从服务器，可以从多个主服务器同步数据。 定义从区域的方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748zone &quot;ZONE_NAME&quot; IN &#123; type slave; masters &#123; MASTER_IP; &#125;; file &quot;slaves/ZONE_NAME.zone&quot;&#125;``` &gt; 前提：无论正向解析反向解析，主服务器的zone文件里，要有从的NS服务器的定义。我们可以查看要被被服务器同步的主服务器的正向解析和反向解析的zone文件，来确认下：![](/images/15020237612906.jpg)![](/images/15086450357684.jpg)NS记录有从服务器的记录才可以配置从服务器。## 实验1:增加从服务器正向解析我们把之前设置的`192.168.111.254`设为主DNS服务器我们在设置一个`192.168.111.253`作为从dns服务器，从主服务器同步dns信息。同步的目录默认为`/var/named/slaves`，系统已经默认在这个目录下面创建一个`slaves`的文件夹(属主属组都是named，`/var/named`目录只有属组是named，而属组没有写权限）### 1. 更改`/etc/named.conf````bashoptions &#123; listen-on port 53 &#123; 192.168.111.253; &#125;; // 监听端口配置为本机的一个网卡的地址 listen-on-v6 port 53 &#123; ::1; &#125;; directory &quot;/var/named&quot;; dump-file &quot;/var/named/data/cache_dump.db&quot;; statistics-file &quot;/var/named/data/named_stats.txt&quot;; memstatistics-file &quot;/var/named/data/named_mem_stats.txt&quot;; allow-query &#123; 192.168.111.0/24; &#125;; // 只允许192.168.11.0/24网段查询recursion yes; dnssec-enable no; // 关闭安全 dnssec-validation no; // 关闭安全 // 下面保持不变，就不贴了 2. 更改/etc/named.rfc1912.zones/etc/named.rfc1912.zones填加下面内容： 12345zone "yulongjun.com" IN &#123; type slave; masters &#123; 192.168.111.254; &#125;; file "slaves/yulongjun.com.zone";&#125; type 和主不同的是，要改为slave 然后需要写masters是谁，可以有多个master，即使就一个，也要写masters，后面跟大括号 file指向的从主同步下来的文件。写slaves/yulongjun.com.zone，即/var/named/slaves/yulongjun.com.zone(自动加了参数里的默认directory/var/named) 3. 重启服务改完了后 ： 1rndc reload tail -20 /var/log/messages查看日志可以看到成功了 ls /var/named/slaves/可以看到同步过来的zone文件。 4. 主服务器发生更改主服务器发生更改，然后rndc reload，会通知所有的从服务器立即进行更改。 实验2:增加从服务器反向解析1. 更改/etc/named.rfc1912.zones/etc/named.rfc1912.zones填加下面内容： 12345zone "111.168.192.in-addr.arpa" IN &#123; type slave; masters &#123; 192.168.111.254; &#125;; file "slaves/192.168.111.zone";&#125; 2. 重启从服务器的服务1rndc reload]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[04-bind各种辅助工具]]></title>
    <url>%2Flinux%2F20170725-05-bind-utils%2F</url>
    <content type="text"><![CDATA[named-checkconf检查/etc/named.conf主配置文件语法是否有错误。 有错误会提示那一行有错误： 如果没有错误，不会提示任何信息。 tips: 因为/etc/named.conf里面定义也include/etc/named.rfc1912.zones文件，所以也会检查/etc/named.rfc1912.zones这个文件。所以有时候提示include &quot;/etc/named.rfc1912.zones&quot;;那行有语法错误，看半天没错误，那就应该去/etc/named.rfc1912.zones取查看语法错误。 named-checkzone检查/var/named/下的区域文件，是否有语法错误。 OK表示没有语法错误。 rndc`rndc status|reload|querylog|trace rndc status rndc reload 重载全局配置文件和区域配置文件。相当于systemctl restart named rndc querylog 开启查询日志，即有走此dns的查询，都会记录下来，默认记录在/var/log/messages，频繁查询对io影响比较大，一般不开启，除非测试查看用。 运行一次rndc querylog打开此功能，在运行一次关闭。 rndc trace rndc trace [LEVEL] 开启debug模式，日志比较详尽，一般不开启，再次运行会增加debug等级，也可以直接指定debug级别： 123456789rndc satatus # 初始状态，无debug，返回debug level: 0rndc tracerndc satatus # 返回debug level: 1rndc tracerndc status # 返回debug level: 2rndc trace 5rndc status # 返回debug level: 5rndc trace 0rndc status # 返回初始状态，debug level: 0 digdig用于测试dns系统，因此，不会查询hosts文件进行解析。 1. dig -t正向解析dig [-t type] name [@server] [query options] -t 指定类型，如SOA、A、MX、NS之类的类型 name指的是要解析的域名 @后接dns服务器的地址,表示使用哪个dns服务器进行解析。如果不写，会使用本机设置的dns服务器地址，即/etc/resolv.conf下面设定的地址。 如果解析地址处，定义了同一个地址到两个IP，会去做轮询。 查询选项： +[no]trace：是否追踪解析过程 +[no]recurse：是否递归解析 12345dig -t SOA yulongjun.com @192.168.111.254dig -t MX yulongjun.com @192.168.111.254dig -t NS yulongjun.com @192.168.111.254dig -t A yulongjun.com @192.168.111.254dig -t A www.yulongjun.com @192.168.111.254 如上，我们查询的如果是一个CNAME地址，即使是type写的A也会查出CNAME地址。 1dig -t A www.baidu.com 1dig -t A www.baidu.com +trace 2. dig -x反向解析dig -x IP_ADDRESS @SERVER 例子：1dig -x 192.168.111.100 @192.168.111.254 dig -t axfr全量区域传送可以查询到dns上的全量数据（好多网络上的dns是禁止使用此选项的） 12dig -t axfr yulongjun.com @192.168.111.254dig -t axfr 111.168.192.in-addr.arpa @192.168.111.254 这是相当危险的，可以去掉全量传送。 hosthost [-t type] [Server] 比dig少@，输出的信息也简洁很多。12host -t A www.yulongjun.com 192.168.111.254host -t NS yulongjun.com 192.168.111.254 nslookup主要用nslookup的交互式模式。 了解下就行，一般不使用。 以上命令，dig用的比较多，功能比较全，建议记牢。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[04-bind（named）配置文件]]></title>
    <url>%2Flinux%2F20170725-04-bind-config%2F</url>
    <content type="text"><![CDATA[CentOS下，yum install bind安装bind软件来实现DNS服务,yum info bind可以查看到描述： BIND是DNS协议的一种实现。BIND包含了一个DNS Server（服务名叫named）,用来解析主机名到ip地址；一个解析库；一些辅助工具，还有一个安全目录工具，分别属于下面几个包： bind：包里主要包含： named DNS服务 named-chkconfig（named.conf文件检查工具） named-checkzone(zone文件检车工具） rndc（本地和远程dns控制工具） bind-libs：named DNS服务的库 bind-utils：包含一系列辅助工具来测试 host dig nslookup nsupdate bind-chroot：切根程序，用来切换默认目录到另外一个深层的安全的目录/var/named/chroot，类似于前面光盘进入救援模式的那种情况。 named 涉及的文件rpm -ql named: 1234567891011/etc/named.conf # bind主配置文件/etc/named.rfc1912.zones # 定义zone的文件/etc/rc.d/init.d/named # bind脚本文件/etc/rndc.conf # rndc配置文件/usr/sbin/named-checkconf # 检测/etc/named.conf文件语法/usr/sbin/named-checkzone # 检测zone和对应zone文件的语法/usr/sbin/rndc # 远程dns管理工具/usr/sbin/rndc-confgen # 生成rndc密钥/var/named/named.ca # 根解析库/var/named/named.localhost # 本地主机解析库/var/named/slaves # 从ns服务器文件夹 可以查看/usr/share/doc/bind-*/sample/下有各种例子可以参考： 根据参考来配置各个文件。 named主配置文件/etc/named.conf这里主要配置named服务的配置，包括： 监听端口(listen-on port)和ip地址 服务作用范围（本机还是指定网段还是全网）（allow-query） 递归还是迭代查询(recursion) 根区域解析文件（zone），其他区域文件可以看到有个include &quot;/etc/named.rfc1912.zones&quot;;，这下面保存了localhost的区域文件，如果新添加的，卸载这个zones文件里，里面指向了zone文件地址。然后每一个zone文件，是在/var/named下面。 下面是原配置文件的部分： 123456789101112131415161718192021222324252627282930313233343536options &#123; listen-on port 53 &#123; 127.0.0.1; &#125;; // ipv4监听端口和ip地址，默认只有本地的 listen-on-v6 port 53 &#123; ::1; &#125;; // ipv6的监听端口和ip地址 directory "/var/named"; dump-file "/var/named/data/cache_dump.db"; statistics-file "/var/named/data/named_stats.txt"; memstatistics-file "/var/named/data/named_mem_stats.txt"; allow-query &#123; localhost; &#125;; recursion yes; // 递归还是迭代查询 dnssec-enable yes; // dns安全扩展,可以改为no关闭 dnssec-validation yes; //可以改为no关闭 /* Path to ISC DLV key */ bindkeys-file "/etc/named.iscdlv.key"; managed-keys-directory "/var/named/dynamic"; pid-file "/run/named/named.pid"; session-keyfile "/run/named/session.key";&#125;;logging &#123; channel default_debug &#123; file "data/named.run"; severity dynamic; &#125;;&#125;;zone "." IN &#123; // 定义zone文件，这里是定义的根域的文件位置 type hint; file "named.ca";&#125;;include "/etc/named.rfc1912.zones"; // 把named.rfc1912.zones文件包含进来include "/etc/named.root.key"; // 把/etc/named.root.key文件包含进来 下面贴出一个修改后的区域文件： 123456789101112131415161718192021222324252627282930313233343536options &#123; listen-on port 53 &#123; 192.168.111.254; 127.0.0.1; &#125;; //监听端口修改为某一网卡地址，和回环地址。 listen-on-v6 port 53 &#123; ::1; &#125;; directory "/var/named"; dump-file "/var/named/data/cache_dump.db"; statistics-file "/var/named/data/named_stats.txt"; memstatistics-file "/var/named/data/named_mem_stats.txt"; allow-query &#123; 192.168.111.0/24; &#125;; //查询范围只允许192.168.111.0网段查询。 recursion yes; dnssec-enable no; //关闭dnssec dnssec-validation no; //关闭dnssec bindkeys-file "/etc/named.iscdlv.key"; managed-keys-directory "/var/named/dynamic"; pid-file "/run/named/named.pid"; session-keyfile "/run/named/session.key";&#125;;logging &#123; channel default_debug &#123; file "data/named.run"; severity dynamic; &#125;;&#125;;zone "." IN &#123; type hint; file "named.ca";&#125;;include "/etc/named.rfc1912.zones";include "/etc/named.root.key"; 配置解析库文件（Zone files）,一般是在/var/named下写，文件名格式一般写为ZONE_NAME.zone named.conf配置文件所有的配置语句 123456789101112acl 定义一个主机匹配列表，用户访问控制权限controls 定义rndc工具与bind服务进程的通信include 把其他文件的内容包含进来key 定义加密秘钥logging 定义系统日志信息lwres 把named配置为轻量级解析器masters 定义主域列表options 设置全局选项server 定义服务器属性trusted-keys 定义信任的dnssec秘钥view 定义视图zone 定义区域 named.rfc1912.zones主配置文件1234zone "ZONE_NAME" IN &#123; type &#123;master|slave|hint|forward&#125;; file "ZONE_NAME.zone";&#125;; zone &quot;ZONE_NAME“：定义解析库名字，通常和解析库文件前缀对应起来。 type：master指的是主dns解析，slave指的是从dns解析，hint指的是根域名解析（根提示域），forward指的是转发，转发不使用file file ：定义区域解析库文件名字（位置默认在/var/named下面）,file的前缀通常和zone的名字通常对应起来，然后加一个.zone的后缀。 这里给出一个自定义的总的区域定义文件，新加一个区域文件的定义： 1234zone "yulongjun.com" IN &#123; type master; file "yulongjun.com.zone";&#125;; /var/named/ZONE_NAME.zone区域配置文件这里给出我一个自定义的区域文件： yulongjun.com.zone 123456789101112131415$TTL 1D@ IN SOA ns1.yulongjun.com. me.yulongjun.com ( 0 1H 10M 1D 3H) IN NS ns1.yulongjun.com IN NS ns2 MX 10 mail1 MX 20 mail2ns1.yulongjun.com IN A 192.168.111.254ns2 IN A 192.168.111.253 db1 A 192.168.111.100db2 A 192.168.111.111web1 A 192.168.111.200web2 A 192.168.111.222mail1 A 192.168.111.10mail2 A 192.168.111.20www CNAME web1 具体配置选项意义，见前一节DNS记录类型。 @指的就是本域yulongjun.com IN ns2.yulongjun.com可以省略写成IN ns2 IN都可以省略不写,比如直接写MX mail 设置.zone文件权限（参照/var/named/name.xxxx的权限来设置，这里xxx为任意字符） 12chmod 640 yulongjun.com.zonechown :named yulongjun.com.zone 配置完毕后，启动或重启(已启动的话）服务。 1service named start|restart 反向区域区域名称：是网络地址的犯些.in-addr.arpa. 192.168.111. –&gt; 111.168.192.in-addr.arpa. 配置方法： 先在/etc/named.rfc1512.zones文件下插入下面内容： 123zone "Reverse_Net_Addr.in-addr.arpa" IN &#123; type &#123;master|slave|forward&#125;; file "Net_Addr.zone" 例子： 1234zone "111.168.192.in-addr.arpa" IN &#123; type master; file "192.168.111.zone";&#125;; 配置/var/named/ZONE_NAME.zone不需要MX、A、AAAA，要有NS记录，以PTR记录为主。 例子： 配置192.168.111.zone： 1234567891011121314151617$TTL 1D@ IN SOA ns1.magedu.com. me.yulongjun.com ( 20170001 1H 5M 7D 1D) IN NS ns1.yulongjun.com. IN NS ns2.yulongjun.com.254 IN PTR ns1.yulongjun.com.253 IN PTR ns2.yulongjun.com.100 IN PTR db1.magedu.com.111 IN PTR db2.magedu.com.200 IN PTR web1.magedu.com.222 IN PTR web2.magedu.com.10 IN PTR mail1.magedu.com.20 IN PTR mail2.magedu.com.]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[03-DNS记录类型]]></title>
    <url>%2Flinux%2F20170725-03-dns-record-types%2F</url>
    <content type="text"><![CDATA[在之前的文章中，我们了解了什么是DNS以及DNS如何工作，现在让我们来看看 DNS 记录有哪些种类，以及它们有什么作用。 要理解不同的 DNS 记录，首先必须了解区域文件是什么? 区域文件(Zone files)区域文件是名称服务器存储其所知道的域名的信息的方式。名称服务器知道的每个域名都存储在区域文件中。对于名称服务器来说，大多数请求都不能在它自己服务器中找到区域文件。 如果它被配置成可以递归查询，如解析名称服务器，那它会递归找到结果并返回。否则，它会告诉请求者方下一步到哪里查询。 名称服务器具有的区域文件越多，它能够权威回答的请求越多。 区域文件描述 DNS “区域”，其基本上是整个 DNS 命名系统的子集。它通常只配置一个域名。它可以包含多个记录，定义了该域名下的资源位置。 区域文件的 $ORIGIN 表示该区域最高等级的权威。 所以如果一个区域文件被配置为 “example.com” 域，$ORIGIN 会被设置为 example.com。 它配置在区域文件的顶部，或者可以在引用区域文件的 DNS 服务器的配置文件中定义。无论哪种方式，此参数描述区域将是什么等级的权威。 类似地，$TTL 配置它提供的信息的 “生存时间”。它基本上是一个计时器。高速缓存名称服务器可以使用先前查询的结果来回答问题，直到 TTL 值用完。 ZONE file的资源记录（RR:Resource Record)的格式： 1name [TTL] IN rr_type value TTL可以从全局继承，即在文件首行放一个类似这样的$TTL 1D的全局字段。 @可以用于表明当前区域的名字，属于省略的写法，如果name后面没有跟区域名，如ns1的话，默认就会补全区域名。 rr_type,资源记录类型（RR:Resource Record)主要分为以下几种： SOA记录（Start Of Authority record）：起始授权记录 A 和 AAAA 记录（Adress record） CNAME：Canonical Name record MX 记录（Mail eXchange record） NS 记录(Name Server record) PTR 记录（PoinTer Record） 下面详解一下各种记录类型： SOA记录（Start Of Authority record）起始授权记录，或者说是 SOA，这种记录是所有区域性文件中的强制性记录。它必须是一个文件中的第一个记录（$ORIGIN 和 $TTL 会在它之前指定）。它还是最难理解的一种记录。 开始权限记录的看起来像这样： 我们来解释一下各部分分别表示什么： domain.com.：这是区域的根。这表明该区域文件用于 domain.com 域名。通常，你会看到这个用 @ 代替，它只是一个占位符，表示我们之前学到的 $ORIGIN 变量的内容。 IN SOA：”IN” 部分表示互联网（它会出现在许多记录中）, IN 可以省略不写。 SOA 是表示这是开始权限记录。 ns1.domain.com.：这定义了该域的主名称服务器。名称服务器可以是主服务器或从服务器，如果配置了动态 DNS，就像这里，则一个服务器需要是 “主服务器”。如果你未配置动态 DNS，那么这只是你其中一个主名称服务器。 admin.domain.com.：这是这个区域文件管理员的邮箱地址。邮箱地址的 @ 这里用一个 . 代替。如果你的名字中也有 . 它会用 \ 代替。（比如 your.name@domain.com 变成 your\name.domain.com） 12083：这是区域文件的序列号。每次编辑区域文件时，必须增加此序列号以使区域文件能够正确传播。从服务器将检查主服务器的区域序列号是否大于它们在系统上的序列号。如果是，它请求新的区域文件，如果不是，它继续服务原始文件。 3h：这是区域的刷新间隔。这是从服务器向主服务器轮询检查区域文件是否变更之间等待的时间量。 30m：这是此区域的重试间隔。如果slave从机在刷新周期结束时无法连接到master主机，则它将等待此时间并重试轮询主机。 3w：这是到期时间。如果slave从服务器在此时间内无法与master主服务器联系，则它不再作为此区域的权威来源的返回响应，并停止对外提供服务。 1h：这是名称服务器在此文件中找不到所请求的名称时缓存找不到结果的时间量。 A 和 AAAA 记录（Adress record）这两个记录都将主机映射到 IP 地址。 “A” 记录用于将主机映射到 IPv4 IP 地址，而 “AAAA” 记录用于将主机映射到 IPv6 地址。 这些记录的一般格式是： 12host IN A IPv4_addresshost IN AAAA IPv6_address 因为我们的 SOA 记录指出了我们的主服务器是 “ns1.domain.com”，而 “ns1.domain.com” 也是 “domain.com” 区域文件定义的，所以我们需要把它指向一个 IP 地址。 这条记录可能看起来像这样： 1ns1 IN A 111.222.111.222 请注意，我们不必提供全名。我们可以只给主机名，不需要 FQDN，然后 DNS 服务器会通过 $ORIGIN 补足其余部分。但是，我们也可以使用完整的 FQDN ： 1ns1.domain.com. IN A 111.222.111.222 大多数情况下，在这里你可以将你的 web 服务器定义为 “www”： 1www IN A 222.222.222.222 我们还可以说明基本域解析到哪里。如下表示： 1domain.com. IN A 222.222.222.222 我们还可以使用 “@” 来表示基本域名： 1@ IN A 222.222.222.222 我们还可以解析此域下未明确定义的任何内容到此服务器。可以使用 “*” 通配符： 1* IN A 222.222.222.222 以上这些对于 AAAA 记录同样适用。 CNAME 记录（Canonical Name record）CNAME 记录为您的服务器（由A或AAAA记录定义的名称）定义规范名称的别名。 例如，我们可以有一个 A 记录定义 “server1” 主机，然后使用 “www” 作为此主机的别名： server1 IN A 111.111.111.111 www IN CNAME server1 请注意，这些别名会带来一些性能损失，因为它们需要对服务器进行额外的查询。大多数时候，通过使用附加的 A 或 AAAA 记录可以实现相同的结果。 推荐使用 CNAME 的一种情况是为当前区域之外的资源提供别名。 MX 记录（Mail eXchange record）MX 记录用来定义用于域的邮件交换。这有助于电子邮件正确到达您的邮件服务器。 与许多其他记录类型不同的是，邮件记录通常不会将主机映射到某些内容，因为它们适用于整个区域。因此，他们通常看起来像这样： IN MX 10 mail.domain.com. 请注意，开头没有主机名。 还要注意，它还有一个额外的数字。如果定义了多个邮件服务器，这是帮助计算机决定发送邮件的服务器的首选项号。较低的数字具有较高的优先级。 MX 记录通常应指向由 A 或 AAAA 记录定义的主机，而不是由 CNAME 定义的主机。 所以，假设我们有两个邮件服务器。可以这样表示： IN MX 10 mail1.domain.com. IN MX 50 mail2.domain.com. mail1 IN A 111.111.111.111 mail2 IN A 222.222.222.222 在这个例子中，”mail1” 主机是首选电子邮件交换服务器。 我们也可以这样写： IN MX 10 mail1 IN MX 50 mail2 mail1 IN A 111.111.111.111 mail2 IN A 222.222.222.222 NS 记录(Name Server record)此记录类型定义用于此区域的名称服务器。 你可能想知道，”如果区域文件放在名称服务器上，为什么它需要引用自身？”。DNS 如此成功的其中一个原因是它的多级缓存。在区域文件中定义名称服务器的一个原因是区域文件可能是另外一个名称服务器的缓存副本。至于其他原因，我们不在这里讨论。 与 MX 记录一样，它也有一些区域范围的参数，因此它们也不使用主机。一般来说，它们看起来像这样： IN NS ns1.domain.com. IN NS ns2.domain.com. 你应该在每个区域文件中至少定义两个名称服务器，以便在一个服务器出现问题时还能正确运行。如果只有一个名称服务器，大多数 DNS 服务器软件都会认为区域文件无效。 同样，把主机的 A 或者 AAAA 映射也包含记录中： IN NS ns1.domain.com. IN NS ns2.domain.com. ns1 IN A 111.222.111.111 ns2 IN A 123.211.111.233 你还可以使用很多其他记录类型，但这些可能是你会遇到的最常见的类型。 PTR 记录（PoinTer Record）PTR 记录用于定义与 IP 地址相关联的名称。 PTR 记录是 A 或 AAAA 记录的逆。 PTR 记录是唯一的，因为它们以 .arpa 根开始并被委派给 IP 地址的所有者。区域互联网注册管理机构（RIRs）管理 IP 地址到组织和服务提供商的指派。区域互联网注册管理机构包括 APNIC，ARIN，RIPE NCC，LACNIC 和 AFRINIC。 这里是一个 111.222.333.444 的 PTR 记录的示例： 444.333.222.111.in-addr.arpa. 33692 IN PTR host.example.com. 我们可以看到地址是反的，而且ip后面加了一个特定的后缀.in-addr.arpa.。 IPv6 地址的这个 PTR 记录示例使用了 Google IPv6 DNS 服务器(2001:4860:4860::8888)的逆转形式的半字节格式。 8.8.8.8.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.6.8.4.0.6.8.4.1.0.0.2.ip6.arpa. 86400IN PTR google-public-dns-a.google.com. dig 命令的 -x 参数可用于查找 IP 地址的反向 DNS 名称。 下面是一个 dig 命令的例子。+short 确保只输出反向 DNS 名称。 dig -x 8.8.4.4 +short 上述 dig 命令的输出将是该 IP 地址的 PTR 记录中的域名： google-public-dns-b.google.com. 互联网上的服务器在日志中使用 PTR 记录，来做出明智的垃圾邮件处理决策，并显示​​其他设备上的易于阅读的详细信息。 最常用的电子邮件服务器将查找从其接收电子邮件的 IP 地址的 PTR 记录。如果源 IP 地址没有与其相关联的 PTR 记录，则发送的电子邮件可被视为垃圾邮件并被拒绝。PTR 中的 FQDN 与要发送的电子邮件的域名是否匹配并不重要，重要的是存在有效的 PTR 记录，具有对应的和匹配的前向 A 记录。 通常，互联网上的网络路由器会被赋予与其物理位置相对应的 PTR 记录。例如，你可能会在纽约市或芝加哥看到使用 “NYC” 或 “CHI”。这对于运行 traceroute 或者 MTR 来检查网络流量经过的路径很有用。 大多数提供专用服务器或 VPS 服务的提供商允许客户为其 IP 地址设置 PTR 记录。 注意: PTR 记录中的 FQDN 具有对应的和匹配的正向 A 记录是非常重要的。示例：111.222.333.444 有一条指向 server.example.com 的 PTR 记录，那 server.example.com 需要具有一条指向 111.222.333.444 的 A 记录。 总结了解了不同类型的 DNS 记录以及它们的作用之后，你就可以根据需要选择不同的 DNS 记录。 不同的域名服务商提供了不一样的 DNS 记录的的配置方法，但是你理解了 DNS 记录的作用之后，配置对你来说就不是难事了。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>DNS</tag>
        <tag>DNS Record</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[02-DNS如何工作]]></title>
    <url>%2Flinux%2F20170725-02-how-dns-work-together%2F</url>
    <content type="text"><![CDATA[上一篇文章(什么是DNS)中，我们解释了 DNS 所涉及到的一些术语，接下来我们来看看 DNS 这个系统是如何工作的？ 从高层次上看，这个系统非常简单，但是当你关注细节时，它又非常复杂。总的来说，它是一个非常可靠的基础设施，对于构建我们当今的互联网，是至关重要的。 根服务器如前所述，DNS 的核心是一个分层系统。在这个系统的顶部是所谓的 “根服务器”。这些服务器由各种组织控制，并由 ICANN（互联网名称和数字地址分配公司）授权。 目前正在使用的根服务器有 13 个。但是，由于每分钟都要解析的名称数量多得令人难以置信，所以实际上每个根服务器都有镜像服务器。有关这个一个有趣的事情是，每个根服务器与它的镜像服务器共享同一个 IP 地址。当你对某个根服务器发出请求时，请求会被路由到该根服务器离你最近的镜像服务器。 这些根服务器做什么的？根服务器处理有关顶级域名信息的请求。因此，如果某个请求低级别名称服务器无法解析，则会向该域的根服务器进行查询。 根服务器不知道实际托管域名的位置。然而，他们会将请求引导到处理特定请求的顶级域名的名称服务器。 因此，如果向根服务器发出对 “www.wikipedia.org” 的请求，则根服务器不能在它的记录文件中找到与 “www.wikipedia.org” 匹配的记录。 但是它会找到 “org” TLD 的记录，并把负责 “org” 地址的名称服务器的地址发回给请求者。 定义根服务器的文件地址：/var/named/named.ca 123456789101112131415161718192021222324252627282930313233343536373839404142;; ANSWER SECTION:. 518400 IN NS a.root-servers.net.. 518400 IN NS b.root-servers.net.. 518400 IN NS c.root-servers.net.. 518400 IN NS d.root-servers.net.. 518400 IN NS e.root-servers.net.. 518400 IN NS f.root-servers.net.. 518400 IN NS g.root-servers.net.. 518400 IN NS h.root-servers.net.. 518400 IN NS i.root-servers.net.. 518400 IN NS j.root-servers.net.. 518400 IN NS k.root-servers.net.. 518400 IN NS l.root-servers.net.. 518400 IN NS m.root-servers.net.;; ADDITIONAL SECTION:a.root-servers.net. 3600000 IN A 198.41.0.4a.root-servers.net. 3600000 IN AAAA 2001:503:ba3e::2:30b.root-servers.net. 3600000 IN A 192.228.79.201b.root-servers.net. 3600000 IN AAAA 2001:500:84::bc.root-servers.net. 3600000 IN A 192.33.4.12c.root-servers.net. 3600000 IN AAAA 2001:500:2::cd.root-servers.net. 3600000 IN A 199.7.91.13d.root-servers.net. 3600000 IN AAAA 2001:500:2d::de.root-servers.net. 3600000 IN A 192.203.230.10e.root-servers.net. 3600000 IN AAAA 2001:500:a8::ef.root-servers.net. 3600000 IN A 192.5.5.241f.root-servers.net. 3600000 IN AAAA 2001:500:2f::fg.root-servers.net. 3600000 IN A 192.112.36.4g.root-servers.net. 3600000 IN AAAA 2001:500:12::d0dh.root-servers.net. 3600000 IN A 198.97.190.53h.root-servers.net. 3600000 IN AAAA 2001:500:1::53i.root-servers.net. 3600000 IN A 192.36.148.17i.root-servers.net. 3600000 IN AAAA 2001:7fe::53j.root-servers.net. 3600000 IN A 192.58.128.30j.root-servers.net. 3600000 IN AAAA 2001:503:c27::2:30k.root-servers.net. 3600000 IN A 193.0.14.129k.root-servers.net. 3600000 IN AAAA 2001:7fd::1l.root-servers.net. 3600000 IN A 199.7.83.42l.root-servers.net. 3600000 IN AAAA 2001:500:9f::42m.root-servers.net. 3600000 IN A 202.12.27.33m.root-servers.net. 3600000 IN AAAA 2001:dc3::35 TLD 服务器请求者然后向负责该请求的顶级域名的 IP 地址（由根服务器给予）发送新请求。 对于我们的例子，它会发送想负责 “org” 域名的名称服务器发送一个请求，看看它是否知道 “www.wikipedia.org” 在哪里。 同样，该名称服务器也不会在记录文件中找到 “www.wikipdia.org” 记录。 但是，它会找到负责 “wikipedia.org” 的名称服务器的 IP 地址。这样就越来越接近我们想要的答案了。 域名级别名称服务器此时，请求者知道了具体负责该资源的实际 IP 地址的名称服务器的 IP 地址。它向该名称服务器发送一个新的请求，再次询问它是否可以解析 “www.wikipedia.org”。 名称服务器检查其区域文件，并发现它有与 “wikipedia.org” 相关联的区域文件。在此文件的内部，有一个 “www” 主机的记录。此记录说明此主机所在的 IP 地址，并向请求者返回最终答案。 请求者是什么？在上面的场景中，我们引用了 “请求者”。在这种情况下请求者指的是什么？ 在几乎所有情况下，请求者都是我们所谓的 “解析名称服务器”。解析名称服务器是配置着为询问其他服务器的问题的。它基本上是用户的中介，它缓存着先前的查询结果来提高速度，并且知道根服务器的地址，以便能够 “解析” 它还不知道的域名。 基本上，用户通常会在其计算机系统上配置多个解析名称服务器。解析名称服务器通常由 ISP 或其他组织提供。例如，Google 提供了你可以使用的 DNS 解析服务器。这些可以在计算机中自动或手动配置。 当你在浏览器的地址栏中键入网址时，你的计算机将首先查看是否可以在本地找到资源所在的位置。它检查计算机上的 “hosts” 文件和其他几个位置。然后它将请求发送到解析名称服务器，并等待接收资源的 IP 地址。 解析名称服务器首先检查其缓存。如果没有，它将通过上述步骤找到答案。 解析名称服务器基本上压缩了最终用户的请求过程。客户端只需要知道请求资源所在的解析名称服务器，并且确信他们会查询并返回最终答案。 总结你现在知道了 DNS 的工作原理。但是要实际操作，你依然需要了解有哪些常见的 DNS记录以及它们的作用。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[01-什么是DNS]]></title>
    <url>%2Flinux%2F20170725-01-what-is-dns%2F</url>
    <content type="text"><![CDATA[DNS，或者说域名系统，通常是学习如何配置网站和服务器的一个非常困难的部分。了解 DNS 的工作原理将有助于诊断网络访问的问题，也有助于理解 DNS 系统背后的工作原理。 这篇文章中，我们会讨论一些基本的 DNS 概念，这些概念将有助于你配置并使用 DNS。 在我们开始配置你自己的服务器域名解析之前，让我们先来看一些关于这些是如何实现的的基本概念。 我们应该先从术语定义开始。虽然有一些术语在谈论计算领域中其它内容时经常出现，但是有许多术语不常使用。 先从简单的开始： 域名系统（Domain Name System）域名系统（通常被称为“DNS”）是一个网络系统，允许我们把对人类友好的名称解析为唯一的地址。 域名（Domain Name）域名是我们习惯于与互联网资源关联的人性化名称。例如，”google.com” 是一个域名。有些人会说 “google” 部分是域名部分，但我们通常可以将组合形式称为域名。 网址 “google.com” 与 Google Inc. 拥有的服务器相关联。当我们在浏览器中键入 “google.com” 时，域名系统允许我们访问其相关联的 Google 服务器。 IP 地址（IP Address）IP 地址是我们所说的网络可寻址位置。每个 IP 地址在其网络中必须是唯一的。我们这里谈论的网络就是指整个互联网。 IPv4，目前最常见的地址形式，由四组数字组成，每组最多有三位数字，每一组用一个点分隔。例如，111.222.111.222 是有效的 IPv4 IP 地址。使用 DNS，我们可以将名称映射到该地址，这样，你就不必记住一组复杂的数字，来访问你需要的网站。 顶级域名（Top Level Domain）顶级域名，或者说 TLD，是域名的最基本部分。顶级域名是右侧的最远部分（由点分隔）。常见的顶级域名是 com、net、org、gov、edu 和 io。 域名 代表含义 域名 代表含义 .com 表示商业机构 .cn 中国 .net 表示网络服务机构 .hk 中国香港 .org 表示非营利性组织 .tw 中国台湾 .gov 表示政府机构 .us 美国 .edu 表示教育机构 .jp 日本 .mil 表示军事机构 顶级域名在域名术语层次结构的最上层。由 ICANN（互联网名称和号码分配公司）对顶级域名进行管理控制。然后，通过域名注册商来分发 TLD 下面的域名。 主机（Host）域名所有者可以定义多个单独的主机，指向可以通过该域名访问的不同的计算机或者服务。例如，大多数域名所有者会让他们的 web 服务器可以通过裸域（example.com）以及 www 主机（www.example.com）访问。 你可以在一个域名下面定义其它主机。比如说，通过 api 主机(api.example.com) 允许 API 访问，通过 ftp 主机或者 files 主机(ftp.example.com 或者 files.example.com）允许 ftp 访问。主机名可以任意指定，只要它们在该域名下是唯一的。 子域名（Sub Domain Name）一个和主机相关的主题就是子域名。 DNS 有层次结构，TLD 下面可以有多个域名。例如，com 下面有 google.com 和 ubuntu.com。”子域名” 是指作为较高层级域名的一部分。所以说，ubuntu.com 可以说是 com 的子域名，但是通常这被称为域名，或者 “ubuntu” 部分是 SLD(Second Level Domain)，所以这是一个二级域名。 同样，每个域名可以控制它下面的子域名。这通常就是我们所指的子域名。例如，你可以把 “www.history.school.edu” 作为你学校的历史部门的域名。 “history” 部分是一个子域名。 主机名和子域名之间的区别是主机定义计算机或资源，而子域名扩展父域。它是一种把域名本身细分的方法。 无论谈论子域名还是主机，你都可以开始看到域名的最左边部分是最具体的。这也是 DNS 的工作原理：从左到右阅读时，从最具体到最不具体。 完全限定域名（Fully Qualified Domain Name）完全限定的域名，通常称为 FQDN，也就是我们所说的绝对域名。DNS 系统中的域名可以是相对的，所以可能是模糊的。FQDN 是一个绝对名称，表示了它相对于域名系统中绝对根目录的位置。 这表明它表示的每个域名都包括 TLD 部分。正确的 FQDN 以点结束，表示 DNS 层次结构的根。“mail.google.com.” 就是一个标准的 FQDN 的例子。有时候，一些软件使用的 FQDN 不需要末尾的点，但是要符合 ICANN 标准的话一定要加上末尾的点。 名称服务器（Name Server）名称服务器(NS)是一种将域名翻译成 IP 地址的计算机。这些服务器完成了 DNS 系统中的大部分工作。由于域名翻译的数量对于任何一台服务器来说都太多了，因此每台服务器可以将请求转发给其他名称服务器或把它们负责的子域名的子集委派给其他名称服务器。 名称服务器可以是 “权威的”，表示它们自己可以提供所负责的域名的查询结果。否则，它们可能会转发到其他服务器，或者提供其他名称服务器数据的缓存副本。 区域文件（Zone Files）区域文件是一个简单的文本文件，包含域名和 IP 地址之间的映射。这是当用户请求某个域名时，DNS 系统最终找出 IP 关联记录的地方。 区域文件放置在名称服务器中，通常定义了特定域名下可用的资源，或者可以去获取该信息的位置。 记录（Record）在区域文件中，保存着记录。其中最简单的记录形式是，是资源和名称之间的单独映射。它们可以将域名映射到 IP 地址，定义域名的名称服务器，定义域名的邮件服务器等。 总结现在你已经了解了 DNS 所涉及到的一些术语，接下来你可以想了解 DNS如何工作。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cobbler 同步网络yum仓库到本地（Reposync用法)]]></title>
    <url>%2Flinux%2F20170722-cobbler-reposync%2F</url>
    <content type="text"><![CDATA[我们在图形界面进行操作： Arch选择x86_64，Breed选择yum或者wget方式都可以，Keep Updated不要勾选（以后你可以设置计划任务，每天凌晨时间更新）。Mirror和Name根据添加的repo不同而不同，列出几个用到的repo：如需还有需要，可以自行添加： Name Mirror centos7.4-base https://mirrors.tuna.tsinghua.edu.cn/centos/7.4.1708/os/x86_64/ centos7.4-updates https://mirrors.tuna.tsinghua.edu.cn/centos/7.4.1708/updates/x86_64/ centos7.4-extras https://mirrors.tuna.tsinghua.edu.cn/centos/7.4.1708/extras/x86_64/ centos7-epel https://mirrors.tuna.tsinghua.edu.cn/epel/7/x86_64/ centos7-mariadb http://yum.mariadb.org/10.2/centos7-amd64/ centos7-nginx http://nginx.org/packages/centos/7/x86_64/ centos7-zabbix-3.4 https://mirrors.tuna.tsinghua.edu.cn/zabbix/zabbix/3.4/rhel/7/x86_64/ centos7-docker-ce-stable https://mirror.tuna.tsinghua.edu.cn/docker-ce/linux/centos/7/x86_64/stable/ centos7-gitlab-ce https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el7/ centos7-saltstack-latest https://mirror.tuna.tsinghua.edu.cn/saltstack/yum/redhat/7/x86_64/latest/ elastic-stack-5.x https://mirrors.tuna.tsinghua.edu.cn/elasticstack/5.x/yum/ jenkins-stable http://pkg.jenkins.io/redhat-stable/ 可以点图形界面 Reposync，但是没有输出，看不到同步过程，不推荐使用图形界面的Reposync按钮，看不到详情： 可以在CLI下运行： 1cobbler reposync 可以看到结果如下（省略部分内容）： 1234567891011121314151617181920212223242526272829303132333435363738394041[root@localhost ~]# cobbler reposynctask started: 2017-10-03_082140_reposynctask started (id=Reposync, time=Tue Oct 3 08:21:40 2017)hello, reposyncrun, reposync, run!creating: /var/www/cobbler/repo_mirror/centos7-nginx/config.repocreating: /var/www/cobbler/repo_mirror/centos7-nginx/.origin/centos7-nginx.reporunning: /usr/bin/reposync -l -n -d --config=/var/www/cobbler/repo_mirror/centos7-nginx/.origin/centos7-nginx.repo --repoid=centos7-nginx --download_path=/var/www/cobbler/repo_mirror -a x86_64received on stdout: Repository rdo-trunk-pike-tested is listed more than once in the configuration3.6 kB 00:00 ... 3.4 kB 00:00 received on stderr: running: createrepo -c cache -s sha /var/www/cobbler/repo_mirror/centos7-nginxreceived on stdout: Spawning worker 0 with 3 pkgsSpawning worker 1 with 3 pkgsSpawning worker 2 with 2 pkgsSpawning worker 3 with 2 pkgsSpawning worker 4 with 2 pkgsSpawning worker 5 with 2 pkgsWorkers FinishedSaving Primary metadataSaving file lists metadataSaving other metadataGenerating sqlite DBsSqlite DBs completereceived on stderr: running: chown -R root:apache /var/www/cobbler/repo_mirror/centos7-nginxreceived on stdout: received on stderr: running: chmod -R 755 /var/www/cobbler/repo_mirror/centos7-nginxreceived on stdout: received on stderr: creating: /var/www/cobbler/repo_mirror/epel-7/config.repocreating: /var/www/cobbler/repo_mirror/epel-7/.origin/epel-7.repo...*** TASK COMPLETE *** 如果想单独只同步某一个仓库，可以使用cobbler reposync --only=REPO_NAME，例如： 1cobbler reposync --only=centos7-mariadb-10.2 我们还可以通过浏览器键入http://172.30.0.222/cobbler/repo_mirror/查看同步下来的仓库： 提示： 由于这篇文章2017年10月3号写的，和上一篇不是一个时间段写的，ip地址已更换，镜像也换成新版的CentOS7.4的地址，不是上一节的地址和系统版本，特此提示。 cat /var/www/cobbler/repo_mirror/xxx/conf.repo，xxx为每一个repo的目录，然后我们可以做一个all.repo文件,例如： 12cd /var/www/cobbler/repo_mirrorcat */config.repo &gt; all.repo 刚出来的all.repo文件是这样的： 12345678910111213[centos7.4-base]name=centos7.4-basebaseurl=http://$&#123;http_server&#125;/cobbler/repo_mirror/centos7.4-baseenabled=1priority=99gpgcheck=0[centos7.4-updates]name=centos7.4-updatesbaseurl=http://$&#123;http_server&#125;/cobbler/repo_mirror/centos7.4-updatesenabled=1priority=99gpgcheck=0# ... 还有其他的仓库 我们可以用vim的替换功能，把${http_server}替换掉： 1:%s#$&#123;http_server&#125;#172.16.0.222#g 或者利用sed命令也可以替换： 1sed -i.bak &apos;s#$&#123;http_server&#125;#base.yulongjun.com#g&apos; all-sed.repo 然后就可以把all.repo copy到各个服务器的/etc/yum.repos.d/下使用。 可以用Ansible或者Salstack推送all.repo配置文件到所有的服务器，这样所有服务器都可以从内网下载安装包了。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Cobbler</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cobbler——无人值守安装多种版本多种配置操作系统]]></title>
    <url>%2Flinux%2F20170722-cobbler%2F</url>
    <content type="text"><![CDATA[本文未经允许，不得转载，否则追究到底。 Cobbler官网地址：cobbler.github.io Cobbler是一个Linux安装服务器，它能实现网络安装环境下的快速安装。 Cobbler是基于Python研发的。 我们可能经常遇到这种情况，需要大规模的安装Linux操作系统（几百上千台），不同版本的操作系统，同一版本又有不同配置，用Cobbler就可以搞定。 Cobber基于DHCP、PXE、TFTP、HTTP、Kickstart的技术，来提供统一的对外服务，另外还有Cobbler Web界面，不过Cobbler CLI已经满足大部分人需求，本节Cobbler Web不做研究，下节有个简单的Web实际用法。 另外Cobbler还可以作为一个本地yum仓库，利用reposync 一、配置Cobbler1. 主机信息虚拟机安装CentOS7，配置两个网卡。一个仅主机模式，关闭仅主机模式的dhcp服务（仅主机模式不影响其他网段的机器，做实验比较安全）；一个桥接模式，主要用来连外网下载Cobbler和Cobbler-Web安装包。 仅主机模式配置静态ip为192.168.111.1；桥接模式的ip用dhcp获取即可。 2. 配置阿里云的CentOS7和epel的yum源（比较快）12345cd /etc/yum.repos.d/mkdir backupmv *.repo backupwget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repowget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo 3. 关闭SELinux和iptables1234setenforce 0sed -i.bak 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/selinux/configsystemctl stop firewalldsystemctl disable firewalld 4. 安装dhcp、tftp、cobbler、cobbler-web, 启动和启用服务yum安装cobbler的时候，除了dhcp和，其他依赖如tftp-server、httpd、syslinux(里面有pxelinux.0文件）等会自动安装，所以只要装dhcp、cobbler、cobbler-web就好。 123yum install cobbler cobbler-web tftp-server dhcpsystemctl enable httpd cobblerd dhcpd systemctl start httpd cobblerd dhcpd 这里启动dhcpd会报错，是因为配置还没配置，不用管，忽略就行。 5. 更改配置文件配置文件路径：/etc/cobbler/settings 12cp /etc/cobbler/settings&#123;,.bak&#125;vim /etc/cobbler/settings 要更改的内容： (1) Default Encrypted Password 默认为 1default_password_crypted: "$1$bfI7WLZz$PxXetL97LkScqJFxnW7KS1" 但这个密码必须要更改，否则cobbler check会报错。 用openssl passwd -1命令来生成新的sha1sum加密密码，这里设置的密码是cobbler1024，加密后变成$1$mq2YqFBn$um6u0ScNqnDHltdWGQSIj0，把生成的密码覆盖原来的密码： 12345# openssl passwd -1Password: Verifying - Password: $1$mq2YqFBn$um6u0ScNqnDHltdWGQSIj0 (2) Server 和 Next_Server server选项是指cobbler server的ip地址，这里要指定一个网卡的ip，实验环境里指的是仅主机模式的192.168.111.1。 next_server选项被用在DHCP/PXE上，用来作为DHCP Server和TFTP Server的IP地址，一般和Cobbler服务地址使用一个IP。 1234# default, localhostserver: 192.168.111.1# default, localhostnext_server: 192.168.111.1 (3) DHCP Management 和 DHCP Server Template（模板） manage_dhcp，0更改为1 12# default, don't managemanage_dhcp: 1 6. 更改dhcp模板由于上一节更改settings里的manage_dhcp为1了，所以，dhcpd变成cobblerd来管理了。我们通过更改/etc/cobbler/dhcp.template，然后sync同步到/etc/dhcp/dhcpd.conf。 12cp /etc/cobbler/dhcp.template&#123;,.bak&#125;vim /etc/cobbler/dhcp.template 修改模板里的内容： 123456subnet 192.168.111.0 netmask 255.255.255.0 &#123; option subnet-mask 255.255.255.0; range dynamic-bootp 192.168.111.100 192.168.111.200; default-lease-time 21600; max-lease-time 43200; next-server $next_server; 备份原来的dhcpd.config,然后用cobbler sync一下： 123cp /etc/dhcp/dhcpd.conf&#123;,.bak&#125;systemctl restart cobblerdcobbler sync 同步完后，这时候去查看一下/etc/dhcp/dhcpd.conf，内容已经被覆盖了,我们也可以看到注释里写的是被Cobbler管理的dhcpd.conf：Cobbler managed dhcpd.conf file 警告：千万不要修改next-server $next_server;这行，不用改。配置是写在#for dhcp_tag in $dhcp_tags.keys():这行之前，不要写在最后。如果想了解更多关于dhcpd.conf的信息，可以man dhcpd.conf 7. 同步配置，重启相关服务1cobbler sync 8. 下载bootloader的加载程序12cobbler get-loaderscobbler sync 9. 配置cobbler-web配置文件是/etc/cobbler/modules.conf。 修改cobbler web登录时候的的用户名和密码： 1htdigest /etc/cobbler/users.digest "Cobbler" cobbler 123systemctl restart cobblerdcobbler syncsystemctl restart httpd 用修改过用户名密码登录测试： https://192.168.111.1/cobbler_web 二、cobbler使用指南1. 导入光盘(1)挂载光盘给虚拟机配置两个光盘，分别挂载CentOS6和CentOS7的光盘。挂载光盘到目录： 1234mkdir /mnt/centos6mkdir /mnt/centos7mount /dev/sr0 /mnt/centos6mount /dev/sr1 /mnt/centos7 如果是拷贝的iso文件到服务器，可以mount iso到目录： 1234mkdir /mnt/centos6mkdir /mnt/centos7mount CentOS-6.9-x86_64-bin-DVD1.iso /mnt/centos6mount CentOS-7-x86_64-Everything-1611.iso /mnt/centos7 (2)cobbler import导入光盘 1cobbler import --name=CentOS6.9 --path=/mnt/centos6 &amp;&amp; cobbler import --name=CentOS7.3 --path=/mnt/centos7 如图我们可以看到，我们添加了两个发行版本到distros,也创建了两个profile(使用的是sample的ks文件），名字都是CentOSx.x-x86_64，是cobblerd自动侦测了是x86_64的版本，自动添加到上面import命令的name后面。 查看distro/profile对，这两个list目前显示应该是一样的。（后期增加不同配置的ks文件，生成不同的profile，就不一样了，还需要把profile默认的两个例子删掉） 123cobbler distro listcobbler profile list 查看导入的发行版操作系统信息(distro)： 123# 导入的发行版操作系统信息cobbler distro report # 全部cobbler distro report --name=CentOS6.9-x86_64 # 单独一个 我们看到有两行信息： 123Kickstart Metadata : &#123;'tree': 'http://@@http_server@@/cblr/links/CentOS7.3-x86_64'&#125;Kickstart Metadata : &#123;'tree': 'http://@@http_server@@/cblr/links/CentOS6.9-x86_64'&#125; 这两行就是你将来ks文件里写的安装url，后续在ks文件就采用这个地址作为源的地址。 ks文件如果原来是cdrom安装方式，把cdrom换成url --url=http://xxxx： CentOS 6: 1url --url=http://192.168.111.1/cblr/links/CentOS6.9-x86_64/ CentOS 7: 1url --url=http://192.168.111.1/cblr/links/CentOS7.3-x86_64/ 导入ks文件如果要自己制作，详见博文自制kickstart光盘 。 然后记得修改cdrom安装方式为url --url=http://192.168.111.1/cblr/links/CentOSx.x-x86_64/，x.x为你的上面写的系统版本。 本人自制的cobbler的ks文件链接: http://pan.baidu.com/s/1i4BGeUh密码:0kfe 如果有网友拿过来，记得更改url地址为自己cobbler的地址。 cobbler文件夹就是存放cobbler用的ks文件,分别对应6和7的最小化安装和开发包安装（其中手选了一些必要的包），包的话可以根据个人喜好自行更改: 把这四个文件copy到cobbler服务器的/var/lib/cobbler/kickstarts/目录下 这时候我们只是拷贝到目录里了，但是cobbler并没有对系统和ks文件做对应关系，我们用cobbler profile report（和distro命令一样，加--name=xxx可以查看具体单个的属性信息）可以看到kickstart的那一条属性只是一个例子而已： 我们删掉例子，来重新添加新的kickstart文件对应关系： 123456cobbler profile remove --name="CentOS6.9-x86_64"cobbler profile remove --name="CentOS7.3-x86_64"cobbler profile add --name=CentOS6.9-Devel--x86_64 --kickstart=/var/lib/cobbler/kickstarts/ks-centos6-devel.cfg --distro=CentOS6.9-x86_64cobbler profile add --name=CentOS6.9-Mini-x86_64 --kickstart=/var/lib/cobbler/kickstarts/ks-centos6-mini.cfg --distro=CentOS6.9-x86_64cobbler profile add --name=CentOS7.3-Devel-x86_64 --kickstart=/var/lib/cobbler/kickstarts/ks-centos7-devel.cfg --distro=CentOS7.3-x86_64cobbler profile add --name=CentOS7.3-Mini-x86_64 --kickstart=/var/lib/cobbler/kickstarts/ks-centos7-mini.cfg --distro=CentOS7.3-x86_64 这时候我们去查看pxelinux.cfg/default文件就能看到菜单选项也跟着变了： 123[root@center tftpboot]# locate pxelinux.cfg/default/var/lib/tftpboot/pxelinux.cfg/default[root@center tftpboot]# cat /var/lib/tftpboot/pxelinux.cfg/default 重启cobblerd 12systemctl restart cobblerdcobblerd sync Cobbler自动化安装图示新增加一台虚机，和cobbler服务器在一个网段，打开运行，就会出现如下界面： 好了，可以尽情的使用了，如果要添加新的版本，按照上面步骤添加就可以了。 Cobbler Web图形界面也能实现类似的导入功能，可以参见下一节举了一个Cobbler Web的用法： cobbler 添加网络同步仓库（Reposync用法)]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Cobbler</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TFTP和PXE]]></title>
    <url>%2Flinux%2F20170722-02-tftp-pxe%2F</url>
    <content type="text"><![CDATA[TFTPTFTP（Trivial File Transfer Protocol,简单文件传输协议）是TCP/IP协议族中的一个用来在客户机与服务器之间进行简单文件传输的协议，提供不复杂、开销不大的文件传输服务。端口号为69，基于UDP协议。 yum info tftp-server或rpm -qi tftp-server可以查看描述： 看到描述我们可以知道，TFTP通常用来作为无盘工作站的启动。允许用户从远程机器上传输文件。 tftp服务可以用来做pxe的启动拉取pxelinux.0文件和启动菜单文件。 一般存放pxe相关文件的位置为/var/lib/tftpboot/下面。 PXEPXE：Preboot Excution Environment, Intel公司研发，没有任何操作系统的主机，能够基于网络完成系统的安装工作。 PXE工作原理： Client向PXE Server上的DHCP发送IP地址请求消息，DHCP检测Client是否合法（主要是检测Client的网卡MAC 地址），如果合法则返回Client的IP地址，同时将启动文件 pxelinux.0的位置信息一并传送给Client Client向PXE Server上的TFTP发送获取pxelinux.0请求消息，TFTP接收到消息之后再向Client发送pxelinux.0大小信息，试探Client是否满意，当TFTP收到Client发回的同意大小信息之后，正式向Client发送pxelinux.0 Client执行接收到的pxelinux.0文件 Client向TFTP Server发送针对本机的配置信息文件（在 TFTP 服务的pxelinux.cfg目录下），TFTP将配置文件发回Client，继而Client根据配置文件执行后续操作。 Client向TFTP发送Linux内核请求信息，TFTP接收到消息之后将内核文件发送给Client Client向TFTP发送根文件请求信息，TFTP接收到消息之后返回Linux根文件系统 Client启动Linux内核 Client下载安装源文件，读取自动化安装脚本。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>tftp</tag>
        <tag>tftpd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DHCP详解]]></title>
    <url>%2Flinux%2F20170722-01-dhcp%2F</url>
    <content type="text"><![CDATA[动态主机配置协议（Dynamic Host Configuration Protocol，DHCP）是一个局域网的网络协议，使用UDP协议工作，主要有两个用途： 用于内部网络或网络服务供应商自动分配IP地址给用户。 用于内部网络管理员作为对所有电脑作中央管理的手段。 DHCP使用UDP协议，服务端的端口为67，客户端的端口为68。 DHCP的服务过程DHCP相关消息： DHCP DISCOVER：客户端到服务器 DHCP OFFER ：服务器到客户端 DHCP REQUES：客户端到服务器 DHCP ACK ：服务器到客户端 DHCP NACK：服务器到客户端指示客户 端的网络地址的概念是不正确的 DHCP DECLINE ：客户端到服务器，指 示地址已被使用 DHCP RELEASE：客户端到服务器，放弃 网络地址和取消剩余的租约时间 DHCP INFORM：客户端到服务器,只要 求本地配置参数，客户端已经具有外部配 置的网络地址 主要用到前四个： DHCP正常的运行分为四个基本过程，分别为： DHCP发现（DISCOVER） DHCP提供（OFFER） DHCP请求（REQUEST） DHCP确认（Acknowledge，ACK） 租期DHCP使用了租约的概念，或称为计算机IP地址的有效期。租用时间是不定的，主要取决于用户在某地连接Internet需要多久。通过较短的租期，DHCP能够在一个计算机比可用IP地址多的环境中动态地重新配置网络。DHCP支持为计算机分配静态地址，可以自行手动指定。 客户在获得了一个IP地址以后，就可以发送一个ARP请求来避免由于DHCP服务器地址池重叠而引发的IP冲突。 租期一般为10分钟，在配置文件里可以更改。 50%：租赁时间达到50%时来续租，刚向DHCP服务器发向新的DHCPREQUEST请求。如果DHCP服务没有拒绝的理 由，则回应DHCPACK信息。当DHCP客户端收到该应答信 息后，就重新开始新的租用周期。 87.5%：如果之前DHCP Server没有回应续租请求，等到 租约期的7/8时，主机会再发送一次广播请求 DHCP实现程序dhcpd服务，主要用到dhcp这个包(也有轻量级的的DNS+DHCP的包，叫dnsmasq。） Client方面，系统默认安装了dhclient。 yum info dhcp我们可以看到dhcp这个包是isc.org这个组织开发的。 这个组织是开发DHCP和BIND（DNS软件）开源项目的组织。 dhcpd主要配置虚机配置仅主机模式，不对外服务，同时在网络编辑器里设置仅主机网络不提供dhcp服务（会跟配置的dhcp服务器冲突）。 安装dhcpd服务 1yum install dhcp 我们需要先行配置dhcpd的配置文件，如果不配置，服务使起不来的。 dhcpd服务的配置文件/etc/dhcp/dhcpd.conf 我们查看dhcpd.conf文件，发现只有这个： 12345## DHCP Server Configuration file.# see /usr/share/doc/dhcp*/dhcpd.conf.example# see dhcpd.conf(5) man page# 让我们去查看示例：/usr/share/doc/dhcp*/dhcpd.conf.example或者man 5 dhcpd.conf。 我们复制一份示例到配置下： 1cp /usr/share/doc/dhcp*/dhcpd.conf.example /etc/dhcp/dhcpd.conf 我们来看下面几个配置选项(更改过的），分别注释下意义： 123456789## 全局网络的选项定义option domain-name "yulongjun.com"; option domain-name-servers 223.5.5.5, 223.6.6.6;option routers 192.168.111.1;default-lease-time 600;max-lease-time 7200;## 局部网络的选项定义subnet 192.168.111.0 netmask 255.255.255.0 &#123; range 192.168.111.100 192.168.111.200; `option domain-name “yulongjun.com”：搜索域，即search domain,网络中获取dhcp的服务器默认被设置的搜索域名。有什么作用呢？在我们ping的时候，ping www即是ping www.yulongjun.com，ping blog即是ping blog.yulongjun.com`。 option routers 192.168.111.1：网关option domain-name-servers 223.5.5.5, 223.6.6.6;：DNS服务器，这里设置的223.5.5.5，223.6.6.6，阿里的dns服务器。 default-lease-time 600;：默认租期时间。单位为秒。 max-lease-time 7200;：最大租期时间。指的是客户端有请求长租期的时候，默认分配的时间。单位为秒。 subnet 写网段的参数，包括range范围之类的，也可以自定义上述全局的那些参数（如domain-name、domain-name-server，router等），就变成这个网段的局部参数，只对这个网段生效。 启动dhcpd服务： 1systemctl start dhcpd 另一台在同一个网段的服务器，如果网络是dhcp获取的，就可以获取range范围内的ip地址。 可以通过查看/var/lib/dhclient/xxx-网卡名.lease看到租期信息。 123456789101112lease &#123; interface "ens192"; fixed-address 192.168.111.100; option subnet-mask 255.255.255.0; option dhcp-lease-time 600; option dhcp-message-type 5; option dhcp-servers 223.5.5.5,223.6.6.6; option dhcp-server-identifier 192.168.111.1; renew 6 2017/07/22 01:46:30; rebind 6 2017/07/22 01:50:46; expire 6 2017/07/22 01:52:01;&#125; renew：续租时间（50%）rebind：7/8时间，再询问的时间（87.5%）expire：过期时间（100%） dhclient -d可以重新发个广播，来请求dhcpd服务。 我们发现还会使用旧的地址，除非你关机了，地址被回收了，那么就会使用新地址。 如果给多个网段提供服务，网关可以写到各个子网段里，而不是写到全局配置里。还有domain-name、domain-name-server，router等参数，也可以写到子网段里。如果全局和局部都有，优先使用局部的，如果没有定义，则使用全局的。如下： 1234567891011121314## 全局网络的选项定义option domain-name "yulongjun.com"; option domain-name-servers 223.5.5.5, 223.6.6.6;option routers 192.168.111.1;default-lease-time 600;max-lease-time 7200;## 局部网络的选项定义subnet 192.168.111.0 netmask 255.255.255.0 &#123; range 192.168.111.100 192.168.111.200;&#125;subnet 192.168.222.0 netmask 255.255.255.0 &#123; range 192.168.222.100 192.168.222.200; option routers 192.168.222.1;&#125; 111网段没有定义局部的routers，所以使用全局的routers ，222网段由于定义了局部的routers，就使用局部的routers dhcpd其他配置filename: 指明引导文件名称next-server: 指明引导文件的服务器ip地址 例如： 12345subnet 192.168.111.0 netmask 255.255.255.0 &#123; range 192.168.111.100 192.168.111.200; filename &quot;pxelinux.0&quot; next-server 192.168.111.1;&#125; 如果我们制定了这两个文件，一个网络引导的有pxe服务的dhcp客户端，就可以通过tftp去拉取next-server上的filename指定的pxelinux.0文件。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>dhcp</tag>
        <tag>dhcpd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第二阶段考试]]></title>
    <url>%2Flinux%2F20170721-exam%2F</url>
    <content type="text"><![CDATA[第一题 (1)、 简述raid0、raid1、raid5三种工作模式的工作原理及特点(2)描述linux系统下创建软RAID5的命令和步骤 (1) RAID 0 RAID 0亦称为带区集。它将两个以上的磁盘并联起来，成为一个大容量的磁盘。在存放数据时，分段后分散存储在这些磁盘中，因为读写时都可以并行处理，所以在所有的级别中，RAID 0的速度是最快的。但是RAID 0既没有冗余功能，也不具备容错能力，如果一个磁盘（物理）损坏，所有数据都会丢失。 RAID 1 两组以上的N个磁盘相互作镜像，在一些多线程操作系统中能有很好的读取速度，理论上读取速度等于硬盘数量的倍数，与RAID 0相同。另外写入速度有微小的降低。只要一个磁盘正常即可维持运作，可靠性最高。其原理为在主硬盘上存放数据的同时也在镜像硬盘上写一样的数据。当主硬盘（物理）损坏时，镜像硬盘则代替主硬盘的工作。因为有镜像硬盘做数据备份，所以RAID 1的数据安全性在所有的RAID级别上来说是最好的。但无论用多少磁盘做RAID 1，仅算一个磁盘的容量，是所有RAID中磁盘利用率最低的一个级别。 如果用两个不同大小的磁盘建RAID 1，可用空间为较小的那个磁盘，较大的磁盘多出来的空间也可以分区成一个区来使用，不会造成浪费。 \begin{aligned}Size&amp;=\min \left(S{1},S{2},S_{3}\dots \right)\end{aligned} RAID 5 RAID Level 5是一种储存性能、数据安全和存储成本兼顾的存储解决方案。它使用的是Disk Striping（硬盘分区）技术。RAID 5至少需要三块硬盘，RAID 5不是对存储的数据进行备份，而是把数据和相对应的奇偶校验信息存储到组成RAID5的各个磁盘上，并且奇偶校验信息和相对应的数据分别存储于不同的磁盘上。当RAID5的一个磁盘数据发生损坏后，可以利用剩下的数据和相应的奇偶校验信息去恢复被损坏的数据。RAID 5可以理解为是RAID 0和RAID 1的折衷方案。RAID 5可以为系统提供数据安全保障，但保障程度要比镜像低而磁盘空间利用率要比镜像高。RAID 5具有和RAID 0相近似的数据读取速度，只是因为多了一个奇偶校验信息，写入数据的速度相对单独写入一块硬盘的速度略慢，若使用“回写缓存”可以让性能改善不少。同时由于多个数据对应一个奇偶校验信息，RAID 5的磁盘空间利用率要比RAID 1高，便宜。 \begin{aligned}Size&amp;=(N-1)\times \min \left(S{1},S{2},\dots ,S_{N}\right)\end{aligned} (2) 新增加一块硬盘sdb，200G 划分4个分区，分别为20Gfdisk /dev/sdb，具体过程不贴了，最后的效果是这样： 123456 Device Boot Start End Blocks Id System/dev/sdb1 2048 41945087 20971520 83 Linux/dev/sdb2 41945088 83888127 20971520 83 Linux/dev/sdb3 83888128 125831167 20971520 83 Linux/dev/sdb4 125831168 419430399 146799616 5 Extended/dev/sdb5 125833216 167776255 20971520 83 Linux sdb1,sdb2,sdb3,sdb5各20G 123456789# 创建md0的软raid5阵列mdadm -C /dev/md0 -a yes -l 5 -n 3 -x 1 /dev/sdb1 /dev/sdb2 /dev/sdb3 /dev/sdb5# 格式化mkfs.xfs /dev/md0# 挂载mkdir /mnt/raid5mount /dev/md0 /mnt/raid5 第二题 每天的2 点和12 点整，将/etc 备份至/testdir/backup目录中，保存的文件名称格式为etcbak-yyyy-mm-dd-HH.tar.xz crontab -e 10 2,14 * * * /usr/bin/tar -Jcvf etcbak-`data +%F-%H`.tar.xz /etc 第三题 列出三个私有地址网络，用 CIDR 表示，并将 10.100.208.0/20 网络划分成 8 个子网，写出最大子网络的 IP 范围。 三个私有地址网络: 10.0.0.0/8172.16.0.0/16 ~ 172.31.0.0/16192.168.0.0/24 ~ 192.168.255.0/24划分后的最大子网络的IP范围为： 10.100.222.1-10.100.223.255 第三题 给CentOS6 eth0 网 卡 ， 分 别 设 置 三 个 IP 地 址 ：10.0.0.200/8,172.18.0.200/16,192.168.0.200/24，请写出步骤 临时配置： 123ifconfig eth0:0 10.0.0.200 netmask 255.0.0.0 upifconfig eth0:1 172.18.0.200 netmask 255.255.255.0 upifconfig eth0:2 192.168.0.200 netmask 255.255.255.0 up 永久生效： vim /etc/sysconfig/network-scripts/ifcfg-eth0:0 12345DEVICE=eth0:0ONBOOT=yesBOOTPROTO=staticIPADDR=10.0.0.200PREFIX=8 vim /etc/sysconfig/network-scripts/ifcfg-eth0:1 12345DEVICE=eth0:1ONBOOT=yesBOOTPROTO=staticIPADDR=172.18.0.200PREFIX=16 vim /etc/sysconfig/network-scripts/ifcfg-eth0:2 12345DEVICE=eth0:2ONBOOT=yesBOOTPROTO=staticIPADDR=192.168.0.200PREFIX=24 第五题 在 CentOS6 中，误删除/boot 下所有文件后无法启动，写出恢复的详细步骤。 救援模式进入系统 1234chroot /mnt/sysimagemount /dev/sr0 /mntrpm -ivh /mnt/Packages/kernel-2.6.32-696.el6.x86_64.rpm --forcegrub-install /dev/sda 手写/boot/grub/grub.conf 123456default =0timeout=5root (hd0,0)title CentOS 6.9 kernel /vmlinuz-2.6.32-696.el6.x86_64 root=/dev/sda2 init initramfs-2.6.32-696.el6.x86_64.img 退出重启 第六题 快速查找/root目录中大于2M的文本，并将文件中的magedu，换成www.magedu.com 1find /root --size +2M -type f -exec sed -i 's/magedu/www\.magedu\.com/g' &#123;&#125; \; 第七题 若系统检测到黑客用root用户登录了系统，如何将黑客所登录的终端杀死，并立即对root用户修改密码。 root用户执行who查看登录的终端信息（TERMINAL）ps -t |grep TERMINAL查看终端的进程号kill -9 PID按终端的进程号号杀掉异常的终端进程echo xxxx |passwd --stdin rootxxxx为新的密码 第八题 简述CentOS6开机启动流程 post–mbr grub 1stage–stage1.5–stage 2 /boot/grub—/boot/grub/grub.conf —kernel /vmlinuz.XXX root=— /boot/initramfs |/boot/initrd.XX.img —/sbin/init –/etc/inittab —/etc/rc.d/rc.sysinit（/etc/fstab） —/etc/rc5.d/K,S —/etc/rc.d/rc.local –login POST加电自检 引导加载器bootloader bootloader的引导程序GRUB的一部分放在MBR中 引导加载器程序GRUB grub 1.5阶段和2阶段 加载内核模块 先加载vmliuz内核，然后加载initramfs文件initd.img(里面都是预加载用到的的模块） 运行init,挂载硬盘和启动程序 运行init程序，init去读inittab启动模式,读取/etc/rc.d/rc.sysinit（里面有硬盘的挂载），找到相应模式对应的程序启动脚本，比如在5模式，去/etc/rc5.d里按顺序启动程序sbin/init –/etc/inittab —/etc/rc.d/rc.sysinit（/etc/fstab） —/etc/rc5.d —/etc/rc.d/rc.local 登录 第九题 Linux现连接一个新的存储(如/dev/sdb,容量为10T)一人应用程序需要在/data目录使用此存储的100G的存储空间，若做成LVM需要哪些步骤，请描述 12345# 让服务器识别硬盘echo '- - -' /sys/class/scsi_host/host2/scan# lsblk可以看到硬盘lsblk lvm创建过程： 123456pvcreate /dev/sdbvgcreate vg1 /dev/sdblvcreate -L 100G -n lv1 vg1mkfs.ext4 /dev/vg1/lv1mkdir /datamount /dev/vg1/lv1 /data 如果要加到fstab里设成开机启动： 1echo "/dev/vg1/lv1 /data ext4 defaults 0 0" &gt;&gt; /etc/fstab 第十题 修改上述网站的http 端口为9527 ，并为之增加SELinux 端口标签。 1234sed -i.bak &apos;s/Listen\ 80/Listen\ 9527/g&apos; /etc/httpd/conf/httpd.conf # 修改端口为9527semanage port -l| grep http_port_t # SELinux策略里没有9527端口semanage port -a -t http_port_t -p tcp 9527 # 添加9527端口semanage port -l| grep http_port_t # 再次查看有了 第十一题 查看crond进程打开了哪些文件 1lsof -c crond|grep REG|tr -s " " |cut -d" " -f9 第十二题 请完成以下操作1）查询file.txt文件里第一列数据数值之和(字段以&amp;符号分隔)2）查询Hie.txt第7行之前添加一行，内容为”#注释”3）打印出file.txt文件第6到第10行 1) 1awk -F'&amp;' 'NR==1 &#123;for (i=1;i&lt;=NF;i++)&#123;sum+=$i&#125;;print sum&#125;' file.txt 2) 1sed -i.bak '7i/#注释' Hie.txt 3) 1awk 'NR &gt;=6 &amp;&amp; NR&lt;=10' file.txt 第十三题 编写脚本，利用变量RANDOM生成10个随机数字，输出这10个数字，并显示其中的最大值和最小值，用两种方法实现 第一种： 12345678for i in `seq 0 9`;do array[$i]=$RANDOM echo $&#123;array[$i]&#125;doneecho "the min number:"echo $&#123;array[*]&#125;|awk -v RS=' ' -v ORS="\n" '&#123;print $0&#125;'|sort -n|grep -v '^$'|head -1echo "the max number:"echo $&#123;array[*]&#125;|awk -v RS=' ' -v ORS="\n" '&#123;print $0&#125;'|sort -n|grep -v '^$'|tail -1 第二种： 123456789101112131415161718for i in `seq 10`;do j=$RANDOM echo $j if [ $i -eq 1 ];then max=$j min=$j else if [ $j -ge $max ];then max=$j fi if [ $j -le $min ];then min=$j fi fidoneecho max number is $maxecho min number is $min 第14题 编写脚本，提示请输入网络地址，如192.168.0.0，判断输入的网段中主机在线状态，并统计在线主机和离线主机各多少 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102#!/bin/bash# ┌───────────────────────────────────────────────────────┐# │Script Name | scan_ip.sh ▮▮▮▮▮▮▮▮ │# │Date | 2017-07-04 ▮▮ │# │Author | Yu Longjun ▮▮▮▮▮▮▮▮▮▮▮▮ │# │Blog | http://www.yulongnjun.com ▮▮ │# │Version | 1.0 ▮▮▮▮▮ │# │Description | This is description. ▮▮ │# └───────────────────────────────────────────────────────┘# 读入网段read -p "Please input network segment(like '172.17.0.0'):" net_seg# 判断是否是ip地址（这里暂时没写是否是网段的校验）echo $net_seg | egrep -o "\&lt;(([0-9]|[1-9][0-9]|1[0-9]&#123;2&#125;|2[0-4][0-9]|25[0-5])\.)&#123;3&#125;([0-9]|[1-9][0-9]|1[0-9]&#123;2&#125;|2[0-4][0-9]|25[0-5])"# 判断是否是ip地址，不是报错退出if [ $? != "0" ]; then echo "FormatError, exit." exitfi# 判断网络位sub1=`echo $net_seg| cut -d. -f1`sub2=`echo $net_seg| cut -d. -f2`sub3=`echo $net_seg| cut -d. -f3`sub4=`echo $net_seg| cut -d. -f4`# func_ping函数，ping主机的函数func_ping() &#123;# 网络为3位if [ $5 == "3" ];then for i in `seq 0 255`;do for j in `seq 0 255`;do for k in `seq 0 255`;do address=$1.$i.$j.$k if [ $address == "$1.0.0.0" -o $address == "$1.255.255.255" ];then continue else ping -c1 -w1 $address &amp;&gt;/dev/null &amp;&amp; echo "host $address is up." | tee -a host_up.log || echo "host $address is down." | tee -a host_down.log &amp; fi done done done# 网络位为2位elif [ $5 == "2" ];then for i in `seq 0 255`;do for j in `seq 0 255`;do address=$1.$2.$i.$j if [ $address == "$1.$2.0.0" -o $address == "$1.$2.255.255" ];then continue else ping -c1 -w1 $address &amp;&gt;/dev/null &amp;&amp; echo "host $address is up." | tee -a host_up.log || echo "host $address is down." | tee -a host_down.log &amp; fi done done# 网络位为1位elif [ $5 == "1" ];then for i in `seq 0 254`;do address=$1.$2.$3.$i ping -c1 -w1 $address &amp;&gt;/dev/null &amp;&amp; echo "host $address is up."| tee -a host_up.log || echo "host $address is down."| tee -a host_down.log &amp; donefi&#125;# 判断网络位是几位if [ $sub1 == "0" -o $sub4 != "0" ];then # 第一位不能是0，最后一位要是0，否则格式错误，报错退出 echo "FormatError, exit." exitelif [ $sub2 == "0" ];then if [ $sub3 == "0" ];then func_ping $sub1 255 255 255 3 else func_ping $sub1 0 $sub3 255 1 fielse if [ $sub3 == "0" ];then func_ping $sub1 $sub2 255 255 2 else func_ping $sub1 $sub2 $sub3 255 1 fifisleep 5if [ -e host_up.log ];then sum_up=`cat host_up.log| wc -l` echo "Up host's number is $sum_up" rm -rf host_up.logelse echo "Up host's number is 0"fiif [ -e host_down.log ];then sum_down=`cat host_down.log|wc -l` echo "Down host's number is $sum_down" rm -rf host_down.logelse echo "Down host's number is 0"fi 第15题 编写服务 脚本/root/bin/testsrv.sh ，完成如下要求(1) 脚本可接受参数：start, stop, restart, status(2) 如果参数非此四者之一，提示使用格式后报错退出(3) 如是start则创建/var/lock/subsys/ SCRIPT_NAME , 并显示“启动成功”考虑：如果事先已经启动过一次，该如何处理？(4) 如是stop则删除/var/lock/subsys/ SCRIPT_NAME, 并显示“停止完成”考虑：如果事先已然停止过了，该如何处理？(5) 如是restart ，则先stop, 再start考虑：如果本来没有start ，如何处理？(6) 如是status, 则如果/var/lock/subsys/ SCRIPT_NAME 文件存在，则显示SCRIPT_NAME is running...如果/var/lock/subsys/ SCRIPT_NAME 文件不存在，则显示 SCRIPT_NAME is stopped...其中： SCRIPT_NAME为当前脚本名 (7) 在所有模式下禁止启动该服务，可用chkconfig 和 service 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061#!/bin/env bash#chkconfig: 345 99 0# ┌───────────────────────────────────────────────────────┐# │Script Name | testsrv.sh ▮▮▮▮▮▮▮▮ │# │Date | 2017-07-04 ▮▮ │# │Author | Yu Longjun ▮▮▮▮▮▮▮▮▮▮▮▮ │# │Blog | http://www.yulongnjun.com ▮▮ │# │Version | 1.0 ▮▮▮▮▮ │# │Description | This is description. ▮▮ │# └───────────────────────────────────────────────────────┘srvfile="/var/lock/subsys/`basename $0`"func_start()&#123; if [ -e $srvfile ];then echo "服务已启动,无需再次启动" else touch $srvfile echo "启动成功" fi&#125;func_stop()&#123; if [ -e $srvfile ];then rm -f $srvfile echo "停止完成" else echo "服务未启动，无需停止" fi&#125;func_restart()&#123; func_stop func_start&#125;func_status()&#123; if [ -e $srvfile ];then echo "`basename $0` is running..." else echo "`basename $0` has stoped..." fi&#125;case $1 in "start") func_start ;; "stop") func_stop ;; "restart") func_restart ;; "status") func_status ;; *) "输入参数错误, Usage: `basename $0` start|stop|restart|status" ;;esac 第16题 编写脚本/root/bin/copycmd.sh(1) 提示用户输入一个可执行命令名称(2) 获取此命令所依赖到的所有库文件列表(3) 复制命令至某目标目录( 例如/mnt/sysroot) 下的对应路径下；如：/bin/bash ==&gt; /mnt/sysroot/bin/bash /usr/bin/passwd ==&gt; /mnt/sysroot/usr/bin/passwd(4) 复制此命令依赖到的所有库文件至目标目录下的对应路径下：/lib64/ld-linux-x86-64.so.2 ==&gt; /mnt/sysroot/lib64/ld-linux-x86-64.so.2(5) 每次复制完成一个命令后，不要退出，而是提示用户键入新的要复制的命令，并重复完成上述功能；直到用户输入quit 12345678910111213141516171819202122232425262728293031#!/bin/bash# ┌───────────────────────────────────────────────────────┐# │Script Name | copycmd.sh ▮▮▮▮▮▮▮▮ │# │Date | 2017-07-04 ▮▮ │# │Author | Yu Longjun ▮▮▮▮▮▮▮▮▮▮▮▮ │# │Blog | http://www.yulongnjun.com ▮▮ │# │Version | 1.0 ▮▮▮▮▮ │# │Description | This is description. ▮▮ │# └───────────────────────────────────────────────────────┘read -p "请输入复制路径:" copy_pathwhile true;do read -p "请输入一个可执行的命令的名称(quit 退出):" command if [ "$command" == "quit" ]; then exit else cmd=`which $command` cmd_path=`dirname $cmd` mkdir -p $copy_path$cmd_path cp -f $cmd $copy_path$cmd_path printf "复制 %-30s ====&gt; $copy_path%-30s" $cmd $cmd_path echo list=`ldd $cmd|grep -o "/lib.* "|tr -d " "` [ -e $copy_path/lib64 -a -e $copy_path/lib ] || mkdir $copy_path/&#123;lib64,lib&#125; for i in $list;do cp -f $i $copy_path$i printf "复制 %-30s ====&gt; $copy_path%-30s" $i $i echo done echo "复制 $cmd 命令完成" fidone]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>exam</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PAM认证模块]]></title>
    <url>%2Flinux%2F20170720-02-pam%2F</url>
    <content type="text"><![CDATA[PAM:Pluggable Authentication Modules（可插拔的认证模块） PAM 是关注如何为服务验证用户的 API，通过提供一些动 态链接库和一套统一的API，将系统提供的服务和该服务的认证方式分开。PAM模块使得系统管理员可以灵活地根据需要给不同的服务配置不同的认证方式而无需更改服务程序。PAM是一种认证框架，自身不做认证。 它提供了对所有服务进行认证的中央机制，适用于login，远程登录（telnet,rlogin,fsh,ftp,点对点协议（PPP）），su等应用程序中。系统管理员通过PAM配置文件来制定不同应用程序的不同认证策略；应用程序开发者通过在服务程序中使用PAM API(pam_xxxx( ))来实现对认证方法的调用；而PAM服务模块的开发者则利用PAMSPI来编写模块（主要是 引出一些函数pam_sm_xxxx( )供PAM接口库调用），将不同的认证机制加入到系统中；PAM接口库（libpam）则读取配置文件，将应用程序和相应的PAM服务模块联系起来。 PAM一般的认证顺序：Service（服务）-&gt;PAM（配置文件）-&gt;pam_*.so（相应的PAM库） PAM认证首先要确定那一项服务，然后加载相应的PAM的配置文件(位于/etc/pam.d下)，最后调用认证库文件(位于 /lib/security下)进行安全认证。 服务对应的pam模块的库的定义的配置，全在/etc/pam.d/目录下面 pam模块相关的库，都存放在/lib64/security下面 PAM模块配置格式PAM模块配置文件：/etc/pam.d/APP_NAME 配置名一般就是程序名，如login、sshd、sudo等等。第一行是PAM模块版本#%PAM-1.0。 下面的内容的格式： module-type control module-path arguments module-type： auth：账号的认证和授权 account：与账号管理相关的非认证类的功能，如：用来限制/允许用户对某个服务的访问时间，当前有效的系统资源(最多可以有多少个用户)，限制用户的位置(例如：root用户只能从控制台登录) passwd：用户修改密码时密码复杂度检查机制等功能 session：用户获取到服务之前或使用服务完成之后需要进行一些附加的操作，如：记录打开/关闭数据的信息，监视目录等 -type： 表示因为缺失而不能加载的模块将不记录到系统日 志,对于那些不总是安装在系统上的模块有用 control：control规定了PAM库如何处理与该服务相关的PAM模块成功或失败情况。 分为两种方式实现：简单和复杂。 简单方式实现：一个关健词实现 required： 一票否决，表示本模块必须返回成功才能通过 认证，但是如果该模块返回失败，失败结果也不会立即通知用户，而是要等到同一type中的所有模块全部执行完毕，再将失败结果返回给应用程序。即为必要条件 requisite ：一票否决，该模块必须返回成功才能通过认证， 但是一旦该模块返回失败，将不再执行同一type内的任何模块，而是直接将控制权返回给应用程序。是一个必要条件 sufficient： 一票通过，表明本模块认证的要求，不必再执行同一type内的其它模块，但如果本模块返回失败可忽略，即为充分条件 optional：表明本模块是可选的，它的成功与否不会对身份认证起关键作用，其返回值一般被忽略 include： 调用其他的配置文件中定义的配置信息 复杂详细实现（用的很少，偶尔有几个）：使用一个或多个“status=action”，[status1=action1 status2=action …] (1)Status:检查结果的返回状态 (2)Action:采取行为。ok，done，die，bad，ignore，reset ok 模块通过，继续检查 done 模块通过，返回最后结果给应用 bad 结果失败，继续检查 die 结果失败，返回失败结果给应用 ignore 结果忽略，不影响最后结果 reset 忽略已经得到的结果 module-path： 模块路径 相对路径：/lib64/security目录下的模块可使用相对路径。如：pam_shells.so、pam_limits.so 绝对路径 Arguments： 用来传递给该模块的参数 tips：修改PAM配置文件将马上生效。所以建议，编辑pam规则时，保持至少打开一个root会话，以防止 root身份验证错误。 PAM模块功能说明：每个pam模块的使用方法，可以用man 模块名来查，比如man pam_shell，man pam_env 也可以去官网下载pdf文档http://www.linux-pam.org/ 日志认证相关的日志，默认写在/var/log/secure pam模块示例示例1：pam_shells.so 示例2：pam_securetty.so 示例3：pam_nologin.so 示例4：pam_limits.so（重要） 模块通过读取配置文件/etc/security/*.conf完成用户对系统资源的使用控制。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>PAM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自制kickstart光盘]]></title>
    <url>%2Flinux%2F20170720-kickstart-iso%2F</url>
    <content type="text"><![CDATA[1. 制作好ks文件。最开始安装的CentOS6里选的开发者模式安装，安装了很多包，还选了中文包，还有一些工具，做为开发机用，故用这台机器生成anaconda.cfg文件进行配置。打开图形工具system-config-kickstart(默认没有安装，yum安装一下），打开系统安装完在root家目录生成的/root/anaconda.cfg文件，进行配置。 File –&gt; Open File 更改每一步的选项，使其适用于kickstart安装，这里给出每页的设置： 这里选新安装，安装源选cd-rom。 这里保持不变。 这里改为clear Master Boot Record清除主引导记录（MBR）,然后按照自己喜好分区。 网卡不变，如果你要装的服务器有多块网卡，可以自行添加。 不变 关闭SELinux和防火墙。 不安装图形环境 包用你安装时候选的就可以，也可以自行添加，也可以后期改安装文件添加。 写安装后脚本，比如添加用户，配置本地yum，拷贝操作机的key到机器上（之后操作机可以免密登录） File –&gt; Save,另存为另外的文件，这里我保存为centos6-devel-ks.cfg(因为我安装时候选了开发组件，故起名字为devel） ！！！注意：记得删除repo --name=&quot;CentOS&quot; --baseurl=cdrom:sr0 --cost=100这行，要不后面光盘制作好了找不到repodata！！！（坑死我了，好几个小时才找到原因） 复制centos6-devel-ks.cfg文件为centos6-mini-ks.cfg，修改里面的%packages到%end的内容为： 12345%packages@core@server-policy@workstation-policy%end 把他们放在一台机器上为之后做iso文件做准备。如果还有想安装的程序，可以手动写到ks文件里面。 修改完ks文件后，怕格式有问题，可以用下面的命令检测一下(此命令来自于pykickstart包，没有的话可以yum安装一下）： 1ksvalidator xxx.cfg 2. 制作光盘前配置先把光盘里内容复制一份: 12mount /dev/sr0 /mediacp -rv /media /app/centos6 在/app/centos6目录下创建ks目录，把两个ks的cfg文件复制过去: 12mkdir /app/centos6/kscp centos6-devel-ks.cfg centos6-mini-ks.cfg /app/centos6/ks 修改启动界面的配置文件： vim /app/centos6/isolinux/isolinux.cfg 把最后面的启动菜单更改为下面格式： 12345678910111213141516label local menu label Boot From ^Local Drive menu default localboot 0xfffflabel manual menu label ^Manual Install Linux kernel vmlinuz append initrd=initrd.imglabel minix menu label ^Automatic Minimal Install kernel vmlinuz append initrd=initrd.img ks=cdrom:/ks/centos6-mini-ks.cfglabel development menu label Automatic ^Development Install kernel vmlinuz append initrd=initrd.img ks=cdrom:/ks/centos6-devel-ks.cfg 解析：第一个菜单为从本地硬盘启动，这样即使超时，也不会误覆盖已有的操作系统；第二个菜单为手动安装，也就是一步步的安装；第3个菜单用的最小化安装的ks；第四个用的是开发机的ks，选了很多包。还可以改这个文件里的一行menu title ...为menu title CentOS 6.9 Kickstart by Yu Longjun，毕竟是自己做的嘛，打个标签的。 3. 删除TRANS.TBL，重做repodata1234find /app/centos6/ -name TRANS.TBL -exec rm -rf &#123;&#125; \;cp /app/centos6/repodata/43d8fd068164b0f042845474d6a22262798b9f0d1f49ad1bf9f95b953089777d-c6-x86_64-comps.xml /root rm -rf /app/centos6/repodata createrepo -g /root/43d8fd068164b0f042845474d6a22262798b9f0d1f49ad1bf9f95b953089777d-c6-x86_64-comps.xml /app/centos6 4. iso镜像制作1mkisofs -R -J -T -v --no-emul-boot --boot-load-size 4 --boot-info-table -V "CentOS 6.9 by Yu Longjun" -b isolinux/isolinux.bin -c isolinux/boot.cat -o /root/CentOS-6.9-x86_64-Kickstart-by-YuLongjun-origin.iso /app/centos6 5. iso镜像写入u盘作为安装盘上面的iso镜像刻成光盘，是可以启动安装的，但是直接dd写入到u盘，是无法工作的，需要用isohybird添加一些启动信息到iso头部： 123cp /root/CentOS-6.9-x86_64-by-YuLongjun-origin.iso /root/CentOS-6.9-x86_64-by-YuLongjun-usb.isoisohybrid /root/CentOS-6.9-x86_64-by-YuLongjun-usb.iso 我们可以ll看到这两个文件大小不一样： 1ll /root/CentOS-6.9-x86_64-by-YuLongjun*]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>kickstart光盘</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP_Wrappers应用层防火墙]]></title>
    <url>%2Flinux%2F20170720-01-tcp_wrappers%2F</url>
    <content type="text"><![CDATA[TCP_Wrappers是一个工作在应用层的安全工具，它只能针对某些具体的应用或者服务起到一定的防护作用。比如说ssh、telnet、FTP等服务的请求，都会先受到TCP_Wrappers的拦截。 TCP_Wrappers是基于库调用实现的。 包名为tcp_wrappers-libs 1234567[root@blog ~]# rpm -ql tcp_wrappers-libs/usr/lib64/libwrap.so.0/usr/lib64/libwrap.so.0.7.6[root@blog ~]# ll /usr/lib64/libwrap.so.0*lrwxrwxrwx. 1 root root 16 Jul 10 20:22 /usr/lib64/libwrap.so.0 -&gt; libwrap.so.0.7.6-rwxr-xr-x. 1 root root 42520 Jun 10 2014 /usr/lib64/libwrap.so.0.7.6 我们可以查询到好多服务都是调用的这个库文件,如sshd、vsftpd、xinetd 123456[root@blog ~]# ldd `which sshd` |grep libwrap.so.0 libwrap.so.0 =&gt; /lib64/libwrap.so.0 (0x00007fc777586000)[root@blog ~]# ldd `which vsftpd` |grep libwrap.so.0 libwrap.so.0 =&gt; /lib64/libwrap.so.0 (0x00007fdb8d276000)[root@blog ~]# ldd `which xinetd` |grep libwrap.so.0 libwrap.so.0 =&gt; /lib64/libwrap.so.0 (0x00007f4ae8036000) TCP_Wrappers访问控制实现TCP_Wrappers访问控制实现，是靠两个文件实现的：/etc/hosts.allow和/etc/hosts.deny .man hosts.allow或者 man hosts.deny可以查看规则和用法。 /usr/sbin/tcpd进程会根据这两个文件判断是否对访问请求提供服务。 /usr/sbin/tcpd进程先检查文件/etc/hosts.allow，如果请求访问的主机名或IP包含在此文件中，则允许访问。如果请求访问的主机名或IP不包含在/etc/hosts.allow中，那么tcpd进程就检查/etc/hosts.deny。看请求访问的主机名或IP有没有包含在hosts.deny文件中。如果包含，那么访问就被拒绝；如果既不包含在/etc/hosts.allow中，又不包含在/etc/hosts.deny中，那么此访问也被允许。 语法： daemon_list: client_list1 [EXCEPT client_list2][:options] deamon_list 应用程序文件名称 而非服务名 应用程序文件名称列表 彼此间使用逗号或空格分隔 All 表示所有服务 client_list1 IP地址 主机名 域名段 ,例如.yulongjun.com,即可以匹配db1.yulongjun.com node1.web.yulongjun.com等。 网络段CentOS6必须使用完整格式的掩码net/mask，如127.16.111.0/255.255.255.0，不能使用net/prefix,如127.16.111.0/24,从CentOS7开始，支持使用net/prefix 短格式的网络段（如 172.16.，相当于172.16.0.0/255.255.0.0） ALL 所有来源主机 KNOW 所有能解析到的主机 UNKNOW 所有未解析到的主机 LOCAL 主机名中不带.的 PARANOID 正反解析不匹配的地址 EXCEPT client_list2 除了client_list2的主机之外，client_list1的都匹配。 options deny 拒绝，主要用于hosts.allow文件中，实现deny功能 allow 允许，主要用在hosts.deny文件中，实现allow功能 spawn 启动额外应用程序,用的不多 twist 无论写在hosts.allow还是hosts.deny都是拒绝，并提示例子1：不允许172.16.111.100的ftp访问 vim /etc/hosts.deny 1vsftpd : 172.16.111.100 例子2：仅允许172.16.111.网段的ftp访问 vim /etc/hosts.allow 1vsftpd : 172.16.111. vim /etc/hosts.deny 1vsftpd : ALL 例子3：仅允许172.16.111.网段的ftp访问，除了172.16.111.100外 vim /etc/hosts.allow 1vsftpd : 172.16.111. EXCEPT 172.16。111.100 vim /etc/hosts.deny 1vsftpd : ALL 例子3：不允许172.16.111.网段访问ftp，写在hosts.allow里 vim /etc/hosts.allow 1vsftpd : 172.16.111. : deny 例子4，不允许192.168.111.网段ssh来访问，尝试的访问记录在/var/log/sshd.deny.log里 vim /etc/hosts.deny 1sshd: 192.168.111. :spawn echo &quot;`date` login attempt from %c to %s,%d&quot; &gt;&gt;/var/log/sshd.deny.log 我们用一台192.168.111.网段的机器ssh访问，可以看到下面结果：12[root@center ~]# cat /var/log/sshd.deny.log Mon Aug 14 17:25:08 CST 2017 login attempt from 192.168.111.100 to sshd@192.168.111.254,sshd 拒绝192.168.111.网段的ftp访问，并输出提示符。vim /etc/hosts.deny 或者 vim /etc/hosts.allow均可： 1vsftpd: 192.168.111. :twist /bin/echo &quot;connection refused!!!&quot;]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>TCP_Wrappers</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sudo]]></title>
    <url>%2Flinux%2F20170718-04-sudo%2F</url>
    <content type="text"><![CDATA[我们之前接触过su（Switch User）命令 我们用过曾经用过这种用法：su - LongDream -c &#39;ll -a ~/&#39;，即临时的切换呢用户并执行命令然后回来。 我们通常用某个用户来执行一些其他用户才能运行的命令，这时候我们用su的话，会用`su - root -c ‘COMMAND’”。这样有个缺点，就是权限不好控制，root的权限太大，有时候不想给root权限和密码给某些用户。 Sudo机制：可以让某些用户像root用户一样运行一些命令，而不需要root密码。 命令格式：sudo COMMAND sudo权限配置文件：/etc/sudoers 默认有这两项： 12root ALL=(ALL) ALL%wheel ALL=(ALL) ALL 一个是root用户可以执行所有命令，一个是wheel用户可以执行所有命令 如果不知道管理员密码，一个有wheel组的用户，也可以切换到root，可以这样：sudo su - root（只要输入用户自己的密码就可以了，可以简写为sudo su -）。 我们看到/etc/sudoers文件有这样一句话：”This file must be edited with the ‘visudo’ command.”(这个文件最好是用visudo命令来编辑）。所以我们尽量用visudo命令来配置，有语法错误会报错： 我们继续来分析参数： 12root ALL=(ALL) ALL%wheel ALL=(ALL) ALL 参数分为几块： Users Hosts=(Runas_users) Commands 也就是运行命令的用户或用户组，在哪些主机上，以哪些用户的身份，来执行哪些命令。 详解： Users username ：用户名 #uid：用户UID %groupname：用户组 %#gid：用户组GID User_Alias：用户别名(sudoers文件中单独定义的) User_Alias用法：User_Alias ADMINS = jsmith, mikem，ADMINS为别名，必须为大写；jsmith, mikem为用户名。 Hosts hostname：主机名 ip_addr：ip地址 network(/netmask)：网段 Host_Alias：主机别名(sudoers文件中单独定义的) Host_Alias定义方法：Host_Alias FILESERVERS = fs1, fs2 Runas_users username ：用户名 #uid：用户UID %groupname：用户组 %#gid：用户组GID Runas_Alias：用户别名(sudoers文件中单独定义的) Runas_Alias定义方法：同Users里User_Alias用法。 Commands command_name：实际的命令，写绝对路径 directory：目录，目录下所有命令 sudoedit：有编辑sudoers文件的权限，相当于有授权权限。 Cmnd_Alias：一组命令的别名 Cmnd_Alias定义方法：Cmnd_Alias SOFTWARE = /bin/rpm, /usr/bin/up2date, /usr/bin/yum SOFTWARE为别名，必须为大写；j/bin/rpm, /usr/bin/up2date, /usr/bin/yum为命令名。 可以不输入用户密码,在Commands前可以加NOPASSWD：(如果有同学接触过Vagrant，就知道默认创建的vagrant用户执行sudo命令不用输入密码)，例如： root ALL=(ALL) NOPASSWD: ALL tips:通常，我们一般也不编辑sudoers文件，一般编辑/etc/sudoers.d/xxxxxx为你自定义的文件，一般以用户名或者组名来命名文件。例如：vim /etc/sudoers.d/vagrant%vagrant ALL=(ALL) NOPASSWD: ALL这样一个用户或一个用户组一个文件，便于后期管理。 Sudo示例示例1：(ALL全权限） 12Student ALL=(ALL) ALL%wheel ALL=(ALL) ALL 示例2：（单独命令和NOPASSWD） 12student ALL=(root) /sbin/pidof,/sbin/ifconfig%wheel ALL=(ALL) NOPASSWD: ALL 示例3：（使用Alias的示例） 123User_Alias NETADMIN= netuser1,netuser2Cmnd_Alias NETCMD = /usr/sbin/ipNETADMIN ALL=（root） NETCMD 示例4：（使用多Alias的示例，其中SERS没写表示任何人） 12345678User_Alias SYSADER=wang,mage,%adminsUser_Alias DISKADER=tomHost_Alias SERS=www.magedu.com,172.16.0.0/24Runas_Alias OP=rootCmnd_Alias SYDCMD=/bin/chown,/bin/chmodCmnd_Alias DSKCMD=/sbin/parted,/sbin/fdiskSYSADER SERS= SYDCMD,DSKCMDDISKADER ALL=(OP) DSKCMD 示例5：（使用正则表达式、NOPASSWD和PASSWD并存的示例，！排除） 123User_Alias ADMINUSER = adminuser1,adminuser2Cmnd_Alias ADMINCMD = /usr/sbin/useradd, /usr/sbin/usermod, /usr/bin/passwd [a-zA-Z]*, !/usr/bin/passwd rootADMINUSER ALL=(root) NOPASSWD:ADMINCMD， PASSWD:/usr/sbin/userdel 示例6：（Defaults表示默认用户，表示如果sudo不指定用户名时，默认使用的用户，在下面，指的是如果wang使用sudo不-u指定用户名，默认是tom） 12Defaults:wang runas_default=tomwang ALL=(tom,jerry) ALL 示例7：（指定了文件夹，但是排除了文件夹下面的useradd命令） 1wang 192.168.175.136,192.168.175.138=(root) /usr/sbin/,!/usr/sbin/useradd 示例8：（命令限定哪些文件，但是用*很不安全，比如我用wang用户 sudo cat /var/log/messages /etc/shadow也是可以的,这里不安全，不要这么使用。） 1wang ALL=(ALL) /bin/cat /var/log/messages* sudo 常用命令参数sudo -l 列出（list）当前用户可以运行的sudo命令。 sudo -b 将要执行的命令放在后台(background)执行。 sudo -u username/#uid 指定以另外一个用户(user)的身份运行命令，不加-u默认是root 默认5分钟内不用输入密码，如果sudo -k，则下次需要输入密码 sudo的好处不给用户root权限，便于日志审计，只要给他sudo权限就好。 如果大家都用root登录，就不知道是谁操作的，用sudo权限来分配，可以直接审计单个用户的操作。 还有一个好处是，便于权限控制。有些用户不能给他太多的权限，就可以用sudo来控制他的权限范围。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Sudo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSH服务端]]></title>
    <url>%2Flinux%2F20170718-03-sshd%2F</url>
    <content type="text"><![CDATA[系统自带的ssh服务端配置文件：/etc/ssh/sshd_config 常用配置（包含默认配置）： Port 22：端口号，可以改为其他的端口号ListenAddress 0.0.0.0：可以设置监听的网段，默认为全网段限制登录(遵循最严权限，如果同时在禁止和允许的名单里，就禁止）： AllowUsers DenyUsers AllowGroups DenyGroups dropbear 第三方ssh服务端安装准备： • 1、安装开发包组: • 2、https://matt.ucc.asn.au/dropbear/下载dropbear-xxx.tar.bz2 安装： • 3、tar xf dropbear-xxx.tar.bz2 • 4、less INSTALL 查看安装过程，按照安装过程安装 • 5、./configure • 6、make PROGRAMS=&quot;dropbear dbclient dropbearkey dropbearconvert scp&quot; • 7、make PROGRAMS=&quot;dropbear dbclient dropbearkey dropbearconvert scp&quot; install 查看安装的程序： 查看使用帮助dropbear -h 默认打开需要key，如果没有指定的话，会去默认位置找，所以要在默认位置创建key 查看安装包里的README和dropbearkey -h里写的，来创建key： 123dropbearkey -t rsa -f /etc/dropbear/dropbear_rsa_host_key -s 2048 # -s 2048可以不写，默认就是2048，可以指定更大的数,最大支持4096或者是dropbearkey -t dss -f /etc/dropbear/dropbear_dsa_host_key # 固定值，1024 启用dropbear的ssh服务 12dropbear -p :2222 -F -E # 前台运行dropbear -p :2222 # 后台运行 客户端访问，可以用系统的ssh，也可以用dropbear的客户端dbclient，使用方法是一样的 12ssh -p 2222 root@127.0.0.1dbclient -p 2222 root@127.0.0.1]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>SSH</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSH转发]]></title>
    <url>%2Flinux%2F20170718-02-ssh-port-forward%2F</url>
    <content type="text"><![CDATA[SSH端口转发SSH的端口转发（port forwarding via SSH),又叫做SSH隧道（SSH tunneling) ，是一种在本地计算机和远程计算机之间建立一个安全的连接，使远程计算机还可以作为中继服务。因为连接是加密的，所以SSH隧道对于传输使用未加密协议的信息（如IMAP，VNC或IRC）很有用。 SSH有3种类型的端口转发： 本地端口转发（Local port forwarding）: 连接是从SSH客户端经由SSH服务端转发，然后传递到目标服务器 远程端口转发（Remote port forwarding）: 连接是从SSH服务器经由ssh client转发，然后传递到目标服务器。 动态端口转发（Dynamic port forwarding）: 连接是从各种应用经由ssh客户端转发，然后经过SSH服务器，最终到达目标服务器。 1. 本地端口转发：1ssh -L [bind_local_address:]local_port:remote_host_address:remote_host_port remote_sshd_jumpserver bind_local_address指的是本机有多个ip地址，可以指定一个ip作为出口,可选项，可以不写，不写默认就是 local_port是指指定一个本地端口，作为连接sshd跳板机的端口 remote_host_address指的是要登录的远程主机地址 remote_host_port指的是要登录的远程主机的端口 remote_ssh_jumpserver 是指开启了sshd服务的跳板机(跟remote_host网络是通的） 选项： -f 后台启用 -N 不打开远程shell，处于等待状态 -g 启用网关功能，跟本地这台机器在同一个网段的，都可以通过这台机器进行转发。 示例1： 1ssh –L 9527:telnetsrv:23 -fN sshsrv 当访问本机的9527的端口时，被加密后转发到sshsrv的ssh服务， 再解密被转发到telnetsrv:23 data &lt;–&gt; localhost:9527 &lt;–&gt; localhost:XXXXX &lt;–&gt; sshsrv:22 &lt;–&gt; sshsrv:YYYYY &lt;–&gt; telnetsrv:23 示例2： 1ssh -fNL 8080:www.ubuntuforums.org:443 -L 12345:www.ubuntu.com:443 172.16.111.200 2. 远程端口转发:1ssh -R [bind_local_address:]local_sshd_server_port:remotehost:remote_host_port sshserver 示例1： 1ssh –R 9527:telnetsrv:23 –fN sshssrv 让sshsrv侦听9527端口的访问，如有访问，就加密后通过ssh 服务转发请求到本机ssh客户端，再由本机解密后转发到telnetsrv:23 Data &lt;–&gt; sshsrv:9527 &lt;–&gt; sshsrv:22 &lt;–&gt; localhost:XXXXX &lt;–&gt; localhost:YYYYY &lt;–&gt; telnetsrv:23 3. 动态端口转发：当用firefox访问internet时，本机的1080端口做为代理服务 器，firefox的访问请求被转发到sshserver上，由sshserver 替之访问internet 在本机firefox设置代理socket proxy:127.0.0.1:1080 1ssh -C -D 1080 root@sshserver X协议转发1ssh -X user@remotehost gedit]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>SSH</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSH客户端命令]]></title>
    <url>%2Flinux%2F20170718-01-ssh-commands%2F</url>
    <content type="text"><![CDATA[相关包 1234[root@centos73 ~]# rpm -qa "openssh*"openssh-6.6.1p1-31.el7.x86_64 # 两者通用设置openssh-server-6.6.1p1-31.el7.x86_64 # 服务端openssh-clients-6.6.1p1-31.el7.x86_64 # 客户端 server的服务都是sshd*,client的服务都是ssh*ls ssh命令ssh命令参数：-p PORT：指定对端端口-X: 支持x11转发-t: 强制伪tty分配 ssh -t remoteserver1 ssh remoteserver2 可以以remoteserver1作为跳板，然后登陆remoteserver2 ssh-keygen、ssh-copy-id命令–基于key的验证(免密登录）ssh-keygen 生成密钥对儿。 ssh-copy-id REMOTESERVER 拷贝公钥到对端服务器（实际是拷贝到.ssh/authorized_keys文件里）。 ssh-keygen -p 更改秘钥的密码（passphrase），如果有旧密码，需要输入旧密码。 ssh root@ADDRESS &#39;cat /etc/shadow&#39; 登录远程机器执行命令，然后退出。 实际应用： 123ssh-keygen # 生成秘钥ssh-copy-id root@172.16.111.200 # 把秘钥copy到远程服务器上ssh root@172.16.111.200 # 此时就可以基于key登录了 在Ansible权威指南有见过一个例子，用了一些参数： 12ssh-keygen -N "" -t rsa -b 4096 -C "me@yulongjun.com" -f /root/.ssh/yulongjun.rsassh-copy-id -i /root/.ssh/yulongjun.rsa.pub root@romate_host 这个例子里，第一个ssh-keygen命令里，-N参数指的是秘钥的密码，这里是空，-t是指的秘钥类型，-b指的是位数，默认2048，-C可以自定义一个邮箱 -f是指定一个自定义的秘钥文件（包括名字）。由于是自定义的秘钥，所以ssh-copy-id需要手动-i指定公钥路径（私钥路径也可以，会自动去匹配公钥发送） ssh-agent bash、ssh-add命令–免重复输入key的密码（passphrase）如果密钥设置了密码，每次输入都很麻烦，这时候可以用ssh-agent代理，只要输入一次口令，之后都可以用。退出会话之后就失效 12ssh-agent bashssh-add ~/.ssh/id_rsa # 此时只后，需要id_rsa的passphrase密码的话，只要输入一次就够了。 scp命令–走ssh端口的远程复制命令scp [options] SRC... DEST/源可以有多个。 主要两种方式： scp [options] [user@]host:/sourcefile /destpath scp [options] /sourcefile [user@]host:/destpath 常用选项： -C: 压缩数据流(compress) -r: 递归复制(recursive) -p: 保持原文件的属性信息(preserve) -q: 静默模式(quiet) -P PORT: 指明remote host的监听的端口(port) rsync命令–更聪明的复制基于ssh和rsh服务实现高效率的远程系统之间复制文件，使用安全的shell连接做为传输方式。 如果重复的文件可以不copy,比scp更快。 选项： -n 模拟复制过程 -v 显示详细过程 -r 递归复制目录树 -p 保留权限 -t 保留时间戳 -g 保留组信息 -o 保留所有者信息 -l 将软链接文件本身进行复制（默认） -L 将软链接文件指向的文件复制 -a 存档，相当于–rlptgoD，但不保留ACL（-A）和SELinux属性（-X） 例子： 12rsync –av /etc server1:/tmp # 复制目录和目录下文件rsync –av /etc/ server1:/tmp # 只复制目录下文件]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>SSH</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CA认证和证书]]></title>
    <url>%2Flinux%2F20170715-ca%2F</url>
    <content type="text"><![CDATA[一些概念： PKI：Public Key Infrastructure 签证机构：CA（Certificate Authority） 注册机构：RA（Register Authority） 证书吊销列表：CRL（Certificate Revoke Lists） 证书存取库 X.509：定义了证书的结构和认证协议的标准。包括版本号、序列号、签名算法、颁发者、有效期限、主体名称、主体公钥、CRL分发点、扩展信息、发行者签名等 获取证书的两种方法： 使用证书授权机构 生成签名请求（csr） 将csr发送给CA 从CA处接收签名 自签名的证书 自已签发自己的公钥 重点介绍一下自建CA颁发机构和自签名。 自建CA颁发机构和自签名实验用两台服务器，一台做ca颁发证书，一台去请求签名证书。 证书申请及签署步骤： 生成申请请求 CA核验 CA签署 获取证书 我们先看一下openssl的配置文件：/etc/pki/tls/openssl.cnf 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768####################################################################[ ca ]default_ca = CA_default # The default ca section(默认的CA配置，是CA_default,下面第一个小节就是)####################################################################[ CA_default ]dir = /etc/pki/CA # Where everything is kept （dir变量）certs = $dir/certs # Where the issued certs are kept（认证证书目录）crl_dir = $dir/crl # Where the issued crl are kept（注销证书目录）database = $dir/index.txt # database index file.（数据库索引文件）new_certs_dir = $dir/newcerts # default place for new certs.（新证书的默认位置）certificate = $dir/cacert.pem # The CA certificate（CA机构证书）serial = $dir/serial # The current serial number（当前序号，默认为空，可以指定从01开始）crlnumber = $dir/crlnumber # the current crl number（下一个吊销证书序号） # must be commented out to leave a V1 CRLcrl = $dir/crl.pem # The current CRL（下一个吊销证书）private_key = $dir/private/cakey.pem# The private key（CA机构的私钥）RANDFILE = $dir/private/.rand # private random number file（随机数文件）x509_extensions = usr_cert # The extentions to add to the cert# Comment out the following two lines for the "traditional"# (and highly broken) format.name_opt = ca_default # Subject Name options（被颁发者，订阅者选项）cert_opt = ca_default # Certificate field options（认证字段参数）# Extension copying option: use with caution.# copy_extensions = copy# Extensions to add to a CRL. Note: Netscape communicator chokes on V2 CRLs# so this is commented out by default to leave a V1 CRL.# crlnumber must also be commented out to leave a V1 CRL.# crl_extensions = crl_extdefault_days = 365 # how long to certify for （默认的有效期天数是365）default_crl_days= 30 # how long before next CRLdefault_md = sha256 # use SHA-256 by defaultpreserve = no # keep passed DN ordering# A few difference way of specifying how similar the request should look# For type CA, the listed attributes must be the same, and the optional# and supplied fields are just that :-)policy = policy_match # 是否匹配规则# For the CA policy[ policy_match ]countryName = match # 国家名是否匹配，match为匹配stateOrProvinceName = match # 州或省名是否需要匹配organizationName = match # 组织名是否需要匹配organizationalUnitName = optional # 组织的部门名字是否需要匹配commonName = supplied # 注释emailAddress = optional # 邮箱地址# For the 'anything' policy# At this point in time, you must list all acceptable 'object'# types.[ policy_anything ]countryName = optionalstateOrProvinceName = optionallocalityName = optionalorganizationName = optionalorganizationalUnitName = optionalcommonName = suppliedemailAddress = optional#################################################################### 重点关注下面的几个参数： 12345678910dir = /etc/pki/CA # Where everything is keptcerts = $dir/certs # Where the issued certs are keptdatabase = $dir/index.txt # database index file.new_certs_dir = $dir/newcerts # default place for new certs.certificate = $dir/cacert.pem # The CA certificateserial = $dir/serial # The current serial numberprivate_key = $dir/private/cakey.pem# The private key 1、创建所需要的文件touch /etc/pki/CA/index.txt 生成证书索引数据库文件 echo 01 &gt; /etc/pki/CA/serial 指定第一个颁发证书的序列号,16进制数，比如可以从1a开始，一般从01开始。 2、CA自签证书在作为CA的服务器上操作： 生成私钥 1(umask 066;openssl genrsa -out /etc/pki/CA/private/cakey.pem 4096) 生成自签名证书 1openssl req -new -x509 -key /etc/pki/CA/private/cakey.pem -days 7300 -out /etc/pki/CA/cacert.pem 参数解析： -new: 生成新证书签署请求 -x509: 专用于CA生成自签证书 -key: 生成请求时用到的私钥文件 -days n：证书的有效期限 -out /PATH/TO/SOMECERTFILE: 证书的保存路径 3、颁发证书 在需要使用证书的主机生成证书请求。 比如给一台作为博客web服务的服务器生成私钥： 1(umask 066; openssl genrsa -out /etc/pki/tls/private/blog.key 4096) 生成证书申请文件 1openssl req -new -key /etc/pki/tls/private/blog.key -days 3560 -out /etc/pki/tls/blog.csr 和CA生成证书的区别是没有-x509参数，加了-x509就是CA自签名证书 将证书请求文件传输给CA 1scp /etc/pki/tls/blog.csr root@172.16.111.100:/tmp/ CA签署证书，并将证书颁发给请求者 1openssl ca -in /tmp/blog.csr –out /etc/pki/CA/certs/blog.crt -days 365 注意：默认国家，省，公司名称三项必须和CA一致 把blog.crt证书回传给申请者，申请者可以使用此证书。 证书可以放在网站里，比如tomacat服务有专门存放证书的地方，还有可能需要转化格式，此处使用方法暂略 4、吊销证书 在客户端获取要吊销的证书的serial 1openssl x509 -in /PATH/FROM/CERT_FILE -noout -serial -subject 在CA上，根据客户提交的serial与subject信息，对比检验是否与index.txt文件中的信息一致，吊销证书： 1openssl ca -revoke /etc/pki/CA/newcerts/SERIAL.pem 指定第一个吊销证书的编号 注意：这里只有在第一次更新证书吊销列表前，才需要执行指定编号。 1echo 01 &gt; /etc/pki/CA/crlnumber 更新证书吊销列表 1openssl ca -gencrl -out /etc/pki/CA/crl/crl.pem 查看crl文件： 1openssl crl -in /etc/pki/CA/crl/crl.pem -noout -text]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>CA</tag>
        <tag>CRL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux From Scratch 8 之三--构建临时系统]]></title>
    <url>%2Flinux%2F20170709-lfs8-3%2F</url>
    <content type="text"><![CDATA[这一节来构造一个最小的Linux系统，这个小系统包含了用来构建的LFS系统所需要的工具，还有工作环境。 构建分为两步： 构建一个跟宿主系统（Fedora）无关的新工具链（编译器（compiler）, 汇编器（assembler）, 链接器（linker）, 库（libraries）, 一些有用的其他工具（utilities）） 用这个新工具链来构建其他的必要工具。 这些新编译的工具将被安装在$LFS/tools里，这是一个临时的文件夹，后期完全构建完系统后会删掉。 构建前检查12echo $LFSls -l `which sh` `which awk` `which yacc` 确保当前用户是lfs 每个包的构建过程要点： 重要下面所有的构建，都是基于下面的步骤，请牢记： 把所有源文件和补丁放到 chroot 环境可访问的目录，例如 /mnt/lfs/sources/。但是千万不能把源文件放在 /mnt/lfs/tools/中。 进入到源文件目录。 对于每个软件包: a. 用 tar 程序解压要编译的软件包。在第五章中，确保解压软件包时你使用的是 lfs 用户。 b. 进入到解压后创建的目录中。(cd xxx-x.x.x) c. 根据指南说明编译软件包(见每个包的要求） d. 回退到源文件目录($LFS/sources) e. 除非特别说明，删除解压出来的目录和所有编译过程中生成的 &lt;package&gt;-build 目录。 开始构建按照下面的顺序依次构建 安装 Binutils 第一部分Binutils 软件包包括了一个链接器、汇编器和其它处理目标文件的工具。 用lfs用户做下面操作： 解压并创建build编译目录 12345cd $LFS/sourcestar -xvf binutils-2.28.tar.bz2cd binutils-2.28mkdir buildcd build/ 配置： 123456../configure --prefix=/tools \ --with-sysroot=$LFS \ --with-lib-path=/tools/lib \ --target=$LFS_TGT \ --disable-nls \ --disable-werror 编译： 1time make -j12 这里是为了统计make编译时间，命令前面加个time，同时虚拟机是在一台 6核cpu * 2颗 的服务器上分配了12颗的cpu，所以使用12个核心同事编译：time make -j12 创建lib64和lib文件夹： 123case $(uname -m) in x86_64) mkdir -v /tools/lib &amp;&amp; ln -sv lib /tools/lib64 ;;esac 安装： 1make install 安装 Gcc安装Gcc需要gmp、mpfr、mpc包，把这3个包解压到gcc的解压目录，记得把目录名更名为无版本号的目录名 123456789cd $LFS/sourcestar -xvf gcc-7.1.0.tar.bz2cd gcc-7.1.0.tar.bz2tar -xf ../mpfr-3.1.5.tar.xzmv -v mpfr-3.1.5 mpfrtar -xf ../gmp-6.1.2.tar.xzmv -v gmp-6.1.2 gmptar -xf ../mpc-1.0.3.tar.gzmv -v mpc-1.0.3 mpc 以下命令将更改GCC的默认动态链接器的位置以使用安装的动态链接器 /tools。它也/usr/include从GCC的包含搜索路径中删除 ： 123456789101112for file in gcc/config/&#123;linux,i386/linux&#123;,64&#125;&#125;.hdo cp -uv $file&#123;,.orig&#125; sed -e 's@/lib\(64\)\?\(32\)\?/ld@/tools&amp;@g' \ -e 's@/usr@/tools@g' $file.orig &gt; $file echo '#undef STANDARD_STARTFILE_PREFIX_1#undef STANDARD_STARTFILE_PREFIX_2#define STANDARD_STARTFILE_PREFIX_1 "/tools/lib/"#define STANDARD_STARTFILE_PREFIX_2 ""' &gt;&gt; $file touch $file.origdone 最后，在x86_64主机上，将64位库的默认目录名设置为lib： 123456case $(uname -m) in x86_64) sed -e '/m64=/s/lib64/lib/' \ -i.orig gcc/config/i386/t-linux64 ;;esac GCC文件建议在专用的构建目录中构建GCC： 12mkdir -v buildcd build 准备GCC编译： 12345678910111213141516171819202122../configure \ --target=$LFS_TGT \ --prefix=/tools \ --with-glibc-version=2.11 \ --with-sysroot=$LFS \ --with-newlib \ --without-headers \ --with-local-prefix=/tools \ --with-native-system-header-dir=/tools/include \ --disable-nls \ --disable-shared \ --disable-multilib \ --disable-decimal-float \ --disable-threads \ --disable-libatomic \ --disable-libgomp \ --disable-libmpx \ --disable-libquadmath \ --disable-libssp \ --disable-libvtv \ --disable-libstdcxx \ --enable-languages=c,c++ 编译GCC： 1time make -j12 安装：1make install 安装 Linux-4.12 API Headers12tar -xvf linux-4.12.tar.xzcd linux-4.12 确保包中不存在过时的文件： 1make mrproper 从源代码中提取用户可见的内核头文件 make -j12 INSTALL_HDR_PATH=dest headers_install1cp -rv dest/include/* /tools/include 安装 glibc-2.25经过前面的几个安装，步骤应该已经熟悉了，下面全部略过安装步骤，只显示时间。 安装listdc++-7.1.0 安装 Binutils-2.28 第二部分 安装 GCC-7.1.0 - 第2部分 安装 tcl-core-8.6.6 安装expect 剩下的略过，同上，参考文档来做改变属主当前，$LFS/tools 目录属于 lfs 用户，这是一个只存在于宿主系统上的帐号。如果继续保持 $LFS/tools 目录的现状，其中的文件将属于一个没有相关联帐号的用户ID。这很危险，因为随后创建的用户有可能会分配到相同的用户ID，从而变成 $LFS/tools 目录及其中所有文件的属主，以致留下恶意操作这些文件的可能。 为了解决这个问题，你可以在随后新的 LFS 系统里创建 /etc/passwd 文件时增加一个 lfs 用户，并注意给它分配和宿主系统里相同的用户和组ID。不过更好的方式是，通过下面的命令将 $LFS/tools 目录的属主改为 root 用户： chown -R root:root $LFS/tools 打包备份 $LFS/tools用root用户打包这个文件保存下来，便于以后使用: 1tar -Jcvf lfs8-tools.tar.xz $LFS/tools]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>LFS 8</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux From Scratch 8 之二--创建LFS的分区，下载源码包]]></title>
    <url>%2Flinux%2F20170709-lfs8-2%2F</url>
    <content type="text"><![CDATA[添加新硬盘并格式化笔者用的虚拟机，直接设置里面添加一块20G硬盘即可,系统识别为sdb 划分分区，并格式化。 分区 用途 文件系统大小 sdb1 /boot ext4 512 MiB sdb2 / ext4 10 GiB sdb3 swap swap 2 GiB fdisk /dev/sdb来分区。记得t来更改sdb3的类型为swap（82）: 对分区进行格式化123mkfs.ext4 /dev/sdb1mkfs.ext4 /dev/sdb2mkswap /dev/sdb3 设置环境变量vim ~/.bashrc或者vim ~/.bash_profile都可以，添加下面环境变量，方便以后使用。 1export LFS=/mnt/lfs . ~/.bashrc使之实时生效。 挂载新分区先挂载跟分区，然后在根分区上创建boot文件夹，然后挂载boot分区到$LFS/boot下。 123456mkdir -pv $LFSmount /dev/sdb2 $LFSmkdir $LFS/bootmount /dev/sdb1 $LFS/bootswapon /dev/sdb3 # 测试是否能挂载上swap 下载源码包下载源码包的wget列表文件wget-list到Fedora上，这里我是下载保存为~/Downloads/wget-list，然后wget这个列表，下载源码包。 123456mkdir -v $LFS/sourceschmod a+wt $LFS/sourceswget -i ~/Downloads/wget-list-c -P $LFS/sources# 或者使用长格式：`wget --input-file=~/Downloads/wget-list --continue --directory-prefix=$LFS/sources` 国内网络环境不好，如果下的很慢，直接把这个列表的里地址复制一下，黏贴到迅雷批量下载里面，直接就全下下来了，下载完了后，再复制到$LFS/sources里 但是还是有坑，有的源文件都没了……还有的是sourceforge.net网站的文件，无法迅雷下载（下载下来文件大小也不对），需要手工去网站下载。笔者整理了完整的一份，连md5sums文件一起打了个包，放到百度云上，有需要的可以去下载。下载链接:http://pan.baidu.com/s/1geDLprd 密码:k5du 下载MD5校验文件进行校验下载md5校验文件md5sums，复制到$/LFS/sources下，运行下面命令： 1234cp ~/Downloads/md5sums $LFS/sourcespushd $LFS/sourcesmd5sum -c md5sumspopd 创建$LFS/tools目录这个目录是一个临时工具目录。临时使用Fedora主机的某些软件而不对原主机构成影响。 12mkdir -v $LFS/toolsln -sv $LFS/tools / 添加lfs用户用root容易损坏原系统，故创建一个lfs用户。 12345useradd -s /bin/bash -m -k /dev/null lfspasswd lfschown -v lfs $LFS/toolschown -v lfs $LFS/sourcessu - lfs 设置lfs的环境切换到lfs用户后，设置lfs用户的环境文件 123cat &gt; ~/.bash_profile &lt;&lt; "EOF"exec env -i HOME=$HOME TERM=$TERM PS1='\u:\w\$ ' /bin/bash EOF 确保构建的shell环境完全为新的空环境，即确保主机系统中的危险环境变量不进入构建的环境中，目的是为了有一个干净的环境。 123456789cat &gt; ~/.bashrc &lt;&lt; "EOF"set +humask 022LFS=/mnt/lfsLC_ALL=POSIXLFS_TGT=$(uname -m)-lfs-linux-gnu PATH=/tools/bin:/bin:/usr/binexport LFS LC_ALL LFS_TGT PATHEOF set +h hash表，可以记住命令的完整路径，不用重复去找，提高效率。 umask 022确保新创建的文件和目录只能由owner写入，但是任何人可以读取和执行。 LFS=/mnt/lfs目录环境变量 LC_ALL=POSIX遵循POSIX规则，确保chroot环境中的的正常工作 LFS_TGT=$(uname -m)-lfs-linux-gnu当编译我们的交叉编译器和链接器以及交叉编译我们的临时工具链时，LFS_TGT变量设置了一个非默认，但兼容的机器说明。 PATH=/tools/bin:/bin:/usr/bin把/tools/bin放到标准的PATH变量前面，这样使后续安装的新版本的命令后，去使用新版本的命令，而不会使用旧版本命令。 export LFS LC_ALL LFS_TGT PAT这里把上述变量变为环境变量 12source ~/.bash_profilesource ~/.bashrc]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>LFS 8</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux From Scratch 8 之一--构建前准备主机系统]]></title>
    <url>%2Flinux%2F20170709-lfs8-1%2F</url>
    <content type="text"><![CDATA[基于20170703的LFS文档，Linux Kernel 采用 4.12(20170702发布) 采用Fedora 25(点击下载)进行构建，已经dnf update到最新包。 介绍本节检查构建LFS所需的工具，然后准备一个LFS系统的分区，并在上面创建一个文件系统，然后挂载 主机准备工作fedora系统需要安装构建系统所需要的包（版本号要求在下面列出的版本之上，但是不要使用不推荐的版本） 列出要安装的包，都有，有的已经安装了，fedora 25里包的版本，正好符合FHS的要求。 1dnf list bash binutils bison bzip2 coreutils diffutils findutils gawk gcc glibc grep gzip kernel m4 make patch perl sed tar texinfo xz 2 无论装没装过，全部装一遍（装过的会skip跳过） 1dnf -y install bash binutils bison bzip2 coreutils diffutils findutils gawk gcc glibc grep gzip kernel m4 make patch perl sed tar texinfo xz 运行脚本检查：直接复制到命令行就可以了。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758cat &gt; version-check.sh &lt;&lt; "EOF"#!/bin/bash# Simple script to list version numbers of critical development toolsexport LC_ALL=Cbash --version | head -n1 | cut -d" " -f2-4MYSH=$(readlink -f /bin/sh)echo "/bin/sh -&gt; $MYSH"echo $MYSH | grep -q bash || echo "ERROR: /bin/sh does not point to bash"unset MYSHecho -n "Binutils: "; ld --version | head -n1 | cut -d" " -f3-bison --version | head -n1if [ -h /usr/bin/yacc ]; then echo "/usr/bin/yacc -&gt; `readlink -f /usr/bin/yacc`";elif [ -x /usr/bin/yacc ]; then echo yacc is `/usr/bin/yacc --version | head -n1`else echo "yacc not found" fibzip2 --version 2&gt;&amp;1 &lt; /dev/null | head -n1 | cut -d" " -f1,6-echo -n "Coreutils: "; chown --version | head -n1 | cut -d")" -f2diff --version | head -n1find --version | head -n1gawk --version | head -n1if [ -h /usr/bin/awk ]; then echo "/usr/bin/awk -&gt; `readlink -f /usr/bin/awk`";elif [ -x /usr/bin/awk ]; then echo awk is `/usr/bin/awk --version | head -n1`else echo "awk not found" figcc --version | head -n1g++ --version | head -n1ldd --version | head -n1 | cut -d" " -f2- # glibc versiongrep --version | head -n1gzip --version | head -n1cat /proc/versionm4 --version | head -n1make --version | head -n1patch --version | head -n1echo Perl `perl -V:version`sed --version | head -n1tar --version | head -n1makeinfo --version | head -n1xz --version | head -n1echo 'int main()&#123;&#125;' &gt; dummy.c &amp;&amp; g++ -o dummy dummy.cif [ -x dummy ] then echo "g++ compilation OK"; else echo "g++ compilation failed"; firm -f dummy.c dummyEOFbash version-check.sh 报了三个错误： yacc not found version-check.sh: line 36: g++: command not found version-check.sh: line 50: g++: command not foundg++ completion failed 我们看到FHS官方文档里写到： yacc可以直接链接到bison： 123cd /usr/binln -s bison yaccll bison yacc g++这里描述的不清楚，fedora装gcc-c++包就可以了： 1dnf install gcc-c++ 再次运行bash version-check.sh脚本，完美：]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>LFS 8</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文本处理工具-sed]]></title>
    <url>%2Flinux%2F20170706-sed%2F</url>
    <content type="text"><![CDATA[sed：Stream EDitor, 行编辑器 usage： sed [option]... &#39;script&#39; inputfile... 常用option： -n：不输出模式空间内容到屏幕，即不自动打印 -e： 多点编辑 -f：/PATH/SCRIPT_FILE: 从指定文件中读取编辑脚本 -r： 支持使用扩展正则表达式 -i.bak： 备份文件并原处编辑 script： ‘地址+命令’ 地址定界： (1) 不给地址：对全文进行处理 (2) 单地址： #: 指定的行 /pattern/：被此处模式所能够匹配到的每一行 (3) 地址范围： #,# #,+# /pat1/,/pat2/ #,/pat1/ (4) ~：步进 1~2 奇数行 2~2 偶数行 编辑命令： d: 删除模式空间匹配的行 p: 显示模式空间中的内容 a [\]text：在指定行后面追加文本 支持使用\n实现多行追加 i [\]text：在行前面插入文本(注意：可以不加斜线，在有多个空白符的时候，不加斜线不显示空白符，加了才会显示） c [\]text：替换行为单行或多行文本 w /path/somefile: 保存模式匹配的行至指定文件 r /path/somefile：读取指定文件的文本至模式空间中 匹配到的行后 =: 为模式空间中的行打印行号 !:模式空间中匹配行取反处理 sed -e &quot;/^[[:space:]]*$/d&quot; -e &quot;/^#/d&quot; /etc/fstab]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[字符串处理]]></title>
    <url>%2Flinux%2F20170705-02-string%2F</url>
    <content type="text"><![CDATA[字符串字符切片 基于模式取子串 字符串查找并替换 字符串查找并删除]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>string</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数组和关联数组]]></title>
    <url>%2Flinux%2F20170705-01-array%2F</url>
    <content type="text"><![CDATA[声明数组：声明数组：declare -a array （数组可以不声明，直接用）声明关联数组：declare -A ass_array（关联数组必须declare声明） 数组赋值数组是带索引的一系列值。 定义数组weeks=(Sun Mon Tue Wed Thu Fri Sat)fruits[0]=&quot;Apple&quot; 遍历数组 *可以换成@ 数组长度 *数组切片 添加元素到末尾]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>array</tag>
        <tag>associate array</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设置Fedora合上盖子不休眠]]></title>
    <url>%2Flinux%2F20170705-fedora25-dont-sleep%2F</url>
    <content type="text"><![CDATA[最近做实验，在另一台笔记本上装了一个Fedora 25，发现合上盖子就休眠了，而且桌面环境的电源设置里也没有针对合上盖子的设置 +_+ 从网上找了一下，找到一篇文章：http://www.tuicool.com/articles/ZvQRF3 下面记录下来，作为参考： Fedora的电源管理是在systemd的管理之下，参数文件为：/etc/systemd/logind.conf。 里面有几行被注释掉的配置，就是默认的电源配置： 1234#HandlePowerKey=poweroff#HandleSuspendKey=suspend#HandleHibernateKey=hibernate#HandleLidSwitch=suspend 前面是动作，后面是系统响应的操作。HandlePowerKey：按下电源后的动作HandleSleepKey：按下挂起键的动作HandleHibernateKey: 按下休眠建的动作HandleLidSwitch：合上笔记本盖子后的动作。 对应的操作有ignore、poweroff、reboot、halt、suspend、hibernate、hybrid-sleep、lock 或 kexec。 这里合上盖子的默认参数是suspend挂起。 复制这条注释，然后去掉#好，把suspend改为lock或者ignore都可以。 12345#HandlePowerKey=poweroff#HandleSuspendKey=suspend#HandleHibernateKey=hibernate#HandleLidSwitch=suspendHandleLidSwitch=lock 重启服务：systemctl restart systemd-logind]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Fedora 25</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[破坏实验--破坏5的initrd、6和7的initramfs文件，然后恢复]]></title>
    <url>%2Flinux%2F20170704-03-rescure-initrd-initramfs%2F</url>
    <content type="text"><![CDATA[删掉5的/boot/initrdxxxxx.img 恢复：救援模式进入系统： mkinitrd /boot/initramfs-$(uname -r).img $(uname -r) 删掉6的/boot/initramfsxxx.img mkinitrd /boot/initramfs-$(uname -r).img $(uname -r) 删掉7的/boot/initramfsxxx.img mkinitrd /boot/initramfs-$(uname -r).img $(uname -r)或者dracut /boot/initramfs-$(uname -r).img $(uname -r)]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>initrd</tag>
        <tag>initramfs</tag>
        <tag>mkinitrd</tag>
        <tag>dracut</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell进阶之函数练习题]]></title>
    <url>%2Flinux%2F20170704-02-function-practice%2F</url>
    <content type="text"><![CDATA[1 打印国际象棋 1234567891011121314151617181920212223242526#!/bin/bash# ┌───────────────────────────────────────────────────────┐# │Script Name | cheer.sh ▮▮▮▮▮▮▮▮ │# │Date | 2017-07-04 ▮▮ │# │Author | Yu Longjun ▮▮▮▮▮▮▮▮▮▮▮▮ │# │Blog | http://www.yulongnjun.com ▮▮ │# │Version | 1.0 ▮▮▮▮▮ │# │Description | This is description. ▮▮ │# └───────────────────────────────────────────────────────┘red()&#123; echo -ne "\033[41m \033[0m"; &#125;yellow()&#123; echo -ne "\033[43m \033[0m"; &#125;for i in `seq 9`; do for k in `seq 3`;do for j in `seq 9`; do let sum=i+j let mod=sum%2 if [ $mod -eq 1 ]; then red else yellow fi done echo donedone 2 斐波那契数列又称黄金分割数列，因数学家列昂纳多·斐波那契以兔子繁殖为例子而引入，故又称为“兔子数列”，指的是这样一个数列：0、1、1、2、3、5、8、13、21、34、……，斐波纳契数列以如下被以递归的方法定义：F（0）=0，F（1）=1，F（n）=F(n-1)+F(n-2)（n≥2）利用函数，求n阶斐波那契数列 12345678910111213141516171819202122232425262728#!/bin/bash# ┌───────────────────────────────────────────────────────┐# │Script Name | fib.sh ▮▮▮▮▮▮▮▮ │# │Date | 2017-07-04 ▮▮ │# │Author | Yu Longjun ▮▮▮▮▮▮▮▮▮▮▮▮ │# │Blog | http://www.yulongnjun.com ▮▮ │# │Version | 1.0 ▮▮▮▮▮ │# │Description | This is description. ▮▮ │# └───────────────────────────────────────────────────────┘read -p "请输入数列个数：" nfib()&#123; if [ $1 -eq 0 ] ; then ret=0 echo $ret elif [ $1 -eq 1 ]; then ret=1 echo $ret elif [ $1 -gt 1 ]; then let ret=$(fib $[$1-1])+$(fib $[$1-2]) echo $ret fi&#125;for i in `seq $n`; do fib $idone#!/bin/bash 3 编写服务脚本/root/bin/testsrv.sh，完成如下要求(1) 脚本可接受参数：start, stop, restart, status(2) 如果参数非此四者之一，提示使用格式后报错退出(3) 如是start:则创建/var/lock/subsys/SCRIPT_NAME, 并显示“启动成功”考虑：如果事先已经启动过一次，该如何处理？(4) 如是stop:则删除/var/lock/subsys/SCRIPT_NAME, 并显示“停止完成”考虑：如果事先已然停止过了，该如何处理？(5) 如是restart，则先stop, 再start考虑：如果本来没有start，如何处理？(6) 如是status, 则如果/var/lock/subsys/SCRIPT_NAME文件存在，则显示“SCRIPT_NAMEis running…”如果/var/lock/subsys/SCRIPT_NAME文件不存在，则显示“SCRIPT_NAME is stopped…”其中：SCRIPT_NAME为当前脚本名(7)在所有模式下禁止启动该服务，可用chkconfig和service命令管理 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061#!/bin/env bash#chkconfig: 345 99 0# ┌───────────────────────────────────────────────────────┐# │Script Name | testsrv.sh ▮▮▮▮▮▮▮▮ │# │Date | 2017-07-04 ▮▮ │# │Author | Yu Longjun ▮▮▮▮▮▮▮▮▮▮▮▮ │# │Blog | http://www.yulongnjun.com ▮▮ │# │Version | 1.0 ▮▮▮▮▮ │# │Description | This is description. ▮▮ │# └───────────────────────────────────────────────────────┘srvfile=&quot;/var/lock/subsys/`basename $0`&quot;func_start()&#123; if [ -e $srvfile ];then echo &quot;服务已启动,无需再次启动&quot; else touch $srvfile echo &quot;启动成功&quot; fi&#125;func_stop()&#123; if [ -e $srvfile ];then rm -f $srvfile echo &quot;停止完成&quot; else echo &quot;服务未启动，无需停止&quot; fi&#125;func_restart()&#123; func_stop func_start&#125;func_status()&#123; if [ -e $srvfile ];then echo &quot;`basename $0` is running...&quot; else echo &quot;`basename $0` has stoped...&quot; fi&#125;case $1 in &quot;start&quot;) func_start ;; &quot;stop&quot;) func_stop ;; &quot;restart&quot;) func_restart ;; &quot;status&quot;) func_status ;; *) &quot;输入参数错误, Usage: `basename $0` start|stop|restart|status&quot; ;;esac]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>function</tag>
        <tag>practice</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell进阶之流程练习题]]></title>
    <url>%2Flinux%2F20170704-01-flow-practice%2F</url>
    <content type="text"><![CDATA[1) 添加10个用户user1-user10，密码为8位随机字符 2) 打印九九乘法表 Shell版本： 12345678#!/bin/env bashfor i in `seq 9`; do for j in `seq $i`; do let x=i*j echo -ne "$&#123;i&#125;x$&#123;j&#125;=$&#123;x&#125;\t" done echodone Python版本： 1234for i in range(1, 10): for j in range(1, i+1): print('&#123;&#125;x&#123;&#125;=&#123;&#125;\t'.format(j, i, i*j), end='') print() 3) 在/testdir目录下创建10个html文件,文件名格式为数字N（从1到10）加随机8个字母，如：1AbCdeFgH.html 1234mkdir /testdirfor i in &#123;1..10&#125;;do alpha=`cat /dev/urandom |tr -dc "a-zA-Z" |head -c 8` touch /testdir/$i$alpha.html 4) 打印等腰三角形 shell版本： 12345678910111213141516171819202122232425#!/bin/bashread -p &quot;请输入等腰三角形行数:&quot; line# 判断输入的是否是数字expr $line + 1 &amp;&gt;/dev/nullif [ $? != &quot;0&quot; ];then echo 输入错误，退出。 exitfi# 循环打印for cur_line in `seq $line`;do let space=line-cur_line let filler=2*cur_line-1 if [ $space == 0 ]; then printf %$&#123;filler&#125;s &quot; &quot; |tr &quot; &quot; &quot;*&quot; echo else printf %$&#123;space&#125;s &quot; &quot; printf %$&#123;filler&#125;s &quot; &quot; |tr &quot; &quot; &quot;*&quot; printf %$&#123;space&#125;s &quot; &quot; echo fidone Python版本： 1234567lines = input("Please iput the lines number:")if isinstance(lines,int): for line in range(1,lines+1): space=lines-line filler=2*line-1 print(" "*space+"*"*filler+" "*space) 4 后续六个字符串：efbaf275cd、4be9c40b8b、44b2395c46、f8c8873ce0、b902c16c8b、ad865d2f63是通过对随机数变量RANDOM随机执行命令：echo $RANDOM|md5sum|cut –c1-10后的结果，请破解这些字符串对应的RANDOM值。 12345678910111213141516171819#!/bin/bash# ┌───────────────────────────────────────────────────────┐# │Script Name | decrypt.sh ▮▮▮▮▮▮▮▮ │# │Date | 2017-07-04 ▮▮ │# │Author | Yu Longjun ▮▮▮▮▮▮▮▮▮▮▮▮ │# │Blog | http://www.yulongnjun.com ▮▮ │# │Version | 1.0 ▮▮▮▮▮ │# │Description | This is description. ▮▮ │# └───────────────────────────────────────────────────────┘encrypt_num_array=(efbaf275cd 4be9c40b8b 44b2395c46 f8c8873ce0 b902c16c8b ad865d2f63)for raw_num in `seq 0 65535`;do encrypt_num=`echo $raw_num | md5sum | cut -c 1-10` for num in $&#123;encrypt_num_array[*]&#125;; do if [ "$encrypt_num" == "$num" ];then echo "$num --&gt; $raw_num" fi donedone 5 编写脚本/root/bin/copycmd.sh(1) 提示用户输入一个可执行命令名称(2) 获取此命令所依赖到的所有库文件列表(3) 复制命令至某目标目录(例如/mnt/sysroot)下的对应路径下；如：/bin/bash ==&gt; /mnt/sysroot/bin/bash/usr/bin/passwd==&gt; /mnt/sysroot/usr/bin/passwd(4) 复制此命令依赖到的所有库文件至目标目录下的对应路径下：如：/lib64/ld-linux-x86-64.so.2 ==&gt; /mnt/sysroot/lib64/ld-linux-x86-64.so.2(5)每次复制完成一个命令后，不要退出，而是提示用户键入新的要复制的命令，并重复完成上述功能；直到用户输入quit退出 123456789101112131415161718192021222324#!/bin/bash# ┌───────────────────────────────────────────────────────┐# │Script Name | copycmd.sh ▮▮▮▮▮▮▮▮ │# │Date | 2017-07-04 ▮▮ │# │Author | Yu Longjun ▮▮▮▮▮▮▮▮▮▮▮▮ │# │Blog | http://www.yulongnjun.com ▮▮ │# │Version | 1.0 ▮▮▮▮▮ │# │Description | This is description. ▮▮ │# └───────────────────────────────────────────────────────┘while true;do read -p "请输入一个可执行的命令的名称(quit 退出):" command if [ "$command" == "quit" ]; then exit else cmd_path=`which $command` mkdir -p /mnt/sysroot$cmd_path cp $cmd_path /mnt/sysroot$cmd_path list=`ldd /bin/ls|grep -o "/lib.* "|tr -d " "` [ -e /mnt/sysroot/lib64 -a -e /mnt/sysroot/lib ] || mkdir /mnt/sysroot/&#123;lib64,lib&#125; for i in $list;do cp $i /mnt/sysroot$i done fidone]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>practice</tag>
        <tag>flow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Axure RP 8 安装与汉化]]></title>
    <url>%2Fsoftware%2F20170704-axure-rp8%2F</url>
    <content type="text"><![CDATA[Axure RP Pro 是专为 Rapid Prototype Design 而生，它可以辅助产品经理快速设计完整的产品原型，并结合批注、说明以及流程图、框架图等元素将产品完整地表述给各方面设计人员，如 UI、UE 等等，并在讨论中不断完善。 Axure RP 能帮助网站需求设计者，快捷而简便的创建基于网站构架图的带注释页面示 意图、操作流程图、以及交互设计，并可自动生成用于演示的网页文件和规格文件，以提供演示与开发。 Axure RP Pro 功能包括站点地图、流程设计、页面框架设计、简单交互设 计等，可以生成HTML、Word等格式。RP操作比用Dreamweaver简单多了，图片、文字、输入框等等所有组件全是可视化操作，可以很方便的实 现网站交互内容的原型设计，可将以前死板的页面版式全部替换为有点击、链接效果的网页!同时可以为网站设计提供AJAX式的交互处理，RP提供一种动态层 的组件，在同一页设定不同状态的效果，然后用链接、按钮等触发即可产生动态效果，这样网站设计就变得更加生动，意图也就更加直观。 下载链接:http://pan.baidu.com/s/1c25ZO7u 密码:61w2 包含内容： AxureRP-Setup.dmg是原版包，也可以去官网下载最新版。 sn.txt 是序列号 AxureRP8_CHSxxx.zip是汉化包 AxureRP_for_chromexxx.zip是chrome插件。 依次安装即可。]]></content>
      <categories>
        <category>software</category>
      </categories>
      <tags>
        <tag>Axure RP 8</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS5、CentOS6启动流程]]></title>
    <url>%2Flinux%2F20170703-03-init%2F</url>
    <content type="text"><![CDATA[这三篇文章讲的都很好，可以看一下，这里就不写了（偷个懒(⊙﹏⊙)b） http://os.51cto.com/art/201407/446819.htm http://www.mamicode.com/info-detail-1165638.html http://www.cnblogs.com/gbk66/p/5900964.html]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>init</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell进阶--函数]]></title>
    <url>%2Flinux%2F20170703-02-function%2F</url>
    <content type="text"><![CDATA[系统里的函数declare -f 查看系统里的函数 declare -f |grep &quot;.* ()&quot;|tr -d &quot; ()&quot;：用grep可以过滤出函数名 declare -f 函数名 ：查看特定的函数 unset 函数名 ：和变量一样的取消一样，可以unset取消函数 自定义函数语法一： 123function f_name &#123; 函数体&#125; 语法二： 123function f_name () &#123; 函数体&#125; 语法三(最常见，记住这个用法就行）： 123f_name () &#123; 函数体&#125; 函数调用函数的调用： 可在交互式环境下定义函数，即直接在bash命令行里写函数和调用函数。 可将函数放在脚本文件中作为它的一部分，即在同一个脚本文件里调用函数。 可放在只包含函数的单独文件中，即其他shell脚本可以调用这个文件，用. path/to/functions_file或者source path/to/functions_file 函数调用很简单：无参数：function_name有参数：functions_name arg1 arg2 ... argN functions_name为函数名，arg为argument（参数）的意思。在函数体中当中，可使用$1, $2调用这些参数；还 可以使用$@, $*, $#等特殊变量 函数返回值函数有两种返回值： 函数的执行结果返回值： (1) 使用echo等命令进行输出 (2) 函数体中调用命令的输出结果 函数的退出状态码： (1) 默认取决于函数中执行的最后一条命令的退出状态码 (2) 自定义退出状态码，其格式为： return 从函数中返回，用最后状态命令决定返回值。 return 0 无错误返回。 return 1-255 有错误返回。 函数中的局部变量当函数中有变量的时候，和函数体外的变量容易冲突，这时候可以用局部变量 在函数中定义局部变量的方法：local NAME=VALUE 递归函数函数直接或间接调用函数自身。 阶乘： 123456789#!/bin/bashfact() &#123; if [ $1 -eq 0 -o $1 -eq 1 ]; then echo 1 else echo $[$1*$(fact $[$1-1])] fi&#125;fact $1 fork炸弹： 123:()&#123; :|:&amp; &#125;;:# 冒号在这里其实就是函数名，换成另外的单词你就理解了：bomb() &#123; bomb | bomb &amp; &#125;; bomb 菲波那切数列： 123456789101112131415161718read -p "请输入数列个数：" nfib()&#123; if [ $1 -eq 0 ] ; then ret=0 echo $ret elif [ $1 -eq 1 ]; then ret=1 echo $ret elif [ $1 -gt 1 ]; then let ret=$(fib $[$1-1])+$(fib $[$1-2]) echo $ret fi&#125;for i in `seq $n`; do fib $idone 环境函数(全局函数）export -f func或者declare -fx func declare中，-f的意思是function，-x的意思是export]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>function</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell进阶--流程]]></title>
    <url>%2Flinux%2F20170703-01-flow%2F</url>
    <content type="text"><![CDATA[由于条件判断和循环跟其他语言都大同小异，学过编程的话很好理解，这里只贴出格式，不具体写用法了。（select菜单会详细讲一下） 条件判断if条件判断普通if条件判断： 123456789if 判断条件1; then 条件为真的分支代码elif 判断条件2; then 条件为真的分支代码elif 判断条件3; then 条件为真的分支代码else 以上条件都为假的分支代码fi 嵌套if条件判断： 12345678910111213141516171819202122232425if 判断条件1; then 条件为真的分支代码else if 判断条件2; then 条件为真的分支代码 else 条件为真的分支代码 fifi``` ### case条件判断```bashcase 变量引用 inPAT1) 分支1 ;;PAT2) 分支2 ;;#...省略*) 默认分支esac 循环for循环普通for循环： 123for 变量名 in 列表;do 循环体done 嵌套for循环： 123456for 变量名1 in 列表1;do 循环体1 for 变量名2 in 列表2;do 循环体2 donedone while循环123while CONDITION; do 循环体done until循环123until CONDITION; do 循环体done 循环中使用continue和breakcontinue 结束本次循环，还会进入下一轮循环break 结束全部循环，不会进入下一轮循环 循环工中使用shift跳过参数列表中的某项用于处理参数不确定的情况，shift比较好用 while循环的特殊用法（遍历文件的每一行）123while read line; do循环体done &lt; /PATH/FROM/SOMEFILE select 菜单 select 循环主要用于创建菜单，按数字顺序排列的菜单项将显示在标准错误上，并显示 PS3 提示符，等待用户输入。 用户输入菜单列表中的某个数字，执行相应的命令 用户输入被保存在内置变量 REPLY 中。 可以和case结合使用。 下面举个和select和case结合使用的例子：1234567891011121314151617181920212223242526PS3="Please choose your food(Input No.): "select food in "exit" "huimian" "juejiangmian" "laomo" "yangroutang"do case $food in "exit") echo Your choice is $REPLY echo "Thanks!" exit ;; "huimian"|"juejiangmian") echo Your choice is $REPLY echo "12 yuan" ;; "laomo") echo Your choice is $REPLY echo "15 yuan" ;; "yangroutang") echo Your choice is $REPLY echo "20 yuan" ;; *) echo "Dont's have this food" ;; esacdone trap 信号捕捉 trap &#39;触发指令&#39; 信号 ：自定义进程收到系统发出的指定信号后，将执行触发指令 ，而不会执行原操作 trap &#39;&#39; 信号 ：信号忽略信号的操作 trap &#39;-&#39; 信号 ：恢复原信号的操作 trap -p：列出自定义信号操作]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>if elif else</tag>
        <tag>for</tag>
        <tag>case</tag>
        <tag>while</tag>
        <tag>until</tag>
        <tag>select</tag>
        <tag>trap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计划任务at、cron]]></title>
    <url>%2Flinux%2F20170630-02-at-cron%2F</url>
    <content type="text"><![CDATA[at 未来的某时间点执行一次任务 batch 系统自行选择空闲时间去执行此处指定（用的比较少） cron 周期性运行某任务 at系统中的服务名叫atd at [option] TIME [option] at -l 显示计划任务at -c NO: 按编号（NO）查看具体作业任务at -d NO按编号（NO）删除计划任务-f /path/from/somefile：从指定的文件中读取任务-m:当任务被完成之后，将给用户发送邮件，即使没有标准输出 TIME定义出什么时候进行 at 这项任务的时间 HH:MM [YYYY-mm-dd] noon, midnight, teatime（4pm） tomorrow now+#{minutes,hours,days, OR weeks} HH:MM: 在今日的 HH:MM 进行，若该时刻已过，则明天此时执行任务 1at 02:00 HH:MM YYYY-MM-DD: 规定在某年某月的某一天的特殊时刻进行该项任务 1at 02:00 2016-09-20 HH:MM[am|pm] [Month] [Date] 12at 04pm March 17at 17:20 tomorrow HH:MM[am|pm] + number [minutes|hours|days|weeks]: 在某个时间点再加几个时间后才进行该项任务 12at now + 5 minutesat 02pm + 3 days 查看生成的计划任务文件：ls /var/spool/at 执行at命令的用户的黑白名单：/etc/at.{allow,deny} 白名单：/etc/at.allow 默认这个文件不存在，只有该文件中的用户才能执行at命令。白名单优先级高，有了白名单，黑名单不生效了（同一个用户又在白名单又在黑名单，只生效白名单，即允许此用户） 黑名单：/etc/at.deny 默认存在，拒绝该文件中用户执行at命令，而没有在at.deny文件中的使用者则可执行。 如果两个文件都不存在，只有 root 可以执行at命令 cron安装包叫cronie 默认一般安装并启用服务了,服务名叫crond： 可以查看服务状态，如果没启动，start启动一下：CentOS 6: service crond statusCentOS 7: systemctl status crond 计划周期性执行的任务提交给crond，到指定时间会自动运行。 /etc/crontab文件系统cron任务：系统维护作业。 x：特定值x。给定时间点有效取值范围内的值* ：每{分钟，小时，日，月等}。给定时间点上有效取值范围内的所有值x,y ：x或y。离散取值。x-y ：x到y。连续取值。/x ：每过多少{分钟，小时，日，月等}执行。在指定时间范围上，定义步长。 简写 意义 @reboot Run once after reboot. @yearly 0 0 1 1 * @annually 0 0 1 1 * @monthly 0 0 1 @weekly 0 0 0 @daily 0 0 * @hourly 0 示例：每3小时echo和wall命令 10 */3 * * * centos /bin/echo “howdy”;/usr/bin/wall “welcome to Magedu!” 用户cron任务：crontab命令 日志：/var/log/cron crontab命令用户cron：crontab命令定义，每个用户都有专用的cron任务文件： /var/spool/cron/USERNAME 命令用法： crontab [-u user] [-l | -r | -e] [-i] -l: 列出所有任务 -e: 编辑任务 -r: 移除所有任务 -i：同-r一同使用，以交互式模式移除指定任务 -u USERNAME: 仅root可运行-u选项，管理某个用户的cron任务。 /etc/cron.{allow,deny}控制计划任务的用户黑白名单。 规则同前面讲到的at.{allow,deny} Notes: 运行结果的标准输出和错误以邮件通知给相关用户。 (1) COMMAND &gt; /dev/null (2) COMMAND &amp;&gt; /dev/null 对于cron任务来讲，%有特殊用途；如果在命令中要使用%， 则需要转义，将%放置于单引号中，则可不用转义 anacron个人电脑用的比较多，时间段属于人的作息时间段。 安装包叫cronie-annacron]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>network</tag>
        <tag>bonding</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kill命令]]></title>
    <url>%2Flinux%2F20170630-01-kill%2F</url>
    <content type="text"><![CDATA[用法：，kill -SIGNAL pid SIGNAL是信号，kill -l可以查看支持的信号。 下面是系统支持的信号，用man 7 signal可以查询到： 常用信号： 1) SIGHUP: 无须关闭进程而让其重读配置文件2) SIGINT: 中止正在运行的进程；相当于Ctrl+c3) SIGQUIT:相当于ctrl+\9) SIGKILL: 强制杀死正在运行的进程15) SIGTERM：终止正在运行的进程18) SIGCONT：继续运行19) SIGSTOP：后台休眠 例子 123kill -9 4365kill -19 4444 # 让4444休眠kil -18 4444 # 让4444继续运行 pkill-SIGNAL：指定信号 -u uid: effective user，生效者 -U uid: real user，真正发起运行命令者 -t terminal: 与指定终端相关的进程 -l: 显示进程名（pgrep可用） -a: 显示完整格式的进程名（pgrep可用） -P pid: 显示指定进程的子进程 例子：pkill -t dev/tty3 运行状态前台运行后台运行后台休眠 kill -19 xxx 后台休眠kill -18 xxx 后台继续运行bg 1 后台运行（在同一个终端窗口执行）fg 1 前台运行（在同一个终端窗口执行） 可以让程序不依赖终端运行的两种方法： nohup COMMAND &amp;&gt;/dev/null &amp; screen;COMMAND 同时运行多个进程，提高效率 方法1 vim all.sh 123f1.sh&amp;f2.sh&amp;f3.sh&amp; 方法2 (f1.sh&amp;);(f2.sh&amp;);(f3.sh&amp;) 方法3 { f1.sh&amp; f2.sh&amp; f3.sh&amp; }]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>kill</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进程]]></title>
    <url>%2Flinux%2F20170628-02-process%2F</url>
    <content type="text"><![CDATA[优先级： 命令pstree-p 把各个子线程都详细显示出来 ps 进程状态（process state）UNIX风格：ps -efBSD风格：ps aux 还有用到o参数，选项显示定制的信息：pid、comm、%cpu、%mem、state、tty、euser、ruser、psr psr:用的哪颗cpu ps axo pid,tid,class,rtprio,ni,pri,psr,pcpu,stat,comm ps -eo stat,euid,ruid,tty,tpgid,sess,pgrp,ppid,pid,pcpu,comm ni: nice值 pri: priority 优先级(数越大优先级越高，跟前面图里的system优先级反过来） psr: processor CPU编号 rtprio: 实时优先级 示例： ps -C PROCESSNAME单独显示某个进程，可以加o参数扩展。 STAT：进程状态 R：running S: interruptable sleeping D: uninterruptable sleeping T: stopped Z: zombie +: 前台进程 l: 多线程进程 L：内存分页并带锁 N：低优先级进程 &lt;: 高优先级进程 s: session leader，会话（子进程）发起者 nice 调整优先级运行某个命令，指定优先级：nice -n -XX COMMAND :xx范围是-20~19 在运行中的程序，修改优先级：renice -n -XX PID:xx范围是-20~19 pgrep 搜索进程信息-u uid: effective user，生效者 -U uid: real user，真正发起运行命令者 -t terminal: 与指定终端相关的进程 -l: 显示进程名 -a: 显示完整格式的进程名 -P pid: 显示指定进程的子进程 pidof按确切的程序名称显示pid命令绝对路径：/sbin/pidof用法：pidof COMMAND 12pidof httpdecho $? # 将来在脚本里可以判断进程是否存在 uptime显示启动状态显示当前时间，系统已启动的时间、当前上线人数，系统平 均负载（1、5、10分钟的平均负载，一般不会超过1） 12root@centos6 ~]# uptime 17:18:44 up 11:40, 2 users, load average: 0.00, 0.00, 0.00 系统平均负载: 指在特定时间间隔内运行队列中的平均进程数。 通常每个CPU内核的当前活动进程数不大于3，那么系统的性能良好。如果每个CPU内核的任务数大于5，那么此主机的性能有严重问题。 如果linux主机是1个双核CPU，当Load Average为6的时候说明机器已经被充分使用。 top显示进程使用系统资源情况 第一行：相当于uptime命令第二行：进程信息第三行：CPU使用情况第四行：内存使用情况第五行：交换分区swap使用情况 cpu那行： us：user, 用户空间占用 sy：system, 内核空间占用 ni：调整nice时间 id：idle, 空闲 wa：wait, 等待IO时间 hi：hard interupt, 硬中断 si：soft interupt, 软中断（模式切换） st：stole, 虚拟机偷走的时间 排序在打开top后，可以按快捷键进行自定义排序： P：以占据的CPU百分比,%CPU M：占据内存百分比,%MEM T：累积占据CPU时长,TIME+ 首部信息是否显示： uptime信息：l（字母l） tasks及cpu信息：t cpu分别显示：1（数字1） memory信息：m 退出命令：q 修改刷新时间间隔：s 终止指定进程：k 保存文件：W vmstat虚拟内存信息用法示例：vmstat 2 5: 每2秒刷一次，刷5次选项：-s: 显示内存的统计数据 显示中的各项含义： procs: r：可运行（正运行或等待运行）进程的个数，和核心数有关 b：处于不可中断睡眠态的进程个数(被阻塞的队列的长度) memory： swpd: 交换内存的使用总量 free：空闲物理内存总量 buffer：用于buffer的内存总量 cache：用于cache的内存总量 swap: si：从磁盘交换进内存的数据速率(kb/s) so：从内存交换至磁盘的数据速率(kb/s) io： bi：从块设备读入数据到系统的速率(kb/s) bo: 保存数据至块设备的速率 system： in: interrupts 中断速率，包括时钟 cs: context switch 进程切换速率 cpu： us:Time spent running non-kernel code sy: Time spent running kernel code id: Time spent idle. Linux 2.5.41前,包括IO-wait time. wa: Time spent waiting for IO.2.5.41前，包括in idle. st: Time stolen from a virtual machine.2.6.11前, unknown. iostat CPU和磁盘IO`iostat 1 10` 每1秒刷新一次，刷新10次 pmap 进程对应的内存映射pmap [options] pid [...] -x: 显示详细格式的信息 glances 监控其他机器C/S模式下运行glances命令 服务器模式： glances -s -B IPADDR IPADDR: 指明监听的本机哪个地址 客户端模式： glances -c IPADDR IPADDR：要连入的服务器端地址 dstat默认采用-cdngy参数 -c: 显示cpu相关信息 -C #,#,…,total -d: 显示disk相关信息 -D total,sda,sdb,… -g：显示page相关统计数据(交换分区） -m: 显示memory相关统计数据 -n: 显示network相关统计数据 -p: 显示process相关统计数据 -r: 显示io请求相关的统计数据 -s: 显示swapped相关的统计数据]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>network</tag>
        <tag>bonding</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网卡绑定(bonding)]]></title>
    <url>%2Flinux%2F20170626-05-bonding%2F</url>
    <content type="text"><![CDATA[就是将多块网卡绑定同一IP地址对外提供服务，可以实现高 可用或者负载均衡。当然，直接给两块网卡设置同一IP地址 是不可能的。通过bonding，虚拟一块网卡对外提供连接， 物理网卡的被修改为相同的MAC地址。 Mode 0 (balance-rr) 轮转（Round-robin）策略：从头到尾顺序的在每一个slave 接口上面发送数据包。本模式提供负载均衡和容错的能力 Mode 1 (active-backup) 活动-备份（主备）策略：只有一个slave被激活，当且仅当活动 的slave接口失败时才会激活其他slave。为了避免交换机发生混 乱此时绑定的MAC地址只有一个外部端口上可见 Mode 3 (broadcast) 广播策略：在所有的slave接口上传送所有的报文,提供容错能力 active-backup、balance-tlb 和 balance-alb 模式不需要 交换机的任何特殊配置。其他绑定模式需要配置交换机以便 整合链接。如：Cisco 交换机需要在模式 0、2 和 3 中使用 EtherChannel，但在模式4中需要 LACP和 EtherChannel 配置方法： 新建文件/etc/sysconfig/network-scripts/ifcfg-bond0： 123456789DEVICE=bond0BONDING_OPTS=&quot;miimon=100 mode=0&quot;BOOTPROTO=noneIPADDR=PREFIX=GATEWAY=DNS1=DNS2=DOMAIN= /etc/sysconfig/network-scripts/ifcfg-eth0 12345DEVICE=eth0BOOTPROTO=noneMASTER=bond0SLAVE=yesUSERCTL=no 同样的，也要修改eth1的ifcfg文件。 查看bond0状态：/proc/net/bonding/bond0 各种bond模式详细说明：详细帮助： /usr/share/doc/kernel-doc-version/Documentation/networking/bonding.txt https://www.kernel.org/doc/Documentation/networking/bonding.txt teamteam网络组：是将多个网卡聚合在一起方法，从而实现冗错和提 高吞吐量 网络组不同于旧版中bonding技术，提供更好的性能和扩展性 网络组由内核驱动和teamd守护进程实现. 多种方式runner broadcast roundrobin activebackup loadbalance lacp (implements the 802.3ad Link Aggregation Control Protocol) 命令格式： 创建team： nmcli con add type team con-name CNAME ifname INAME [config JSON] CNAME 连接名，INAME 接口名 JSON 指定runner方式 格式：&#39;{&quot;runner&quot;: {&quot;name&quot;: &quot;METHOD&quot;}}&#39; METHOD 可以是broadcast, roundrobin,activebackup, loadbalance, lacp 添加从属接口： nmcli con add type team-slave con-name CNAME ifname INAME master TEAM CNAME 连接名 INAME 网络接口名 TEAM 网络组接口名连接名若不指定，默认为team-slave-IFACE 查看team状态 1teamdctl team0 state down team 1nmcli connect down team0 up team 123nmcli connect up team0nmcli conect up team-slave-eth0nmcli connect up team-slave-eth1 down掉team，连slave也down掉。up的时候，只启动team，要手动启动各个slave。 实验： 1234567891011121314151617nmcli con add type team con-name team0 ifname team0 config ‘&#123;&quot;runner&quot;: &#123;&quot;name&quot;: &quot;loadbalance&quot;&#125;&#125;&apos;nmcli con mod team0 ipv4.addresses 192.168.1.100/24nmcli con mod team0 ipv4.method manualnmcli con add con-name team0-eth1 type team-slave ifname eth1 master team0nmcli con add con-name team0-eth2 type team-slave ifname eth2 master team0nmcli con up team0nmcli con up team0-eth1nmcli con up team0-eth2teamdctl team0 state; # nmcli dev dis eth1]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>network</tag>
        <tag>bonding</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7网络配置]]></title>
    <url>%2Flinux%2F20170626-04-network-config-centos7%2F</url>
    <content type="text"><![CDATA[把网卡命名方式改为传统eth方式： vim /boot/grub2/grub.cfg linux16那行，最后添加net.ifnames=0 hostnamectlhostnamectl statushostnamectl set-hostname xxxxx：更改主机名，同时写到/etc/hostname配置文件里。 tips：记得也改下/etc/hosts里，最后加上新加的主机名 nmcli修改连接名 nmcli connection modify enp0s25 connection.id eth0 添加一条新的配置 nmcli connection add con-name eth1-lan type ethernet ifname eth1 nmcli connection modify eth0 xxxx.xxxx xxxx xxxx.xxxx xxxx指的是：connection.autoconnect yesipv4.method manual/autoipv4.addresses xxx.xxx.xxx.xxxipv4.gateway xxx.xxx.xxx.xxx 重启连接：nmcli connection reload 还有其他的： 对应关系： 去掉ip连接，不down设备：nmcli dev disconnect nmtui字符界面： 编辑连接、激活连接、设置主机名 bondbond也可以用bond来作 添加bonding接口 1nmcli con add type bond con-name mybond0 ifname mybond0 mode active-backup 添加从属接口 123nmcli con add type bond-slave ifname ens7 master mybond0nmcli con add type bond-slave ifname ens3 master mybond0 注：如无为从属接口提供连接名，则该名称是接口名称加类型构成 要启动绑定，则必须首先启动从属接口 123nmcli con up bond-slave-ens7nmcli con up bond-slave-ens3 启动绑定 1nmcli con up mybond0 down掉,并删除bond 12nmcli connect down mybond0nmcli connect del mybond0]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>network</tag>
        <tag>bonding</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS6网络配置]]></title>
    <url>%2Flinux%2F20170626-03-network-config-centos6%2F</url>
    <content type="text"><![CDATA[/etc/sysconfig/network-scripts/ifcfg-xxxip、mask、gateway、dns相关配置文件 1234567891011NAME=xxxDEVICE=XXXONBOOT=yesBOOTPROTO=dhcp/none #dhcp还是静态，不写就是手工指定。IPADDR=xx.xx.xx.xx # ip地址PREFIX=xx # 掩码，新格式# NETMASK=xxx.xxx.xxx.xxx # 掩码，旧格式DNS1=xxx.xxx.xxx.xxxDNS2=xxx.xxx.xxx.xxxHWADDR=xx:xx:xx:xx:xx:xx # 硬件MAC地址MACADDR=yy:yy:yy:yy:yy:yy # 手动修改MAC地址，要用MACADDR，而不能用HWADDR 例子： 123456DEVICE=eth0NAME=eth0IPADDR=192.168.100.100PREFIX=24GATEWAY=192.168.100.254DNS1=223.5.5.5 NetworkManager服务会在你修改完文件后，自动生成 /etc/resolv.conf，这个就是DNS地址。 /etc/resolv.confDNS和DOMAIN相关的配置文件。通常不用管，会自动生成。 DOMAIN是搜索域DOMAIN yulongjun.com ping www就是ping www.yulongjun.com /etc/sysconfig/network主机名配置文件 /etc/hosts本地的域名解析，优先解析hosts里定义的域名，然后没有才会去DNS里查。 tips：如果要修改顺序，可以更改/etc/nsswitch文件里的内容：hosts: file dns –&gt; hosts: dns file可以先使用dns，后使用/etc/hosts文件。 vim ifcfg-IFNAME:xxx给网卡设置另外一个地址，指定label设备名为网卡名:xxx 1234DEVICE=eth1:officeBOOTPROTO=noneIPADDR=5.5.5.5PREFIX=24 在实现一个网卡获取两个ip地址，一个dhcp自动获取，一个固定ip的时候，要注意，dhcp要先配置，然后新增的设为固定ip。 例如更改ifcfg-eth1里面的参数为dhcp模式，ifcfg-eth1:2里的参数为固定ip模式。 如果顺序反过来，会有问题。 /etc/sysconfig/network-scripts/route-IFNAME路由配置文件，永久生效。需要重启网络服务后才能生效。 两种写法： TARGET via GW如：10.0.0.0/8 via 172.16.0.1 每三行定义一条路由： 123ADDRESSXXX=TARGETNETMASKXXX=maskGATEWAYXXX=GW XXX是数字，一般从1开始写]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS6网络命令]]></title>
    <url>%2Flinux%2F20170626-02-network-commands-centos6%2F</url>
    <content type="text"><![CDATA[ifconfig route netstat ss setup ip {link, addr, route} ifconfig例子： 123ifconfig # 查看所有网卡信息ifconfig eth1 #查看eth1的网卡信息ifconfig eth1 172.17.111.100/16 # 临时设置ip routeroute -n : 查看路由route add [-net|-host] target [netmask Nm] [gw Gw][[dev] Interface] 例如： 1234# 主机route add -host 192.168.1.3 gw 172.16.0.1 dev eth0# 网段route add -net 192.168.0.0/24 gw 172.16.0.1 dev eth0 添加默认路由，默认路由即默认网关： 1234# 第一种写法：route add -net 0.0.0.0 netmask 0.0.0.0 gw 172.16.0.1# 简单写法：route add default gw 172.16.0.1 删除路由： 12route del -host 192.168.1.3route del -net 192.168.0.0/24 netstat常用参数： -t: tcp协议相关 -u: udp协议相关 -a: 所有状态 -n: 以数字显示IP和端口 -l: 处于监听状态 -p: 显示相关进程及PID 显示接口统计数据： netstat -i: 显示所有接口统计数据netstat –I=IFACE或者netstat -Ixxxx: 显示单个接口的统计数据 1watch -n1 netstat -Ieth0 ss新的ss效率更高，用法和netstat差不多。 有一些高级用法： 123ss -o state established &apos;( dport = :ssh or sport = :ssh )&apos; # 显示所有已建立的ssh连接ss -o state established &apos;( dport = :http or sport = :http )&apos; # 显示所有已建立的HTTP连接 setupsetup可以打开TUI（Text-based User Interface）基于文本的交互式界面。可以配置网络（Network configuration），配置防火墙(Firewall configuration)，启用关闭系统服务（System services）等等。 ip以前用的不多的新命令，很好很强大的命令。主要用到3个子命令 ip link、ip addr 、ip route ip linkip link show [IFNAME] ：显示网卡mac信息（link，链路层），不加网卡名就是全部，加上就是显示单个网卡的mac信息。ip link set up/down：设置网卡启用或关闭，在物理层禁止。 ip addrip addr show [IFNAME]：显示网卡ip信息，不加网卡名就是全部，加上就是显示单个网卡的ip信息。ip addr add xxx.xxx.xxx.xxx/xx dev IFNAME label IFNAME:LABELNAME：临时添加ip。 1ip addr add 192.168.100.100/24 dev eth1 label eth1:tmp-net ip addr del xxx.xxx.xxx.xxx/xx dev IFNAME： 1ip addr del 192.168.100.100/24 dev eth1 ip addr flush IFNAME：清楚网卡上所有ip地址，连非临时的都删掉。 1ip addr flush eth1 tips: 重启机器或者网络服务，所有临时添加的ip会消失。 ip routeip route add TARGET via gw 添加路由 12ip route add 192.168.0.0/24 via 172.16.0.1ip route add 192.168.1.13 via 172.16.0.1 ip route delete TARGET 删除路由 12ip route delete 192.168.0.0/24ip route delete 192.168.1.13 ip route show|list 显示路由ip route flush dev IFACE清空路由表 1ip route flush dev eth1]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[克隆虚拟机后，需要对克隆的虚拟机做的相关操作]]></title>
    <url>%2Flinux%2F20170626-01-clone-vm%2F</url>
    <content type="text"><![CDATA[模拟实验机器相关配置： 操作系统：CentOS6.9 两块网卡eth0 和eth1 1） 用自带的克隆虚机功能 启动两台机器，我们ifconfig看到两块网卡的名称、ip地址、mac地址都变了。 然后看到网卡配置文件里面也是旧的文件，还有一个重要的文件/etc//etc/udev/rules.d/70-persistent-net.rules也是错的： 我们先把/etc/udev/rules.d/70-persistent-net.rules下的前面两条注释掉，然后修改第三条第四条的eth2和eth3为eth0和eth1。 然后修改/etc/sysconfig/network-scripts/下的ifcfg-eth0 和ifcfg-eth1,把文件里的UUID和HWADDR给删掉，PART如果是DHCP的，就不用改，如果原来是固定IP的，把IP地址改一下。 可以重启电脑，如果不想重启电脑，可以用卸载然后重新加载网卡驱动模块的方法来使之生效： 我们用ethtool -i eth2可以看到网卡驱动型号： 然后我们可以先卸载，然后装载驱动: 123456789101112# 卸载网卡驱动：modprobe -r e1000#或者 `rmmod e1000`也可以# 装载网卡驱动：modprobe e1000service network restartservice NetworkManager restart 这时候发现，有一个网卡获取不到ip 这时候笔者更改了网卡的默认名字system eth0为eth0（同样的system eth1也改）,这时候再次重启NetworkManager服务，正常获取到了ip。这里猜测NetworkManager某些地方有bug（6里的NetworkManager真是个坑啊！），在名字方面不能跟原来的相同。 至此，克隆的CentOS6完全可用。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络知识(看书，略）]]></title>
    <url>%2Flinux%2F20170623-network-introduction%2F</url>
    <content type="text"><![CDATA[看《趣学CCNA》前5章内容，即可了解，这里略过。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络模型]]></title>
    <url>%2Flinux%2F20170621-network-model%2F</url>
    <content type="text"><![CDATA[OSI七层模型（理论） TCP/IP模型（现实）]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>network</tag>
        <tag>OSI</tag>
        <tag>TCP/IP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[逻辑卷管理（LVM）]]></title>
    <url>%2Flinux%2F20170619-lvm%2F</url>
    <content type="text"><![CDATA[LVM：Logical Volume Management 逻辑卷管理 LVM是建立在硬盘和分区之上的一个逻辑层，来提高磁盘分区管理的灵活性。 传统磁盘管理：我们上层是直接访问文件系统，从而对底层的物理磁盘进行读取。 lvm工作原理：对底层的磁盘进行封装，以逻辑卷（logical volume）的方式呈现给上层应用，逻辑卷里可以方便的添加删除分区和硬盘。 基本的LVM术语概念：PV（Physical Volume）- 物理卷 物理卷在逻辑卷管理中处于最底层，它可以是实际物理硬盘上的分区（例如sdb1），也可以是整个物理硬盘（例如sdc），也可以是raid设备（例如md0）。 VG（Volume Group）- 卷组 卷组建立在物理卷之上，一个卷组中至少要包括一个物理卷，在卷组建立之后可动态添加物理卷到卷组中。一个逻辑卷管理系统工程中可以只有一个卷组，也可以拥有多个卷组。 LV（Logical Volume）- 逻辑卷 逻辑卷建立在卷组之上，卷组中的未分配空间可以用于建立新的逻辑卷，逻辑卷建立后可以动态地扩展和缩小空间。系统中的多个逻辑卷可以属于同一个卷组，也可以属于不同的多个卷组。 PE（Physical Extent）- 物理块 PE是整个LVM 最小的储存区块，也就是说，其实我们的资料都是由写入PE来处理的。简单的说，这个PE就有点像文件系统里面的block大小。 创建PV、VG、LV（增与查）0. 准备工作：在上述创建的那个虚机上增加两块硬盘，各200G。重启虚机，会识别为sdb和sdc，把sdc分区为3个分区：sdc1，sdc2，sdc3。 123fdisk /dev/sdcn来创建3个磁盘。t更改格式为8e（Linux LVM格式） 1. 创建PV（pvcreate）： 命令格式为：pvcreate /dev/DEVICE1 /dev/DEVICE2 /dev/DEVICE3DEVICE可以是sda，sdb，sdc这样的硬盘，也可以是sda1 ，sdb2，sdc3这样的分区，甚至是md0，md1这样的软raid。 实验操作： 1234pvcreate /dev/sdb /dev/sdc1 /dev/sdc2pvs # 简要显示pv组成部分pvdisplay #详细的显示pv的组成部分 2. 创建vg（vgcreate）: 命令格式为：vgcreate volume_group_name /dev/DEVICE1 /dev/DEVICE2 ... /dev/DEVICEN 实验操作： 123vgcreate vg2 /dev/sdc1 /dev/sdc2 /dev/sdc3vgdisplay vg2 #显示创建的vg2的信息 3. 创建lv（lvcreate） 命令格式为：lvcreate -L 大小 -n 名称 vg2参数L为LogicalVolumeSize的意思，大小的单位可为K，M，G，T，P，E参数n的意思是name 实验操作： vg2下创建lv_test1, lv_test2, lv_test33个lv，大小分别为10G，20G，30G 123456789101112131415161718# 创建3个lvlvcreate -L 10G -n lv_test1 vg2lvcreate -L 20G -n lv_test2 vg2lvcreate -L 30G -n lv_test3 vg2lvs # 简要的显示lv信息lvdisplay # 详细的显示lv信息# 格式化lvmkfs.ext4 /dev/vg2/lv_test&#123;1,2,3&#125; #创建目录，作为挂在目录mkdir test&#123;1,2,3&#125; # 挂载mount /dev/vg2/lv_test1 /test1mount /dev/vg2/lv_test2 /test2mount /dev/vg2/lv_test3 /test3 修改分区（改）1. lvextend、lvreduce、lvresize1.1 lvextend：扩展lv用法： 123lvextend -L [+][mMgGtT] /dev/VG_NAME/LV_NAMEresize2fs /dev/VG_NAME/LV_NAME 也可以使用 -l +100%free，可以划分剩下的全部的lv。 可以不用resize2fs，可以在命令后面加参数-r或--resizefs可以自动更新。 12345678910lvrextend -r -l +100%free /dev/VG_NAME/LV_NAME``` #### 1.2 `lvreduce`：减小lv用法：```bashlvreduce -L [-][mMgGtT] /dev/VG_NAME/LV_NAMEresize2fs /dev/VG_NAME/LV_NAME 可以不用resize2fs，可以在命令后面加参数-r或--resizefs可以自动更新。 123456789101112lvrextend -r -L -20G /dev/vg2/lv_test2``` #### 1.3 `lvresize`：修改lv大小用法：```bashlvresize [[+|-]大小 /dev/VGNAME/LVNAMEresize2fs /dev/VGNAME/LVNAME +为增加的意思，-为减少，省略掉即为直接设置大小。 resize2fs写入到内存，使硬盘信息和内存信息保持一致。 可以不用resize2fs，可以在命令后面加参数-r或--resizefs可以自动更新。 1234567891011# 先备份数据# 卸载逻辑卷umount /dev/vg2/lv_test3lvresize -L -5G /dev/vg2/lv_test3e2fsck -f /dev/vg2/lv_test3resize2fs /dev/vg2/lv_test3lvdisplay 2. vgextend、vgreduce2.1 vgextend：扩展vg12345pvcreate /dev/sdc3vgextend vg2 /dev/sdc3vgdisplay 2.2 vgreduce：缩减vg123vgreduce vg2 /dev/sdc3vgdisplay 3. lvrename、vgrename3.1 lvrename：修改lv名lvrename oldname newname 3.2 vgrename：修改vg名vgrename oldname newname 删除lv，vg，pv（删）lvremove、vgremove、pvremove12345lvremove /dev/vg2/lv_test2vgremove /dev/vg2pvremove /dev/sdb 图形界面操作感兴趣的同学可以试试。 运行命令system-config-lvm]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HPE x86服务器硬RAID做法]]></title>
    <url>%2Fserver%2F20170616-02-server-hard-raid%2F</url>
    <content type="text"><![CDATA[由于现在服务器普遍采用UEFI模式，这种模式更先进，支持的硬盘容量也更大（可以支持大于2TB的硬盘），所以老的Legency BIOS模式（不支持2TB以上硬盘）已经开始逐渐弃用。新的服务器基本默认全是UEFI模式，可以直接使用。 tips: UEFI模式下，默认用的GPT分区方法，所以在Linux下，不会只有3个主分区一个扩展主分区，而是最多支持128个主分区。 1) 开机启动，按F10进入硬件Intelligent Provisioning（简称IP） 2) 选择 HPE Smart Storage Administrator（HPE只能存储管理） 3) 进入下面界面后，点击左边的磁盘阵列卡（Smart Array Pxxx）,然后点配置(Congifure) 4) 如果是之前有阵列，如下图依次点击，Delete Array（删除阵列） 5) 然后重新Create Array（创建阵列） 6) 此处，选择Sort By Location(按位置排序），然后Select All(选择全部） 7) 磁盘RAID level，选择RAID 10(磁盘容量=n/2) 或者RAID 5（磁盘容量=n-1）。如果是生产环境，选择前者，测试环境可以选择后者。后面全部默认，然后点Create Logical Drive） tips: 关于RAID知识可以看这里 8) 创建完毕可以关闭界面 9) 重启]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>HPE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[磁盘阵列（RAID）]]></title>
    <url>%2Flinux%2F20170616-01-raid%2F</url>
    <content type="text"><![CDATA[独立硬盘冗余阵列（RAID, Redundant Array of Independent Disks），旧称廉价磁盘冗余阵列（Redundant Array of Inexpensive Disks），简称磁盘阵列。其基本思想就是把多个相对便宜的硬盘组合起来，成为一个硬盘阵列组，使性能达到甚至超过一个价格昂贵、容量巨大的硬盘。根据选择的版本不同，RAID比单颗硬盘有以下一个或多个方面的好处：增强数据集成度，增强容错功能，增加处理量或容量。另外，磁盘阵列对于电脑来说，看起来就像一个单独的硬盘或逻辑存储单元。——维基百科 目前常用的有： 标准RAID RAID 0 RAID 1 RAID 5 RAID 6 混合RAID RAID 10 RAID 50 RAID 60 RAID 0 RAID 0亦称为带区集。它将两个以上的磁盘并联起来，成为一个大容量的磁盘。在存放数据时，分段后分散存储在这些磁盘中，因为读写时都可以并行处理，所以在所有的级别中，RAID 0的速度是最快的。但是RAID 0既没有冗余功能，也不具备容错能力，如果一个磁盘（物理）损坏，所有数据都会丢失。 RAID 1 两组以上的N个磁盘相互作镜像，在一些多线程操作系统中能有很好的读取速度，理论上读取速度等于硬盘数量的倍数，与RAID 0相同。另外写入速度有微小的降低。只要一个磁盘正常即可维持运作，可靠性最高。其原理为在主硬盘上存放数据的同时也在镜像硬盘上写一样的数据。当主硬盘（物理）损坏时，镜像硬盘则代替主硬盘的工作。因为有镜像硬盘做数据备份，所以RAID 1的数据安全性在所有的RAID级别上来说是最好的。但无论用多少磁盘做RAID 1，仅算一个磁盘的容量，是所有RAID中磁盘利用率最低的一个级别。 如果用两个不同大小的磁盘建RAID 1，可用空间为较小的那个磁盘，较大的磁盘多出来的空间也可以分区成一个区来使用，不会造成浪费。 \begin{aligned}Size&amp;=\min \left(S{1},S{2},S_{3}\dots \right)\end{aligned} RAID 5 RAID Level 5是一种储存性能、数据安全和存储成本兼顾的存储解决方案。它使用的是Disk Striping（硬盘分区）技术。RAID 5至少需要三块硬盘，RAID 5不是对存储的数据进行备份，而是把数据和相对应的奇偶校验信息存储到组成RAID5的各个磁盘上，并且奇偶校验信息和相对应的数据分别存储于不同的磁盘上。当RAID5的一个磁盘数据发生损坏后，可以利用剩下的数据和相应的奇偶校验信息去恢复被损坏的数据。RAID 5可以理解为是RAID 0和RAID 1的折衷方案。RAID 5可以为系统提供数据安全保障，但保障程度要比镜像低而磁盘空间利用率要比镜像高。RAID 5具有和RAID 0相近似的数据读取速度，只是因为多了一个奇偶校验信息，写入数据的速度相对单独写入一块硬盘的速度略慢，若使用“回写缓存”可以让性能改善不少。同时由于多个数据对应一个奇偶校验信息，RAID 5的磁盘空间利用率要比RAID 1高，便宜。 \begin{aligned}Size&amp;=(N-1)\times \min \left(S{1},S{2},\dots ,S_{N}\right)\end{aligned} RAID 6与RAID 5相比，RAID 6增加第二个独立的奇偶校验信息块。两个独立的奇偶系统使用不同的算法，数据的可靠性非常高，任意两块磁盘同时失效时不会影响数据完整性。RAID 6需要分配给奇偶校验信息更大的磁盘空间和额外的校验计算，相对于RAID 5有更大的IO操作量和计算量，其“写性能”强烈取决于具体的实现方案，因此RAID6通常不会通过软件方式来实现，而更可能通过硬件/固件方式实现。 同一数组中最多容许两个磁盘损坏。更换新磁盘后，数据将会重新算出并写入新的磁盘中。依照设计理论，RAID 6必须具备四个以上的磁盘才能生效。 可使用的容量为硬盘总数减去2的差，乘以最小容量，公式为： \begin{aligned}Size&amp;=(N-2)\times \min \left(S{1},S{2},S{3},\dots ,S{N}\right)\end{aligned} 同理，数据保护区域容量则为最小容量乘以2。 RAID 6在硬件磁盘阵列卡的功能中，也是最常见的磁盘阵列档次。 RAID 10 RAID 10是先镜射再分区数据，再将所有硬盘分为两组，视为是RAID 0的最低组合，然后将这两组各自视为RAID 1运作。 当RAID 10有一个硬盘受损，其余硬盘会继续运作。 RAID 50 RAID 5与RAID 0的组合，先作RAID 5，再作RAID 0，也就是对多组RAID 5彼此构成Stripe访问。由于RAID 50是以RAID 5为基础，而RAID 5至少需要3颗硬盘，因此要以多组RAID 5构成RAID 50，至少需要6颗硬盘。以RAID 50最小的6颗硬盘配置为例，先把6颗硬盘分为2组，每组3颗构成RAID 5，如此就得到两组RAID 5，然后再把两组RAID 5构成RAID 0。 RAID 50在底层的任一组或多组RAID 5中出现1颗硬盘损坏时，仍能维持运作，不过如果任一组RAID 5中出现2颗或2颗以上硬盘损毁，整组RAID 50就会失效。 RAID 50由于在上层把多组RAID 5构成Stripe，性能比起单纯的RAID 5高，容量利用率比RAID5要低。比如同样使用9颗硬盘，由各3颗RAID 5再组成RAID 0的RAID 50，每组RAID 5浪费一颗硬盘，利用率为(1-3/9)，RAID 5则为(1-1/9)。 RAID 60 RAID 6与RAID 0的组合：先作RAID 6，再作RAID 0。换句话说，就是对两组以上的RAID 6作Stripe访问。RAID 6至少需具备4颗硬盘，所以RAID 60的最小需求是8颗硬盘。 由于底层是以RAID 6组成，所以RAID 60可以容许任一组RAID 6中损毁最多2颗硬盘，而系统仍能维持运作；不过只要底层任一组RAID 6中损毁3颗硬盘，整组RAID 60就会失效，当然这种情况的概率相当低。 比起单纯的RAID 6，RAID 60的上层通过结合多组RAID 6构成Stripe访问，因此性能较高。不过使用门槛高，而且容量利用率低是较大的问题。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[磁盘分区管理]]></title>
    <url>%2Flinux%2F20170614-disk-management%2F</url>
    <content type="text"><![CDATA[硬盘机制磁盘分区信息是放在硬盘上的，而不是操作系统里，存在整个硬盘的第0个扇区（sector）。 MBR机制：Master Boot Record（主引导记录）占用空间为512bytes： bootloader（一段程序，引导加载器的程序）加载指定操作系统的内核：446bytes fat：64bytes，每16个bytes存放一个分区信息，最多只有4个分区。 55 AA：MBR有效性标记，2bytes GPT机制：大于2T的磁盘机制GPT全称是GUID Partition Table，GUID指的是全球统一标识符（Globals Unique Identifiers）。 GPT分区需要硬件有UEFI接口。 硬盘接口类型 IDE（ATA）：并口，每个控制器可接两块硬盘，早期PC机用的比较多，现在已经淘汰。133MB/s SCSI（Small computer System Interface）：并口，可以接 N多块硬盘。转速高，寿命长，早期的服务器用的很多。320MB/s，目前面临淘汰。 SAS （Serial Attached SCS）：串行SCSI，可以与SATA兼容。600MB/s 现在的x86服务器上，主流就是SAS口，可以支持SATA口的硬盘，也可支持SAS口的硬盘。 SATA（Serial ATA）：串行ATA口。目前很多台式机的机械硬盘是此类接口。 SATA1：150MB/s SATA2：300MB/s SATA3：600MB/s mSATA（mini-SATA）：mini SATA口。好多笔记本的SSD用mini-SATA口，目前最新版是M.2 mSATA M.2(mini-SATA 2)：socket3类型最高支持4GB/s。 PCI-e（PCI-express）：台式机的SSD，还有部分笔记本（比如苹果Macbook），用的是PCI-e，此接口比mSATA要快，最高支持8GB/s USB（Universal Serial Bus）：u盘、移动硬盘。 USB2.0：60MB/s USB3.0：500MB/s USB3.1（也叫type-c）：1.2GB/s 查看分区（查）df查看磁盘状态df：disk free * `-h`：human readable，人类可读 * `-T`：print type，输出格式。 12345[root@yulongjun ~]# df -hTFilesystem Type Size Used Avail Use% Mounted on/dev/sda2 ext4 50G 5.2G 42G 11% /tmpfs tmpfs 3.9G 0 3.9G 0% /dev/shm/dev/sda1 ext4 190M 39M 142M 22% /boot fdisk -l 列出所有磁盘信息。Id： 83：Linux可以使用的文件系统。 8e：指的是逻辑卷（logical volume） 常见的几种文件格式：基本：ext3（CentOS 5默认）， ext4（CentOS 6默认），xfs（CentOS 7 默认）光盘：iso9660可移动U盘：fat32（文件最大不能超过4G）， exfatwindows：ntfs（linux可编译安装ntfs-3g来识别） 创建分区（增）fdisk /dev/sda进入管理sda磁盘 常用的几个： m：menu，列出帮助菜单d：delete，删除n：new，新建p：print，列出t：调整分区IDl：list，列出内核支持的分区ID83 Linux（linux基础分区）5 extend（扩展分区）8e LVM（逻辑卷管理）ee GPT（2T以上硬盘）w：write，保存退出q：quit，不保存退出 new新分区的时候，如果是加主分区，只能加到第四个。如果想要更多的分区，可以把第四个加为扩展分区。然后再在扩展分区上创建分区。 删除分区（删）1234567fdisk /dev/sdad #进入删除模式# 输入要删除的分区号w #保存退出 修改分区格式（改）1234567891011121314151617fdisk /dev/sdat # 进入修改模式# 输入要修改的分区L # 列出可以修改的格式# 输入要修改的格式的代码w # 保存退出# 然后用到上面让内核识别的两个命令：kpartx -af /dev/sda # 强制添加分区到内核中partx -a /dev/sda # 再添加一次# 上述命令多次都不成功，只能重启了 通知内核识别新分区CentOS 5，7：partprobe 1parprobe /dev/sda CentOS 6 ：partx，kpartx 123kpartx -l /dev/sda # 列出sda中可重新加载到内核的分区kpartx -af /dev/sda # 强制添加分区到内核中partx -a /dev/sda # 再添加一次 CentOS 6 有时候不管用，只能重启系统(目前版本6.9，这个bug还没有修复。)，不过对于新硬盘，进行创建操作的时候，CentOS6不会有这个问题。 CentOS 5 和 7 使用partprobe即可，无bug。 创建文件系统 mkfs -t FSTYPE /dev/DEVICE mkfs.FSTYPE /dev/DEVICE mkswap /dev/DEVICE 创建交换分区。 mke2fs更加精细的操作 -t：ext2, ext3, ext4, xfs -L：label，指定卷标名 -b：block size ，（1024、2048、4096）默认是4k（4096） -i #: 为数据空间中每多少个字节创建一个inode；此大 小不应该小于block的大小 -N #：指定分区中创建多少个inode -I # 一个inode记录占用的磁盘空间大小，128—4096 -m #: 默认5%,为管理人员预留空间占总空间的百分比 -O FEATURE[,...]：启用指定特性 -O ^FEATURE：关闭指定特性 -o: 调整文件系统的默认挂载选项，–o acl 12mkfs.ext2 -O has_journal /dev/sda5# 上面虽然指定的格式是ext2，但是启动journal特性，所以就变成了ext3了。 acl权限：xfs创建的默认就带acl权限，ext系列的格式的需要手工指定。 卷标的操作：e2label /dev/DEVICE：查看卷标。e2label /dev/DEVICE LABEL_NAME：修改卷标。 示例： 1234mkfs -t ext4 /dev/sda5mkfs.ext4 /dev/sda5mke2fs.ext4 -t ext4 -L DB /dev/sda5mkswap /dev/sda6 查看磁盘分区的类型和uuid在Linux里，设备名是有可能变动的，比如我们添加一块IDE的磁盘，会变成sda，系统原来的sda会变成sdb，这样，我们就不能用设备名来唯一表示设备，这时候我们就用到UUID。 blkid /dev/DEVICE UUID 设备唯一标识 TYPE 文件系统类型 123blkid /dev/sda5/dev/sda5 UUID="XXXXXXXX" TYPE="ext4" 检测和修复文件系统检测修复ext类型的文件系统fsck DEVICE ：file system check ,文件系统检测fsck -t ext4 /dev/sda5检测文件系统错误fsck -r DEVICE:交互式检测文件系统fsck -y DEVICE：不用交互，一路确认检测文件系统。 检测修复xfs类型的文件系统，要用另外一个命令：xfs_check -y DEVICE tips：xfs_check命令需要安装xfsprogs包 挂载挂载的本质就是调用blkid查看设备UUID，然后查找到设备，进行挂载。 (1)手动挂载挂载交换分区：swapon /dev/sda6启用指定的交换分区swapon -a启用所有的交换分区swapon -s 显示交换分区的挂载情况卸载交换分区：swapoff /dev/sda6关闭指定的交换分区swapoff -a 关闭所有的临时交换分区 挂载普通分区：mount [-t FILETYPE] [-o option] /dev/DEVICE DIRECTORY参数详解： 卸载普通分区：umount /dev/DEVICE 或者umount /DIRECTORY，具体参数情况，见文章最后一节：附2：mount命令详解 查看挂载信息：mount 示例：123456789mount -t ext4 /dev/sda5 /u01mount -t iso9660 -o loop xxx.iso /mediamountumount /dev/sda5unmount /media (2)永久挂载修改/etc/fstab配置文件。fstab：file system table 123456789101112131415161718[root❄CentOS6 ~]☭ cat /etc/fstab ## /etc/fstab# Created by anaconda on Wed May 17 01:52:09 2017## Accessible filesystems, by reference, are maintained under &apos;/dev/disk&apos;# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info#UUID=964e8f82-ef35-4b1e-ae3f-9a95e36b5ee2 / ext4 defaults 1 1UUID=899d5f64-7a0c-4aba-b77f-a94f9c6df085 /app ext4 defaults 1 2UUID=ce69275d-68f5-46c7-975b-785e653d3d79 /boot ext4 defaults 1 2UUID=3aa122ef-cf5f-4198-81a7-48b799c9d914 swap swap defaults 0 0tmpfs /dev/shm tmpfs defaults 0 0devpts /dev/pts devpts gid=5,mode=620 0 0sysfs /sys sysfs defaults 0 0proc /proc proc defaults 0 0/dev/sr0 /media iso9660 defaults 0 0 字段从左到右含义： 要挂载的设备： 设备文件/dev/sda、/dev/sr0 卷名LABEL=&quot;ladel&quot; UUIDUUID=xxx 挂载点：挂载在那个目录下面。有的文件系统没有挂载点 ，例如swap，挂载点为swap。 文件系统类型：ext2,3,4、xfs、iso9660 挂载选项：多个选项间使用逗号分隔 loop：loop设备 ro：只读（默认rw） pri=xxx：priority，优先级，默认都是-1，你可以写0~65535，数值越大，优先级越高。 转储频率：0：从不备份（CentOS7 采用xfs，默认从不备份）1：每日备份（6 采用ext4，默认是1）2：每隔一天备份（很少使用） 自检次序：1：首先自检，通常只能被/使用2-9：顺序0：从不自检（默认从不自检） /etc/fstab里写挂载的几个特殊例子： 123456#目录挂目录/boot /mnt/boot none bind 0 0# loop文件挂目录/app/partfile /mnt/part loop 0 0#windows共享挂目录//winsvr_url/share_file /mnt/win cifs 0 0 实验：将swap分区迁移到高速磁盘上，优化性能，原swap不删除，作为次swap。(提示：利用pritory优先级） 1# TODO 卸载 查看挂载情况:findmnt MOUNT_POINT 查看正在访问指定文件系统的进程：lsof MOUNT_POINT或fuser -v MOUNT_POINT 终止所有在正访问指定的文件系统的进程：fuser -km MOUNT_POINT 卸载：umount DEVICEumount MOUNT_POINT 附1：其他常用命令findmntfindmnt /DEVICE或者findmnt PATH查找某个设备是否挂载，或者某个路径是否为挂载点。 123[root❄centos7 ~]☭ findmnt /dev/sdb5[root❄centos7 ~]☭ echo $?1 查看/mnt/sdb5是否是挂载点，如果不是，就把/dev/sdb5挂载在/mnt/sdb5上。 1findmnt /mnt/sdb5 &gt;&gt; /dev/null || mount /dev/sdb5 /mnt/sdb5 findfsfindfs LABEL=xxxxxfindfs UUID=xxxxx 查找dir对应的uuid的挂载磁盘12[root❄centos7 ~]☭ dir=/;findfs `egrep &quot;$dir[[:space:]]+&quot; /etc/fstab | cut -d&quot; &quot; -f1`/dev/sda2 tips: 一个设备可以挂载到不同的挂载点。不同的设备，可以挂载到同一个挂载点，最后一个挂载的设备生效。 ##附2：mount命令详解 参数解析： device：指明要挂载的设备； 设备文件：例如/dev/sda5 卷标：-L &#39;LABEL&#39;, 例如 -L &#39;MYDATA&#39; UUID, -U &#39;UUID&#39;：例如 -U &#39;0c50523c-43f1-45e7-85c0-a126711d406e&#39; 伪文件系统名称：proc, sysfs, devtmpfs, configfs dir：挂载点 事先存在；建议使用空目录 进程正在使用中的设备无法被卸载 -t vsftype 指定要挂载的设备上的文件系统类型 -fnrsvw： -r: readonly，只读挂载 -w: read and write, 读写挂载 -n: 不更新/etc/mtab，mount不可见(可以用cat /proc/mounts看到挂载） -a：自动挂载所有支持自动挂载的设备(定义在了/etc/fstab 文件中，且挂载选项中有auto功能) -L &#39;LABEL&#39;: 以卷标指定挂载设备 -U &#39;UUID&#39;: 以UUID指定要挂载的设备 -B, --bind: 绑定目录到另一个目录上 12mount -B /var/ftp/pub /var/www/html/# 这样可以实现同一份数据，在两个地方。 查看内核追踪到的已挂载的所有设备：cat /proc/mounts -o options：(挂载文件系统的选项)，多个选项使用逗号分隔 async：异步模式 sync：同步模式,内存更改时，同时写磁盘 atime/noatime：包含目录和文件的访问时间戳 diratime/nodiratime：目录的访问时间戳 auto/noauto：是否支持自动挂载,是否支持-a选项 exec/noexec：是否支持将文件系统上运行应用程序 dev/nodev：是否支持在此文件系统上使用设备文件 suid/nosuid：是否支持suid和sgid权限 remount：重新挂载 ro：只读 rw：读写 user/nouser：是否允许普通用户挂载此设备，默认管理员才能挂载 acl：启用此文件系统上的acl功能 Defaults：相当于rw, nosuid, dev, exec, auto, nouser, async 附3：loop特殊设备CentOS 6 默认只支持8个loop设备，7没有限制(每增加一个，control会去生成一个）: 123[root❄CentOS6 ~]☭ ls /dev/loop*/dev/loop0 /dev/loop2 /dev/loop4 /dev/loop6/dev/loop1 /dev/loop3 /dev/loop5 /dev/loop7 12[root❄centos7 ~]☭ ll /dev/loop*crw-rw---- 1 root disk 10, 237 Jun 14 10:17 /dev/loop-control 要想让6支持更多，要更改内核参数,kernel那一行，最后面加上max_loop=数量参数 123...kernel /vmlinuz-2.6.32-696.el6.x86_64 ro root=UUID=964e8f82-ef35-4b1e-ae3f-9a95e36b5ee2 rd_NO_LUKS rd_NO_LVM LANG=en_US.UTF-8 rd_NO_MD SYSFONT=latarcyrheb-sun16 crashkernel=auto KEYBOARDTYPE=pc KEYTABLE=us rd_NO_DM rhgb quiet max_loop=100... losetup命令 指定loop号挂载，可以不用按顺序挂载 losetup -a ：显示系统挂载的loop设备(CentOS 7 不用加-a)losetup LOOP-DEVICE LOOP-FILE：关联loop文件到指定的loop设备上 12losetup /dev/loop9 /app/partfile9 #关联loop文件到指定的/dev/loop设备上mount /dev/loop9 /mnt/part9 # 把关联的设备挂载到目录上 挂载Windows共享文件： 123mkdir /mnt/winmount -o username=test,password=magedu //192.168.8.1/winshare /mnt/win]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[01-macOS磁盘管理工具]]></title>
    <url>%2Fmacos%2F20170614-apple-hfs%2F</url>
    <content type="text"><![CDATA[自带磁盘工具 macOS格式化磁盘的选项： 格式： 格式 英文 中文 HFS+ Mac OS Extended (Journaled) MacOS 扩展（日志式） HFSX MAC OS Extended (Case-sensitive, Journaled) MacOS 扩展（区分大小写，日志式） exFAT exFAT exFAT FAT32 MS-DOS(FAT) MS-DOS(FAT) 方案： GUID分区图（GPT）：使用启动基于Intel的MAC，或将磁盘当做非启动盘用于任何装有MAC OS X V10.4 或更高版本的MAC 主引导记录（MBR）：使用该磁盘启动DOS和Windows电脑，或者将磁盘配合需要DOS兼容分区或Windows兼容分区的设备来使用。 Apple分区图（APM）：使用该磁盘启动基于PowerPC的MAC 电脑，或将该磁盘当做非启动盘用于任何MAC电脑 小技巧：在我们格式化一个新的移动硬盘的时候，为了兼容macOS和Windows，通常会使用下面的方式：格式选择exFAT，方案选择主引导记录。 dd命令dd命令，通常在我们做iso镜像的启动盘、安装盘的时候使用。 具体教程可以看我之前写的一个文章：http://bbs.feng.com/read-htm-tid-9131601.html CentOS、RHEL、Fodera、Ubuntu都支持这种模式的制作方式，其他的暂未测试过。]]></content>
      <categories>
        <category>macos</category>
      </categories>
      <tags>
        <tag>macOS</tag>
        <tag>GUID</tag>
        <tag>MBR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[04-编译安装]]></title>
    <url>%2Flinux%2F20170609-04-make-install%2F</url>
    <content type="text"><![CDATA[编译安装，是指从源码进行编译，然后根据安装规则把编译好的文件，分发到预先设置好的目录，目录可以自定义。 我们以在 CentOS 7 上安装apache2.4为例： 在apache官网下载源码,解压。 yum groups install Development Tools安装开发包。 cd httpd-2.4 查看一下 README INSTALL ./configure --prefix=/app/appche24按照配置生成配置文件。 如果报错，查看下报错提示缺什么包，把缺失的包装上，一般新版本的选xxx-devel包就可以支持。 make编译 make install复制到规定的目录 1234567891011121314mkdir /app/apache24tar -xvf httpd-2.4.25.tar.bz2cd httpd-2.4.25yum groups install "Development Tools"./configure --prefix=/app/apache24 --sysconfdir=/etc/apache24 --enable-rewriteyum install apr-devel./configure --prefix=/app/apache24 --sysconfdir=/etc/apache24 --enable-rewriteyum install apr-util-devel./configure --prefix=/app/apache24 --sysconfdir=/etc/apache24 --enable-rewriteyum install pcre-devel./configure --prefix=/app/apache24 --sysconfdir=/etc/apache24 --enable-rewritemakemake install 把bin目录加到PATH里： vim /etc/profile.d/apache24.sh 1PATH=$PATH:/app/apache24/bin]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>make install</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[03-打包压缩命令tar、zip、split]]></title>
    <url>%2Flinux%2F20170609-03-extract-compress%2F</url>
    <content type="text"><![CDATA[tar(gz、bz2、xz) zip split 1. tartar的意思是Together ARchive（打包归档）。我们可以用来打包，也可以用来解压包，而且还支持打包后用各种格式压缩（gz、bz2、xz等）。 单个参数意义：f: 归档filev: verbose（注：详细），显示压缩过程的详细信息t: list,显示归档的内容x: extract,解压c: compress,压缩z: gzip格式压缩，后缀为.gzj: bzip2格式压缩，后缀为.bz2J: xz格式压缩，后缀为.xz 常用组合： 组合参数 意义 压缩文件后缀 cvf 原始tar包，不压缩 .tar zcvf 先tar，后gzip压缩 tar.gz 、tgz jcvf 先tar，后bzip2压缩 tar.bz2 、tbz2 Jcvf 先tar，后xz压缩 tar.xz、txz xvf 解压所有格式，通用解压命令 - tips: 在编写shell脚本打包的时候，我们通常不会用v选项，这样屏幕输出会比较乱，我们一般用echo在打包前后提示一下打包开始和打包完成，就ok了。举个我之前写的脚本例子： 1234567#!/bin/bashecho &quot;==&gt;开始打包文件夹...&quot;tar -czf Blog`date +%Y%m%d`.tar.gz Blogecho &quot;==&gt;打包成Blog`date +%Y%m%d`.tar.gz完毕.&quot;echo &quot;==&gt;移动打包文件到/Volumes/Transcend/Backup/Blog/...&quot;mv -f Blog`date +%Y%m%d`.tar.gz /Volumes/Transcend/Backup/Blog/echo &quot;==&gt;移动完毕.&quot; 执行效果就是这样： 12345LongDream❄MBP:Scripts]☭ ./backup_blog.sh==&gt;开始打包文件夹...==&gt;打包成Blog20170607.tar.gz完毕.==&gt;移动打包文件到/Volumes/Transcend/Backup/Blog/...==&gt;移动完毕. 2. zip&amp;unzip打包并压缩：zip -r xxx.zip xxx解压缩解包：unzip xxx.zip 举个解压oracle安装包的例子： 1unzip p13390677_112040_platform_1of7.zip &amp;&amp; unzip p13390677_112040_platform_2of7.zip &amp;&amp; unzip p13390677_112040_platform_4of7.zip splitsplit：切割打包。 默认包分割后的名字后缀是aa, ab, ac, ... -b SIZE 指定每个分割包的大小 -d DIGIT 每个分割包名后缀按数字命名：01, 02, ... 例子1（不加-d）: 12345678910[root❄centos7 bin]☭ ll -h bin.tar.gz -rw-r--r--. 1 root root 54M Jun 7 20:41 bin.tar.gz[root❄centos7 bin]☭ split -b 10M bin.tar.gz bin_[root❄centos7 bin]☭ ll -h bin_*-rw-r--r--. 1 root root 10M Jun 7 20:44 bin_aa-rw-r--r--. 1 root root 10M Jun 7 20:44 bin_ab-rw-r--r--. 1 root root 10M Jun 7 20:44 bin_ac-rw-r--r--. 1 root root 10M Jun 7 20:44 bin_ad-rw-r--r--. 1 root root 10M Jun 7 20:44 bin_ae-rw-r--r--. 1 root root 3.8M Jun 7 20:44 bin_af 例子2（加-b）: 1234567891011[root❄centos7 bin]☭ ll -h bin.tar.gz-rw-r--r--. 1 root root 54M Jun 7 20:41 bin.tar.gz[root❄centos7 bin]☭ split -b 10M -d bin.tar.gz bin_[root❄centos7 bin]☭ ll -h bin_[0-9]?-rw-r--r--. 1 root root 10M Jun 7 20:47 bin_00-rw-r--r--. 1 root root 10M Jun 7 20:47 bin_01-rw-r--r--. 1 root root 10M Jun 7 20:47 bin_02-rw-r--r--. 1 root root 10M Jun 7 20:47 bin_03-rw-r--r--. 1 root root 10M Jun 7 20:47 bin_04-rw-r--r--. 1 root root 3.8M Jun 7 20:47 bin_05 合并切割的包 例子：cat mybackup-parts* &gt; mybackup.tar.gz]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>tar</tag>
        <tag>zip</tag>
        <tag>split</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[02-程序包管理工具yum]]></title>
    <url>%2Flinux%2F20170609-02-yum%2F</url>
    <content type="text"><![CDATA[yum首先要有一个网络上或本地或远程的yum仓库。然后需要yum安装程序的机器去yum仓库下载yum元数据（包括包信息和依赖信息）到本地的cache里。当需要安装程序的时候，会查看yum源数据里是否有此包，并且查找此包的依赖信息，然后去yum仓库里面下载包和依赖包到本地cache里，并且进行安装。 校验码：远程仓库数据有可能发生改变，这样本地的信息就和仓库信息不符。这样根据校验码，来确定文件是否更改，这样可以节省网络带宽。（对于我们来说，yum一般配置本地仓库，yum源来自操作系统的iso镜像，一般不去校验） yum仓库(yum repository)yum的意思是Yellowdog Update Modifier yum repository存放了众多的rpm包，以及包的相关元数据文件（元数据存放于特定目录下：repodata）CentOS和Redhat安装操作系统的时候，anaconda也会去调用yum来安装（不过是调用的本地的光盘上的yum repository） tips: 无论任何仓库，repodata目录的父目录就是yum源的目录。比如CentOS 5是在光盘/Server/下,6和7在光盘/下。 网络文件服务器：CentOS已经配置好，联网可以直接使用（redhat不可使用，需要购买服务），是网络上的的文件服务器。 本地文件服务器： file://配置本地文件 ftp://配置本地ftp服务器 http://、https://配置本地http服务器 yum的配置文件： /etc/yum.confyum的公共配置文件 /etc/yum.repos.d/*.repo具体的每个仓库的配置，分开文件是为了方便管理和配置。 /etc/yum.conf 常用配置项： 123456789101112[main] #yum仓库idcachedir=/var/cache/yum/$basearch/$releasever #缓存和数据库文件，baseserach指的架构，如`x86_64`，releaserver指的是版本，如`6`或`7`keepcache=0 #缓存源文件和安装成功后的下载包是否保存debuglevel=2 #debug级别logfile=/var/log/yum.log #日志文件位置exactarch=1 #精确平台匹配obsoletes=1gpgcheck=1 #来源完整性和包完整性检查plugins=1 # 支不支持插件机制installonly_limit=5 # 允许同时安装几个程序包bugtracker_url=http://bugs.centos.org/set_project.php?project_id=19&amp;ref=http://bugs.centos.org/bug_report_page.php?category=yum #bug报告distroverpkg=centos-release #ditribution version pkg 发行版版本号获取 /etc/yum.repos.d/*.repo 常用配置项： 123456[repositoryid] # 仓库哦idname=Some name for this repository # 仓库名字baseurl=url://path/to/repository/ # 仓库地址enable=&#123;1|0&#125; # 是否可用gpgcheck=&#123;0|1&#125; # 是否检查gpggpgkey=URL # 如果检查，写gpgkey地址 yum安装日志：/var/log/yum.log 配置实战：yum仓库配置实战1-本地仓库： 挂载iso镜像到media目录 mount -t iso9660 -o loop /var/ftp/pub/CentOS-6.8-x86_64-bin-DVD1.iso /media 配置/etc/yum.repos.d/local.repo [local]name=Repo on Local Cdrom Mediabaseurl=file:///mediagpgcheck=0enable=1 创建缓存看是否成功 yum makecache yum仓库配置实战2-ftp仓库： 创建之前先删除之前的cache：rm -rf /var/cache/yum 配置/etc/yum.repos.d/ftp.repo [ftp]name=Repo on 172.17.0.1baseurl=ftp://172.17.0.1/pub/CentOS6u9gpgcheck=0enable=1 创建缓存看是否成功 yum makecache yum用法： yum makecache：创建yum缓存 yum repolist显示启用的仓库列表 yum grouplist显示包组 yum list显示所有可用包 yum list vsftpd*显示和vsftpd*匹配的包 yum list installed显示已安装的包 yum install package1 [package2] [...]可以安装一个或多个包 -y参数，即yes，表示不用交互询问，直接安装。 yum reinstall package1 [package2] [...] 可以重新安装一个或多个包 yum update [package1] [package2]不跟包名的话，是更新所有包，带包名的是更新具体的包 yum check-update检查可用升级 yum remove|erase package1 [package2]卸载程序包 yum info查看程序包信息 yum provides COMMAND1 [COMMANDN]COMMAND命令是由哪个包提供的。 yum search xxx模糊搜索程序包 yum clean all清除所有缓存(如果还清不了，可以手动删除rm -rf /var/cache/yum) 非常常用的几个个命令：yum clean allyum makecacheyum -y install xxx yyy zzzyum remove 自制第三方yum源createrepo /rpmdir会在目录下面生成一个repodata文件夹，存放了包的元数据。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>yum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[01-程序包管理工具rpm]]></title>
    <url>%2Flinux%2F20170609-01-rpm%2F</url>
    <content type="text"><![CDATA[rpm就是一个程序的打包工具。在安装软件的时候，可以把不同的目录拷贝到相应的目录下（如二进制文件，配置文件等等。） RedHat里全名叫Redhat Package Management SuSe为了避免冲突，就叫RPM Package Management（类似于GNU，GNU is not a unix） rpm包格式： 程序报名-版本号-打包号.操作系统号.架构.rpm如：vsftpd-3.0.2-21.el7.x86_64.rpm 插入小练习，查看rpm包架构： 123456789# 第一种方法ls *.rpm |rev|cut -d. -f2|rev|sort | uniq -c 1337 noarch 2494 x86_64 # 第二种方法ls *rpm |egrep -o &quot;[^.]+\.rpm&quot; | cut -d. -f1 |sort |uniq -c 1337 noarch 2494 x86_64 包里面内容： path/files 要安装的文件和相对路径 metadata 元数据 scripts 脚本(安装前脚本、安装后脚本、卸载前脚本、卸载后脚本） 包安装信息数据库：/var/lib/rpm * 程序包名称及版本 * 依赖关系 * 功能说明 * 包安装后生成的各文件路径及校验码信息 程序包的来源1. 系统发版的光盘或官方的服务器；CentOS官网：https://www.centos.org/download/阿里云：http://mirrors.aliyun.com网易：http://mirrors.163.com清华：https://mirror.tuna.tsinghua.edu.cn/中科大：http://mirrors.ustc.edu.cn/浙大：http://mirrors.zju.edu.cn/ 2. 项目官方站点举几个例子： https://grafana.com/grafana/download https://portal.influxdata.com/downloads#influxdb 3. 第三方组织Fedora-EPEL： Extra Packages for Enterprise Linux 基本上镜像站都提供epel源。 4. 搜索引擎：http://pkgs.org http://rpmfind.net http://rpm.pbone.net https://sourceforge.net/ 5. 自己制作注意：第三方包建议要检查其合法性 来源合法性 程序包的完整性 rpm命令安装卸载-i：install ,安装-v：verbose,显示详情-h：显示进度条-e：erase，删除（卸载）-U upgrade，升级--force强制安装（不能用于强制卸载）--test： 测试安装，不真正执行安装。--nodeps：忽略依赖性（一般不忽略）--oldpackage 降级安装（一般不降级） 内核安装默认是不覆盖安装的，装了多个kernel，可以修改grub.conf修改默认启动内核顺序。可以rpm -e卸载旧的kernel 查询rpm -q PackageName查询某个包rpm -qa 查询已安装的所有包rpm -qa |grep xxx 模糊过滤rpm -qf FILE 硬盘上的文件(file)是来自于哪个rpm包（可以是二进制程序，也可以是配置文件等）rpm -qi xxx.rpm 查询安装包详细信息（information）rpm -ql xxx.rpm 查看某个包安装后在系统里的所有文件rpm -qc xxx 查询安装包后的配置（config）文件位置rpm -q --scripts查询程序自带的脚本 rpm校验rpm --import xxx/yyy/RPM-GPG-KEY-CentOS-7：导入包完整性校验文件rpm -K xxxxx.rpm校验某个包 查找安装gpg-pubkeyrpm -qa &quot;gpg-*&quot; 1234567[root❄centos7 Packages]☭ rpm --import /media/RPM-GPG-KEY-CentOS-7 [root❄centos7 Packages]☭ rpm -K tree-1.6.0-10.el7.x86_64.rpm [root❄centos7 Packages]☭ rpm -qa &quot;gpg-*&quot;gpg-pubkey-f4a80eb5-53a7ff4b[root❄centos7 Packages]☭ rpm -e gpg-pubkey [root❄centos7 Packages]☭ rpm -K tree-1.6.0-10.el7.x86_64.rpm tree-1.6.0-10.el7.x86_64.rpm: RSA sha1 ((MD5) PGP) md5 NOT OK (MISSING KEYS: (MD5) PGP#f4a80eb5)]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>rpm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[01-误删系统重要文件，无法启动，如何恢复（以删除库文件为例）]]></title>
    <url>%2Flinux%2F20170609-01-rescure%2F</url>
    <content type="text"><![CDATA[模拟误删（删除库文件）ldd 命令 ldd 查看命令依赖的库文件: 我们可以看到好多命令都依赖libc.so.6文件，我们就删除这个。 123456789[root❄centos6 ~]☭ ldd /bin/ls...libc.so.6 =&gt; /lib64/libc.so.6 (0x00007f7b1d9c0000)...[root❄centos6 bin]☭ ldd /bin/rm...libc.so.6 =&gt; /lib64/libc.so.6 (0x00007f169c741000)...[root❄centos6 bin]☭ rm -rf /lib64/libc.so.6 删除之后，系统都无法重启，只能硬关机。 如何恢复系统用安装光盘或安装u盘启动系统，选择Rescure installed system进入救援模式。 选择no 我们可以看到提示，Linux系统会尝试挂载在/mnt/sysimage目录下，我们点继续。 提示你系统已经挂载到/mnt/sysimage 启动一个shell df查看一下挂载情况，我们可以看到系统原来的根，挂载在了/mnt/sysimage下面。 我们从当前运行环境中的lib64的文件里，复制一份，把原来删掉的文件，给恢复回来： 重启恢复。 CentOS 7和6差不多，就是光盘启动后，选择的是TroubleShooting–&gt;Rescure]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>rescure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[macOS重装后初始设置(运维和开发人员自用版，可参考）]]></title>
    <url>%2Fmacos%2F20170608-macos-init-config%2F</url>
    <content type="text"><![CDATA[macOS作为类unix的系统，很多命令和功能和Linux等兼容度非常高，又支持很多国外流行软件、国内桌面软件（QQ、百度网盘、迅雷之类的），经常作为Linux运维人员和开发人员的首选系统。下面列出一些常用的软件和设置。 1. 软件1.1 安装app store里的一些常用应用App Store里搜索下载： Xcode（必装，后续有其他软件调用Xcode的组件） Numbers（mac下的表格软件） Pages（mac下的文件处理软件） Keynote（mac下的演示软件） 印象笔记 qq 微信 yy 钉钉 网易云音乐 Dr.Unarchive最好用的解压缩软件 1.2 打开允许来自“任何来源”的app的使用终端下运行下面命令： 1sudo spctl --master-disable 1.3 安装非app store 里的应用（可点击名字去下载页面） 搜狗拼音 搜狗五笔 迅雷 百度云 腾讯微云 RealVNC：vnc工具 Teamviewer：远程桌面连接工具 Visual Studio Code：微软出的最好用的轻量级编辑器（比Atom、Sublime Text都好用） Shadowsocks-NG：科学上网软件，要自行购买vps，安装配置见博文用搬瓦工和Shadowsocks搭梯子 Lantern：免费科学上网软件，不是很稳定。 Google Chrome：翻墙后可以直接下载，然后还可以在Chrome应用商店搜索下载下面的插件： Adblock Plus：屏蔽网页广告 印象笔记·剪藏：剪藏网页到印象笔记 Markdown Here：在邮件里写markdown直接转换为html格式，也可用在支持html裸格式的博客之类的。 Firefox Developer Edition：前段开发者最爱，同时支持不翻墙同步账号密码和标签。 1.4 收费软件 不鼓励破解和用网上序列号注册。如果前期学习的话，可以试用。如果后面长期用，还是付费的好。当然，笔者比较穷，都是在这个网站找资源： 爱情守望者 Office 2016 for mac 微软的优秀Office套件 CleanMyMac 3：Mac清理优化软件 Hands Off!：优秀的防火墙软件，可以针对具体软件来防，比如防止某些软件连接激活服务器（比如禁止Adobe全系列的网络连接） 禁止网络，只要Deny掉就可以了。 Adobe Photoshop/Illutrator/Acrobat/Dreamveaver：推荐用Adobe Creative Cloud安装全系列，然后见科学教程。 Idea/PyCharm/WebStorm：商业化的IDE软件，开发人员必备。官网下载，然后在这里找科学码。 Mweb：mac下最好用的Markdown编辑软件。支持同步到印象笔记、为知笔记；发布到WordPress博客；同时针对Hexo，Jekyll等静态博客做了优化；支持导出html、pdf、docx、rtf、图片格式。 笔者博客用的hexo，Mweb针对hexo的预览做了优化（采用外部模式方法），所以相当好用，以前markdown插入图片的预览是个问题，这个外部模式解决了我的痛点） Navicat Premium数据库工具，这个不用说了吧，搞数据库开发的好多都用这个软件，支持主流的数据库软件：MySQL、Oracle、PostgreSQL、SQLite、SQL Server、MariaDB。 iStat Menus：状态栏软件。可显示CPU、内存、电池、网络、日历、温度等。 状态栏效果： 下拉效果： Monodraw：强大的ASCII艺术编辑器，用来在脚本里画图用（虽然没什么卵用……但好看啊……） 我也写了个脚本，可以自动生成（当然是根据从Monodraw画出来的格式来编写啦） 官网的图： iThoughtX：比Xmind强大的脑图软件，支持markdown（最爱md）。 OmniGraffle：流程图软件，被誉为 Mac 上的 Visio，主要用于绘制流程图、图表、组织结构图、UI界面设计等等，支持 Visio 导入/导出。 VMware Fusion：等同于Windows和Linux下的VMware Workstation Pro 1.5 安装brew macOS没有类似apt-get、yum、dnf这种软件包管理器，Homebrew这个第三方的软件包管理器非常好用。 终端下运行： 1/usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot; tips：Node.js、Python3、nmap、bash-completion等都可以用brew来安装。 2. CLI设置2.1 终端设置 更改计算机名字为MBP，改短点，这样‘终端’显示效果比较好。偏好设置–&gt;共享： 或者可选择自定义终端显示，vim ~/.bash_profile（没有则创建）： 123# PS1export PS1="[\[\033[01;32m\]\u❄h\[\033[00m\]:\[\033[01;34m\]\W\[\033[00m\]]☭ " 显示效果： 使ls命令显示文件文件夹颜色，同时设置ll别名。 vim ~/.bash_profile（没有则创建） 12345# LS_COLORexport LS_OPTIONS='--color=auto' # 如果没有指定，则自动选择颜色export CLICOLOR='Yes' #是否输出颜色# aliasalias ll="ls -l" 2.2 vim设置vim ~/.vimrc，设置vim参数（没有则创建）： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657&quot; Configuration file for vimset modelines=0 &quot; CVE-2007-2438&quot; Normally we use vim-extensions. If you want true vi-compatibility&quot; remove change the following statementsset nocompatible &quot; Use Vim defaults instead of 100% vi compatibilityset backspace=2 &quot; more powerful backspacing&quot; Don&apos;t write backup file if vim is being called by &quot;crontab -e&quot;au BufWrite /private/tmp/crontab.* set nowritebackup nobackup&quot; Don&apos;t write backup file if vim is being called by &quot;chpass&quot;au BufWrite /private/etc/pw.* set nowritebackup nobackupsyntax on&quot; 语法高亮set hlsearch&quot; 高亮搜索set incsearch&quot; 搜索逐字符高亮set ai&quot; 自动缩进set showmatch&quot; 括号成对匹配set matchtime=5&quot; 对应括号高亮的时间（单位为十分之一秒）set autoread&quot; 设置当文件被外部编辑器改动时候自动载入autocmd InsertLeave * se noculautocmd InsertEnter * se cul&quot; 用浅色高亮当前行set tabstop=4set expandtabset autoindent&quot; Tab键设置为4个空格set softtabstop=4set shiftwidth=4&quot; 统一缩进为4set number&quot; 显示行号colorscheme default &quot; 设置颜色主题,default,elflord,morning,peachpuff,slate,blue,delek,evening,murphy,ron,torte,darkblue,desert,koehler,pablo,shine,zellnerset ruler&quot; 在编辑过程中，在右下角显示光标位置的状态行 3 偏好设置3.1 通用只勾选了使用暗色菜单栏和Dock（根据个人喜好），默认浏览器给切换到Chrome（根据个人喜好），打开了handoff，关于handoff见官网解释。 3.2 安全与隐私关闭所有软件的定位（除了系统服务的不关）： 关闭所有访问通讯录的软件： 3.3 iCloud去掉照片和邮件的同步，iCloud Drive里只保留偏好设置的同步 3.4 互联网账户只保留iCloud，其它Game Center,微博之类的都删掉 3.5 App Store去掉自动下载在其他Mac上购买的应用，购买项目由始终需要改为15分钟后需要。免费下载改始终需要为存储密码。 3.6 用户与群组关闭客人用户。 3.7 日期与时间去掉勾选在菜单栏中显示日期和时间(前面软件iStat Menus已经显示了）]]></content>
      <categories>
        <category>macos</category>
      </categories>
      <tags>
        <tag>macOS</tag>
        <tag>Serria</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第一阶段测试题]]></title>
    <url>%2Flinux%2F20170608-exam%2F</url>
    <content type="text"><![CDATA[第1题题目： yum源的配置与使用1)创建一个本地yum源base源指向https://mirrors.aliyun.com/centos/7/os/x86_64/epel源指向https://mirrors.aliyun.com/epel/7Server/x86_64/2) 安装开发包组 解答： 123456789101112131415161718192021222324252627282930#!/bin/env bash# Filename: config_yum.sh# Author: Yu Longjun# 移动原repo文件到backup目录下yumdir=/etc/yum.repos.d/mkdir $yumdir/bakcupmv $yumdir/*.repo $yumdir/backup# 挂载光盘umount /dev/sr0 &gt; /dev/nullmount /dev/sr0 /media &amp;&gt;/dev/null# 增加base.repo文件cat &gt;base.repo &lt;&lt;EOF[base]name=centos7-basebaseurl=https://mirrors.aliyun.com/centos/7/os/x86_64/gpgcheck=0[epel]name=centos7-epelbaseurl=https://mirrors.aliyun.com/epel/7Server/x86_64/gpgcheck=0EOF# yum元数据缓存，安装"Devlopment Tools"包组yum makecache &gt;/dev/nullyum groups install "Development Tools" &gt;/dev/null 第2题题目： 复制/etc/ssh/sshd_config 到/tmp/中并更名为sshd_config.bak。将/tmp/sshd_config.bak文件中所有以非#号开头与包含空白字符的行保存至/tmp/sshd_config中。 解答： 123cp /etc/ssh/sshd_config /tmp/sshd_config.bakcat /tmp/sshd_config.bak |grep &quot;^[^#]&quot;|grep &quot;^[^[:space:]*$]&quot; 第3题题目： 编写脚本/root/bin/sysinfo.sh显示当前主机系统信息，包括主机名，操作系统版本，内核版本,CPU型号，内存大小，硬盘分区。 解答： 12345678910#!/bin/env bash# Filename: sysinfo.sh# Author: Yu Longjunecho "主机名 ： $HOSTNAME"echo "系统版本： `cat /etc/centos-release`"echo "内核版本： `uname -r`"echo "CPU型号 ：`cat /proc/cpuinfo | grep "model name"|cut -d: -f2|head -1`"echo "内存大小： `free -m |grep Mem|tr -s " "|cut -d" " -f2` MB"echo -e "硬盘分区：\n`df -hT |egrep -o "^/dev/sd.*\&gt;"|tr -s " " | cut -d" " -f1,3|sort`" 第4题题目： 给root用户定义别名命令vimnet，相当于vim /etc/sysconfig/network-scripts/ifcfg-ens33，并使root执行history命令时，显示每个命令执行的具体时间。 解答： 用root用户执行下面ch_bashrc.sh脚本： 123456789101112#!/bin/env bash# Filename: ch_bashrc.sh# Author: Yu Longjuncat &gt;&gt;~/.bashrc &lt;&lt;EOF# shortnamealias vimnet="vim /etc/sysconfig/network-scripts/ifcfg-ens33"# history with timestampexport HISTTIMEFORMAT="%F %T "EOF 第5题题目： 指出软链接与硬链接的异同之处(至少四处) 解答： 软链接就相当于Windows的快捷方式，删掉源文件，快捷方式和就失效了，软链接就找不到源文件了。 硬链接相当于多个链接指向同一份数据存储区域，每多一个硬链接，硬链接数+1，如果一个文件，有n个硬链接，删除n-1个硬链接，源文件还在，直到删除所有硬链接，才会删除源文件。 1. 复制（cp） 在复制过程中，复制软连接相当于复制了快捷方式，速度很快，而且可以跨分区。 在复制过程中，复制硬链接分为两种情形： 在同一分区复制，相当于多创建一个链接指向原数据存储位置，速度很快。 在不同分区复制，相当于把原来分区的数据拷贝过去存储，同时创建一个指向新数据区域的指针，速度比较慢。 2. 删除（rm）在删除过程中，删除软连接相当于删除了快捷方式，源文件还在。在删除过程中，删除硬连接相当于删除了一个到数据块的指针，，除非删除所有硬链接文件，源文件才删除。 3. 移动（mv）在移动过程中，移动软连接相当于移动了快捷方式而已。在移动过程中，移动硬连接分为两种情形： 在同一分区移动，相当于创建了一个新inode，指向数据块，并把原来的inode删掉 在不同分区移动，要把数据块复制到新分区，然后在新分区创建新的inode号指向新的数据块，并且把原来分区的inode号和数据块都删掉。 4. 软连接支持对目录创建，硬链接不支持 ln dir1 dir2不成功 ln /etc/sysconfig/network-scripts/ifcfg-ens33 /etc/ens33成功 第6题题目： 下载编译安装httpd 2.4最新版本，写出安装过程。 解答： 见博文04-编译安装 第7题题目： 过滤ifconfig命令结果中所有大于0且小于255的三位数 解答： 1ifconfig | egrep -o &quot;\&lt;((1[0-9]&#123;2&#125;|2[0-4][0-9]|25[0-4]))&quot; 第8题题目： 将用户mage被误删除的的家目录恢复，复制/etc/shadow到mage家目录中。并设置只有用户wang可以读取/home/mage/shadow。 解答： 1234567891011121314# root用户执行下面命令mkdir /home/magechown mage:mage /home/mage# ll -d /home/wang 查看到wang家目录的权限为700chmod 700 /home/mage# 切换到mage用户su - magecp /etc/skel/\.* .cp -r /etc/skel/.mozilla/ .# root用户执行下面命令cp /etc/shadow /magesetfacl -m u:wang:r shadow 第9题题目： 统计/var/log/httpd/access.log日志访问频繁前十的地址，并从大到小排序。 解答： 1cat access.log |cut -d" " -f1 |sort |uniq -c |sort -nr|head -n10 第10题题目： 开启两个终端，将终端1 中输入命令的执行结果输出，并同时输出到终端2 。 解答： COMMAND为终端1输入的命令： 1COMMAND | tee &gt;/dev/pts/1 第11题题目： 误删除/lib64/libc.so.6系统库文件，如何恢复之，实验说明。 解答： 见博文01-误删系统重要文件，无法启动，如何恢复（以删除库文件为例） 第12题题目： 误删除rpm包命令，如何恢复之，实验说明。 解答： 前5步同11题前5步。 后面的步骤： 123cd /mnt/sysimage/media/Packagesrpm -ivh rpm-4.11.3-21.el7.x86_64.rpm 重启进入系统，rpm可以使用了。 第13题题目： 计算2+4+6+…+96+98+100之和。 解答： 1echo &#123;2..100..2&#125;|tr &quot; &quot; &quot;+&quot;|bc 第14题题目： 取/etc/sysconfig/network-scripts/ifcfg-ens33基名，用两种方法实现。 解答： 12345# 第一种：basename /etc/sysconfig/network-scripts/ifcfg-ens192 ifcfg-ens33# 第二种：echo /etc/sysconfig/network-scripts/ifcfg-ens33 | egrep -o "[^/]+$" 第15题题目： 对/etc/目录，分别执行命令，实现以下功能(1)按从大到小顺序显示文件列表(2)只显示隐藏文件(3)只显示目录(4)按mtime时间显示文件列表(5)按atime时间显示文件列表 解答： 12345ll -S /etcll -d /etc/.*ll -d /etc/*/ll -t /etcll -u /etc 第16题题目： 编写/root/bin/excute.sh，实现与用户交互，判断用户给予的参数是否可读，可写，可执行。 解答： 123456789101112#!/bin/env bash# Author: Yu Longjunread -p &quot;请输入文件绝对路径: &quot; pathif [ -e $path ]; then [ -r $path ] &amp;&amp; echo &quot;文件可读&quot; || echo &quot;文件不可读&quot; [ -w $path ] &amp;&amp; echo &quot;文件可写&quot; || echo &quot;文件不可写&quot; [ -x $path ] &amp;&amp; echo &quot;文件可执行&quot; || echo &quot;文件不可执行&quot;else echo &quot;文件不存在&quot;fi 第17题题目： 编写/root/bin/create.sh可以生成新的脚本包括作者、联系方式、版本、时间和描述等，并且可以直接对其进行编辑，编辑完后自动加上执行权限。 解答： 123456789101112131415161718#!/bin/env bash#! Author: Yu Longjuncomments=&quot;&quot;&quot;#!/bin/env bash\n# Author: Yu Longjun\n# Tel: 010-8888888\n# Version: 0.1\n# Date: `date +%F`\n# Description: description\n&quot;&quot;&quot;if [ $# -gt 1 ]; then echo &quot;参数太多,请只输入一个参数&quot;elif [ $# -eq 1 ]; then if [ -e $1 ]; then echo &quot;存在文件$1&quot; else echo -e $comments &gt;$1 chmod +x $1 /usr/bin/vim + -c o $1 fielse echo &quot;没有输入参数，请输入一个参数&quot;fi 第18题题目： 写一个脚本，让它可以传递两个参数后，实现对该参数的加、减、乘、除运算并输出运算后的值。 解答： 123456789101112131415161718192021#!/bin/env bash# Author: Yu Longjunif [ $# -ne 2 ]; then echo &quot;参数个数不对，请输入两个参数&quot;else let result1=$1+$2 let result2=$1-$2 let result3=$1*$2 echo $1 + $2 = $result1 echo $1 - $2 = $result2 echo $1 \* $2 = $result3 if [ $2 -eq 0 ];then echo &quot;$1 / $2 无结果，因为除数不能为0&quot; else let result4=$1/$2 echo $1 / $2 = $result4 fifi 第19题题目： 编写/root/bin/wcfile.sh统计/etc目录中的目录的个数，文件的个数，并求出/etc/目录中的目录和文件个数的总和。 解答： 12345678910#!/bin/env bash# Author: Yu Longjunetc_dir_count=`ls -d /etc/*/ |wc -l`etc_sum_count=`ls -d /etc/* |wc -l`let etc_file_count=$etc_sum_count-$etc_dir_countecho &quot;目录个数为：$etc_dir_count&quot;echo &quot;文件个数为： $etc_file_count&quot;echo &quot;目录文件总和为：$etc_sum_count&quot; 第20题题目： 编写/root/bin/baketc.sh 查找/etc/目录中超过1天未修改的文件，将其压缩备份至/bakup目录。若之前没有备份过则备份之，若存在的备份文件超过了2分钟则备份之，否则退出。备份的格式为YYYY-MM-DD-hh-mm-ss.xz（Y表示年，M表示月，D表示日，h表示时，m表示分，s表示秒） 解答： 12345678#!/bin/env bash# Author: Yu Longjun# 查找backup下的文件(注意不要用/backup要用/backup/*)不超过两分钟的文件，如果没有，就打包文件。flag=`find /backup/* -mmin -2`if [ -z $flag ]; then find /etc/ -mtime +1 |xargs tar -Jcvf /backup/`date +"%Y-%m-%d-%H-%M-%S"`.tar.xzfi]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>test</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[05-bash配置相关]]></title>
    <url>%2Flinux%2F20170605-05-bash-profile%2F</url>
    <content type="text"><![CDATA[配置文件bash的配置文件，按生效范围划分，存在两类： 全局配置： 配置文件 内容 /etc/profile 为登录程序而设置的系统广泛使用的环境和启动程序。官方建议不动，想自定义全局配置的话建议改/etc/profile.d里面的内容。 /etc/profile.d/*.sh 各种配置，如256term.sh（终端配色方案）、vim.sh（vim相关配置）、less.sh（less命令相关）、colorls.sh（命令显示颜色相关）、lang.sh（语言相关）等。 /etc/bashrc 主要设置用户的PS1、history、umask等的全局设置。 个人配置： 配置文件 内容 ~/.bash_profile 个人定义的一些bash变量。 ~/.bashrc 个人定义的一些别名和功能。 tips：个人配置其实写上面哪个文件都行，都可以生效。 登录方式登录方式分为两种方式： 交互式登录。分为下面几种： 直接通过终端输入账号密码登录 使用 su - UserName 切换的用户 执行顺序：/etc/profile –&gt; /etc/profile.d/*.sh –&gt; ~/.bash_profile –&gt; ~/.bashrc –&gt; /etc/bashrc 非交互式登录。分为下面几种： 使用su UserName切换用户 图形界面下打开的终端 执行脚本 任何其它的bash实例 执行顺序： ~/.bashrc –&gt; /etc/bashrc –&gt; /etc/profile.d/*.sh 退出配置退出配置保存在用户的~/.bash_logout文件中，在退出登录shell时运行。 通常配置里写： 创建自动备份 清除临时文件]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>bashrc</tag>
        <tag>bash_profile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[04-条件测试]]></title>
    <url>%2Flinux%2F20170605-04-shell-condition%2F</url>
    <content type="text"><![CDATA[条件测试分为三种，我们通过man test可以看到大部分的条件测试。 test 命令可以写成[ EXPRESSION ]，这种写法，中括号两边要有空格，表达式是比较的，每一段都要有空格。 tips: 还有一种[[ EXPRESSION ]]的写法，这种写法支持通配符（globing）,一般用通配符的时候才会去用，尽量用单中括号来写。 test命令可以判断三类条件： 数值比较 字符串比较 文件比较 算术比较 表达式 英文描述 中文描述 n1 -eq n2 equal 等于 n1 -ge n2 greater equal 大于等于 n1 -gt n2 greater than 大于 n1 -le n2 less equal 小于等于 n1 -lt n2 less than 小于 n1 -ne n2 not equal 不等于 字符串比较[ EXPRESSION ] tips：[ EXPRESSION ]这种方法的时候，&gt;``&lt;号记得加\转义。 表达式 描述 str1 == str2 相同 str1 != str2 不同 str1 &lt; str2 ascii值比较 str1 &gt; str2 ascii值比较 -n str1 not zero ，是否为非空 -z str1 zero ，是否为空 tips: test 命令和测试表达式使用标准的数学比较符号来表示字符串比较，而用文本代码来表示数值比较。这个细微的特性被很多程序员理解反了。如果你对数值使用了数学运算符号， shell会将它们当成字符串值，可能无法得到正确的结果。 [[ EXPRESSION ]]先看看系统中用[[ EXPESSION ]]的例子： 1234[root❄CentOS6 ~]☭ cat /etc/rc.d/rc.sysinit| grep &quot;\[\[&quot;if [[ &quot;$system_release&quot; == *&quot;Red Hat&quot;* ]]; thenelif [[ &quot;$system_release&quot; == *Fedora* ]]; thenelif [[ &quot;$system_release&quot; =~ &quot;CentOS&quot; ]]; then 这个文档很长，但是很多都是用的单括号，只有涉及到通配符的，才会去用双中括号，所以，我们可以借鉴大牛的做法：普通测试都用单中括号，只有用到通配符的时候，才去用双中括号。 文件比较我们可以使用不同的条件标志测试不同的文件系统相关的属性。 [ -f $file_var ]：如果给定的变量是文件，则返回真。 [ -d $dict_var ]：如果给定的变量是目录，则返回真。 [ -e $file_dict_var ]：如果给定的变量是文件或文件夹，则返回真。 [ -r $readable_var ]：如果给定的变量包含的文件可读，则返回真。 [ -w $write_var ]：如果给定的变量包含的文件可写，则返回真。 [ -x $x_fvar ]：如果给定的变量包含的文件可执行，则返回真。 [ -c $char_var ]：如果给定的变量包含的是一个字符设备文件的路径，则返回真。 [ -b $block_var ]：如果给定的变量包含的是一个块设备文件的路径，则返回真。 [ -L $link_var ]：如果给定的变量包含的是一个符号链接，则返回真。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>test</tag>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[03-运算]]></title>
    <url>%2Flinux%2F20170605-03-shell-operation%2F</url>
    <content type="text"><![CDATA[算术运算略，后续在写 tips: $RANDOM：随机数0~32767echo $[$RANDOM%50]：随机数0-49 赋值运算普通赋值： =增强型赋值： +=, -=, *=, /=, %=自增自减：不推荐使用。 tips: 不推荐使用自增自检，在c语言里，为了计算机好识别，采用了自增自减。在比较新的语言，如Python，Ruby都不使用自增自减（很容易实现，但是不做），代码读起来不流畅，JavaScript支持自增自减，但是官方也不推荐使用。 布尔运算true false 略，后续再写]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[02-位置变量和退出码]]></title>
    <url>%2Flinux%2F20170605-02-shell-position-variables-and-exit-code%2F</url>
    <content type="text"><![CDATA[位置变量位置变量：在脚本代码中调用通过命令行传递给脚本的参数 $1, $2, ...$9, ${10}：对应脚本后参数的位置，超过两位数后要加花括号。 $0: 脚本本身（绝对路径） 1234567#!/bin/bashecho The script name is `basename $0`echo "1st arg is $1"echo "2st arg is $2"echo "9st arg is $9"echo "10st arg is $&#123;10&#125;" 结果： 123456[LongDream❄MBP:Scripts]☭ ./testarg.sh &#123;1..10&#125;The script name is testarg.sh1st arg is 12st arg is 29st arg is 910st arg is 10 $*: 传递给脚本的所有参数，全部参数合为一个字符串 $@: 传递给脚本的所有参数，每个参数为独立字符串 $#: 传递给脚本的参数的个数 tips: $@ $* 只在被双引号包起来的时候才会有差异 shift NUM可以用来想做移动位置参数。 12345678910111213141516171819202122232425# shift.sh echo 1st arg is $1echo 2st arg is $2echo 9st arg is $9echo the args counts is $#echo all args are "$*"shiftecho 1st arg is $1echo 2st arg is $2echo 9st arg is $9echo the args counts is $#echo all args are "$*"shiftecho 1st arg is $1echo 2st arg is $2echo 9st arg is $9echo the args counts is $#echo all args are "$*"shift 2 可以看到执行效果：12345678910111213141516[root❄centos7 bin]☭ ./shift.sh &#123;a..z&#125;1st arg is a2st arg is b9st arg is ithe args counts is 26all args are a b c d e f g h i j k l m n o p q r s t u v w x y z1st arg is b2st arg is c9st arg is jthe args counts is 25all args are b c d e f g h i j k l m n o p q r s t u v w x y z1st arg is c2st arg is d9st arg is kthe args counts is 24all args are c d e f g h i j k l m n o p q r s t u v w x y z 退出状态0代表命令运行成功1-255代表命令运行失败 脚本中可以自定义退出码，比如exit 100$?上一个命令运行时候的退出状态码。 &amp;&amp; 与 ||&amp;&amp;：前面命令成功，则运行后面命令。||：前面命令失败，则运行后面命令。 练习题实现自动生成sh脚本的模板。 实现： 12345678#!/bin/env bashecho "#!/bin/bash" &gt;&gt; $1echo "# Script Name: `basename $1`" &gt;&gt;$1echo "# Author: Yu Longjun" &gt;&gt;$1echo "# Version: 0.1" &gt;&gt;$1echo "# Date: `date +%F`" &gt;&gt;$1echo "# Description: " &gt;&gt;$1]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>position variables</tag>
        <tag>exit code</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[01-全局变量和局部变量]]></title>
    <url>%2Flinux%2F20170605-01-shell-global-and-local-variables%2F</url>
    <content type="text"><![CDATA[全局变量对于shell会话和所有生成的子shell都是可见的。局部变量则只对创建它们的 shell可见。 全局变量（global variables）用printenv就可以打印全局变量，里面会包括系统生成的全局环境变量和用户自定义的环境变量。 下面列出部分CentOS的全局环境变量： 12345678910111213141516171819XDG_SESSION_ID=226HOSTNAME=centos7.yulongjun.com #主机名TERM=xterm-256color #颜色方案SHELL=/bin/bash #当前使用的shellHISTSIZE=1000 #历史命令最大条目SSH_CLIENT=172.17.251.64 50610 22 # ssh client信息，也就是我登录的地址信息SSH_TTY=/dev/pts/2 # 我的终端号USER=root # 当前用户名LS_COLORS=xxxxxxxxxxxxxxxx #ls时文件的配色，太长了省略MAIL=/var/spool/mail/root # 当前用户的系统邮件存放的位置PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin # 命令的查找路径PWD=/app/scripts # 当前目录LANG=en_US.UTF-8 # 当前使用的语言HISTCONTROL=ignoredups # 历史命令控制选项，当前只有一个：去除连续重复的命令SHLVL=1 #shell 层级，当前只有一层shellHOME=/root # 当前用户家目录LOGNAME=root # 登录用户名SSH_CONNECTION=172.17.251.64 50610 172.17.37.200 22 # ssh连接信息，两端的信息都有OLDPWD=/app # 前一个工作目录 可以只打印某一个全局环境变量，有两种方法，记得要用echo调用变量的话，要在变量名前面加一个$： 12345[root@centos7 ~]# printenv HOME/root[root@centos7 ~]# echo $HOME/root 全局变量可用于子shell中(也可以用于当前shell下运行的脚本中，其实运行脚本就是在子shell中运行的）： 1234567891011121314[root@centos7 ~]# bash[root@centos7 ~]# bash[root@centos7 ~]# ps -f --forestUID PID PPID C STIME TTY TIME CMDroot 25202 25198 0 14:22 pts/2 00:00:00 -bashroot 26148 25202 0 15:44 pts/2 00:00:00 \_ bashroot 26180 26148 0 15:45 pts/2 00:00:00 \_ bashroot 26207 26180 0 15:45 pts/2 00:00:00 \_ ps -f --forest[root@centos7 ~]# echo $HOME/root[root@centos7 ~]# exitexit[root@centos7 ~]# exitexit 局部变量（local variables）没有专门的命令查看局部变量，只有一个set命令，会显示当前bash进程设置的所有变量，包括全局和局部。 123456789101112131415161718[root@centos7 ~]# setABRT_DEBUG_LOG=/dev/nullBASH=/bin/bashBASHOPTS=checkwinsize:cmdhist:expand_aliases:extglob:extquote:force_fignore:histappend:interactive_comments:login_shell:progcomp:promptvars:sourcepathBASH_ALIASES=()BASH_ARGC=()BASH_ARGV=()BASH_CMDS=()BASH_COMPLETION_COMPAT_DIR=/etc/bash_completion.d...HISTSIZE=1000HOME=/rootHOSTNAME=centos7.yulongjun.comHOSTTYPE=x86_64ID=0IFS=$&apos; \t\n&apos;... 创建局部变量和全局变量创建局部变量的方法很简单，就是变量名=值，例如var=10。 把局部变量export之后就是全局变量了。 12345678910111213141516[root@centos7 ~]# var=10[root@centos7 ~]# echo $var10[root@centos7 ~]# bash[root@centos7 ~]# echo $var[root@centos7 ~]# exitexit[root@centos7 ~]# echo $var10[root@centos7 ~]# export var[root@centos7 ~]# echo $var10[root@centos7 ~]# bash[root@centos7 ~]# echo $var10 调用变量$变量名即可调用变量，既返回(return)变量的值。 例如： 123456789101112131415[root@centos7 ~]# var=10[root@centos7 ~]# echo $var10[root@centos7 ~]# echo $USERroot[root@centos7 ~]# echo &quot;My hostname is $HOSTNAME&quot;My hostname is centos7.yulongjun.com[root@centos7 ~]# echo $PATH/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin[root@centos7 ~]# export PATH=$PATH:/root/bin[root@centos7 ~]# echo $PATH/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin:/root/bin tips：PATH=$PATH:/root/bin看起来可能有点绕，其实就是$PATH取出原有的PATH的值，然后和后面的:/root/bin字符串连接起来，然后把连接后的字符串赋值给PATH。 删除环境变量unset 变量名 unset之后，调用变量就是空的。12[root@centos7 ~]# unset var[root@centos7 ~]# echo $var]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>variables</tag>
        <tag>Shell</tag>
        <tag>local variables</tag>
        <tag>global variables</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[01-vim简明教程(附快速记忆方法)]]></title>
    <url>%2Flinux%2F20170602-01-vim%2F</url>
    <content type="text"><![CDATA[vim分为四种模式： 普通模式（normal mode） 插入模式（insert mode） 可视模式（visual mode） 命令模式（excute mode） 下面整理了常用的快捷键和记忆方法（结合英文的记忆方法法） 普通模式光标移动： 按键 效果 记忆方法 h j k l 向左/下/上/右移动 ←↑↓→ w 移动到下个单词开头 word W 移动到下个单词开头(包含标点) Word e 移动到下个单词结尾 end E 移动到下个单词结尾(单词含标点) End b 移动到上个单词开头 back B 移动到上个单词结尾(单词含标点) Back 0 移动到行首 hard ⇤ ^ 移动到行首的非空白符 soft ⇤ $ 移动到行尾 ⇥ H 当前屏幕的第一行 High M 当前屏幕的中间 Middle L 当前页的的最后一行 Low gg 移动到文件第一行 goto line1 G 移动到文件最后一行 Goto EOF 5G 移动到第五行 -Goto line5 查找： 按键 效果 记忆方法 f{char}/F{char} 在行内向下/向上查找字符{char} （光标在字符上） find/Find t{char}/T{char} 在行内向下/向上查找字符{char}（光标在字符前面） till /Till ;/, 跟f/F/t/T结合使用，，跟查找顺序相同/相反的下一个匹配项 - /pattern 文档向下查找匹配项 - ?pattern 文档内向上查匹配项 - n/N 跟/和?结合使用，跟查找顺序相同/相反的下一个匹配项 next/Next 剪切, 复制, 粘贴： 按键 效果 记忆方法 yy 复制当前行 yank 5yy 复制 5 行 5次yank yw 当光标在单词首字母处，复制当前单词 yank word yaw 当光标在单词内部，复制当前单词（单词后面空格也复制） yank around word yiw 当光标在单词内部，复制当前单词（单词后面空格不复制） yank inside word p 在光标后粘贴 paste P 在光标前粘贴 Paste dd 剪切当前行 delete 2dd 剪切 2 行 2次delete dw/dW 光标在单词首字母处，剪切当前单词 delete word daw/daW 剪切当前单词(后面有空格也剪切) delete around word diw/diW 剪切当前单词(后面有空格也剪切) delete inside word D 剪切, 从光标位置到行末 Delete ⇥ x 向后剪切掉一个字符，不用进入插入模式 向后x掉 X 向前剪切掉一个字符，不用进入插入模式 向前X掉 J 去掉行尾的换行符，即连接两行 Join lines u 撤销 undo &lt;ctrl-r&gt; 重做 redo 滚屏： 按键 效果 记忆方法 &lt;Ctrl + b&gt; 向后滚动一屏 backwards &lt;Ctrl + f&gt; 向前滚动一屏 forwards &lt;Ctrl + d&gt; 向后滚动半屏 down &lt;Ctrl + u&gt; 向前滚动半屏 up 插入模式 按键 效果 记忆方法 i 从光标前开始插入字符 insert I 从行首开始插入字符 Insert a 从光标后开始插入字符 append A 从行尾开始插入字符 Append o 在当前行之下另起一行, 开始插入字符 open a new line O 在当前行之上另起一行, 开始插入字符 Open a new line s 删除当前字符，然后进入插入模式(替换) substitute S 删除当前行，然后进入插入模式（替换） substitute r 替换当前字符（其实是属于replace模式） replace R 替换连续的几个字符（属于replace模式） Replace cw/cW 删掉一个单词/带标点的单词，然后进入插入模式 change C 删除光标所在行的光标后面的内容 Change &lt;Esc&gt; 退出插入模式 - 可视模式（visual mode） 按键 效果 记忆方法 v 选择字符 visual V 选择行 Visual line &lt;ctrl-v&gt; 选择块 visual block gv 重复上次的高亮区域 - o 结合可视模式用的o，回到活动端点 - vw 光标在单词首字母处，选择单词 visual word vaw 选择单词（包括单词后面的空格） visual around world viw 选择单词（不包括单词后面的空格） visual inside world vit 选择标签内的内容（html） visual inside tags 命令行模式 按键 效果 记忆方法 :w 保存、写入 write :x/:wq 保存并退出 write quit :q! 直接退出 quit r filename 读文件内容到当前文件中 read filename w filename 将当前文件内容另存到另一个文件 write filename !command 执行命令 !command r!command 读入命令的输出 read !command :set number 设置行符 略 :syntax on/:syntax off 开启/关闭代码高亮 略 替换命令： :s/target/replacement/：替换当前行的第一个target为replacement :s/target/replacement/g：替换当前行的所有的target为replacement :n,$s/target/replacement/：替换第n到最后一行的第一个target为replacement :n,$s/target/replacement/g：替换第n到最后一行的所有的target为replacement :%s/target/replacement：替换所有行的第一个target为replacement :%s/target/replacement/g：替换所有行的所有的target为replacement 用#或+作为分隔符，/作为匹配项中的内容: :s#target/#/replacement#g：替换所有行的第一个target/为/replacement :%s+/oradata/apras/+/user01/apras1+g:替换所有行的/oradata/apras/为/user01/apras1/ 颜色&lt;ctrl+v+[&gt; 在颜色方案前面插入上述三个按键，效果是蓝色的^[（并不是字符^[，只是这三个键呈现在屏幕的效果） 呈现的效果是这样： tips：颜色方案参考回显命令中的打印带颜色的回显]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[03-文本处理练习题]]></title>
    <url>%2Flinux%2F20170531-03-practice%2F</url>
    <content type="text"><![CDATA[grep练习题1、显示/proc/meminfo文件中以大小s开头的行(要求：使用两 种方法) 12345678# 第一种：grep "^[Ss] /proc/meminfo# 第二种：grep -i "^s" /proc/meminfo# 第三种：grep -i "^\(S\|s\)" /proc/meminfo# 第四种：grep -e "^s" -e "^S" /proc/meminfo 2、显示/etc/passwd文件中不以/bin/bash结尾的行 1grep -v "/bin/bash$" /etc/passwd 3、显示用户rpc默认的shell程序 1grep "^rpc\&gt;" /etc/passwd| cut -d : -f1,7 4、找出/etc/passwd中的两位或三位数 1grep -o "\&lt;[[:digit:]]\&#123;2,3\&#125;\&gt;" /etc/passwd 5、显示CentOS7的/etc/grub2.cfg文件中，至少以一个空白字符开头的且后面存非空白字符的行 1grep "^[[:space:]]\+[^[:space:]]\+" /etc/grub2.cfg 6、找出“netstat -tan”命令的结果中以‘LISTEN’后跟任意多个空白字符结尾的行 1netstat -tan | grep "\&lt;LISTEN\&gt;[[:space:]]*" 7、显示CentOS7上所有系统用户的用户名和UID 1234# 第一种方法：cat /etc/passwd |cut -d: -f1,3 | grep ":[[:digit:]]\&#123;,3\&#125;$"# 第二种方法：cat /etc/passwd |cut -d: -f1,3 | grep "\&lt;[[:digit:]]\&#123;,3\&#125;\&gt;$" 8、添加用户bash、testbash、basher、sh、nologin(其shell 为/sbin/nologin),找出/etc/passwd用户名同shell名的行 1234567echo bash testbash basher sh nologin | xargs -n1 useraddchsh -s /sbin/nologin nologin# grep：cat /etc/passwd | grep "\(^.*\&gt;\).*/\1$"# egrep 扩展：cat /etc/passwd | egrep "(^.*\&gt;).*/\1$" 9、利用df和grep，取出磁盘各分区利用率，并从大到小排序 1234第一种方法：df |grep "/dev/sd"|tr -s " "|cut -d" " -f1,5|sort -nr -k2第二种方法：df |grep "/dev/sd"|egrep -o "[[:digit:]]+%"|sort -nr egrep练习题1、显示三个用户root、mage、wang的UID和默认shell 1egrep "^(root|mage|wang)\&gt;" /etc/passwd | cut -d: -f1,3,7 2、找出/etc/rc.d/init.d/functions文件中行首为某单词(包括下划线)后面跟一个小括号的行用[:alnum:]或者单词边界\&gt;、\b123egrep -o "^[[:alnum:]_]+\(\)" /etc/rc.d/init.d/functionsegrep -o "^.*\&gt;\(\)" /etc/rc.d/init.d/functionsegrep -o "^.*\b\(\)" /etc/rc.d/init.d/functions 3、使用egrep取出/etc/rc.d/init.d/functions中其基名 123456# 文件，或者目录后面不带/：echo /etc/rc.d/init.d/functions |egrep -o "[[:alnum:]]+$"echo /etc/rc.d/init.d/functions |egrep -o "[^/]+$"# 文件或目录，后面带不带/都行，通用写法：echo /etc/rc.d/init.d/functions/ |egrep -o "[[:alnum:]]+/?$"echo /etc/rc.d/init.d/functions/ |egrep -o "[^/]+/?$" 4、使用egrep取出上面路径的目录名 12 5、统计last命令中以root登录的每个主机IP地址登录次数 1last |tr -s " " |cut -d" " -f1,3|egrep "root.*[[:digit:]].+"|sort|uniq -c 6、利用扩展正则表达式分别表示0-9、10-99、100-199、 200-249、250-255 12345echo &#123;0..1000&#125; |egrep -o "\&lt;[0-9]\&gt;"echo &#123;0..1000&#125; |egrep -o "\&lt;[1-9][0-9]\&gt;"echo &#123;0..1000&#125; |egrep -o "\&lt;1[0-9]&#123;2&#125;\&gt;"echo &#123;0..1000&#125; |egrep -o "\&lt;2[0-4][0-9]\&gt;"echo &#123;0..1000&#125; |egrep -o "\&lt;25[0-5]\&gt;" 7、显示ifconfig命令结果中所有IPv4地址 1ifconfig | egrep -o "\&lt;(([0-9]|[1-9][0-9]|1[0-9]&#123;2&#125;|2[0-4][0-9]|25[0-5])\.)&#123;3&#125;([0-9]|[1-9][0-9]|1[0-9]&#123;2&#125;|2[0-4][0-9]|25[0-5])" 8、将此字符串：welcome to magedu linux 中的每个字符 去重并排序，重复次数多的排到前面 1echo welcom to magedu linux |grep -o . |sort|uniq -c|sort -nr]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>RegExp</tag>
        <tag>grep</tag>
        <tag>egrep</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[02-正则表达式(RegExp)]]></title>
    <url>%2Flinux%2F20170531-02-regexp%2F</url>
    <content type="text"><![CDATA[Regular Expression，正则表达式，简写为RegExp。 BRE ：Basic RegExp，基本正则表达式 ERE ：Extend RegExp，扩展正则表达式 PCRE ：Perl Compatible RegExp，Perl兼容的正则表达式 基本正则表达式字符匹配 . 匹配任意单个字符：如r..t [] 匹配指定范围内的任意单个字符：如[abc]r [^] 匹配指定范围外的任意单个字符：如[^abc]r [:alnum:] 字母和数字 [:alpha:] 代表任何英文大小写字符，亦即 A-Z, a-z [:lower:] 小写字母 [:upper:] 大写字母 [:blank:] 空白字符（空格和制表符） [:space:] 水平和垂直的空白字符（比[:blank:]包含的范围广） [:cntrl:] 不可打印的控制字符（退格、删除、警铃…） [:digit:] 十进制数字 [:xdigit:]十六进制数字 [:graph:] 可打印的非空白字符 [:print:] 可打印字符 [:punct:] 标点符号 匹配次数 * 匹配前面的字符任意次，包括0次（贪婪模式，尽可能长的匹配） .* 任意长度的任意字符 \? 匹配其前面的字符0或1次 \+ 匹配前面的字符1次或多次 \{n\} 匹配前面的字符n次 \{m,n\} 匹配前面的字符至少m次，至多n次 \{,n\} 匹配前面的字符至多n次 \{n,\} 匹配前面的字符至少n次 位置锚定位置锚定：定位出现的位置 ^ 行首锚定，用于模式的最左侧(要跟字符匹配里的[^]区分开，那个是在中括号里面的) $ 行尾锚定，用于模式的最右侧 ^PATTERN$ 用于模式匹配整行 ^$ 空行 ^[[:space:]]*$ 空白行 \&lt; 或 \b 词首锚定，用于单词模式的左侧 \&gt; 或 \b 词尾锚定；用于单词模式的右侧 \&lt;PATTERN\&gt; 匹配整个单词 分组分组：\(\)将一个或多个字符捆绑在一起，当作一个整体进 行处理，如：\(root\)\+ 分组括号中的模式匹配到的内容会被正则表达式引擎记录于 内部的变量中，这些变量的命名方式为: \1, \2, \3, …\1 表示从左侧起第一个左括号以及与之匹配右括号之间的 模式所匹配到的字符 示例： \(string1\+\(string2\)*\) \1 ：string1\+\(string2\)* \2 ：string2 后向引用：引用前面的分组括号中的模式所匹配字符，而非模式本身 grep &quot;\(root\).*\1&quot; /etc/passwd 或者\| 示例： a\|b: a或b C\|cat: C或cat \(C\|c\)at:Cat或cat 扩展正则表达式egrep == grep -E egrep其实很简单，就是把grep里的斜线去掉了，不过有些还没有去掉。 字符匹配： . 任意单个字符 [] 指定范围的字符 [^] 不在指定范围的字符 次数匹配： *：匹配前面字符任意次 ?：0或1次 +：1次或多次 {m}：匹配m次 {m,n}：至少m，至多n次 位置锚定： ^：行首 $：行尾 \&lt;, \b :语首 \&gt;, \b :语尾 分组： () 后向引用：\1, \2, … 或者：| 示例： a|b: a或b C|cat: C或cat (C|c)at:Cat或cat]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>RegExp</tag>
        <tag>grep</tag>
        <tag>egrep</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[01-文本处理工具(cut、sort、tr、grep等)]]></title>
    <url>%2Flinux%2F20170531-01-text-tools%2F</url>
    <content type="text"><![CDATA[命令目录，查看某一个命令可点击直接跳转： 文件查看 cat tac rev more less 按行截取 head tail 转化内容 tr 按列操作 cut paste 分析文本 wc sort uniq diff、patch 按关键字过滤 grep 文件查看cat查看文件，从第一行到最后一行全部显示。 参数： -E: 显示行结束符$ -A：显示不可打印字符，通常查看脚本是否有多加空格tab回车之类的。 -n：对显示出的每一行进行编号 -s：显示行号，压缩连续的空行，只显示一行空行 -b ：空行不加行号，等同于nl命令 示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344[root❄centos7 app]☭ cat catfileAAA BBBCCC DDDEEEGGGHHH[root❄centos7 app]☭ cat -A catfile AAA^IBBB$CCC DDD$EEE$$GGG$$$HHH$[root❄centos7 app]☭ cat -n catfile 1 AAA BBB 2 CCC DDD 3 EEE 4 5 GGG 6 7 8 HHH[root❄centos7 app]☭ cat -b catfile 1 AAA BBB 2 CCC DDD 3 EEE 4 GGG 5 HHH[root❄centos7 app]☭ cat -s catfileAAA BBBCCC DDDEEEGGGHHH tac从后往前显示文件，和cat相反。 示例： 123456789[root❄centos7 app]☭ tac catfileHHHGGGEEECCC DDDAAA BBB revreverse lines水平反转每一行里的字母。 示例1，水平翻转文件： 123456789[root❄centos7 app]☭ rev catfile BBB AAADDD CCCEEEGGGHHH 示例2，倒序+水平翻转文件： 123456789[root❄centos7 app]☭ tac catfile | revHHHGGGEEEDDD CCCBBB AAA more分页显示，显示到最后会退出。 空格或者f下一页 b上一页（管道后跟more无法上一页） less分页显示，显示到最后也不会退出，要按q退出。 翻屏操作： 键盘按键 效果 空格键 向下滚动一屏 b 向上滚动一屏 j 向下移动一行 k或回车 向上移动一行 gg 跳转至第一行 5g 跳转到第5行 G 跳转到最后一行 q 退出 文本搜索: 键盘按键 效果 /keyword 向下查找，不区分大小写 ?keyword 向上查找，不区分大小写 n 查找下一个，与查找方向相同 N 查找上一个，与查找方向相反 按行截取head取文件头部的行，默认头10行。 参数： -c NUM：显示几个字符 -n NUM：显示几行 12# 取随机数里，数字或字母的字符，取前20个字符，可以用来做随机密码。cat /dev/urandom | tr -dc "0-9a-zA-Z" | head -c 20 tail显示文件尾部的行，默认最后10行。 参数： -c NUM：只显示倒数几个字符。 -n NUM：示倒数几行。 -f：follow，跟踪这个文件的变动，用来看日志比较多 例子：1tail -n0 -f /var/log/messages &amp;` -n0只显示新增加的内容，命令最后加一个&amp;，表示放在后台运行，可以去运行其他命令不受影响。当日志变动的时候，会在前台打印出一条，按回车可以继续运行其他命令。 转化内容trtr [OPTION]... SET1 [SET2]把输入的数据当中的字符，凡是在SET1定义范围内出现的，通通对位转换为SET2出现的字符 参数： tr SET1 SET2 &lt; /path/from/somefile对位转化SET1中的字符为SET2中的字符 tr -d SET1 &lt; /path/from/somefile删除指定集合里出现的字符 tr -s &quot;\n&quot; /path/from/somefile把指定的连续的字符以一个字符表示，压缩。 tr -cComplement ,取字符集的补集，通常与其他参数结合使用，例如-dc 123456789101112[root❄centos7 ~]☭ tr &apos;a-z&apos; &apos;A-Z&apos;aabbcc33AABBCC33^C[root❄centos7 ~]☭ tr &apos;a-z&apos; &apos;A-Z&apos; &lt;/etc/issue\SKERNEL \R ON AN \M[root❄centos7 ~]☭ tr &apos;a-z&apos; &apos;A-Z&apos; &lt; /etc/issue &gt; /app/issue2[root❄centos7 ~]☭ cat /app/issue2\SKERNEL \R ON AN \M tips：如果是输入后再输出到同一个文件，就会清空这个文件，所以最好不要这么用，下面是一个错误示范： 12345[root❄centos7 ~]☭ cd /app/[root❄centos7 app]☭ cp issue2 issue3[root❄centos7 app]☭ tr &apos;a-z&apos; &apos;A-Z&apos; &lt; issue3 &gt;issue3[root❄centos7 app]☭ cat issue3[root❄centos7 app]☭ 追加是可以的，在原有文件基础上再追加一段： 1234567891011[root❄centos7 app]☭ cat issue2\SKERNEL \R ON AN \M[root❄centos7 app]☭ tr &apos;A-Z&apos; &apos;a-z&apos; &lt; issue2 &gt;&gt; issue2[root❄centos7 app]☭ cat issue2\SKERNEL \R ON AN \M\skernel \r on an \m dc结合使用： 123456789[root❄centos7 app]☭ echo &#123;a..z&#125; &gt;f1[root❄centos7 app]☭ cat f1a b c d e f g h i j k l m n o p q r s t u v w x y z[root❄centos7 app]☭ tr -d &apos;f-n&apos; &lt;f1a b c d e o p q r s t u v w x y z[root❄centos7 app]☭ cat f1a b c d e f g h i j k l m n o p q r s t u v w x y z[root❄centos7 app]☭ tr -dc &apos;f-n&apos; &lt; f1fghijklmn[root❄centos7 app]☭ 按列操作cutcut可以实现分割每一行，并且指定输出列的字段。 -d DELIMITER：指定分隔符（delimiter） -f FIELDS：取指定字段（fileds） 示例1： 123456789# 以冒号作为分隔符，取1到3、7的字段cut -d: -f1-3,7 /etc/passwd# 结果root:x:0:/bin/bash...LongDream:x:1000:/bin/bashyu:x:1001:/bin/bashalice:x:1002:/bin/bashtom:x:1003:/bin/bash 示例2： 123456789101112# 取磁盘利用率,先tr压缩空格为一个空格，然后以空格作为分隔符，取第五个字段df |tr -s " "| cut -d" " -f5# 结果Use%5%0%0%1%0%1%22%0% paste把多个文件的多行进行合并，逐行进行合并。 参数： -d指定分隔符,默认是tab -s把每个文件里的多行合成一行，每个文件一行。 示例： 1234567891011121314151617181920212223[root❄centos7 app]☭ cat file1nameaaabbbccc[root❄centos7 app]☭ cat file2age182022[root❄centos7 app]☭ paste file1 file2name ageaaa 18bbb 20ccc 22[root❄centos7 app]☭ paste -d: file1 file2name:ageaaa:18bbb:20ccc:22[root❄centos7 app]☭ paste -s file1 file2name aaa bbb cccage 18 20 22 分析文本wc直接运行原wc命令：输出文件中的行数、单词数、字节数 参数： -c：输出字节数 -m：输出字符数 -l：输出行数 -L：输出最长的行的长度。 -w： 输出单词统计数。 sort排序，默认是按照字符的大小来排列 -t ：指定分隔符 -k：以哪一个为分割 -n：按数字大小排列，从小到大 -r：反向，从打到小 -u：删除重复的行 示例1：1234# 以冒号分割，取第三列UID，nr表示按照数值大小倒序（由大到小）排列。sort -t: -k3 -nr /etc/passwd# 先cut只留第一列用户名和第三列UIDcut -d: -f1,3 /etc/passwd | sort -t: -k2 -nr 示例2： 12# 取分区使用率最大值df |tr -s " " "%"|cut -d% -f5|sort -nr|head -n1 uniq唯一，从输入中删除前后相接的重复的行 -c: 显示每行重复出现的次数 -d: 仅显示重复过的行 -u: 仅显示不曾重复的行 常和sort 命令一起配合使用，示例： 1234# 把用户名列表进行排序（重复的会在相邻的行），然后统计重复用户出现的次数：sort userlist.txt | uniq -c# 登录用户的登录次数：`last | cut -d ' ' -f1|sort| uniq -c |sort -nr` diff、patchdiff比较两个文件的区别 1234567# 比较两个文件的区别，发现第5行有区别diff foo.conf-broken foo.conf-works5c5&lt; use_widgets = no---&gt; use_widgets = yes patch可以用diff生成的patch来修复另一个文件。 123diff -u foo.conf-broken foo.conf-works &gt; foo.patch #把差异写到foo.patch补丁里cp foo.conf-broken foo.conf-broken.bak #备份一下patch -b foo.conf-broken foo.patch # 从差异的补丁进行恢复 按关键字过滤grep文本过滤工具 不带参数普通用法： grep root /etc/passwd 带参数： -v：显示不被pattern匹配到的行 -i：忽略字符大小写 -n：显示匹配的行号 -c：统计匹配的行数 -o：仅显示匹配到的字符串 -q：静默模式，不输出任何信息(quiet，可以结合echo $?状态码使用) -A NUM after, 包含匹配行的后NUM行 -B NUM:before, 包含匹配行的前NUM行 -C NUM context, 包含匹配行的前后各NUM行 -e: 实现多个选项间的逻辑or关系 -w匹配整个单词(字母、下划线、数字汉字，这几个连在一起算一个单词) -E使用ERE -F相当于fgrep，不支持正则表达式 参考书籍：关于grep的各个参数的具体用法，可以看《Linux Shell 脚本攻略（第2版）》4.3章节，有详细说明，这里不做赘述。 例子： 12# 扫描172.16.252。0段的机器，如果主机是up状态（Host is up）的，显示之前一行（-B1）,前一行有ip地址，然后grep for是因为只有有ip的那行有for，然后以空格为分隔符，取第五个，就是ip地址。nmap -v -sP 172.17.252.0/24 |grep -B1 "Host is up."|grep for|cut -d" " -f5]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>grep</tag>
        <tag>cut</tag>
        <tag>sort</tag>
        <tag>wc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[04-权限和ACL练习题]]></title>
    <url>%2Flinux%2F20170527-04-practice%2F</url>
    <content type="text"><![CDATA[1、在/testdir/dir里创建的新文件自动属于g1组，组 g2的成员如：alice能对这些新文件有读写权限，组g3 的成员如：tom只能对新文件有读权限，其它用户（不 属于g1,g2,g3）不能访问这个文件夹。 前期准备： 1234567[root❄centos7 ~]☭ echo g&#123;1,2,3&#125; |xargs -n 1 groupadd[root❄centos7 ~]☭ tail -n 3 /etc/groupg1:x:1002:g2:x:1003:g3:x:1004:[root❄centos7 ~]☭ useradd alice -g g2[root❄centos7 ~]☭ useradd tom -g g3 题目解答： 12345chgrp g1 /testdir/dirchmod g+s /testdir/dirsetfacl -Rm d:g:g2:rw /testdir/dirsetfacl -Rm d:g:g3:r /testdir/dirchmod o= /testdir/dir 2、备份/testdir/dir里所有文件的ACL权限到/root/acl.txt中，清除/testdir/dir中所有ACL权限 ，最后还原ACL权限。 题目解答： 123456789101112# 备份权限[root❄centos7 /]☭ getfacl -R /testdir/dir &gt; /root/acl.txt# 清除/testdir/dir权限[root❄centos7 /]☭ setfacl -Rb /testdir/dir# 还原ACL权限，两种方法。# 第一种绝对路径法：setfacl --set-file=/root/acl.txt /testdir/dir# 第二种相对路径法（查看acl.txt看是相对路径testdir/dir,是相对于/的，所以先cd到/,这步不能省）：[root❄centos7 /]☭ cd /[root❄centos7 /]☭ setfacl --restore /root/acl.txt]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>acl</tag>
        <tag>facl</tag>
        <tag>permission</tag>
        <tag>practice</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[03-访问控制列表（ACL）]]></title>
    <url>%2Flinux%2F20170527-03-acl%2F</url>
    <content type="text"><![CDATA[ACL：Access Control List 访问控制列表 除了文件原本的权限位设置，可以自定义用户访问控制。 CentOS 7 默认创建的xfs和ext4文件系统具有ACL功能 CentOS 7 之前版本，系统安装时候创建的文件系统有ACL功能，默认手工创建的ext4文件系统无ACL功 能，需手动增加。 比如在6上新加一块磁盘，创建了sdb1分区，可以用下面命令使其支持ACL： 123tune2fs –o acl /dev/sdb1mount –o acl /dev/sdb1 /mnt/test 基本命令用法getfacl XXX获取文件或文件夹的权限： 123456789101112131415161718[root❄centos7 app]☭ touch a[root❄centos7 app]☭ getfacl a# file: a# owner: root# group: rootuser::rw-group::r--other::r--[root❄centos7 app]☭ mkdir dir1[root❄centos7 app]☭ getfacl dir1# file: dir1# owner: root# group: rootuser::rwxgroup::r-xother::r-x setfacl(set file acl)给一个文件加了facl的话，整个权限位后面会有个+号，表示设置了facl权限。 -m 参数，表示modify 禁止yu用户访问file1 12345678910[root❄centos7 app]☭ setfacl -m u:yu:000 file1[root❄centos7 app]☭ getfacl file1# file: file1# owner: root# group: rootuser::rw-user:yu:---group::r--mask::r--other::r-- 禁止yu组访问file2 12345678910[root❄centos7 app]☭ setfacl -m g:yu:000 file2[root❄centos7 app]☭ getfacl file2# file: file2# owner: root# group: rootuser::rw-group::r--group:yu:---mask::r--other::r-- 禁止其它用户访问file1 12345678[root❄centos7 app]☭ setfacl -m o:0 file3[root❄centos7 app]☭ getfacl file3# file: file3# owner: root# group: rootuser::rw-group::r--other::--- 默认的从上到下的权限依次是： #owner:文件的拥有者#group：文件的拥有组user：自定义的用户（可多个）group：自定义的组（可多个）other：自定义的其它用户（可多个） 如果一个用户属于多个自定义的组，权限是这几个组的权限的累加。 setfacl的其他用法setfacl -Rb *：清除所有acl setfacl -M TEXT：利用列表来批量设置权限 1234567891011121314[root❄centos7 ~]☭ cat file.acl u:yu:-g:yu:rwx[root❄centos7 ~]☭ setfacl -M file.acl xxx[root❄centos7 ~]☭ getfacl xxx# file: xxx# owner: root# group: rootuser::rw-user:yu:---group::rw-group:yu:rwxmask::rwxother::rw- -d 参数（default的意思），默认在facl权限下的目录，新创建的文件和文件夹继承上一级目录的权限。例如： setfacl -md d:u:yu:rwx /app/dir2 那么在dir2下新创建的目录就默认继承dir2的acl权限。 -x删除某个权限： setfacl -x u:yu:rwx /app/dir2 -X按照文件里的内容来批量删除权限： setfacl -X file.acl xxx acl中的maskfacl的mask是高压线，是影响自定义用户和自定义组的权限，有了mask后，会与自定义的用户和组的权限做逻辑与，这之后是自定义用户和组的真实权限。 默认是没有高压线的，默认值一般都是所有自定义用户和组的最高权限累加。 如果设置了，就相当于设定了高压线，高于这个高压线的权限，会降低到高压线之下。 12345678910111213141516171819202122232425[root❄centos7 app]☭ touch file4[root❄centos7 app]☭ setfacl -m u:yu:rwx file4 [root❄centos7 app]☭ setfacl -m g:yu:rw- file4[root❄centos7 app]☭ getfacl file4# file: file4# owner: root# group: rootuser::rw-user:yu:rwxgroup::r--group:yu:rw-mask::rwxother::r--[root❄centos7 app]☭ setfacl -m m:r-- file4[root❄centos7 app]☭ getfacl file4# file: file4# owner: root# group: rootuser::rw-user:yu:rwx #effective:r--group::r--group:yu:rw- #effective:r--mask::r--other::r-- 我们可以看到，设置了高压线后，自定义用户和自定义组的有效值（effective）是不超过mask的r-- facl权限的复制、备份和恢复复制acl权限： getfacl file1 | setfacl --set-file=- file2 主要的文件操作命令cp和mv都支持ACL，只是cp命令需要 加上-p 参数。但是tar等常见的备份工具是不会保留目录 和文件的ACL信息。 123456789101112# 得到app目录及其目录里所有文件的acl权限（-R参数），写入到/root/app.acl文件里[root❄centos7 app]☭ getfacl -R /app &gt;/root/app.acl# 去掉/app目录及其目录里所有文件的acl权限（-b去除）[root❄centos7 app]☭ setfacl -R -b /app# 恢复权限# 绝对路径法：setfacl --set-file=/root/app.acl /app#相对路径法（需要在要恢复的文件夹或文件的上一级目录运行）：setfacl --restore /root/app.acl]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>acl</tag>
        <tag>facl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[02-特殊权限]]></title>
    <url>%2Flinux%2F20170527-02-special-permission%2F</url>
    <content type="text"><![CDATA[X（大写）X：给目录x权限，不给文件x权限（当文件本来就有x权限的话会重新赋予x权限） 例如： chmod -R +X dir2 对dir2文件夹本身和dir2里的文件夹加执行权限对文件的话： 如果这个文件原来没有x权限，就不加。 如果这个文件任意位置有x权限，就会给这个文件重新增加执行权限。 SUIDSUID属性一般运用在可执行文件上，当用户执行该执行文件时，会临时拥有该执行文件所有者的权限。 表现在权限位上就是一个s： 12[root❄centos7 ~]☭ ll /bin/passwd-rwsr-xr-x. 1 root root 27832 Jun 10 2014 /bin/passwd 必须放在二进制的、可执行的程序上才有用，比如/bin/passwd就有suid权限。 当普通用户使用passwd执行修改密码时，发给root去执行写入/etc/shadow的操作。（写/etc/shadow的这个操作，普通用户对/etc/shadow无写权限，这时候就需要s权限） 用法： chown u+s BIN chown u-s BIN chown 4xxx BIN tips：当一个文件或文件夹没有x权限时候，表明SUID无效，表现为一个S（大写）： 123456[root❄centos7 app]☭ chmod a-x file1[root❄centos7 app]☭ ll file1-rw-r--r-- 1 root root 0 May 29 16:27 file1[root❄centos7 app]☭ chmod u+s file1[root❄centos7 app]☭ ll file1-rwSr--r-- 1 root root 0 May 29 16:27 file1 SGIDSGID于SUID不同，SGID属性可以应用在目录或可执行文件上。 当SGID属性应用在目录上时，该目录中所有建立的文件或子目录的拥有组都会是该目录的拥有组。当SGID属性应用在可执行文件上时，其他用户在使用该执行文件时就会临时拥有该执行文件拥有组的权限。 chmod g+s BINchmod g-s BINchmod 2xxx BIN Sticky 粘滞位Sticky作用在目录上才有意义。 在目录上加这个权限，那在这个目录里的文件，只有拥有者用户自己或者root可以删，其他普通用户不能删。 chmod o+t DIRchmod o-t DIRchmod 1xxx DIR 1234[root❄centos7 app]☭ chmod 7770 haha[root❄centos7 app]☭ lltotal 0-rwsrws--T. 1 root root 0 May 25 19:49 haha tips：执行完更改特殊权限位，最好ll看一下有没有问题，要养成这样的好习惯。 chattrchattr +i xxx 锁定该文件 ，不允许修改，删除，重命名，重定向方式清空也不可以。 chattr -i xxx 去掉锁定。 chattr +a xxx只能&gt;&gt;追加内容，不能删除和减少。 chattr -a xxx去掉只能追加这种锁定 ls是看不到attr属性的，可以用lsattr显示特定属性。 12345678910111213[root❄centos7 app]☭ touch file1[root❄centos7 app]☭ chattr +i file1[root❄centos7 app]☭ lsattr file1----i----------- file1[root❄centos7 app]☭ echo &quot;yulongjun&quot; &gt; file1-bash: file1: Permission denied[root❄centos7 app]☭ echo &quot;yulongjun&quot; &gt;&gt; file1-bash: file1: Permission denied[root❄centos7 app]☭ mv file1 /tmpmv: cannot remove ‘file1’: Operation not permitted[root❄centos7 app]☭ rm file1rm: remove regular empty file ‘file1’? yrm: cannot remove ‘file1’: Operation not permitted 123456789101112[root❄centos7 app]☭ touch file2[root❄centos7 app]☭ chattr +a file2[root❄centos7 app]☭ lsattr file2-----a---------- file2[root❄centos7 app]☭ echo &quot;yulongjun&quot; &gt; file2-bash: file2: Operation not permitted[root❄centos7 app]☭ echo &quot;yulongjun&quot; &gt;&gt; file2[root❄centos7 app]☭ cat file2yulongjun[root❄centos7 app]☭ rm file2rm: remove regular file ‘file2’? yrm: cannot remove ‘file2’: Operation not permitted]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>special permission</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[01-文件和目录权限]]></title>
    <url>%2Flinux%2F20170527-01-permission%2F</url>
    <content type="text"><![CDATA[权限位rwxrwrwx：左三位：定义user（owner）的权限，属主权限中三位：定义group的权限，属组权限有三位：定义other的权限，其他的权限 进程对文件的访问权限应用模型：进程的属主与文件的属主是否相同。如果相同，则应用属主权限；否则去检查金证的属于是否属于文件的属组；如果是，则应用属组权限，否则，就只能引用other权限。 权限：r：readable，可读w：writable，可写x：executble，可执行 文件 r：可获取文件的数据 w：可修改文件的数据 x：可将此文件运行为进程 目录 r：可使用ls命令获取旗下的所有文件列表 w：可修改次目录下的文件列表，即创建或删除文件 x：可cd值此目录中，且可使用ll来获取到所有文件详细属性信息 权限组合机制： ---：二进制000，十进制0 --x：二进制001，十进制1 -w-：二进制010，十进制2 -wx：二进制011，十进制3 r--：二进制100，十进制4 r-x：二进制101，十进制5 rw-：二进制110，十进制6 rwx：二进制111，十进制7 文件权限管理命令chmod的三种用法： chmod [OPTION]… MODE[,MODE]… FILE…chmod [OPTION]… OCTAL-MODE FILE…chmod [OPTION]… –reference=RFILE FILE… 三类用户： u：属主 g：属组 o；其他 a：所有 (1)MODE表示法：chmod [OPTION]... MODE[,MODE]... FILE... 赋值表示法：直接操作一类用户的所有权限位： u= g= o= a= 授权表示法：直接操作一类用户的一个或多个权限位： u+、u- g+、g- o+、o- a+、a- 1234567891011121314151617181920212223touch testchmod g=rw testllchmod ug=r testllchmod u=rwx,g=rw,o= testllchmod u-x testllchmod o+r testllchmod ug+x testllchmod g-wx testllchmod u-r testllchmod +x test # +x对所有都有效llchmod +w test # +w只对属主有效llchmod u+x,g+w testll (2)八进制表示法：chmod [OPTION]… OCTAL-MODE FILE… 1234chmod 660 testllchmod 777 testll (3)参考某个文件的权限：chmod [OPTION]… –reference=RFILE FILE… 1chmod --reference=/etc/fstab test (4)chmod选项 -R ：recursive ，递归修改 从属关系管理命令主要有两个命令chown，chgrp chown更改文件的的属主(属组也能更改) -R：递归修改 用法：chown -R USERNAME[:FILENAME] FILENAME 例如：chown -R oracle:oinstall /u01 chgrp更改文件的属组 -R：递归修改 用法：chgrp -R GROUPNAME FILENAME用到很少，chown可以修改属组，这个命令就被打入冷宫了，很少用。 新建文件和目录的默认权限（umask）新建的文件和文件夹都有一个默认权限，那么是如何实现的呢？就是用umask实现的。 umask原理： 针对新建文件：666-umask后的权限就是新建文件的权限 针对新建目录：777-umask后的权限就是新建目录的权限。 我们可以看/etc/bashrc里面的umask规则： ![]/images/1496043520606.png) 看代码，即UID 大于199，umask为002，否则umask为022 普通用户UID在CentOS 6下大于500，CentOS7下大于1000，所以umask值为002，默认创建的文件和文件夹权限分别为666-002=664、777-002=775。 而root用户，UID为0，umask值为022，默认创建的文件和文件夹权限分别为666-022=644、777-022=755。 练习题1、当用户xiaoming对/testdir 目录无执行权限时，意味着无 法做哪些操作？ 无法cd到这个目录，无法删除、移动这个文件。 2、当用户xiaoqiang对/testdir 目录无读权限时，意味着无 法做哪些操作？ 无法查看这个目录，也无法ls查看这个目录里面内容。 3、当用户wangcai 对/testdir 目录无写权限时，该目录下的只读文件file1是否可修改和删除？ 不可以修改和删除。 4、当用户wangcai 对/testdir 目录有写和执行权限时，该目 录下的只读文件file1是否可修改和删除？ 可以修改和删除，但是没有读权限的话，只能盲找。 5、复制/etc/fstab文件到/var/tmp下，设置文件所有者为 wangcai读写权限，所属组为sysadmins组有读写权限，其他人无权限 123cp /etc/fstab /var/tmp/chown wangcai:sysadmins /var/tmp/fstabchmod 660 /var/tmp/fstab 6、误删除了用户wangcai的家目录，请重建并恢复该用户家目录及相应的权限属性 1234rm -rf /home/wangcaicp -r /etc/skel/ /home/wangcaichmod 700 /home/wangciachown -R wangcai:wangcai /home/wangcai]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>permission</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[05-实践：Linux用户、组和密码相关文件被破坏如何恢复系统]]></title>
    <url>%2Flinux%2F20170526-05-recovery-system%2F</url>
    <content type="text"><![CDATA[我们先看一下用户用户组和密码相关文件： 123456789[root❄centos7 ~]☭ ll /etc/passwd* /etc/shadow* /etc/group* /etc/gshadow*-rw-r--r--. 1 root root 988 May 28 02:34 /etc/group-rw-r--r--. 1 root root 975 May 28 02:29 /etc/group-----------. 1 root root 801 May 28 02:34 /etc/gshadow----------. 1 root root 790 May 28 02:19 /etc/gshadow--rw-r--r--. 1 root root 2247 May 28 02:19 /etc/passwd-rw-r--r--. 1 root root 2247 May 28 02:19 /etc/passwd-----------. 1 root root 1257 May 28 02:19 /etc/shadow----------. 1 root root 1262 May 28 02:19 /etc/shadow- 我们可以看到每一个文件都有一个带-后缀的文件。如果我们不小心破坏了原来的文件，可以用后面的带-文件恢复，基本上能恢复所有的账号和密码。 下面进行破坏模拟实验： CentOS 7 破坏模拟1、 在/etc/passwd文件的首行root行加注释#，保存退出： 12#root:x:0:0:root:/root:/bin/bash... 2、 然后重启服务器，发现进不去系统。 3、 然后我们重启下，然后再按e修改启动方法： 4、 进入到这个界面后，找到linux16那行： 5、 在这行的尾部添加init=/bin/bash，然后按&lt;Ctrl-x&gt;后启动： 6、 然后我们进入bash： 7、 这时候系统是无法写入的，我们要重新以rw的模式remount一下，命令为mount -o rw,remount / 8、 我们可以修复被修改的/etc/passwd文件，记得先给原/etc/passswd做个备份，然后再复制/etc/passwd-文件去覆盖/etc/passwd，（如果有其他文件如/etc/shadow等被破坏，也可以用此方法） tips：备份是个好习惯，更改重要文件前最好都要先备份下。 9、重启服务器（reboot，init，shutdown等重启命令都无法使用，只能硬重启），正常进入操作系统。 CentOS 6 破坏模拟1、 在/etc/shadow文件的首行root行加注释#，保存退出： 12#root:$6$6P086Sg8NUDccylN$O1g3CU1Jhfxp.RwBvwylXF.yVml2dQvAGIAAM.LzIDDqsueS8FrFWfDa/S4JZ.4uLs./iQ9f6Ifm7qCYlVV6U.:17313:0:99999:7:::... 2、 然后重启服务器，发现可以进入系统，但是输入root密码后，提示不正确（不输入密码直接进也进不去）。 3、 然后我们重启下，在这个界面按任意键进入启动菜单： 4、按a修改启动内核启动参数： 5、进入到这个界面后，在后面输入init=/bin/bash，然后按回车： 6、 然后我们进入bash： 7、 这时候系统是无法写入的，我们要重新以rw的模式remount一下，命令为mount -o rw,remount /（和CentOS 7 一样，就不贴图了） 8、 我们可以修复被修改的/etc/shadow文件，记得先给原/etc/shadow做个备份，然后再复制/etc/shadow-文件去覆盖/etc/shadow，（如果有其他文件如/etc/shadow等被破坏，也可以用此方法）（和CentOS7 一样，就不贴图了） tips：备份是个好习惯，更改重要文件前最好都要先备份下。 9、重启服务器（reboot，init，shutdown等重启命令都无法使用，只能硬重启），正常进入操作系统。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>recovery</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[04-用户和组练习题]]></title>
    <url>%2Flinux%2F20170526-04-user-group-practice%2F</url>
    <content type="text"><![CDATA[练习1创建用户gentoo，附加组为bin和root，默认shell为 /bin/csh，注释信息为”Gentoo Distribution” 123[root❄centos7 skel]☭ useradd gentoo -G bin,root -s /bin/csh -c &quot;Gentoo Distribution&quot;[root❄centos7 skel]☭ cat /etc/passwd |grep gentoogentoo:x:1001:1001:Gentoo Distribution:/home/gentoo:/bin/csh 练习2创建下面的用户、组和组成员关系 名字为admins 的组 用户natasha，使用admins 作为附属组 用户harry，也使用admins 作为附属组 用户sarah，不可交互登录系统，且不是admins 的成员， natasha，harry，sarah密码都是centos 123456789101112131415161718[root❄centos7 skel]☭ groupadd admins[root❄centos7 skel]☭ useradd natasha -G admins[root❄centos7 skel]☭ useradd harry -G admins[root❄centos7 skel]☭ useradd sarah -s /sbin/nologin[root❄centos7 skel]☭ echo centos | passwd --stdin natashaChanging password for user natasha.passwd: all authentication tokens updated successfully.[root❄centos7 skel]☭ echo centos | passwd --stdin harryChanging password for user harry.passwd: all authentication tokens updated successfully.[root❄centos7 skel]☭ echo centos | passwd --stdin sarahChanging password for user sarah.passwd: all authentication tokens updated successfully.[root❄centos7 skel]☭ tail -n 3 /etc/passwdnatasha:x:1002:1003::/home/natasha:/bin/bashharry:x:1003:1004::/home/harry:/bin/bashsarah:x:1004:1005::/home/sarah:/sbin/nologin]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>user</tag>
        <tag>group</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[03-用户和用户组的管理命令]]></title>
    <url>%2Flinux%2F20170526-03-user-group-cmmands%2F</url>
    <content type="text"><![CDATA[用到的命令主要有： 组命令：groupadd、groupdel、groupmod、gpasswd、groupmems、 newgrp 用户命令：useradd、userdel、usermod、passwd 其他相关命令： getent：getent passwd USERNAME、getent shadow GROUPNAME chage chsh id su 用户组命令：groupaddgroupadd GROUP_NAME:创建新组 可选参数： -g GID：手动指定GID，默认是上一个组的GID+1 -r：创建系统组 groupmodgroupmod GROUP_NAME 修改组信息 -g GID：修改GID -n NEW_NAME OLD_NAME：修改组名 groupdelgroupdel GROUP_NAME：删除组 例子：12345678groupadd grpgroupadd -g 2000 grp1groupadd -r sysgrpgroupadd -r -g 306 sysgrp1groupmod -g 702 sysgrp1groupmod -n newsysgrp1 sysgrp1groupdel grp gpasswdgpasswd GROUP_NAME：给组加密码，一般默认不加，不加的话，用户就不能用newgrp切换属组（组密码那里是两!!，表示无密码，无密码的组，用户也不能临时切换到这个组。） groupmems12345678910用法：groupmems [选项] [动作]选项： -g, --group groupname 更改组 groupname，而不是用户的组(只 root)动作： -a, --add username 将用户 username 添加到组成员中 -d, --delete username 从组的成员中删除用户 username -p, --purge 从组中移除所有成员 -l, --list 列出组中的所有成员 比如下面，就是列出admins组里的所有成员，然后删除其中的一个成员natasha： 1234[root❄centos7 skel]☭ groupmems -g admins -lnatasha harry [root❄centos7 skel]☭ groupmems -g admins -lharry newgrpnewgrp GROUPNAME 临时切换主组，如果切换不属于的组，要输入组密码。如果不属于的组而且没有设置组密码，则无法切换。 用户命令useradduseradd ：创建新用户或者更新默认新用户信息 -u：指定UID -g：指定基本组GID，组名必须存在才行，不能用来新建GID。 -G GROUP1[,GROUP2,...[GROUPN]]：指定GID，指明用户的附加组，多个组之间用逗号分隔。 -c COMMENT：注释信息 -d HOME_DIR：指定家目录（本质是通过复制/etc/skel目录并重命名实现的），如果目录路径本身就存在，则不会为用户复制/etc/skel下的内容。 -s SHELL： 指定用户的默认shell，可用于所有shell列表存在的shell(shell列表：/etc/shells) -r ：创建系统用户 -D：修改创建用户时候的默认选项（man useradd可以看一下详情,，其实更改的就是/etc/default/useradd） 1234567891011121314151617181920useradd dockeruseradd -u 3000 openstackuseradd -u 3001 -g 3001 openshiftuseradd -g cloudgroup cloudstackuseradd -G grp,grp1 archlinuxuseradd -c &quot;Hacker Linux&quot; kalilinuxuseradd -d /opt/sybase sybasemkdir /tmp/test1useradd -d /tmp/test1 test1useradd -s /bin/csh test2useradd -s /sbin/nologin test3 tips：要查看useradd的默认规则，可以查看/etc/default/useradd文件。 123456789[root❄centos7 default]☭ cat /etc/default/useradd# useradd defaults fileGROUP=100HOME=/homeINACTIVE=-1EXPIRE=SHELL=/bin/bashSKEL=/etc/skelCREATE_MAIL_SPOOL=yes 我们可以看到有个SKEL，skel里存放的是环境变量文件，当创建新用户时候，会复制一份到用户家目录里面。 123[root❄centos7 default]☭ cd /etc/skel/[root❄centos7 skel]☭ ls -a. .. .bash_logout .bash_profile .bashrc .mozilla usermodusermod：修改用户属性 -u UID：修改用户的UID-g：修改用户所属的基本组-G ：修改用户的附加组，原来的附加组会被覆盖掉-a：append，和-G结合使用，表示新添加的组，兵不会覆盖掉原来的组-c COMMENT：修改注释信息-d：修改用户的家目录，用户原有的文件不会被转移到新位置。-m：move-home，更改用户主目录，和-d配合使用，会移动原来家目录的文件。-l：修改用户名 -s SHELL： 修改用户的默认shell，可用于所有shell列表存在的shell(shell列表：/etc/shells) -L：Lock，锁定用户密码（在原来的密码字符串之前加一个!） -U：unlock，解锁用户的密码（删掉!） userdeluserdel：删除用户-r：删除用户并删除其家目录和mail spool passwdpasswd修改用户自己的密码passwd USERNAME修改其他用户的密码（root有此权限） -- stdin 参数 echo ‘test2&#39; | passwd --stdin test2记住echo后面的字符串要用弱引用，强引用的话如果密码串里有特殊字符，就会不是原始密码了。 其他相关命令chagechage：change age 更改用户密码过期时间 chage USERNAME：不跟参数，会进入一个交互式的模式来修改各个时间，如下面：设置最短修改密码时间为0；最长密码时间为92天过期，上次更改密码时间保持默认那天（20170526），快过期的开始警告设置的在快过期前7天开始，密码过期后，7天内要修改密码，否则变为不活动（Inactive，即锁住），最后一条是设置账号过期时间，设置为默认不过期（-1）。 12345678910[root❄centos7 skel]☭ chage gentooChanging the aging information for gentooEnter the new value, or press ENTER for the default Minimum Password Age [0]: 0 Maximum Password Age [99999]: 92 Last Password Change (YYYY-MM-DD) [2017-05-26]: Password Expiration Warning [7]: 7 Password Inactive [-1]: 7 Account Expiration Date (YYYY-MM-DD) [-1]: 带参数，下面是参数设置，和上面类似，就是把交互式变成了参数选项： chage [option] USERNAME -d LAST_DAY -d 0:第一次登陆，强制让你该口令。 -E –expiredate EXPIRE_DATE -I –inactive INACTIVE -m –mindays MIN_DAYS -M –maxdays MAX_DAYS -W –warndays WARN_DAYS –l 显示密码策略 示例： 12345chage -d 0 tom #下一次登录强制重设密码chage -m 0 –M 42 –W 14 –I 7 tomchage -E 2016-09-10 tom idid [USERNAME]：显示用户的uid和gid，USERNAME省略的话表示只显示当前用户的id信息。 -u显示用户id -g显示基本组id -G显示所有组id -n显示名字而不是id susu命令：switch user，切换用户 登录式切换：会通过读取目标用户的配置文件来重新初始化 su - USERNAME*su -l USERNAMEl就表示login 非登陆式切换：不会读取目标用户的配置文件来进行初始化 su USERNAME Note：管理员可无密码切换到其他任意用户。 参数：-c &#39;COMMAND&#39;：仅以目标用户登录，后执行后面的命令，然后就退出 示例：su -test -c &#39;whoami&#39; getentget entries from Name Service Switch libraries从命名服务切换库获得条目 getent passwd [USERNAME]：不输入USERNAME默认是全部用户，如果输入了，就是指定的那个 12[root❄centos7 skel]☭ getent passwd gentoogentoo:x:1001:1001:Gentoo Distribution:/home/gentoo:/bin/csh getent shadow [GROUPNAME]：不输入GROUPNAME默认是全部用户组信息，如果输入了，就是指定的那个 12[root❄centos7 skel]☭ getent shadow gentoogentoo:!!:17312:0:92:7:7:: finger查看用户信息 12345678910[root❄ centos7 ~]☭ finger rootLogin: root Name: rootDirectory: /root Shell: /bin/bashOn since Sun May 28 16:17 (CST) on pts/0 from 172.17.251.64 4 seconds idleOn since Wed May 24 20:40 (CST) on :0 from :0 (messages off)On since Wed May 24 20:40 (CST) on pts/2 from :0 3 days 19 hours idleNo mail.No Plan.]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>user</tag>
        <tag>group</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[02-用户和组文件]]></title>
    <url>%2Flinux%2F20170526-02-user-group-file%2F</url>
    <content type="text"><![CDATA[/etc/passwdroot:x:0:0:root:/root:/bin/bash 1234whatis passwdman 5 passwdname:password:UID:GID:GECOS:directory:shell name：用户名 password：密码占位符x UID：User ID GID：Group ID GECOS：注释信息 directory：用户的家目录 shell：用户的默认shell，登录时候默认的shell程序 tips：用户的注释信息（GECOS）可以通过chfn更改： 12345678[root❄centos7 ~]☭ chfn LongDreamChanging finger information for LongDream. Name [LongDream]: Yu LongjunLongjun Office []: Beijing Office Phone []: 010-8888888 Home Phone []: 188888888Finger information changed. 1234567[root❄centos7 ~]☭ finger LongDreamLogin: LongDream Name: Yu LongjunDirectory: /home/LongDream Shell: /bin/bashOffice: Beijing, 010-8888888 Home Phone: +1-888-888-8888Last login Thu May 25 08:59 (CST) on pts/0No mail.No Plan. /etc/shadowroot:$6$gzEdnxzX$na8Z8EEYpr.piY4jcCsC.52.4HG0uo6aSbvdg5Yu1TJetkmKGfYElSS//AebAglmUoW.Z5QodAHYpatAfg7pR/:16967:0:99999:7::: 以冒号分割的各个段落的意思： account:用户名 encrypted passwd：加密后密码 。两个$符号之间： 第一个6表示加密算法的第六种，sha512sum 第二个是salt（随机数） 第三个是真正的密码块 如果整段为!!，表明被锁定，不能登录，去掉，就可以以空密码登录。可以直接改shadow文件，给有密码的前面加个！号，这个账号就无法登录了。 date of last passwd change：最后一次更改密码的日期。最近一次更改密码的时间，从1970年1月1日开始的天数。如果是0，表示用户要在下次登录时候更改密码。空表示被禁用了 minimum passwd age：最小密码年龄。更改密码后，最短多长时间能更改密码，默认是0，随时可以更改 maximum password age：最大密码年龄。在更改密码多少天后，用户必须要更改密码，默认是99999，相当于永不过期 password warning period：密码警告时间段密码过期之前，提前警告用户的天数，一般是7，提前7天通知你。 password inactivity period：密码禁用期密码过期了之后，仍可以用旧密码的天数，过了这个天数，就给你锁定了，只能用root去解锁了。默认是空，永远可以用。 account expiration date：账号过期日期账户要多少天过期，从1970年1月1日起的天数来表示，如果过期了，这个账号就不能使用了。默认是空，永不过期。 reserved field：保留字段，后续功能添加 /etc/grouproot:x:0: group_name:passwd:GID:user_list group_name：组名 passwd：组密码 GID：组ID user_list：附加组的用户 tips：由于安全问题，group的密码一般不设置，所以gshadow文件也不用去研究，基本不用。所以只讲了上面三个文件，不用研究/etc/gshadow]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>group</tag>
        <tag>passwd</tag>
        <tag>shadow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[01-什么是用户和组]]></title>
    <url>%2Flinux%2F20170526-01-whatis-user-group%2F</url>
    <content type="text"><![CDATA[3A Authentication：认证（用户的识别（密码、指纹、虹膜）） Authorization：授权（用户的访问权限控制） Accounting：审计（用户的动作记录，监督权限的使用） 用户：user组：group（组在有些系统里组被称为角色） 用户用户类别: 管理员 普通用户 系统用户 登录用户 用户标识： UID(User ID)，范围为16bits（0-65535） 管理员：0 普通用户：1-65535 系统用户：1-499（CentOS6）1-999（CentOS7） 登录用户：500-60000（CentOS6），1000-60000（CentOS7）、 名称解析：UserName &lt;–&gt; UID根据名称解析库进行：/etc/passwd 组组类别1 管理员组 普通用户组 系统组 登录组 组标识： GID(Group ID)，范围为16bits（0-65535） 管理员：0 普通用户组：1-65535 系统组：1-499（CentOS6）1-999（CentOS7） 登录组：500-60000（CentOS6），1000-60000（CentOS7）、 名称解析：GroupName &lt;–&gt; GID根据名称解析库进行：/etc/group 组类别2一个用户属于多个组，可以划分为： 用户主组(基本组)(g)：primary group 附加组(G)：supplymentary group 用户必须属于主组，有且只有一个主组，附加组可有可无，可以有多个。 组类别3私有组：组名同用户名，且只包含一个用户公共组：组内包含了多个用户 认证信息通过比对事先存储的信息，与登录时候提供的信息否一致。密码：passwd /etc/shadow(用户密码)/etc/gshadow(组密码) 加密算法： 对称加密：加密和解密使用同一个密码 非对称加密：加密和解密使用一对儿秘钥。 公钥：public key 私钥：private key 单向加密：只能加密，不能解密：提取数据特征码 定长输出（跟原来的数据量多大没关系） 雪崩效应（数据的一点点差别，加密后差别很大 ）echo &quot;How are you?&quot; | md5sumecho &quot;How are you&quot; | md5sum 算法： md5：message digest（消息摘要）version5， 128位 sha：secure hash algorithm（安全的哈希算法） sha1sum sha224sum sha256sum sha384sum sha512sum 账户输入密码后，加点salt（添加随机数），这样保证不同用户用同样的密码，加密后结果不一样。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>user</tag>
        <tag>group</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IO重定向和管道练习题]]></title>
    <url>%2Flinux%2F20170524-03-practice%2F</url>
    <content type="text"><![CDATA[1、将/etc/issue文件中的内容转换为大写后保存至/tmp/issue.out文件中 答案（两种方法）： 123tr &apos;a-z&apos; &apos;A-Z&apos; &lt; /etc/issue &gt; /tmp/issuecat /etc/issue | tr &apos;a-z&apos; &apos;A-Z&apos; &gt; /tmp/issue 解析： 第一种方法用的输入输出重定向，是把/etc/issue文件作为tr命令的输入，然后输出到/tmp/issue; 第二种方法是用的管道和输出重定向，把cat命令的输出，作为tr命令的输入，然后结果输出到/tmp/issue 2、将当前系统登录用户的信息转换为大写后保存至/tmp/who.out文件中 答案： 1who |tr &apos;a-z&apos; &apos;A-Z&apos; &gt; /tmp/who.out 解析： who输出的登录信息，作为tr命令的输入，然后tr命令的输出重定向到/tmp/who.txt文件 3、一个linux用户给root发邮件，要求邮件标题为”help”，邮件正文如下： Hello, I am 用户名,The system version is here,please help me to check it ,thanks!操作系统版本信息 答案： 1234cat &lt;&lt;EOF | mail -s help root&gt;Hello, I am $USER,The system version is here,please help me to check it ,thanks! &gt;My OS is `cat /etc/centos-release`&gt;My OS&apos;s Kernel is `uname -a` 解析： 先用cat &lt;&lt;EOF来把下面行的输入信息 输出出来，作为后面mail命令的输入。 4、将/root/下文件列表，显示成一行，并文件名之间用空格隔开 答案： 1ls -1 |tr &apos;\n&apos; &apos; &apos; 解析： ls显示所有文件行，用tr命令把尾部的\n替换成空格 5、计算1+2+3+..+99+100的总和 答案： 1echo &#123;1..100&#125; |tr &apos; &apos; &apos;+&apos; |bc 解析： echo输出100个数，然后把中间的空格转化为加号，然后再传给bc计算 6、删除Windows文本文件中的‘^M’字符 答案： 1cat windows.txt |tr -d &quot;\r&quot; 解析： 7、处理字符串“xt.,l 1 jr#!$mn 2 c*/fe 3 uz 4”，只保留其中的数字 和空格 答案： 1echo “xt.,l 1 jr#!$mn 2 c*/fe 3 uz 4” | tr -d &quot;^0-9 &quot; 解析： -d选项是delete的意思，^是非的意思，0=9是数字，后面跟一个空格，组合起来就是非数字和空格，然后-d删除 8、将PATH变量每个目录显示在独立的一行 答案： 1echo $PATH | tr &quot;:&quot; &quot;\n&quot; 解析： 冒号转化为换行 9、将指定文件中0-9分别替代成a-j 答案： 1tr &quot;0-9&quot; &quot;a-j&quot; file 解析： 略 10、将文件中每个单词（由字母组成）显示在独立的一行，并无空行 答案： 1cat 1.log |tr -c &apos;a-zA-Z&apos; &apos;\n&apos; 解析： cat命令的输出，作为tr命令的输入，-c选项是选择补集，即不是字母的单词]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>inode</tag>
        <tag>link</tag>
        <tag>hard link</tag>
        <tag>soft link</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[02-管道]]></title>
    <url>%2Flinux%2F20170524-02-pipe%2F</url>
    <content type="text"><![CDATA[管道（|）基本用法管道（|）用来连接命令 命令格式： COMMAND1 | COMMAND2 | COMMAND3 | ... 实现了把前一个命令的标准输出作为后面命令的输入。 tips: IO重定向和管道的区别：IO重定向，是把前一个命令的标准输出，重定向到普通文件或者设备文件。而管道，是把前一个命令的标准输出作为后面命令的标准输入。一个是到文件，一个是作为后面命令的标准输入。 例子： ls -C | tr &#39;a-z&#39; &#39;A-Z&#39;：ls出来的文件列表，作为tr的输入，这样小写被转化为大写。 ls -l /etc |less：ls输出的文件列表，作为less的输入，这样可以逐行显示 echo &quot;test email&quot; | mail-s &quot;test&quot; user@example.com：echo输出的字符串，作为mail 的输入 cat /etc/issue | tr &#39;a-z&#39; &#39;A-Z&#39;：略 who | head -2 | tr &#39;a-z&#39; &#39;A-Z&#39; | tr -d &#39;0-9&#39;：略 echo &#39;Text through stdin&#39; | cat - file.txt tips：在上面代码中，-指的就是前面输出的内容，再举个例子：123456[root@fedora Scripts]# touch 1 2 3 4 5[root@fedora Scripts]# ls [0-9]1 2 3 4 5[root@fedora Scripts]# ls [0-9] |xargs rm -rf -[root@fedora Scripts]# ls [0-9]ls: cannot access &apos;[0-9]&apos;: No such file or directory 2&gt;&amp;1和|&amp;当既有标准输出又有错误输出的时候，标准输出是可以输入到后面命令的，错误输出是无法输入到后面命令。可以使用2&gt;&amp;1和|&amp;实现错误的也输入到后面命令。1234567891011121314151617181920[root❄centos7 app]☭ ls /app /err | tr &apos;a-z&apos; &apos;A-Z&apos;ls: cannot access /err: No such file or directory/APP:F1ISSUE2ISSUE3[root❄centos7 app]☭ ls /app /err 2&gt;&amp;1 | tr &apos;a-z&apos; &apos;A-Z&apos;LS: CANNOT ACCESS /ERR: NO SUCH FILE OR DIRECTORY/APP:F1ISSUE2ISSUE3[root❄centos7 app]☭ ls /app /err |&amp; tr &apos;a-z&apos; &apos;A-Z&apos;LS: CANNOT ACCESS /ERR: NO SUCH FILE OR DIRECTORY/APP:F1ISSUE2ISSUE3 teetee：read from standard input and write to standard output and files从标准输入读，写到标准输出和文件。当然如果再跟一个管道，标准输出就输出到另外一个命令了。 12345678910111213# 写到屏幕和文件/tmp/issue.tee[root❄centos7 ~]☭ cat /etc/issue | tee /app/issue.tee\SKernel \r on an \m[root❄centos7 ~]☭ cat /app/issue.tee\SKernel \r on an \m# 写到/tmp/issue.tee ，写到标准输出的通过管道又传递了一次[root❄centos7 ~]☭ cat /etc/issue | tee /tmp/issue.tee | tr 'a-z' 'A-Z'\SKERNEL \R ON AN \M]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>pipe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[01-IO重定向]]></title>
    <url>%2Flinux%2F20170524-01-io-redirection%2F</url>
    <content type="text"><![CDATA[标准IO（Standard Input/Output）可用于做输入的设备： 键盘设备、文件系统上的常规文件、网卡等。 可用于做输出的设备： 显示器、文件系统上的常规文件、网卡等。 程序的数据流有三种： 输入的数据流：&lt;– 标准输入（stdin(standard input)）,默认接受来自键盘的输入。 输出的数据流：–&gt; 标准输出（stdout(standard output)），默认输出到终端窗口。 错误输出流：–&gt; 标准错误（stderr(standard error)），默认输出到终端窗口。 fd:file descriptor，文件描述符标准输入：0标准输出：1标准错误：2 echo $?（bash脚本编程中，很多判断基于$?这个来决定） IO重定向(Input/Output Redirection) 输入本来默认是键盘，我们改成其他输入，就是输入重定向 ：例如从文本文件里输入。本来输出的位置是显示器，我们改成其他输出，就是输出重定向：例如输出到文件。 set -C： 禁止覆盖输出重定向到已存在的文件(在这种模式下，如果你非要覆盖，可以使用&gt;|） set +C： 关闭上述特性 /dev/null 特殊设备，空设备，也叫黑洞，数据进去都没了。 输出重定向（Output Redirection）的几种方法1. 正常输出重定向：&gt;（覆盖输出）、&gt;&gt;（追加输出）例子：1234567891011121314&gt;&gt;&gt; cat /etc/issue &gt; /tmp/issue.out#开两个ssh连接,我们先看第二个的终端所在的虚拟设备文件，然后在第一个输入#第二个ssh：&gt;&gt;&gt; tty/dev/pts/1#第一个ssh输入：&gt;&gt;&gt; cat /etc/issue &gt; /dev/pts/1# 我们看到第二个ssh输出了信息#追加输出ls /var &gt; /tmp/test.outcat /etc/fstab &gt;&gt; /tmp/test.out 2. 错误输出重定向：2&gt;（覆盖输出）、2&gt;&gt;（追加输出）123ls /etc/issue1111 2&gt;&gt; /tmp/error.outcatt /etc/issue 2&gt;&gt; /dev/null 3. 正确和错误的都进行输出重定向： 新写法：COMMAND &amp;&gt; /path/to/somefile、COMMAND &amp;&gt;&gt; /path/to/somefile 老写法：COMMAND &gt; /path/to/somefile 2&gt;&amp;1、COMMAND &gt;&gt; /path/to/somefile 2&gt;&amp;1 1234ls /boot /err &amp;&gt; /tmp/all1.log # 新写法ls /boot /err &amp;&gt;&gt; /tmp/all2.log # 新写法ls /boot /err &gt; /tmp/all3.log 2&gt;&amp;1 # 老写法ls /boot /err &gt;&gt; /tmp/all4.log 2&gt;&amp;1 # 老写法 输入重定向（Input Redirection）的方法tr命令tr [OPTION]... SET1 [SET2]把输入的数据当中的字符，凡是在SET1定义范围内出现的，通通对位转换为SET2出现的字符 tr SET1 SET2 &lt; /path/from/somefile对位转化SET1中的字符为SET2中的字符 tr -d SET1 &lt; /path/from/somefile删除指定集合里出现的字符 tr -s &quot;\n&quot; /path/from/somefile把指定的连续的字符以一个字符表示，压缩。 tr -cComplement ,取字符集的补集，通常与其他参数结合使用，例如-dc 123456789101112[root❄centos7 ~]☭ tr &apos;a-z&apos; &apos;A-Z&apos;aabbcc33AABBCC33^C[root❄centos7 ~]☭ tr &apos;a-z&apos; &apos;A-Z&apos; &lt;/etc/issue\SKERNEL \R ON AN \M[root❄centos7 ~]☭ tr &apos;a-z&apos; &apos;A-Z&apos; &lt; /etc/issue &gt; /app/issue2[root❄centos7 ~]☭ cat /app/issue2\SKERNEL \R ON AN \M tips：如果是输入后再输出到同一个文件，就会清空这个文件，所以最好不要这么用，下面是一个错误示范： 12345[root❄centos7 ~]☭ cd /app/[root❄centos7 app]☭ cp issue2 issue3[root❄centos7 app]☭ tr &apos;a-z&apos; &apos;A-Z&apos; &lt; issue3 &gt;issue3[root❄centos7 app]☭ cat issue3[root❄centos7 app]☭ 追加是可以的，在原有文件基础上再追加一段： 1234567891011[root❄centos7 app]☭ cat issue2\SKERNEL \R ON AN \M[root❄centos7 app]☭ tr &apos;A-Z&apos; &apos;a-z&apos; &lt; issue2 &gt;&gt; issue2[root❄centos7 app]☭ cat issue2\SKERNEL \R ON AN \M\skernel \r on an \m dc结合使用 123456789[root❄centos7 app]☭ echo &#123;a..z&#125; &gt;f1[root❄centos7 app]☭ cat f1a b c d e f g h i j k l m n o p q r s t u v w x y z[root❄centos7 app]☭ tr -d &apos;f-n&apos; &lt;f1a b c d e o p q r s t u v w x y z[root❄centos7 app]☭ cat f1a b c d e f g h i j k l m n o p q r s t u v w x y z[root❄centos7 app]☭ tr -dc &apos;f-n&apos; &lt; f1fghijklmn[root❄centos7 app]☭ Here documents输出到屏幕，或创建多行文档)：&lt;&lt;终止词 例子： 123456789101112131415161718192021[root❄centos7 app]☭ cat &lt;&lt;EOF&gt; yulongjun&gt; zhaoweiqiang&gt; EOFyulongjunzhaoweiqiang[root❄centos7 app]☭ cat &gt;cat.out &lt;&lt;END&gt; yulongjun&gt; zhaoweiqiang&gt; hanjinze&gt; songda&gt; END[root❄centos7 app]☭ cat /tmp/cat.out yulongjunzhaoweiqianghanjinzesongda -代表输出流 此段来源于：https://www.cnblogs.com/dachenzi/p/6790596.html 搭配cat cat -：如果指定cat的文件为-，表示从标准输入读取（和直接使用cat，好像没什么区别） 搭配| echo 123 | cat -：表示把管道符前面的输出流，在交给cat执行一遍（这就很牛逼了） 例子： 如果操作系统没有scp命令，只有ssh，那么是不是就不能远程拷贝了（前提：没有openssh-clients软件包） 利用-，就可以实现： 1cat jdk.tar.gz | ssh 192.168.56.101 &apos;cat - &gt; /tmp/jdk.tar.gz&apos; cat jdk.tar.gz 产生输出流， 在管道后面的 - ,则可以接受输出流，并重定向到 /tmp/jdk.tar.gz]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>IO</tag>
        <tag>IO Redirection</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[05-inode、软硬链接]]></title>
    <url>%2Flinux%2F20170522-05-inode-link%2F</url>
    <content type="text"><![CDATA[关于inode是什么，可以看这篇文章：http://www.cnblogs.com/adforce/p/3522433.html 如何查看inodell -di /boot / /app查看文件和文件夹的inode号 df -i查看挂载点文件夹的inode号 做inode增长实验创建60万个文件的方法1（效率不高）：for i in {1..600000}; do touch file$1; echo file$i is created;done创建60万个文件的方法2（效率高）：echo file{1..600000} | touch删除前20万个文件：echo file{1..200000} |args rm 在创建的过程中，可以另开一个窗口，用下面命令，每隔1秒运行df -hi命令，可以查看inode的增长情况：watch -n1 df -hi tips：文件粉碎工具shred：shred -uzvn10 FILE重复随机写入10次覆盖源文件，然后最后删除此文件。 硬链接、软链接软链接就相当于Windows的快捷方式，删掉源文件，快捷方式和就失效了，软链接就找不到源文件了。 硬链接相当于多个链接指向同一份数据存储区域，每多一个硬链接，硬链接数+1，如果一个文件，有n个硬链接，删除n-1个硬链接，源文件还在，直到删除所有硬链接，才会删除源文件。 1. 复制（cp） 在复制过程中，复制软连接相当于复制了快捷方式，速度很快，而且可以跨分区。 在复制过程中，复制硬链接分为两种情形： 在同一分区复制，相当于多创建一个链接指向原数据存储位置，速度很快。 在不同分区复制，相当于把原来分区的数据拷贝过去存储，同时创建一个指向新数据区域的指针，速度比较慢。 2. 删除（rm）在删除过程中，删除软连接相当于删除了快捷方式，源文件还在。在删除过程中，删除硬连接相当于删除了一个到数据块的指针，，除非删除所有硬链接文件，源文件才删除。 3. 移动（mv）在移动过程中，移动软连接相当于移动了快捷方式而已。在移动过程中，移动硬连接分为两种情形： 在同一分区移动，相当于创建了一个新inode，指向数据块，并把原来的inode删掉 在不同分区移动，要把数据块复制到新分区，然后在新分区创建新的inode号指向新的数据块，并且把原来分区的inode号和数据块都删掉。 4. 软连接支持对目录创建，硬链接不支持 ln dir1 dir2不成功 ln /etc/sysconfig/network-scripts/ifcfg-ens33 /etc/ens33成功 tips1：当我们看到一个磁盘，使用空间没满，但是却提示”no space left on device”，那可能是inode用完了。 tips2：如何删除数量很多的文件（比如前面做实验创建的60万个文件。）:技巧是使用管道|和xargs，管道|后面会讲，管道是指的是前面命令的输出作为后面命令的输入。xargs，前面命令多个输出，可以用xargs一个个的传给后面的命令，而不是已下载全传给后面命令，可以解决参数太长的情况。 ls | xargs rm 5. 如何写软连接相对路径 软连接写相对路径，要根据软连接文件的路径来写。 例如要在把/etc/issue 软连接到/app/d1/d2/d3/ilink 1ln -s ../../../../../etc/issue /app/d1/d1/d3/ilink 6. 如何软链接设备文件 设备文件比较特殊，如果要创建设备文件的链接，需要用到mknod命令： 12345[root@centos7 etc]# ll /dev/sdabrw-rw----. 1 root disk 8, 0 May 22 09:06 /dev/sda #得到主设备号和复设备号。mknod /app/sda b 8 0ll -i /dev/sda /app/sda 软链接练习： 创建一个目录tomcat-8.5.23，创建一个软连接tomcat到这个目录；在创建一个目录tomcat-9.0.1, 把tomcat的软连接指向新的tomcat-9.0.1目录。 123ln -sv tomcat-8.5.23 tomcatrm -rf tomcatln -sv tomcat-9.0.1 tomcat 创建一个目录/mnt/lfs/tools， 然后创建/mnt/lfs/tools的软连接/tools，一般有这样的命令：ln -sv /mnt/lfs/tools /tools，如何可以更短？ 12mkdir -v /mnt/lfs/toolsln -sv /mnt/lfs/tools / file命令常用选项: -b 列出文件辨识结果时，不显示文件名称 -f 列出文件中文件名的文件类型 -F 使用指定分隔符号替换输出文件名后默认的”:”分隔符 -L 查看对应软链接对应文件的文件类型 --help 显示命令在线帮助 file /etc/system-relase file命令就是查看的文件头部的信息，可以用hexdump查看源文件源码信息 （也可以用xxd命令看）。 如果是二进制文件，会显示二进制的头信息。 如果是文本文件，就直接是文本。 1234567891011121314[root@centos7 ~]# hexdump -C -n 100 /bin/ls00000000 7f 45 4c 46 02 01 01 00 00 00 00 00 00 00 00 00 |.ELF............|00000010 02 00 3e 00 01 00 00 00 48 4b 40 00 00 00 00 00 |..&gt;.....HK@.....|00000020 40 00 00 00 00 00 00 00 18 c4 01 00 00 00 00 00 |@...............|00000030 00 00 00 00 40 00 38 00 09 00 40 00 1e 00 1d 00 |....@.8...@.....|00000040 06 00 00 00 05 00 00 00 40 00 00 00 00 00 00 00 |........@.......|00000050 40 00 40 00 00 00 00 00 40 00 40 00 00 00 00 00 |@.@.....@.@.....|00000060 f8 01 00 00 |....|00000064[root@centos7 ~]# hexdump -C -n 100 /etc/issue00000000 5c 53 0a 4b 65 72 6e 65 6c 20 5c 72 20 6f 6e 20 |\S.Kernel \r on |00000010 61 6e 20 5c 6d 0a |an \m.|00000016 readlink命令读取软连接指向的真实路径 12[root❄centos7 ~]☭ readlink /etc/redhat-release centos-release]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>inode</tag>
        <tag>link</tag>
        <tag>hard link</tag>
        <tag>soft link</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[04-Linux文件类型和文件相关命令]]></title>
    <url>%2Flinux%2F20170522-04-linux-file-command%2F</url>
    <content type="text"><![CDATA[文件类型ll后可以看到文件详情： -：常规文件（内部类型是什么，用file命令） d：directory，目录文件 b：blobk device，块设备文件，支持以“block”为单位进行随机访问 major number：主设备号，用来表示设备类型，进而确定要加载的驱动程序 minor number：次设备号，用于表示同一类型中的不同设备。 如下图的1,3 、1,5 c：character device，字符设备文件，支持以”character”为单位进行线性访问 l：symbolic link，符号链接文件（软连接文件） p：pipe，命名管道 s：socket，套接字文件 路径绝对路径：以斜线开始的，从/开始的路径。 /etc/syscofnig/network-scrpits绝对路径分为两段，dirname和basename： 1234[root@centos7 app]# dirname /etc/sysconfig/network-scripts/ifcfg-ens192/etc/sysconfig/network-scripts[root@centos7 app]# basename /etc/sysconfig/network-scripts/ifcfg-ens192ifcfg-ens192 相对路径：不以斜线开始的路径。 xxx/yyy ：当前目录下的xxx子目录的yyy子目录 .：当前目录 ..：上级目录 ~：用户的家目录 -：切换上次输入的目录，和命令配合使用 tips:-原理，系统记住上一个工作目录，存储在环境变量OLDPWD，可以用echo $OLDPWD查看到。 常用命令：1. pwd：显示工作目录printing working directory 2. cd：切换目录change directory cd：切换到家目录 cd ~：切换到家目录 cd ~USERNAME：切换到用户USERNAME的家目录 cd -：在上一次所在目录与当前目录来回切换（PWD to OLDPWD） cd ..：切换到上级目录 cd /path/to/directory 切换到一个绝对目录 cd path/to/directory：切换到一个相对目录 3. ls：列出内容list(用/var目录做例子) -a， --all：列出所有文件包含隐藏文件 -A，--almost-all：列出除.和..之蛙所有的文件 -F：-F参数在目录名后加了正斜线（/），以方便用户在输出中分辨它们。类似地，它会在可执行 文件（比如上面的my_script文件）的后面加个星号，以便用户找出可在系统上运行的文件。 l，--long：长格式信息，列出文件的详细属性，命令可以简写为ll，alias ll=&#39;ls -l --color=auto&#39; -h，--human-readable：size用人类可读的格式表示 -d, --directory：查看目录本身而非内部的文件详情 -r, --reverse：反转排序（降序） -R, --recursive 递归显示（基本不用这个，递归显示用tree命令更直观） -t：按修改时间排序 4. cat：文本文件输出到终端concatenate 拼接 可以单独cat：cat /etc/issue 可以连接多个文件显示cat /etc/issue /etc/redhat-release 123456789[root@CentOS6 app]# cat /etc/issueCentOS release 6.9 (Final)Kernel \r on an \m[root@CentOS6 app]# cat /etc/issue /etc/redhat-releaseCentOS release 6.9 (Final)Kernel \r on an \mCentOS release 6.9 (Final) 参数： cat -s file：删除多余的空白行（多行空白行，删除到只剩一行空白行） 12345678910111213141516171819$ cat multi_blanks.txt line 1line2line3line4$ cat -s multi_blanks.txt #压缩相邻的空白行 line 1line2line3line4 cat -T file：将制表符显示为^I 用来看脚本里的制表符，通常我们写脚本要避免用制表符，而用多个空格。所以此命令通常用来查询哪里用了制表符。 cat -n file：显示行号 123456789$ cat lines.txt line line line$ cat -n lines.txt 1 line 2 line 3 line 5. tac： 跟cat相反，从后面行往前面行输出stat 查看文件状态可以看到atime(Access)、mtime(Modify)、Ctime(Change)，还有文件的权限，文件拥有者和拥有组，还有文件大小相关的内容。12345678910[root@centos7 ~]# stat /etc/issue File: ‘/etc/issue’ Size: 23 Blocks: 8 IO Block: 4096 regular fileDevice: 802h/2050d Inode: 134320235 Links: 1Access: (0644/-rw-r--r--) Uid: ( 0/ root) Gid: ( 0/ root)Context: system_u:object_r:etc_t:s0Access: 2017-05-22 09:07:34.832999490 +0800Modify: 2016-11-30 02:12:59.000000000 +0800Change: 2017-05-17 16:53:20.670996867 +0800 Birth: - 6. 文件通配符（globbing） * ：匹配零个或多个字符 ? ：匹配任何单个字符 ~ ：当前用户家目录 ~longdream ：用户longdream的家目录 ~+ ：当前工作目录 ~-：前一个工作目录 [0-9]：匹配数字范围，匹配一个 [a-z]或[A-Z]：字母，不区分大小写 tips：因为不区分大小写，[a-d]代表的就是匹配AaBbCcDd中的一个 [a-z0-9]：字母或数字 [wang]：匹配列表中的任何的一个字符,匹配w或a或n或g [^wang] 匹配列表中的所有字符以外的字符，除了w、a、n、g 只显示隐藏文件： 预定义的字符类：man 7 glob [:digit:]：任意数字，相当于0-9 [:lower:]：任意小写字母 [:upper:]: 任意大写字母 [:alpha:]: 任意大小写字母 [:alnum:]：任意数字或字母 [:blank:]：水平空白字符 [:space:]：水平或垂直空白字符 [:punct:]：标点符号 [:print:]：可打印字符 [:cntrl:]：控制（非打印）字符 [:graph:]：图形字符 [:xdigit:]：十六进制字符 练习练习1：显示/var/log目录下所有以l开头，以一个小写字母结尾，且中间出现一位任意字符的文件或目录。 练习2：显示/etc目录下，以任意一位数字开头，且以非数字结尾的文件或目录。 练习3：显示/etc目录下，以非字母开头，后面跟一个字母及其他任意长度任意字符的文件或目录。 练习4：复制/etc目录下，所有以m开头，以非数字结尾的文件或目录到/tmp/test目录。 练习5：复制/usr/share/man目录下，所有以man开头，后跟一个数字结尾的文件或目录至/tmp/test/man目录下。 练习6：复制/etc目录下，所有以.conf结尾，且以m,n,r,p开头的文件或目录到/tmp/conf.d/目录下。 答案： 123456789101112131415ls -d /var/l?[[:lower:]]ls -d /etc/[0-9]*[^0-9]ls -d /etc/[^a-z][a-z]*mkdir /tmp/testcp -r /etc/m*[^0-9] /tmp/test/mkdir /tmp/test/mancp -r /usr/share/man/man[0-9] /tmp/test/manmkdir /tmp/conf.dcp -r /etc/[mnrp]*.conf /tmp/conf.d/ 7. touchtouch [OPTION]... FILE... -a ：仅改变 atime和ctime -m ：仅改变 mtime和ctime -t [[CC]YY]MMDDhhmm[.ss]：指定atime和mtime的时间戳 -c ：如果文件不存在，则不予创建 9. cpcp ：copy cp /etc/fstab /app ：复制单个文件到目录下面。cp /etc/{fstab,issue} /app/dir/，cp /etc/fstab /etc/bashrc /app/dir/：复制多个文件到某目录下。cp /etc/fstab /app/1.txt ：复制并覆盖目标文件（没有则创建）。 参数 -f ，--force：强制覆盖目标文件。 -r，-R，`--recursive：递归复制目录 (-r == -R)。cp -r /var/log /app/log -d：复制符号链接本身，而不是他指向的文件。cp -d /etc/system-release /app -a，--archive：归档，等同于-dr -p：复制文件的原来属性，等同于下面的--preserv=[mode,ownership,timestamp] --preserv[=ATTR_LIST] mode：权限 ownership：属主属组 timestamp：时间戳 links：复制链接的源文件 xattr context all -v, --verbose：看到详细信息 练习： 1) 定义别名命令baketc，每天将/etc/目录下所有 文件，备份到/testdir独立的子目录下，并要求子目 录格式为 backupYYYY-mm-dd，备份过程可见 2) 创建/testdir/rootdir目录，并复制/root下所有 文件到该目录内，要求保留原有权限 解答： 1) 1alias baketc=cp -av /etc/* /testdir/`date -u` 2) 1cp -ap /root/* /testdir/rootdir tips: 小技巧 利用通配符来复制：cp -a /etc/passwd{,.bak}相当于 cp -a /etc/passwd /etc/passwd.bak 10. mvmv：move -f 强制移动或覆盖 移动文件（不在同一目录下），重命名文件（在同一目录下）移动目录或重命名目录 11. rename重命名后缀 rename [options] expression replacement file... 选项 1234567891011EXAMPLES Given the files foo1, ..., foo9, foo10, ..., foo278, the commands rename foo foo0 foo? rename foo foo0 foo?? will turn them into foo001, ..., foo009, foo010, ..., foo278. And rename .htm .html *.htm will fix the extension of your html files. 1234mkdir testcd texttouch &#123;1,2,3,4,5&#125;.txtrename -v .txt .txt.bak *.txt rmrm： remove 删除文件-i：interactive，交互式-r 递归删除-f 强制删除 rm -rf /(5是可以删除根的，6和7是不可以删除的) 我们可以留一个习惯：不用的文件，不要直接删除，可以用mv move到某个专用目录（比如都移动到/tmp下） 12. tree参数： -d: 只显示目录 -L level：指定显示的层级数目 -P pattern: 只显示由指定pattern匹配到的路径 13. mkdir、rmdirmkdir：make directory -p 递归创建 -v ：verbose，创建目录的详情 -m mode，权限 rmdir:remove empty directory(只能删除空目录) 练习1：创建test1/x/y1, test1/x/y2, test1/x/y1/a, test1/x/y1/b 练习2： test2目录下面创建a_c, a_d,b_c, b_d 练习3：在test3目录下创建以下目录结构： 1234567891011121314151617181920test3├── bin├── etc│ └── sysconfig│ └── network-scripts├── sbin├── usr│ ├── bin│ ├── lib│ ├── lib64│ ├── local│ │ ├── bin│ │ ├── etc│ │ ├── lib│ │ └── sbin│ └── sbin└── var ├── cache ├── log └── run 练习3：创建/testdir/dir1/x, /testdir/dir1/y, /testdir/dir1/x/a, /testdir/dir1/x/b, /testdir/dir1/y/a, /testdir/dir1/y/b 练习4：创建/testdir/dir2/x, /testdir/dir2/y, /testdir/dir2/x/a, /testdir/dir2/x/b 练习5：创建/testdir/dir3, /testdir/dir4, /testdir/dir5, /testdir/dir5/dir6, /testdir/dir5/dir7 答案： 123456789101112mkdir -pv test1/x/&#123;y1/&#123;a,b&#125;,y2&#125;mkdir -pv test2/&#123;a,b&#125;&#123;c,d&#125;mkdir -pv test3/&#123;bin,sbin,etc/sysconfig/network-scripts,usr/&#123;bin,sbin,local/&#123;bin,sbin,etc,lib&#125;,lib,lib64&#125;,var/&#123;cache,log,run&#125;&#125;mkdir -pv /testdir/dir1/&#123;x,y&#125;/&#123;a,b&#125;mkdir -pv /testdir/dir2/&#123;x/&#123;a,b&#125;,y&#125;mkdir -pv /testdir/dir&#123;3,4,5/dir&#123;6,7&#125;&#125; 14. 延伸删除大文件的方法（没被释放删除，空间还占用的文件）： 实验：在一个会话下，dd if=/dev/zero of=bigfile bs=1M count=2048，vim bigfile，在vim模式下不要退出。 打开另外一个会话窗口，删除文件，结果发现，文件是删除了，但是空间没有释放，因为vim占用着文件。 这时候我们就可以用&gt;来搞定： 12&gt; bigfile3rm -rf bigfile3 &gt; 和&gt;&gt;开单章讲，在后面的IO和重定向部分。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>File Type</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[03-bash快捷键]]></title>
    <url>%2Flinux%2F20170522-03-shotcuts%2F</url>
    <content type="text"><![CDATA[bash中命令运行中相关快捷键和相关命令 &lt;Ctrl + l&gt;：清屏，相当于clear命令。 &lt;Ctrl + c&gt;：取消（终止）前台运行命令，可以用来中断当前运行的命令。&lt;Ctrl + z&gt;：挂起命令到后台，并暂停。命令状态为Stopped。jobs：查看后台的命令，每个命令都有一个序号，从1开始。bg %NUM：将挂起在后台的命令，让其在后台继续运行，NUM为命令的序号。如果不写序号，默认继续运行最后一个挂起的命令。jobs查看命令状态变成Running状态。fg %NUM：后台命令送到前台运行。kill %n：中断(Terminted)后台某个命令。（Stopped状态的和Running状态都可以中断） COMMAND &amp;：把命令送到后台。 nohup COMMAND &amp; [&gt;XXX]：将程序放在后台运行，退出会话也不退出。（如果没有退出会话，jobs可以看到程序，按照序号杀死，如果关了会话的话，jobs是看不到的，杀死程序进程需要找到程序的进程号，用kill杀掉。 1nohup ping github.com &amp; 关于&gt;xxx后面重定向时候会学到。默认nohup 明星会重定向到运行程序的当前目录下的nohup.out。 bash控制和移动快捷键：&lt;Ctrl-a&gt;：光标跳转至行首 （用的最多）&lt;Ctrl-e&gt;：光标跳转至行位 （用的最多）&lt;Ctrl-u&gt;：从光标所在位置删除到行首&lt;Ctrl-k&gt;：从光标所在位置删除到行尾&lt;Alt-f&gt;：光标向右移动到一个单词的末尾&lt;Alt-b&gt;：光标向左移动到一个单词的首部]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>shotcuts</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[02-历史命令用法]]></title>
    <url>%2Flinux%2F20170522-02-history%2F</url>
    <content type="text"><![CDATA[history命令： 直接运行，显示历史命令，默认最多记录1000行 新执行的命令存在内存里，正常退出shell后，会写在~/.bash_history -c清空 -a把当前内存里存的历史命令存入~/.bash_history文件。 *-p 可以有这种用法，反引号里写命令，可以不保存命令到历史（可以用来做坏事哦） 1history -p `hostname` `ifcofnig` -s伪造历史命令，其实没执行： history -s &quot;rm -rf /*&quot;（可以用来吓唬人） tips：printenv可以打印出系统全局变量，可以看到有个HISTSIZE，echo $HISTSIZE可以看到此全局环境变量设置的是1000，这个就是历史命令大小，这个全局环境变量的参数的配置信息存在/etc/profile文件里。 利用历史命令来执行的方法： 常用的几个记住就好： !!：重复执行上一个命令 ! NUM：执行序号为NUM的命令： !-NUM：倒数第几个命令 !:NUM：上一个命令的以空格分割的索引 Esc .：可以重复上面一个命令的最后的参数比如我们本来要编辑一个文件，发现输入错了，输入的cd，可以再输入vim Esc .就把上一条的参数弄过来了。 设置HISTTIMEFORMAT 这样就可以显示每条命令执行的时间。例如设置 ~/.bash_profile里添加用户系统环境变量export HISTTIMEFORMAT=&quot;%F %T &quot;]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>history</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[01-Linux系统层级结构标准]]></title>
    <url>%2Flinux%2F20170522-01-fhs%2F</url>
    <content type="text"><![CDATA[Linux Foundation有一套标准规范: FHS: Filesystem Hierarchy [‘haɪərɑːkɪ] Standard（文件系统层级标准）目前最新的标准是2.3版本：http://refspecs.linuxfoundation.org/FHS_2.3/ /bin ：所有用户可用的基本命令程序文件 /sbin ：系统用户管理命令 /boot： boot loader的静态文件（kernel，initramfs（initrd），grub等） /dev ：存储特殊文件（tty虚拟终端之类）和设备文件（字符设备（键盘、显示器）、块设备（硬盘、光盘）） tips：主设备名，次设备名如/dev/null就是1,3，/dev/zero就是1,5 /etc：配置文件 /home：非root用户的家目录 /root：root用户的额家目录 /lib：为系统启动或者根文件系统上的应用程序（/bin,/sbin）等提供共享库，以及为内核提供内核模块 libc.so.*：动态链接的c库 ld*：运行时链接器/加载器 modules：用于存储内核模块的目录 /lib64：64位系统特有的存放64位共享库的路径 /media：便携式设备的挂载点（如光盘cdrom、u盘floppy）。 /mnt：临时文件系统挂载点。 /opt：附加程序的安装位置 /srv：当前主机为服务提供的数据 /tmp：临时文件（temporary files）（可供所有用户执行写入操作） /usr：全局共享只读文件（Universial Shareable Read-only）（第二主要的层级目录） bin：非系统启动时用到的程序 sbin：非系统启动时用到的系统程序 include：c程序的头文件（header files） lib：程序依赖的库 lib64：程序依赖的库（64位） local：用来安装本地应用程序（又一个层级目录），第三方程序（比如在MacOS下，brew安装的程序都会安装在usr/local/bin下） share：命令man手册页，命令自带文档 /usr/share/dict/words 暴力破解的密码表(弱口令) src：某些程序的源代码 tips ：CentOS 7 都是把根目录的一些目录软连接到/usr下的目录 /var：可变数据文件（系统日志、缓存文件） log cache mail等 /proc：基于内存的虚拟文件系统（一切皆文件，把实时的内核参数和进程的信息进行可视化）（系统调优经常用到） /proc/cpuinfo： /proc/partitions： /sys：sysfs虚拟文件系统，提供了一种比proc更为理想的访问内存数据的途径，为管理Linux设备提供了一种统一模型的接口（see also: https://www.ibm.com/developerworks/cn/linux/l-cn-sysfs/）（**系统条有经常用到**）]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>FHS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[作业]]></title>
    <url>%2Flinux%2F20170519-10-practice%2F</url>
    <content type="text"><![CDATA[1、别名，内部，外部，hash 优先级？ 别名&gt;内部&gt;hash&gt;外部 2、实现screen 协助 一台screen -S协助名称 另外一台screen -ls列出目前开的协助会话(session)，找到上面协助名称对应的session号。 screen -x SESSION，SESSION为上面的会话号码。如果是只有一个的话，可以只输入screen -x 3、显示昨天是星期几 1234[root@centos7 ~]# date --date=&quot;yesterday&quot; +%aSun[root@centos7 ~]# date --date=&quot;yesterday&quot; +%ASunday 4、显示当前时间，格式：2016-06-18 10:20:30 date +&quot;%F %T&quot; 5、设置当前日期为2019-08-07 06:05:10 date 080706052019.10 6、在本机字符终端登录时，除显示原有信息外，再显示当前登录终端号，主机名和当前时间 man issue发现不详细，然后看到提示有12SEE ALSO motd(5), agetty(8), mingetty(8) agetty也不详细，mingetty最详细，我们找到想要的信息了： 12345678910111213141516171819202122ISSUE ESCAPES mingetty recognizes the following escapes sequences which might be embedded in the /etc/issue file: \d insert current day (localtime), \l insert line on which mingetty is running, \m inserts machine architecture (uname -m), \n inserts machine’s network node hostname (uname -n), \o inserts domain name, \r inserts operating system release (uname -r), \t insert current time (localtime), \s inserts operating system name, \u resp. \U the current number of users which are currently logged in. \U inserts &quot;n users&quot;, where as \u only inserts &quot;n&quot;. \v inserts operating system version (uname -v). 可以根据需要来自定义了,vim /etc/isue 123Terminal: \lHostname: \nLocaltime: \t 7、今天18：30自动关机，并提示用户shutdown -h 18:30 &quot;System will shutdown at 18:30, please backup you data&quot;]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>homework</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[09-延伸小技巧screen、script、scriptreplay]]></title>
    <url>%2Flinux%2F20170519-09-screen-script-scriptreplay%2F</url>
    <content type="text"><![CDATA[screen详解：http://www.cnblogs.com/mchina/archive/2013/01/30/2880680.html script &amp; scriptreplayhttp://www.cnblogs.com/cornell/p/3833955.html]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>command</tag>
        <tag>screen</tag>
        <tag>script</tag>
        <tag>scriptreplay</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[07-回显命令]]></title>
    <url>%2Flinux%2F20170519-07-echo%2F</url>
    <content type="text"><![CDATA[echo参数 -E：禁止对在字符串里的那些转义符进行解释，默认echo命令，就带此参数 -n：不自动换行 -e：让\转义符（escapes）生效，同时不会自动加回车。下面是常用的几个转义符，如果字符串中出现以下字符，则特别处理，而不会将它当成一般文字输出： 转义字符意义ASCII码值（十进制）\a响铃(BEL)007\b退格(BS) ，将当前位置移到前一列008\f换页(FF)，将当前位置移到下页开头012\n换行(LF) ，将当前位置移到下一行开头010\r回车(CR) ，将当前位置移到本行开头013\t水平制表(HT) （跳到下一个TAB位置）009\v垂直制表(VT)011\代表一个反斜线字符’’\’092\’代表一个单引号（撇号）字符039\”代表一个双引号字符034\? 代表一个问号 063 \0空字符(NULL)000\ooo1到3位八进制数所代表的任意字符三位八进制\xhh1到2位十六进制所代表的任意字符二位十六进制 打印带颜色的回显：示例：echo -e &#39;\033[43;31;5mFBI Warning!\033[0m&#39; 格式: echo -e “控制码字符串\033[0m” 控制码控制显示字体 如果有多个以m结尾的控制码可以使用分号隔开，在最后加m，例如：\033[43;31;5m 中间写字符串 最后\033[0m结束属性，这样后面的输入不会变颜色。（可以不加最后的这段自己测试下是什么样子） 控制码的说明： \033[0m 关闭所有属性 \033[1m 设置高亮度 \033[4m 下划线 \033[5m 闪烁 \033[7m 反显 \033[8m 消隐 \033[30m -- \033[37m 设置前景色 \033[40m -- \033[47m 设置背景色 \033[nA 光标上移n行 \033[nB 光标下移n行 \033[nC 光标右移n行 \033[nD 光标左移n行 \033[y;xH设置光标位置 \033[2J 清屏 \033[K 清除从光标到行尾的内容 \033[s 保存光标位置 \033[u 恢复光标位置 \033[?25l 隐藏光标 \033[?25h 显示光标 字体背景颜色范围: 40—-49 40: 黑 41: 红 42: 绿 43: 黄 44: 蓝 45: 紫 46: 青 47: 白 字体前景色范围: 30———–39 30: 黑 31: 红 32: 绿 33: 黄 34: 蓝 35: 紫 36: 青 37: 白 引用双引号：&quot;：弱引用，转化变量 单引号：&#39;：强引用不转化，输出原格式 反向单引号：`：反向单引号里运行的是命令，然后把命令作为前面命令的参数 1234567891011121314151617181920212223[root@centos7 ~]# echo &apos;$USER&apos;$USER[root@centos7 ~]# echo $USERroot[root@centos7 ~]# echo &quot;$USER&quot;root[root@centos7 ~]# echo &apos;$USER&apos;$USER[root@centos7 ~]# echo `$USER`bash: root: 未找到命令...[root@centos7 ~]# echo echo $USERecho root[root@centos7 ~]# echo &quot;echo $USER&quot;echo root[root@centos7 ~]# echo &apos;echo $USER&apos;echo $USER[root@centos7 ~]# echo `echo $USER`root[root@centos7 app]# touch oper`date +%F`.log[root@centos7 app]# lsoper2017-05-20.log 命令行扩展：$( ) 或 `` 把一个命令的输出打印给另一个命令的参数1234[root@centos7 ~]# echo &quot;This system&apos;s name is $(hostname) &quot;This system&apos;s name is centos7.yulongjun.com [root@centos7 ~]# echo &quot;i am `whoami` &quot;i am root 括号扩展：{ } 打印重复字符串的简化形式 123456789101112131415161718[root@centos7 app]# echo file&#123;1,3,5&#125;file1 file3 file5[root@centos7 app]# touch file&#123;1,3,5&#125;[root@centos7 app]# lsfile1 file3 file5[root@centos7 app]# rm -rf file&#123;1,3,5&#125;[root@centos7 app]# echo &#123;1..10&#125;1 2 3 4 5 6 7 8 9 10[root@centos7 app]# echo &#123;a..z&#125;a b c d e f g h i j k l m n o p q r s t u v w x y z[root@centos7 app]# echo &#123;z..a&#125;z y x w v u t s r q p o n m l k j i h g f e d c b a[root@centos7 app]# echo &#123;A..z&#125;A B C D E F G H I J K L M N O P Q R S T U V W X Y Z [ ] ^ _ ` a b c d e f g h i j k l m n o p q r s t u v w x y z[root@centos7 app]# echo &#123;000..20..2&#125;000 002 004 006 008 010 012 014 016 018 020/* 三位数字，最大为20，步长为2]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>command</tag>
        <tag>echo</tag>
        <tag>quote</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[06-日期时间相关命令]]></title>
    <url>%2Flinux%2F20170519-06-date-datetime%2F</url>
    <content type="text"><![CDATA[1. date默认直接输入date显示当前系统时间 高级使用方法： date [OPTION]... [+FORMAT] date [-u|--utc|--universal] [MMDDhhmm[[CC]YY][.ss]] 第一种用法是一种显示时间方法： 1234[root@centos7 ~]# date +&quot;%Y%m%d&quot;20170519[root@centos7 ~]# date +&quot;%F %T&quot;2017-05-19 20:01:17 FORMAT的多种格式，可以通过man date来查看具体格式， 下面列出常用的： %F ：年月日全格式，例如2016-06-21 %T ：时间全格式，例如13:14:42 %Y：年 %m：月 %d：日 %H：小时 %M 分 -%S 秒 %s：从1970年1月1日00:00:00开始的秒数 第二种用法是用来更改时间的： 更改的时间格式为MMDDhhmm[[CC]YY][.ss] MM:month DD:day hh:hour mm:minute CC:centery YY:year ss:second 看可选项我们能明白，必须写月日小时分钟，可以只写年的两位，不写世纪，也可以年和世界都不写（就是不更改年），秒可写可不写。例如设置到2012年12月21日 11:11:11 12[root@centos7 ~]# date 122111112012.11Fri Dec 21 11:11:11 CST 2012 2. clock硬件时钟（clock==hwclock）clock又或者hwclock，是一样的命令。 主要用到两个： -s --hctosys：硬件时钟（hardware clock）to 系统时钟（system time），把系统时间调成和硬件时钟一样。-w, --systohc：系统时钟（system time） to 硬件时钟（hardware clock），把硬件时钟调成和系统时钟一样。 3. ntpdatentpdate IP：如htpdate 172.17.0.1 tips：前提是IP所在的那台机器启用了NTP服务，NTP服务后面我们会学，这里先了解下。 4. 更改时区CentOS 6和7都支持的命令：tzselect，是一个交互式的命令。 先让你选择洲，这里我选的5 Asia，然后选择国家，这里我选的9 China，然后选择时区，这里我选的1 Beijing。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859[root@centos7 ~]# tzselect Please identify a location so that time zone rules can be set correctly.Please select a continent or ocean. 1) Africa 2) Americas 3) Antarctica 4) Arctic Ocean 5) Asia 6) Atlantic Ocean 7) Australia 8) Europe 9) Indian Ocean10) Pacific Ocean11) none - I want to specify the time zone using the Posix TZ format.#? 5Please select a country. 1) Afghanistan 18) Israel 35) Palestine 2) Armenia 19) Japan 36) Philippines 3) Azerbaijan 20) Jordan 37) Qatar 4) Bahrain 21) Kazakhstan 38) Russia 5) Bangladesh 22) Korea (North) 39) Saudi Arabia 6) Bhutan 23) Korea (South) 40) Singapore 7) Brunei 24) Kuwait 41) Sri Lanka 8) Cambodia 25) Kyrgyzstan 42) Syria 9) China 26) Laos 43) Taiwan10) Cyprus 27) Lebanon 44) Tajikistan11) East Timor 28) Macau 45) Thailand12) Georgia 29) Malaysia 46) Turkmenistan13) Hong Kong 30) Mongolia 47) United Arab Emirates14) India 31) Myanmar (Burma) 48) Uzbekistan15) Indonesia 32) Nepal 49) Vietnam16) Iran 33) Oman 50) Yemen17) Iraq 34) Pakistan#? 9Please select one of the following time zone regions.1) Beijing Time2) Xinjiang Time#? 1The following information has been given: China Beijing TimeTherefore TZ=&apos;Asia/Shanghai&apos; will be used.Local time is now: Fri May 19 20:31:30 CST 2017.Universal Time is now: Fri May 19 12:31:30 UTC 2017.Is the above information OK?1) Yes2) No#? 1You can make this change permanent for yourself by appending the line TZ=&apos;Asia/Shanghai&apos;; export TZto the file &apos;.profile&apos; in your home directory; then log out and log in again.Here is that TZ value again, this time on standard output so that youcan use the /usr/bin/tzselect command in shell scripts:Asia/Shanghai CentOS 7还有一个非交互式的命令： 时间状态：timedatectl status 列出时区timedatectl list-timezones 更改时区timedatectl set-timezones 洲/城市 6和7都支持一个非交互式的方法，是直接覆盖文件： cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 5. cal显示日历，用法： cal [options] [[[day] month] year] cal：显示当月 cal -y：显示当年日历 cal [[[day] month] year]：如cal 21 12 2012 123456789[root@centos7 ~]# cal 21 12 2012 December 2012 Su Mo Tu We Th Fr Sa 1 2 3 4 5 6 7 8 9 10 11 12 13 14 1516 17 18 19 20 21 2223 24 25 26 27 28 2930 31]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>command</tag>
        <tag>date</tag>
        <tag>clock</tag>
        <tag>ntpdate</tag>
        <tag>timezone</tag>
        <tag>cal</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[05-关机重启命令]]></title>
    <url>%2Flinux%2F20170519-05-shutdown-reboot%2F</url>
    <content type="text"><![CDATA[poweroff ：关机 halt ：关机，CentOS 6 断电，CentOS 7 不断电 reboot ：重启 init方式： init 0：关机 init 3：CLI界面(Command Line Interface) init 5：图形界面(GUI Graphycal U Interface) init 6：重启 shutdown：关机或重启 USAGE：shutdown [OPTIONS] ... TIME [MESSAGE] OPTIONS: -h：halt，关机 -r：reboot，重启 -c：cancel，取消关机或重启 TIME: now: 立刻 +m: 相对时间表示法，多久之后；例如 +3 hh:mm: 绝对时间表示，指明具体时间 MESSAGE：关机前发送的消息广播 shutdown的几个例子： shutdown -h now shutdown -r now shutdown -r +60 shutdown -h 18:30 &quot;系统即将关机&quot; shutdown -c]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>command</tag>
        <tag>poweroff</tag>
        <tag>halt</tag>
        <tag>reboot</tag>
        <tag>init</tag>
        <tag>shutdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[04-别名的使用方法]]></title>
    <url>%2Flinux%2F20170519-04-useage-of-alias%2F</url>
    <content type="text"><![CDATA[主要用到两个命令：alias&amp;unalias` alias：显示当前使用的别名。 alias NAME=&quot;XXXX&quot;：给某段命令或路径加别名 unalias NAME：去掉某个命令的别名 1234567891011121314151617181920212223242526272829[root@centos7 ~]# alias cdnet=&quot;cd /etc/sysconfig/network-scripts/&quot;[root@centos7 ~]# cdnet[root@centos7 network-scripts]# pwd/etc/sysconfig/network-scripts[root@centos7 network-scripts]# aliasalias cdnet=&apos;cd /etc/sysconfig/network-scripts/&apos;alias cp=&apos;cp -i&apos;alias egrep=&apos;egrep --color=auto&apos;alias fgrep=&apos;fgrep --color=auto&apos;alias grep=&apos;grep --color=auto&apos;alias l.=&apos;ls -d .* --color=auto&apos;alias ll=&apos;ls -l --color=auto&apos;alias ls=&apos;ls --color=auto&apos;alias mv=&apos;mv -i&apos;alias rm=&apos;rm -i&apos;alias which=&apos;alias | /usr/bin/which --tty-only --read-alias --show-dot --show-tilde&apos;[root@centos7 network-scripts]# unalias cdnet[root@centos7 network-scripts]# alias alias cp=&apos;cp -i&apos;alias egrep=&apos;egrep --color=auto&apos;alias fgrep=&apos;fgrep --color=auto&apos;alias grep=&apos;grep --color=auto&apos;alias l.=&apos;ls -d .* --color=auto&apos;alias ll=&apos;ls -l --color=auto&apos;alias ls=&apos;ls --color=auto&apos;alias mv=&apos;mv -i&apos;alias rm=&apos;rm -i&apos;alias which=&apos;alias | /usr/bin/which --tty-only --read-alias --show-dot --show-tilde&apos; 不用别名，用原始命令的话，可以用下面的方法： \COMMAND &#39;COMMAND&#39; &#39;/PATH/TO/COMMAND&#39; 如下图，ls原始命令是带颜色的，用\ls后不带颜色了 永久保存alias的方法： 针对一个用户的环境变量：更改vim ~/.bash_rc文件 针对全局用户：更改/etc/bash_rc文件（不推荐，不同用户有不同需要和偏好） 下面是某些alias设置1234alias vi =&quot;vim&quot;alias cdnet=&quot;cd /etc/sysconfig/network-scripts&quot;alias vimnet1=&quot;vim /etc/syscofig/network-scripts/eth0&quot;alias vimnet2=&quot;vim /etc/syscofnig/network-scripts/eth1&quot; 更改完成后，可以用source或.命令来使之立即生效，或者重启shell： 12[root@centos7 ~]# source ~/.bashrc [root@centos7 ~]# . ~/.bashrc]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>alias</tag>
        <tag>unalias</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[03-命令信息相关命令]]></title>
    <url>%2Flinux%2F20170519-03-command-info%2F</url>
    <content type="text"><![CDATA[1. type COMMAND查看命令类型shell builtin（shell 内建命令)： cd、ls、pwd、wall等。 enable或help出来的全是内部命令。help有简单的参数提示。 外部命令：非shell内建命令都是外部命令。 内部和外部都有的命令，优先使用内部命令。 type -a COMMAND：可以列出某命令的所有位置（包括内部和外部） type -P COMMAND：可以显示命令的路径 12345678910111213[root@centos7 ~]# type cdcd is a shell builtin[root@centos7 ~]# type -a cdcd is a shell builtincd is /usr/bin/cd[root@centos7 ~]# type -P cd/usr/bin/cd[root@centos7 ~]# type -a cdcd is a shell builtincd is /usr/bin/cd enable -n COMMAND1 ... COMMANDN：禁用一个或多个命令 enable COMMAND1 ... COMMANDN：启动一个或多个命令 上面这两个命令造成的影响，重登录bash失效。 2. which查看外部命令的路径which -a查看PATH变量下所有路径有没有此命令 which --skip-alias有的命令的别名，加此参数可以路过别名 3. whereis列出外部命令本身路径，和man帮助文件命令12[root@centos7 ~]# whereis cdcd: /usr/bin/cd /usr/share/man/man1/cd.1.gz /usr/share/man/man1p/cd.1p.gz 4. hash哈希表，缓存表系统初始hash表为空，当外部命令执行时，默认会从 PATH路径下寻找该命令，找到后会将这条命令的路径记录到 hash表中，当再次使用该命令时，shell解释器首先会查看hash 表，存在将执行之，如果不存在，将会去PATH路径下寻找。利 用hash缓存表可大大提高命令的调用速率。 hash：显示命令缓存，还有用了几次（hits） hash -l：列出（list）缓存过的命令 hash -p PATH NAME：可以给命令建立缓存 hash -d COMMAND：删除某个命令的缓存 hash -t COMMAND：列出单个别名的路径 hash -r：清空hash表 12345678910111213141516171819202122232425[root@centos7 ~]# hashhits command 2 /usr/bin/file 8 /usr/bin/ls[root@centos7 ~]# hash -lbuiltin hash -p /usr/bin/file filebuiltin hash -p /usr/bin/ls ls[root@centos7 ~]# hash -p /usr/bin/file f[root@centos7 ~]# hash -lbuiltin hash -p /usr/bin/file filebuiltin hash -p /usr/bin/file fbuiltin hash -p /usr/bin/ls ls[root@centos7 ~]# hash -d f[root@centos7 ~]# hash -lbuiltin hash -p /usr/bin/file filebuiltin hash -p /usr/bin/ls ls[root@centos7 ~]# hash -t file/usr/bin/file[root@centos7 ~]# hash -r[root@centos7 ~]# hashhash: hash table empty]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>hash</tag>
        <tag>command</tag>
        <tag>type</tag>
        <tag>which</tag>
        <tag>whereis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[02-查看命令的帮助]]></title>
    <url>%2Flinux%2F20170519-02-command-help%2F</url>
    <content type="text"><![CDATA[whatis模糊操作命令的帮助，并列出在哪个手册，比如下面搜索date，会列出条目和简介里带date字眼的所有命令字段。前面是命令，后面是简介。命令后面括号里的数字指的就是man手册的序号。 12345MBP:~ LongDream$ whatis datecal(1), ncal(1) - displays a calendar and the date of easterdate(1) - display or set date and timeiwidgets_datefield(n), iwidgets::datefield(n) - Create and manipulate a date field widgetntpdate(8) - set the date and time via NTP 执行的whatis 命令是查询数据库提供的，并不一定是最新的，可手动更新数据库，第一次运行可能会有点慢： CentOS 6 上：makewhatis CentOS 7 上：mandb help &amp; --help大部分命令都有--help选项，也是一个简要的帮助文档。 manman后的格式和内容详细的帮助文档：man COMMAND NAME 功能能行说明 SYNOPSIS 语法概要 []表示可选选项 &lt;&gt;表示必需提供的 |多选一 {}分组的 ...前面的内容可以出现多次 DESCRIPTION 描述 OPTIONS 选项 EXAMPLES 使用示例 AUTHOR 作者 REPORTING BUGS 报告bug方式 COPYRIGHT 版权 SEE ALSO 参考其他 man的序号 1-9 用户命令 系统调用 库调用 设备文件 文件格式 游戏 杂项 管理命令 whatis COMMAND：可以查看命令有哪几个manual 12345[root@centos7 ~]# whatis tartar (1) - manual page for tar 1.26tar (5) - format of tape archive files[root@centos7 ~]# whatis ifcfgifcfg (8) - simplistic script which replaces ifconfig IP management 默认查的是序号最小的那个man手册，如要要查其它的，可以用man 序号 COMMAND来查看命令,例如man 5 tar man手册操作方法翻屏操作：很多特别像vim的命令 键盘按键 效果 空格键 向下滚动一屏 b 向上滚动一屏 j 向上移动一行 k或回车 向下移动一行 gg 跳转至第一行 5g 跳转到第5行 G 跳转到最后一行 q 退出 文本搜索 键盘按键 效果 /keyword 向下查找，不区分大小写 ?keyword 向上查找，不区分大小写 n 查找下一个，与查找方向相同 N 查找上一个，与查找方向相反 man选项：man -M /path/to/somedir： 某些程序man目录不在标准的/usr/share/man到指定目录下查找命令手册并打开它。 程序自带帮助文档很多会放在/usr/share/doc/APP-VERSION下 README：程序的相关信息 INSTALL：安装帮助 CHANGES：版本改动信息 主流发行版官方文档http://www.redhat.com/doc等 程序的官方文档官方站点上会有docs/documents/documentation等字眼 善用搜索引擎google搜pdf文档这样： centos filetype:pdf 搜站点里资源都这样：centos site:centos.org 书籍出版社 O’REILLY Wrox 人民邮电出版社 机械工业出版社 电子工业出版社 清华大学出版社 图灵社区]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>command</tag>
        <tag>man</tag>
        <tag>help</tag>
        <tag>whatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[01-命令基本格式]]></title>
    <url>%2Flinux%2F20170519-01-command-base-type%2F</url>
    <content type="text"><![CDATA[命令的基本格式COMMAND [OPTIONS...] [ARGUMENTS...] 命令（COMMAND) 选项（OPTIONS）： 短格式， 如-a、-h、-l、-r、-f等 长格式， 如--forest,--exclude=PATTERN等 参数（ARGUMENTS)：通常为文件 可以执行多个命令，用逗号分隔开ls;pwd;hostname;who 这个不是特别好，如果中间有报错的命令，下面的命令也会继续执行。后面会学一个命令&amp;，可以在前面命令执行成功后再执行后面命令ls&amp;pwd&amp;hostn&amp;who，执行到hostn就会报错，后面的命令不予执行。当然也有好的 \回车后可以再接着写这种方式常用在长格式的命令下面用，段落更清晰。 下面举个例子。tar命令暂时没讲，知道\的作用就行： 12345678[root@centos7 ~]# tar -czvf \&gt; 20170519.tar.gz \&gt; * \&gt; --exclude=&quot;test&quot;anaconda-ks.cfginitial-setup-ks.cfg 执行中的命令退出 ctrl + d：正常退出 ctrl +c：强制退出]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>command</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[08-换行（LF）和回车（CR）详解]]></title>
    <url>%2Flinux%2F20170518-08-lf-cr%2F</url>
    <content type="text"><![CDATA[我们打开Visual Studio Code编辑器，可以看到右下角有这个LF，这是VS Code的默认行尾序列的符号： 点开后，我们可以到，有两种模式可选，LF，CRLF： 为什么是这样呢，这两种模式有什么区别呢？ 在Linux下，默认换行的话，是LF模式，见下图两个红框部分： Linux下创建的LinuxFIle文件，用Linux的编辑器在里面写了三行文本。然后我用Python显示出转义符，可以看到是\n，这里的\n就是指的是换行符（LF） 然后我们在Windows下用记事本，写一个文件WindowsFile.txt，然后上转到Linux上去同样的方法查看。可以看到是\r\n，\r指的就是回车（CR），\r\n连起来就是回车换行（CRLF） 也就是说：在Linux里编辑文件，一行结束后跟的是\n；在Windows里用自带的记事本编辑文件，一行结束后跟的是\r\n tips：在Windows下有很多编辑器，是默认支持LF的方式，如Visual Studio Code、Sublime Text、Notepadd++，而且默认的编码格式是UTF-8，所以，大家在Windows下写Linux脚本，或打开Linux下的文件，可以用上面的编辑器，而不要用Windows自带的记事本。 CR和LF是缩写，其实他们的全称分别是：Carriage-Return和Line-Feed。追本溯源的说，CR(Carriage-Return)和LF(Line-Feed)这两个词来源于打字机的发明和使用。 打字机的纸张向下卷动一行，就是换行(LF, Line-Feed) 将打印头从最右边归位到最左边，就是回车(CR, Carriage-Return) 如果把一个Windows记事本建立的文档，放到Linux里用的话，要用dos2unix来转换一下后，再使用。当然最好的方法还是用专门的编辑器，不要用记事本。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>LF</tag>
        <tag>CR</tag>
        <tag>CRLF</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 安装步骤]]></title>
    <url>%2Flinux%2F20170517-02-install-centos7%2F</url>
    <content type="text"><![CDATA[1. 虚拟机软件Windows和Linux下推荐使用VMware Workstation macOS下推荐使用VMware Fusion 2. 虚拟机分配的资源因为用的软件不一样，这里设置方法无法截图，但大至如下： 2CPU/1G内存/200G硬盘 去掉打印机等没用的硬件（macOS要去掉打印机和摄像头） 光盘开始选择空白光盘，不要在这里选择iso安装，会有一个简易的自动安装，等完成设置后，再手动编辑设置改为iso镜像。同时勾选连接光盘和已连接。 3. 系统安装过程1、 加载光盘后，默认的选项是第二行：Test this media &amp; install CentOS Linux 7(测试媒介&amp;安装CentOS Linux 7)，按键盘↑选择Install CentOS Linux7（安装CentOS 7） 2、 在安装过程中使用的语言，这里使用默认的英文 3、 日期和时间DATA &amp; TIME 4、 软件选择SOFTWARE SELECT 这里选择Sever with GUI或者GNOME Desktop 5、 安装位置 选择I will configure partitioning（我将会配置分区），然后Done进入分区页面 默认分区方式为lvm，这里改为Standard Partition标准分区。 然后按+号开始划分分区 点Done后，弹出变更摘要Summary of changes，点Accept Changes 6、 NETWORK &amp; HOSTNAME（网络和主机名） 把网卡都打开 Host name自定义一下，然后点Apply 7、 设置结束，开始安装 8、 安装过程中，设置下root密码，然后创建一个用户 设置root密码 创建用户，勾选下作为管理员Make this user Administrator 9、 安装完后点重启 10、 重启后，接受下协议 11、 完成设置 12、 ifconfig检查两个网卡是否都起来了，是否有ip地址分配，如果没有，可以cat /etc/sysconfig/network-scripts/ifcfg-网卡名，看看里面有一行ONBOOT=no(这条配置决定了开机是否启动网卡)，如果是no, 可以用nano或gedit或vim等工具来更改为yes，这样下次重启后就永久生效了，然后ifup 网卡名实时启动网卡（避免重启）。 13、关闭系统，拍一个快照。 关机位置在这：]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>CentOS 7</tag>
        <tag>install</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 6 安装步骤]]></title>
    <url>%2Flinux%2F20170517-01-install-centos6%2F</url>
    <content type="text"><![CDATA[1. 虚拟机软件Windows和Linux下推荐使用VMware Workstation macOS下推荐使用VMware Fusion 另外还有Virtual Box也非常好用。 2. 虚拟机分配的资源 2CPU/1G内存/200G硬盘 去掉打印机等的没用的硬件 光盘开始选择空白光盘，不要在这里选择iso安装，会有一个简易的自动安装，等完成设置后，再手动编辑设置改为iso镜像。同时勾选连接光盘和已连接。 3. 系统安装过程1、 选择“Install or upgrade an existing system”（安装或升级现存的系统） 2、 检测光盘有无问题，这里跳过，不检测 3、 下一步 4、 在安装过程中使用的语言，这里选英文 5、 键盘，选择U.S. English 6、 磁盘这里，选择基本存储设备（Basic Storage Devices） 7、 删除磁盘上的分区和文件系统，选Yes, discard any data 8、 hostname主机名填一个自定义的主机名。 9、 然后点击左下角的配置网络（Configure Network）来配置网卡信息。 10、 这里我们两个网段都有DHCP，所以可以都自动获取，但是这两个网卡默认都是不启用的，所以要打开自动连接（Connect automatically） 11、 都打开后，点击下一步 12、 这里选择时区，点地图上的点，点到上海，下面会自动变为Asia/Shanghai，然后关闭UTC时间（System clock uses UTC前面的勾去掉） 13、 设置root用户密码 14、 安装方式，选择自定义布局Create Custom Layout 15、 点击sda或者free，然后点Create创建分区。 16、 分区，各分区大小(这里给个参考，可跟据自己机器自由选择) 分区 大小（GB） 大小（MB） /boot 1 1024 / 100 102400 /app 50 51200 swap 2 2048 最后剩下的不用管，后面做lvm等磁盘实验用，先不分。 17、 这是让你确认是否开始格式化，点Format格式化 18、 是否开始给硬盘分区，点Write change to disk 19、 这里选择默认的就好。 tips：生产中有时候用u盘来给服务器装操作系统，这里要看到boot loader（很小的一小段空间，446字节，但很重要）的安装位置是不是/dev/sda，不要不小心把boot loader装到u盘(/dev/sdb)了，这里要手动改一下设备的。如果没注意，很有可能写到u盘里，这样u盘也无法使用了，然后拔掉u盘后，系统也无法启动了。 20、 选择安装包，选择Desktop，然后再自定义选择Customize now。 21、 自定义就可以选一些包了，比如选一个中文支持包，选一个KDE桌面包（跟据个人爱好，我还是比较喜欢Gnome） 包里其实有还有些可选包，在包上点右键，可以选择Select all optional packages，即选择所有可选包。我们可以看到Chinese Support的包为6 of 7，右键选完后，就变为7 of 7了。 22、 然后进入安装界面，开始安装包 23、 等待安装，安装完后，点击reboot 24、 进入一个欢迎界面，还有些设置要设置一下。 25、 同意协议 26、 创建用户，这里可以自己创建一下，或不填跳过，都可以。 27、 设置时间 28、 开启kdump，这里选择No，可以不用重启操作系统，如果按Yes，需要重启操作系统。 29、 安装完毕 30、 ifconfig检查两个网卡是否都起来了，是否有ip地址分配，如果没有，可以cat /etc/sysconfig/network-scripts/ifcfg-网卡名，看看里面有一行ONBOOT=no(这条配置决定了开机是否启动网卡)，如果是no, 可以用nano或gedit或vim等工具来更改为yes，这样下次重启后就永久生效了，然后ifup 网卡名实时启动网卡（避免重启）。 31、 关闭系统，拍一个快照。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>install</tag>
        <tag>CentOS 6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux各发行版时间线2017年版本]]></title>
    <url>%2Flinux%2F20170516-01-linux-distribution-timeline%2F</url>
    <content type="text"><![CDATA[时间线目前版本16.12，于2017年2月1日发布，参见wikipedia svg图片太长，无法显示，可以点击链接下载:https://upload.wikimedia.org/wikipedia/commons/1/1b/Linux_Distribution_Timeline.svg]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Timeline</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[学会科学上网——用搬瓦工和Shadowsocks搭梯子]]></title>
    <url>%2Flinux%2F20170515-04-shadowsocks%2F</url>
    <content type="text"><![CDATA[在学习Linux的过程中，经常遇到查阅英文文档被墙，以及不能使用Google的痛苦。这时候我们就需要科学上网。 购买vps云服务器http://banwagong.cn/其实这个网站不是搬瓦工的官网，但是可以跳转到英文版的搬瓦工的镜像网站，里面还有中文的介绍和优惠码，还有安装说明。 根据个人喜好，选择付费方案，kvm架构六机房的好处是可以换机房，在某个机房速度慢的时候，可以重新换个机房。一般是选固定洛杉矶和佛利蒙的机房，相同的价格，流量加倍，目前是1TB流量： 跳转到英文网站，选择付费方案（月付、季付、半年付、年付），一般选年付比较便宜，然后点Add to Crat，添加到购物车： 跳转到了结算页面，这里填入优惠码，然后可以省一点钱，然后点checkout结账： 填一些个人信息，地址国家选中国后，随便填，手机号也可以随便填(不会给中国的手机发短信的)。邮箱和密码要记住，是这个搬瓦工网站的账号和密码，支付方式选择alipay。 点Pay Now 就会跳转到支付宝的支付页面，手机扫描支付就可以了（支付宝支持汇率自动计算）。 配置虚拟机在搬瓦工的页面：点击Client Area登录 然后点击Services –&gt; My Services 进入服务面板，可以看到购买的虚拟机，有虚拟机的ip地址和主机名。点KiwVM Control Panel进入虚拟机控制面板。 点start启动虚拟机，还可以看到主控面板上服务器的ip地址、ssh端口号： 还有其他选项，可以修改服务器root密码什么的（随机生成一个root的密码）： 还可以更换操作系统(默认安装的CentOS 32位的系统)： 剩下的自己可以研究下，比如ssh终端之类的。 Shadowsocks国外服务端安装ssh登录到服务器上： 运行下面3个命令进行一键安装（参考：https://teddysun.com/342.html） 12345wget --no-check-certificate -O shadowsocks.sh https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks.shchmod +x shadowsocks.sh./shadowsocks.sh 2&gt;&amp;1 | tee shadowsocks.log 安装过程中会让你设置shadowsocks服务的密码和端口号 然后就开始自动化安装了。 最后会出现这样一个页面，就安装服务成功了。 服务的管理方法，CentOS6是这样的： service shadowsocks stop 关闭service shadowsocks start 启动service shadowsocks restart 重启 在自己电脑上配置客户端客户端下载地址(GitHub上)： Windows tips：Windows有可能提示要下载.NET Framwork，根据提示自行查找.NET的版本安装。 macOS Android iOS tips: 或者App Store 里搜索Shadowrocket，可以使用，付费的，目前可能有其他免费的客户端，大家可以自行搜索下。(2017.10.14更新：Shadowrocket被下架，目前有一个shadowWingy) Windows下载后，在D盘(C盘会有权限问题，要以管理员运行)新建个文件夹，把解压后的Shadowsocks.exe放进去，然后启动后，在右下角小图标处，点配置服务器，可以直接输入ip、端口号（shadowsocks的服务端口号，不是ssh端口号）、选择加密方法、输入密码（shadowsocks服务的密码），然后选择启动服务。 还可以点生成二维码，共享给他人，其他人可以通过扫描二维码添加服务器，而不用手动设置。 macOS直接拖到应用程序里就可以了，配置方法和Windows类似。 手机端的，可以自行摸索，大同小异。 贴一个macOS的服务器设置页面：]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>bandwagon</tag>
        <tag>Shadowsocks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[工欲善其事必先利其器 —— Xmanager Enterprise 5 和 RealVNC 5/6 介绍]]></title>
    <url>%2Flinux%2F20170515-03-xmanager-realvnc%2F</url>
    <content type="text"><![CDATA[Xmanager Enterprise 5Xmanager Enterprise 5 是一个套件，内含Xshell、Xftp、X 有很多强大的功能，支持多种设备和系统的登录，Xshell支持的协议有：TELNET(远程登录) 、RLOGIN（UNIX登录）、 SSH（Linux登录） 、SFTP（SSH协议的SFTP） 、SERIAL（串口协议，通常用来直连网络设置如交换机、路由器等使用，替代了原来Windows下的超级终端） 主要用到两个工具： xshell界面 xftp 特色： 界面漂亮，扁平化设计 保存会话连接，会话可分组 保存账号密码，可自动登陆 可把常用的连接，放到界面的标签上，这样更便于连接 锁屏 设置方法： 效果 可以在设置里面更改多长时间不用锁屏 可以切换编码以适应系统，默认utf-8 可更改配色 可映射TUI（Text-based User Interface）基于文本用户界面到本地 可映射GUI（Graphical User Interface）图形用户界面到本地 tips：可以不用设置xdisplay，用最开始登陆时候的用户登录，就可以直接输入命令打开图形界面。（比如Oracle安装时候的OUI界面，直接用oracle用户直接登录，而不是root登录后切换oracle用户） 可以自定义复制和粘贴的方法 比如勾选这两个选项，选择即复制，然后去掉空白符： 鼠标，默认设置的是鼠标中间滚轮按下，是粘贴，右键，是弹出菜单。 如果喜欢SecureCRT风格的方式， 可以改为右键粘贴，不过我一般是用默认的中键，不会误操作。 下载地址：netsarang.com 下载链接是发到你邮箱的，所以要填你姓名和邮箱地址，然后点Submit提交，然后你就可以去邮箱收一下了。 RealVNC 5.x 的 VNC Address Book (本地) 可保存会话 可以保存主机信息（地址、端口、密码） 可以设置锁定密码 可以导出导入到另一台机器 RealVNC 6.x的 VNC Address Book（云）新的RealVNC 6支持云同步会话地址（不同步密码，密码比较重要，同步到云上也不安全，但本地会保存密码） 支持label标签(同上面5的文件夹，不过可以加多个标签)，可按标签分组机器。 手机版的RealVNC也有，可以自动同步过来地址（不同步密码） 下载地址：RealVNC]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Xmanager</tag>
        <tag>realVNC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[本文章集合所遵循的开源协议以及开源协议介绍(GPL,LGPL,BSD,MIT,Apache,CC)]]></title>
    <url>%2Flinux%2F20170515-02-six-pl%2F</url>
    <content type="text"><![CDATA[图片来自于：https://github.com/phodal/licenses 版权声明：本博客所有文章除特别声明外，均采用CC BY-NC-SA 3.0许可协议。转载请注明出处。 下面介绍了各种协议。内容转载自https://www.oschina.net/question/54100_9455 什么是许可协议？ 什么是许可，当你为你的产品签发许可，你是在出让自己的权利，不过，你仍然拥有版权和专利（如果申请了的话），许可的目的是，向使用你产品的人提供 一定的权限。 不管产品是免费向公众分发，还是出售，制定一份许可协议非常有用，否则，对于前者，你相当于放弃了自己所有的权利，任何人都没有义务表明你的原始作者身份，对于后者，你将不得不花费比开发更多的精力用来逐个处理用户的授权问题。 而开源许可协议使这些事情变得简单，开发者很容易向一个项目贡献自己的代码，它还可以保护你原始作者的身份，使你至少获得认可，开源许可协议还可以阻止其它人将某个产品据为己有。以下是开源界的 5 大许可协议。 GNU GPLGNU General Public Licence (GPL) 有可能是开源界最常用的许可模式。GPL 保证了所有开发者的权利，同时为使用者提供了足够的复制，分发，修改的权利： 可自由复制你可以将软件复制到你的电脑，你客户的电脑，或者任何地方。复制份数没有任何限制。 可自由分发在你的网站提供下载，拷贝到U盘送人，或者将源代码打印出来从窗户扔出去（环保起见，请别这样做）。 可以用来盈利你可以在分发软件的时候收费，但你必须在收费前向你的客户提供该软件的 GNU GPL 许可协议，以便让他们知道，他们可以从别的渠道免费得到这份软件，以及你收费的理由。 可自由修改如果你想添加或删除某个功能，没问题，如果你想在别的项目中使用部分代码，也没问题，唯一的要求是，使用了这段代码的项目也必须使用 GPL 协议。 需要注意的是，分发的时候，需要明确提供源代码和二进制文件，另外，用于某些程序的某些协议有一些问题和限制，你可以看一下 @PierreJoye 写的 Practical Guide to GPL Compliance 一文。使用 GPL 协议，你必须在源代码代码中包含相应信息，以及协议本身。 GNU LGPLGNU 还有另外一种协议，叫做 LGPL （Lesser General Public Licence），它对产品所保留的权利比 GPL 少，总的来说，LGPL 适合那些用于非 GPL 或非开源产品的开源类库或框架。因为 GPL 要求，使用了 GPL 代码的产品必须也使用 GPL 协议，开发者不允许将 GPL 代码用于商业产品。LGPL 绕过了这一限制。 BSDBSD 在软件分发方面的限制比别的开源协议（如 GNU GPL）要少。该协议有多种版本，最主要的版本有两个，新 BSD 协议与简单 BSD 协议，这两种协议经过修正，都和 GPL 兼容，并为开源组织所认可。 新 BSD 协议（3条款协议）在软件分发方面，除需要包含一份版权提示和免责声明之外，没有任何限制。另外，该协议还禁止拿开发者的名义为衍生产品背书，但简单 BSD 协议删除了这一条款。 MITMIT 协议可能是几大开源协议中最宽松的一个，核心条款是： 该软件及其相关文档对所有人免费，可以任意处置，包括使用，复制，修改，合并，发表，分发，再授权，或者销售。唯一的限制是，软件中必须包含上述版权和许可提示。 这意味着： 你可以自由使用，复制，修改，可以用于自己的项目。 可以免费分发或用来盈利。 唯一的限制是必须包含许可声明。 MIT 协议是所有开源许可中最宽松的一个，除了必须包含许可声明外，再无任何限制。 ApacheApache 协议 2.0 和别的开源协议相比，除了为用户提供版权许可之外，还有专利许可，对于那些涉及专利内容的开发者而言，该协议最适合（这里有 一篇文章阐述这个问题）。 Apache 协议还有以下需要说明的地方: 永久权利一旦被授权，永久拥有。 全球范围的权利在一个国家获得授权，适用于所有国家。假如你在美国，许可是从印度授权的，也没有问题。 授权免费，且无版税前期，后期均无任何费用。 授权无排他性任何人都可以获得授权 授权不可撤消一旦获得授权，没有任何人可以取消。比如，你基于该产品代码开发了衍生产品，你不用担心会在某一天被禁止使用该代码。 分发代码方面包含一些要求，主要是，要在声明中对参与开发的人给予认可并包含一份许可协议原文。 Creative CommonsCreative Commons (CC) 并非严格意义上的开源许可，它主要用于设计。Creative Commons 有多种协议，每种都提供了相应授权模式，CC 协议主要包含 4 种基本形式： 署名权必须为原始作者署名，然后才可以修改，分发，复制。 保持一致作品同样可以在 CC 协议基础上修改，分发，复制。 非商业作品可以被修改，分发，复制，但不能用于商业用途。但商业的定义有些模糊，比如，有的人认为非商业用途指的是不能销售，有的认为是甚至不能放在有广告的网站，也有人认为非商业的意思是非盈利。 不能衍生新作品你可以复制，分发，但不能修改，也不能以此为基础创作自己的作品。 这些许可形式可以结合起来用，其中最严厉的组合是“署名，非商用，不能衍生新作品”，意味着，你可以分享作品，但不能改动或以此盈利，而且必须为原 作者署名。在这种许可模式下，原始作者对作品还拥有完全的控制权，而最宽松的组合是“署名”，意味着，只要为原始作者署名了，就可以自由处置。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>GPL</tag>
        <tag>LGPL</tag>
        <tag>BSD</tag>
        <tag>MIT</tag>
        <tag>Apache</tag>
        <tag>CC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[笔记所使用的markdown语法]]></title>
    <url>%2Flinux%2F20170515-01-markdown%2F</url>
    <content type="text"><![CDATA[Markdown是什么？Markdown是web上的一种格式文本。Markdown功能强大，我们可以使用Markdown控制文档的显示、把文字格式为粗体或斜体、添加图像、创建列表等等。特别值得一提的是，Markdown编写只需普通文字与一些非字母字符，比如#或*，易于学习与掌握。 Markdown文件的后缀是.md或.markdown 此篇教程就是用Markdown编写的，而且采用的是Github的markdown扩展语法——GFM(GitHub Flavored Markdown) markdown软件 Mweb（目前使用的） 支持平台： web/chrome app/windows/macOS 官网： http://zh.mweb.im/ 收费情况：试用14天，收费版98/年。 优点： 对 Hexo、Octpress、Jekyll 等静态博客做了优化，以方便插入图片和实时预览。可以同步到各种平台，如印象笔记，Wordpress等。支持图片存储到七牛云。 缺点：只有Mac版和iOS版本 网上评价：https://zhuanlan.zhihu.com/p/21760223 马克飞象（用过两年） 支持平台： web/chrome app/windows/macOS 官网： https://maxiang.io/ 收费情况：试用10天，无免费版，收费版79/年。 优点：有浏览器就能使用，可随便贴图，而不用指定图片路径，可与印象笔记同步，可导出md源格式，导出生成pdf或html格式。 缺点：收费，联网才能使用。 网上评价：https://www.zhihu.com/question/24676344 Visual Studio Code 支持平台：Windows/macOS/Linux 官网：https://code.visualstudio.com/ 收费情况：完全免费 优点：界面美观，插件众多，一个功能强大的编辑器，支持众多语法，支持git，微软随便弄一个团队做出业的产品，就比市面上的类似产品，如Atom,Sublime Text好很多,打开大文件速度非常快，没有Atom卡慢的问题，比Sublime Text安装插件的方式更简洁。 缺点：markdown的话，无法贴图，要放好位置，手动敲入图片路径（不知道是否有插件能支持） 网上评价：https://www.zhihu.com/question/29984607 简书博客平台 支持平台：Web/Android/iOS 官网：www.jianshu.com 收费情况：完全免费 优点：支持直接贴图，可以做为博客使用，界面美观 缺点：无法导出md源文件(连图片都导出的那种功能)，无法导出pdf Markdown语法讲解文本加粗、斜体和超链接代码： 12用Markdown让词句有**加粗**或*斜体*的效果很容易.你也可以创建一个文本超链接，像这样：[连接到Github](https://github.com) 代码的效果： 用Markdown让词句有加粗或斜体的效果很容易.你也可以创建一个文本超链接，像这样：连接到Github 列表代码： 12345678910111213141516171819202122232425有时候你想要带数字编号的列表1. 一2. 二3. 三有时候你想要`·`作为编号，以下3个符号`*`、`+`、`-`可以混用* 可以用`*`* 继续用`*`+ 可以用`+`+ 继续用`+`- 可以用`-`- 继续用`-`还可以用分级形式1. 第一章2. 第二章3. 第三章 - 你好 - 再见 代码的效果： 有时候你想要带数字编号的列表 一 二 三 有时候你想要·作为编号，以下3个符号*、+、-可以混用 可以用* 继续用* 可以用+ 继续用+ 可以用- 继续用- 还可以用分级形式 第一章 第二章 第三章 你好 再见 图片代码： 123Github的Yaktocat![ Yaktocat图片](https://octodex.github.com/images/yaktocat.png) 代码的效果： Github的Yaktocat 标题标题由#+标题表示，从#到######一共六个等级的标题代码： 123#标题1##标题2###标题3 代码的效果： 引用如果你想要引用某些东西，在行前面用&gt;符号。例如： 代码： 123456&gt; 我是一个运维，刚开始学编程,我觉得：&gt;&gt; Markdown真是一个好用的工具。&gt;&gt; 编程是一个不停实践的过程。&gt; ——*于龙君* 代码的效果： 我是一个运维，刚开始学编程,我觉得： Markdown真是一个好用的工具。编程是一个不停实践的过程。 ——于龙君 代码加阴影和高亮无论是一小行代码加阴影还是一整段程序加阴影，都可以用反引号`。 ####代码： 代码的效果： 段落中出现的代码可以用，如/usr/bin/env python3,整个大段的程序代码也可以用： 1234#!/usr/bin/env python3# -*- encoding: utf-8 -*-print('Hello,World!')print('Hello,Markdown') 任务列表代码： 123456我是一个程序员小白，我在学编程，我的学习列表是：- [x] Markdown使用方法- [x] git&amp;github使用方法- [x] Python3.5学习- [ ] Python3实战项目- [ ] shell 代码的效果： 我是一个程序员小白，我在学编程，我的学习列表是： [x] Markdown使用方法 [x] git&amp;github使用方法 [x] Python3学习 [ ] Python3实战项目 [ ] Shell 这个属于GMF语法 表格表格支持左对齐:----，右对齐----:，居中对齐 :--:，如果没有:，默认左对齐。 代码： 123456| 我喜欢的电子产品 | 价格(USD) | 喜欢程度 || :------------ | ----: | :--: || Macbook pro | 1399-2799| ★★★★★ || Surface Book | 1499-3199 | ★★★★★ || ipad pro | 599-1129 | ★★★☆☆ || iphone plus | 869-969 | ★★★★☆ | 代码的效果： 我喜欢的电子产品 价格(USD) 喜欢程度 Macbook pro 1399-2799 ★★★★★ Surface Book 1499-3199 ★★★★★ ipad pro 599-1129 ★★★☆☆ iphone plus 869-969 ★★★★☆]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[堆（heap）]]></title>
    <url>%2Fpython%2F20170514-08-heap%2F</url>
    <content type="text"><![CDATA[二叉堆（Binary Heap）堆是一种特殊的基于树的数据结构，他满足堆的特性：所有的节点要么全大于，要么全等于，要么全小于他的每一孩子节点。 满二叉树Full Binary Tree：树上一个每一个节点要么有0个，要么有2个子节点。 完全二叉树Complete Binary Tree：除最后一层外，若其余层都是满的，并且最后一层或者是满的，或者是在右边缺少连续若干节点。 二叉堆Binary Heap：二叉堆是一种特殊的堆，二叉堆是完全二叉树或者是近似完全二叉树。二叉堆满足堆特性：父节点的键值总是保持固定的序关系于任何一个子节点的键值，且每个节点的左子树和右子树都是一个二叉堆。当父节点的键值总是大于或等于任何一个子节点的键值时为大顶堆Max Heap； 当父节点的键值总是小于或等于任何一个子节点的键值时为小顶堆Min Heap。 大顶堆： 小顶堆： 二叉堆的性质（这里假设根节点索引是0)： 索引为1的左子节点的索引是(2*i+1) 索引为i的右子节点的索引是(2*i+2) 索引为i的父节点的索引是(i-1)//2 下面部分文字和图片源自chao_yu的博客，做了部分更改，原文是用c实现的，这里图片中还保留数组字眼，不影响理解。(允许我懒一下，后面课程我都没跟上大部队，写笔记比较费时间) 你一定发觉了，最小的一个元素就是列表第一个元素，那么二叉堆这种有序列表如何入队呢？看图： 假设要在这个二叉堆里入队一个单元，键值为2，那只需在列表末尾加入这个元素，然后尽可能把这个元素往上挪，直到挪不动，经过了这种复杂度为Ο(logn)的操作，二叉堆还是二叉堆。 出堆一定是出列表的第一个元素，这么来第一个元素以前的位置就成了空位，我们需要把这个空位挪至叶子节点，然后把列表最后一个元素插入这个空位，把这个“空位”尽量往上挪。这种操作的复杂度也是Ο(logn)，比Ο(n)强多了吧？ Python3实现代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677import mathimport randomclass Heap: def __init__(self): self.__data = [] def insert(self, value): self.__data.append(value) idx = len(self.__data) - 1 parent = math.floor((idx - 1) / 2) while parent &gt;= 0 and self.__data[parent] &lt; value: self.__data[idx] = self.__data[parent] self.__data[parent] = value idx = parent parent = math.floor((idx - 1) / 2) def pop(self): if not self.__data: raise Exception('Empty') ret = self.__data[0] value = self.__data.pop() self.__data[0] = value idx = 0 left = 2 * idx + 1 right = 2 * idx + 2 while len(self.__data) &gt; left: tmp_idx = left if len(self.__data) &gt; right and self.__data[right] &gt; self.__data[left]: tmp_idx = right if self.__data[tmp_idx] &gt; value: self.__data[idx] = self.__data[tmp_idx] self.__data[tmp_idx] = value else: return ret idx = tmp_idx left = 2 * idx + 1 right = 2 * idx + 2 return ret def remove(self, i): if len(self.__data) - 1 &lt; i: raise Exception('Empty') ret = self.__data[i] value = self.__data.pop() self.__data[i] = value idx = i left = 2 * idx + 1 right = 2 * idx + 2 while len(self.__data) &gt; left: tmp_idx = left if len(self.__data) &gt; right and self.__data[right] &gt; self.__data[left]: tmp_idx = right if self.__data[tmp_idx] &gt; value: self.__data[idx] = self.__data[tmp_idx] self.__data[tmp_idx] = value else: return ret idx = tmp_idx left = 2 * idx + 1 right = 2 * idx + 2 return ret def view(self): print(self.__data)if __name__ == '__main__': heap = Heap() for _ in range(8): i = random.randint(0, 100) print('i is ', i) heap.insert(i) heap.view() #heap.pop() heap.remove(1) heap.view()]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>heap</tag>
        <tag>binary heap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[07-tree]]></title>
    <url>%2Fpython%2F20170514-07-tree%2F</url>
    <content type="text"><![CDATA[一个树形的数据结构就是树，有根节点，有子树。 二叉树binary tree：是每个节点最多有两个子树的树结构。通常子树被称作左子树left subtree和右子树right subtree。二叉树常被用于实现,二叉查找树Binary Search Tree 和 二叉堆Binary Heap。 构建一个二叉树，类似于这种： 代码： tree.py: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150from stack import Stackfrom queue import Queueclass Node: def __init__(self, value): self.value = value self.left = None self.right = None def __str__(self): return '&#123;0&#125;&lt;--&#123;1&#125;--&gt;&#123;2&#125;'.format(self.left, self.value, self.right) def __repr__(self): return self.__str__()class Tree: def __init__(self, node): self.root = node def add_left(self, tree): self.root.left = tree def add_right(self, tree): self.root.right = tree @property def left(self): return self.root.left @property def right(self): return self.root.right @left.setter def left(self, value): self.root.left = value @right.setter def right(self, value): self.root.right = value @left.deleter def left(self): del self.root.left @right.deleter def right(self): del self.root.right # 先序遍历,用递归的方式。 # 先访问root，再访问左子树，再访问右子树。 # fn为访问函数。 def visit_first(self, fn): fn(self.root.value) if self.left: self.left.visit_first(fn) if self.right: self.right.visit_first(fn) # 中序遍历，用递归的方式。 # 先访问左子树，再访问root，再访问右子树。 # fn为访问函数。 def visit_middle(self, fn): if self.left: self.left.visit_middle(fn) fn(self.root.value) if self.right: self.right.visit_middle(fn) # 后续遍历，用递归的方式。 # 先访问左子树，再访问右子树，最后访问root。 # fn为访问函数。 def visit_last(self, fn): if self.left: self.left.visit_last(fn) if self.right: self.right.visit_last(fn) fn(self.root.value) # 先序遍历，非递归的方式。 # 利用栈来实现。 # fn为访问函数。 def iter_visit_first(self, fn): stack = Stack() stack.push(self) #push整棵树 while stack.top: #当栈顶不为空的时候 p = stack.pop() #弹出栈顶 fn(p.root.value) #先访问root # 入栈先入右，再入左，因为先进后出，所以后入左，出的时候就先出左。 if p.right: stack.push(p.right) if p.left: stack.push(p.left) # 层序遍历。 # 利用序列来实现。 # fn为访问函数。 def visit_level(self, fn): queue = Queue() queue.put(self) while not queue.empty(): p = queue.get() fn(p.root.value) if p.left: queue.put(p.left) if p.right: queue.put(p.right)if __name__ == '__main__': d = Tree(Node('D')) e = Tree(Node('E')) b = Tree(Node('B')) b.left = d b.right = e f = Tree(Node('F')) g = Tree(Node('G')) c = Tree(Node('C')) c.left = f c.right = g a = Tree(Node('A')) a.left = b a.right = c from functools import partial p = partial(print, end='') a.visit_first(p) print() a.visit_middle(p) print() a.visit_last(p) print() a.iter_visit_first(p) print() a.visit_level(p) # ABDECFG 先序遍历，递归方法 # DBEAFCG 中序遍历，递归方法 # DEBFGCA 后序遍历，递归方法 # ABDECFG 先序遍历，非递归的方法，用栈的方法。从左到右，从上到下。 #TODO 中序、后序遍历的非递归方法 # ABCDEFG 层序遍历，一层层遍历，用序列的方法。从第一层到最后一层]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>tree</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[06-哈希（hash）]]></title>
    <url>%2Fpython%2F20170514-06-hash%2F</url>
    <content type="text"><![CDATA[在Python里面叫字典（dict），在ruby里面叫哈希（hash），在java里面叫map，是一种kv结构（key-value)，也是一种线性结构。 散列表（Hash table，也叫哈希表），是根据 键-值(Key value)而直接进行访问的数据结构。也就是说，它通过把关键码值映射到表中一个位置来访问记录，以加快查找的速度。这个映射函数叫做散列函数，存放记录的数组叫做散列表。给定表M，存在函数f(key)，对任意给定的关键字值key，代入函数后若能得到包含该关键字的记录在表中的地址，则称表M为哈希(Hash）表，函数f(key)为哈希(Hash) 函数。 下图为拉链法： 定义来自百度百科。 先介绍几个概念： 拉链法： 求模：fn(k)%n（除法比乘法慢，有效率问题） 平方位移法：fn(k)**2 +n（乘法，快一些） 斐波那契位移法：hash(k)*fab(64) （64位系统上） 开地址法： g = current + 1 （ 很少用，有效率问题） 其他g函数（效率较高的g函数，暂略过） 介绍几个小技巧,便于理解后面的代码。 列表复制： 123456In [8]: list1 = ['pig', 'monkey', 'lion', 'tiger']In [9]: list2 = list1[:]In [10]: list2Out[10]: ['pig', 'monkey', 'lion', 'tiger'] 枚举函数enumerate——给可迭代对象加上索引：1234567891011list1 = ['pig', 'monkey', 'lion', 'tiger']for index, item in enumerate(list1): print (index, item) In [4]: for index, item in enumerate(list1): ...: print (index, item) ...:0 pig1 monkey2 lion3 tiger hash（map）用python代码来表示：map.py:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354class Node: def __init__(self, key, value): self.key = key self.value = value def __eq__(self, other): return self.key == other.key# 拉链法实现hash（map）class Map: def __init__(self, init_size, hash=hash): #初始化槽位 self.__slot = [[] for _ in range(init_size)] # for _ in range(init_size): # self.__slot.append([]) self.__size = init_size self.hash = hash def put(self, key, value): node = Node(key, value) # 拉链法的简单方法：求模。 # 虽然效率有问题，可以暂时用来做演示。 address = self.hash(node.key) % self.__size self.__slot[address].append(node) def get(self, key, default=None): _key = self.hash(key) address = _key % self.__size for node in self.__slot[address]: if node.key == key: return node.value return default def remove(self, key): address = self.hash(key) % self.__size try: self.__slot[address].remove(Node(key, None)) except ValueError: pass # for idx, node in enumerate(self.__slot[address][:]): # if node.key == key: # self.__slot[address].pop(idx)if __name__ == '__main__': map = Map(16) for i in range(20): map.put(i, i) map.remove(3) for i in range(20): print(map.get(i, 'not set'))]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>hash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[05-队列（queue）]]></title>
    <url>%2Fpython%2F20170514-05-queue%2F</url>
    <content type="text"><![CDATA[自写一个简单的队列队列结构和链表差不多。队列遵循先进先出的pop()方法。 写一个简单的队列：（看不懂代码的可以去复习一下链表，有相似之处，再来看队列，就觉得很简单了） queue.py 1234567891011121314151617181920212223242526272829303132333435class Node: def __init__(self,value): self.value = value self.next = Noneclass Queue: def __init__(self): self.head = None self.tail = None def put(self,value): node = Node(value) if self.head is None: self.head = node self.tail = node else: self.tail.next = node self.tail = node def pop(self): if self.head is None: raise Exception('empty queue') node = self.head self.head = node.next return node.valueif __name__ == '__main__': q = Queue() for i in range(10): q.put(i) for _ in range(10): # 下划线的意思是我取到的数不要，直接丢弃，默认用法，可参考cookbook第一章，是一种pythonic的小技巧 print(q.pop()) python标准库中的队列（Queue)复杂的就暂时不说了，我们来看下Python标准库中Queue的用法。或者from queue import Queue后，help(Queue)查看用法： 说简单说几个，如果要看详细的，请参考Python标准库 __init__(self, maxsize=0)：Queue有一个maxsize属性，可以用来限制队列的大小。 empty(self)：判断队列是不是空队列 full(self)：判断队列有没有满 get(self, block=True, timeout=None)：从队列移除并返回一个元素，block=True的时候如果队列为空，则阻塞住，timeout可以设置阻塞的时间，超过timeout设置的时间再抛出异常，没设置就持续阻塞。 get_nowait(self)：重定向到get方法上，只不过block为false，不阻塞，当队列为空的时候，直接抛出一个空异常。 join(self)：队列多用于多线程的情况下，join方法可以等待其他所有持有这个队列的线程退出，再运行。 put(self, item, block=True, timeout=None)：给队列加元素，block=True的时候，当队列满了，则阻塞住，timeout可以设置阻塞的时间，超过timeout设置的时间再抛出异常，没设置就持续阻塞。 put_nowait(self)：重定向到put方法上，只不过默认block为false，不阻塞，当队列为空的时候，直接抛出一个空异常。 qsize(self)：返回当前队列的长度。 队列暂时提一下，后续多线程和并发会讲到具体用法。 分布式队列：httpsqs，kafka，redis，AMQP， qpid 后面会讲到用队列实现RPC ——远程过程调用协议 Remote Procedure Call Protocol 双端队列（deque）和普通队列不同的是，他是两段都可以进，两段都可以出，分左和右。 我们来看下标准库的实现，用代码理解(只列举部分，可以自己去试验)： 1234567891011121314151617181920212223242526272829303132333435363738In [1]: from collections import dequeIn [9]: dq = deque([1,2,3,4,5])In [10]: dqOut[10]: deque([1, 2, 3, 4, 5])In [11]: dq.append(6)In [12]: dqOut[12]: deque([1, 2, 3, 4, 5, 6])In [13]: dq.appendleft(0)In [14]: dqOut[14]: deque([0, 1, 2, 3, 4, 5, 6])In [15]: dq.pop()Out[15]: 6In [16]: dqOut[16]: deque([0, 1, 2, 3, 4, 5])In [17]: dq.popleft()Out[17]: 0In [18]: dqOut[18]: deque([1, 2, 3, 4, 5])In [19]: dq.extend([6,7,8])In [20]: dqOut[20]: deque([1, 2, 3, 4, 5, 6, 7, 8])In [28]: dq.extendleft([0,-1,-2])In [29]: dqOut[29]: deque([-2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8]) 环形队列初始化固定的size，元素链接成一个环，head和tail连接起来。deque也是一个环装队列123456789101112131415161718192021In [2]: from collections import dequeIn [3]: ring = deque(maxlen=5)In [4]: ringOut[4]: deque([])In [5]: ring.append(1)In [6]: ringOut[6]: deque([1])In [7]: ring.extend([2,3,4,5])In [8]: ringOut[8]: deque([1, 2, 3, 4, 5])In [9]: ring.append(6)In [10]: ringOut[10]: deque([2, 3, 4, 5, 6]) 有什么作用呢，历史记录就可以用环装队列来保存，当记录过多，就把之前的记录顶替掉了，免得满了，占太多空间。比如默认存200条历史记录，当超过200条时候，就把最开始的历史记录删掉。还比如日志分析时候，要往报错的信息往前查看几行信息，而不是光报错那行，就可以用环装队列。每匹配一条，就把他放在环装队列里面，当匹配到的那条报警了，我们就把整个环装队列的内容都返回回去，这样就能看到前面的几行了。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>queue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[04-stack应用-规则解析]]></title>
    <url>%2Fpython%2F20170514-04-stack-parse-rules%2F</url>
    <content type="text"><![CDATA[写一个简单的规则解析，只涉及表达式的True和False的解析。 定义的匹配 规则是： 表达式用两个#括起来，类似于#expr#，只计算表达式的布尔值：True或False。 非用!， 与用&amp;， 或用| 。 可以用()来改变优先级。 先理解一个python的re.match的用法，下面代码用的到： re是一个正则表达式处理函数。re.match的函数原型为：re.match(pattern, string, flags)。 第一个参数是正则表达式，如果匹配成功，则返回一个Match，否则返回一个None； 第二个参数表示要匹配的字符串； 第三个参数是标致位，用于控制正则表达式的匹配方式，如：是否区分大小写，多行匹配等等。 解析式样式类似于这样：‘(#e1# &amp; #e2#) |(!#e3# &amp; #e4#)’具体的可能是这样：&#39;(#abc# &amp; #324#) | (!#def# &amp; #789#)&#39; 我们来分析下： 读到(，(直接入栈。 读到第一个#，入栈。 遇到&amp;、|、!，直接入栈。 继续读，后面的如果不是#，就全部读入一个字符串，把这个字符串表达式入栈。 遇到第二个# ，就去读栈顶，把栈顶的那个字符串取出来，然后再取出栈顶#，两个#抵消，把中间的字符串表达式入栈.这时候要查看表达式的前一个元素，如果前一个元素是!，直接对表达式取反（加一个Not前面），然后把取反后的布尔值入栈。 遇到)，把栈顶值取出来，然后再取出栈顶，也就是(，两个括号抵消，把之前那个栈顶值入栈。 遇到空格，pass 注意一个小陷阱，表达式里面也有可能有运算符或者括号，这时候要加一个flags来验证是不是在表达式内部的。 下面是规则解析的代码（缺详细注释，后续添加）：rule_parser.py123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107# #expr# &amp; | ! ()# (#e1# &amp; #e2#) |(!#e3# &amp; #e4#)from stack import Stack# '(#abc# &amp; #324#) | (!#def# &amp; #789#)'# 定义一个match匹配函数，接受表达式，当前的一行日志line，fn。# fn为正则匹配函数,fn接收两个参数，expr和line。def match(exprs, line, fn): stack = Stack() is_expr = False #flags expr = [] for c in exprs: if c == '#': if not is_expr: is_expr = True else: is_expr = False v = fn(line, ''.join(expr)) expr = [] if stack.top is None: stack.push(v) continue s = stack.pop() if s == '!': v = not v if stack.top is None: stack.push(v) continue s = stack.pop() if s == '&amp;': if isinstance(stack.top.value, bool): v = stack.pop() and v stack.push(v) else: raise Exception('wrong expr') elif s == '|': if isinstance(stack.top.value, bool): v = stack.pop() or v stack.push(v) else: raise Exception('wrong expr') elif s == '(': stack.push(s) stack.push(v) else: raise Exception('wrong expr') else: if is_expr: expr.append(c) else: if c in '(&amp;!|': stack.push(c) elif c.strip() == '': pass elif c == ')': v = stack.pop() if not isinstance(v, bool): raise Exception('wrong expr') s = stack.pop() if s == '!': v = not v s = stack.pop() if s == '(': stack.push(v) else: raise Exception('wrong expr') else: raise Exception('wrong expr') while stack.top: v = stack.pop() if not isinstance(v, bool): raise Exception('wrong expr') s = stack.pop() if s == '!': v = not v s = stack.pop() if s == '&amp;': v2 = stack.pop() if not isinstance(v2, bool): raise Exception('wrong expr') v = v and v2 elif s == '|': v2 = stack.pop() if not isinstance(v2, bool): raise Exception('wrong expr') v = v or v2 else: raise Exception('wrong expr') if stack.top is None: return v else: stack.push(v)if __name__ == '__main__': import re line = 'abc 123 def 456 asd 789' exprs = '(#abc# &amp; #324#) | (!#def# &amp; #789#)' # False def callback(line, expr): return re.match(expr, line) is not None print(match(exprs, line, callback))#TODO 优化两个程序， 使其模块化]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>stack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[03-stack应用--表达式解析]]></title>
    <url>%2Fpython%2F20170514-03-stack-parse-expr%2F</url>
    <content type="text"><![CDATA[先写一个简单的算术表达式计算器，有数字，有括号，有运算符（暂时不考虑运算符优先级）。 假如是这样的算数表达式：(3+4)*5/((2+3)*3) 先分析解析思路，纸上谈兵（有点长，慢慢看）： 读到(，(直接入栈。 读到3， 是数字，此时栈顶是(，不是运算符，所以就入栈3。 读到+，是运算符，直接入栈。 读到4，是数字，此时的栈顶是运算符+，所以把+出栈，然后再把此时的栈顶3也出栈，运算出来，等于7，然后把运算出来的结果7入栈。 读到)，此时的栈顶是数字的话，就出栈并且暂存下，然后再出栈一次，就把(也出栈了，两个括号抵消了，把暂存的7继续入栈。 读到*，是运算符，直接入栈。 读到5，是数字，此时的栈顶是运算符*，所以把*出栈，然后再把此时的栈顶7也出栈，运算出来，等于35，然后把运算出来的结果35入栈。 读到/，是符号，直接入栈。 读到(，(直接入栈。 读到(，(直接入栈。 读到2， 是数字，此时栈顶是(，不是运算符，所以就入栈2。 读到+，是运算符，直接入栈。 读到3，是数字，此时栈顶是运算符+,把+出栈，然后再把此时的栈顶2也出栈，运算出来，等于5，然后把运算出来的结果5入栈。 读到*，是运算符，直接入栈。 读到3，是数字，此时栈顶是运算符*,把*出栈，然后再把此时的栈顶5也出栈，运算出来，等于15，然后把运算出来的结果15入栈。 读到)，此时的栈顶是数字的话，就出栈并且暂存下，然后再出栈一次，就把(也出栈了，两个括号抵消了，把暂存的15继续入栈。17.栈还是有元素，就继续从头开始上面的步骤，此时可以用到迭代来做，如果没有元素了，就把最后pop出来的那个栈顶给return出来，就是最终结果。 我们总结出一套规则： 读到(和运算符，(和运算符就直接入栈。 读到空格，就直接pass就好，不做任何操作 读到数字，查看此时的栈顶，如果不是运算符，就入栈此数字，如果是运算符，就把运算符出栈，然后再出一次栈顶（把运算符之前的数字取出来），进行运算，然后把运算出来的结果入栈。 读到)，此时的栈顶是数字的话，就出栈并且暂存下，然后再出栈一次，就把(也出栈了，两个括号抵消了，再把暂存的数字继续入栈。（还要考虑一种情况，就是多打个)的话，就没有(和他匹配，这时候就得raise Exception） 迭代，直到最后栈为空 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172from stack import Stackfunc_map = &#123; '+': lambda x, y: x+y, '*': lambda x, y: x*y, '/': lambda x, y: x/y, '-': lambda x, y: x-y&#125;# (3 + 4) * 5 / ((2+3) *3)def cacl(expr): stack = Stack() for c in expr: # 读到`(`和运算符，`(`和运算符就直接入栈。 if c in '(+-*/': stack.push(c) # 读到空白符（space、制表符tab、换行符\n)，直接pass elif c.strip() == '': pass # else剩下的就是读到数字和`)`的情况 else: # 读到数字，查看此时的栈顶： # 如果是运算符，就把运算符出栈，然后再出一次栈顶（把运算符之前的数字取出来）; # 如果不是运算符，就入栈此数字； # 进行运算，然后把运算出来的结果入栈。 if c != ')': c = int(c) # 这里假设c是正整数，暂时不考虑浮点数的情况 # 如果栈顶是运算符： if stack.top.value in '+-/*': s = stack.pop() if not isinstance(stack.top.value, (int, float)): raise Exception('wrong expr') v = stack.pop() v = func_map[s](v, c) stack.push(v) # 如果栈顶是数字： else: stack.push(c) # 读到`)`，把右括号之前的数字pop出来，然后再把之前的`(`也pop出来，括号抵消了，把数字存进去。 # 如果`)`前面不是数字，就报错。 # 如果pop数字后，再pop出来的不是`(`，也报错。 if c == ')': if isinstance(stack.top.value, (int, float)): v = stack.pop() if stack.top.value == '(': stack.pop() stack.push(v) else: raise Exception('wrong expr') else: raise Exception('wrong expr') #当栈顶不为空时候，还要继续运算： while stack.top: c = stack.pop() if not isinstance(c, (int, float)): raise Exception('wrong expr') if stack.top.value in '+-/*': s = stack.pop() if not isinstance(stack.top.value, (int, float)): raise Exception('wrong expr') v = stack.pop() v = func_map[s](v, c) if stack.top is None: return v stack.push(v) else: raise Exception('wrong expr')if __name__ == '__main__': print(cacl('(3 + 4) * 5 / ((2+3) *3)'))#TODO 实现带优先级的算术表达式解析]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>stack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[02-stack]]></title>
    <url>%2Fpython%2F20170514-02-stack%2F</url>
    <content type="text"><![CDATA[栈就好像是一个桶，往里加数据（push）和拿数据（pop），先进入桶的在桶底，后进入的在桶顶（top），出数据的时候先出桶顶的。遵循后进先出原则（LIFO, Last In First Out）。 python代码实现： 12345678910111213141516171819202122232425class Node: def __init__(self,value): self.value = value self.next = Noneclass Stack: def __init__(self): self.top = None def push(self,value): node = Node(value) node.next = self.top self.top = node def pop(self): node = self.top self.top = node.next return node.valueif __name__ == '__main__': stack = Stack() for i in range(10): stack.push(i) while stack.top: print(stack.pop()) 代码解读图示： stack.push(i)： stack.pop()：]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>stack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[01-单向链表（Singly linked list）]]></title>
    <url>%2Fpython%2F20170514-01-singly-linked-list%2F</url>
    <content type="text"><![CDATA[链表（Linked list）的定义： 链表中的每个元素通常被叫做节点（node）。每个节点包括两个域，一个是存储数据的，叫数据域（data field）或者信息域（information field），另一个域存储指向下一个节点的地址，叫做指针域（pointer field）。 单向链表（Singly linked list）是最简单的一种链表，每个节点也包含两个域，一个数据域和一个指针域，这个指针域只指向下一个节点，所以叫单向链表。 单向链表的第一个节点称为头节点（head node），最后一个节点称为尾节点（tail node)，尾节点的指针域为空（None），不指向下一个节点。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566class Node: def __init__(self, data): self.data = data self.next = Noneclass LinkedList: def __init__(self): self.head = None self.tail = None def append(self, data): node = Node(data) if self.head is None: self.head = node self.tail = node else: self.tail.next = node self.tail = node def iter(self): if not self.head: return cur = self.head yield cur.data while cur.next: cur = cur.next yield cur.data def insert(self, idx, value): cur = self.head cur_idx = 0 while cur_idx &lt; idx-1: cur = cur.next if cur is None: raise Exception('list length less than index') cur_idx += 1 node = Node(value) node.next = cur.next cur.next = node if node.next is None: self.tail = node def remove(self, idx): cur = self.head cur_idx = 0 while cur_idx &lt; idx-1: cur = cur.next if cur is None: raise Exception('list length less than index') cur_idx += 1 cur.next = cur.next.next if cur.next is None: self.tail = curif __name__ == '__main__': linkedlist = LinkedList() for i in range(10): linkedlist.append(i) linkedlist.insert(2, 10) linkedlist.remove(2) for data in linkedlist.iter(): print(data) main运行图解： 1) linkedlist = LinkedList() head和tail都指向空的linkedlist。 2) for i in range(10): linkedlist.append(i) 循环添加元素： linkedlist.append(0)： linkedlist.append(1) linkedlist.append(2) ….. linkedlist.append(9) 3) linkedlist.insert(2,10) insert插入 4) linkedlist.remove(2) remove移除： 5) for data in linkedlist.iter(): print(data) iter迭代输出：]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>singly linked list</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[模块化（Modularization)]]></title>
    <url>%2Fpython%2F20170513-modularization%2F</url>
    <content type="text"><![CDATA[基本概念：在Python中，模块（modules)、包（packages）和库（librarys）的概念并没有那么清晰，通常我们认为： 一个.py文件就是一个模块（module），模块名就是文件名,例如foo.py，模块名就是foo。 一个目录，包含了__init__.py就是一个包。 当一个包或者若干包，包含一个setup.py就认为是一个可分发的库。 导入模块语法： 12import modulefrom module import submodule 例子： 123456789101112131415161718192021222324252627In [1]: import os #直接导入一级模块，明明空间要带全In [2]: os.path.basename('/a/b/c.py')Out[2]: 'c.py'In [3]: import os.path # 直接导入二级模块，命名空间要带全In [4]: os.path.basename('/a/b/c.py')Out[4]: 'c.py'In [5]: import os.path.basename #最底层模块无法直接导入---------------------------------------------------------------------------ImportError Traceback (most recent call last)&lt;ipython-input-5-fceecbf39c0c&gt; in &lt;module&gt;()----&gt; 1 import os.path.basenameImportError: No module named 'os.path.basename'; 'os.path' is not a packageIn [6]: from os import path #从一级导入二级模块In [8]: path.basename('/a/b/c.py') #只写二级模块名就可以了Out[8]: 'c.py'In [9]: from os.path import basename #从二级导入三级模块In [10]: basename('/a/b/c.py') # 只写三级模块就可以了Out[10]: 'c.py' 导入模块后重命名当模块名字太长，或者有函数和模块重名，就可以用as来重命名： 12345678In [7]: def basename(): ...: return 'ha ha ha' ...:In [8]: from os.path import basename as bIn [9]: b('/a/b/c.py')Out[9]: 'c.py' 自定义模块导入模块其实是导入了模块所在的文件本身。 在我们写自定义模块的时候，要尽量避免那种全局语句，比如下面这两个.py文件，main.py调用foo.py： foo.py: 1234print("I'm foo")def bar(): print("I'm bar in foo") main.py: 12import foofoo.bar() 执行main.py,输出： 12I'm fooI'm bar in foo 即使是from foo import bar()，输出结果还是上面那两句话,第一行print(&quot;I&#39;m foo&quot;)就是一个全局语句，这是我们不想看到的结果，我们可能只想输出I&#39;m bar in foo所以， 要尽量避免全局语句。 7.4 绝对导入和相对导入举个例子，我们有个magedu的包，我们定义了三个模块 foo.py, bar.py, main.py: 我们看到，这三个是同级的，所以bar.py可以相对引入foo.py：from foo import fn。 也可以像main.py一样，打全绝对路径，绝对引入foo.py：from magedu.bar import bar 如果是不同级呢，我们建一个sub子模块，子模块下有个x.py，再在sub下建一个子模块subsub，下面有个y.py: 我们看到x.py和y.py都是写的相对路径，而main中的3个语句都可以执行（main中有的写相对路径，有的写绝对路径）。 如果是不同的包之间引用，一般是用绝对导入。 7.5 循环导入应该尽量避免循环导入: 7.6 发布自己的库写一个setup.py就可以了 1234567from distutils.core import setupsetup(&#123; name='package_name', version='0.0.1', package=[], requires:=[]&#125;) name是起的模块名，version是版本，packages有三个，包括二级包和三级包，requires是需求什么模块。 例子： 在目录下运行下面命令生成模块： build将会在build文件夹下面创建包，install就会把这个包安装。 由于要写出所有的packages，如果有很多，一个个写太麻烦了，我们还可以用setuptools来简化packages的写法： 12345678from setuptools import setup, find_packagessetup( name='magedu', version='0.0.1' packages=find_requests(), install_requires=['requests=2.9.0']) packages直接写find_requests()会自动找多层的包，install_requires可以写具体的版本（不指定就是安装最新版） pip命令：install、uninstall就不用说了，有个freeze介绍一下。 pip freeze会把当前所有安装的库列出来: 1234pip freeze &gt;requirements.txt#在一个新的环境中，就可以导入requirements里面的所有包，保持和原来环境一样。pip install -r requirements.txt]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Modularization</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[异常（Exception）]]></title>
    <url>%2Fpython%2F20170513-exception%2F</url>
    <content type="text"><![CDATA[异常处理的一般语法处理异常的基本语法： 123456try: blockexcept ExceptionClass as e: passfinally: pass 异常处理是以try开始。 当异常发生时按照一定规则执行except块，可以存在多个except块。 可选的finally块，无论如何都会执行，通常用于清理工作。 except块的选择： 判断try块中抛出的异常实例，是否是ExceptionClass的实例 如果是，执行异常处理语句，可选的as e ，把跑出的异常实例赋值给e（例如try TypeError as e: print(e)) 如果不是，继续往下执行 单独的except捕获任意异常 需要注意except的顺序，子类异常在前，父类异常在后。 看下面几个例子理解下： 1234567891011121314151617In [1]: 3/0---------------------------------------------------------------------------ZeroDivisionError Traceback (most recent call last)&lt;ipython-input-1-a0641230c7a8&gt; in &lt;module&gt;()----&gt; 1 3/0ZeroDivisionError: division by zeroIn [2]: try: ...: 3/0 ...: except ZeroDivisionError as e: ...: print(e) ...: finally: ...: print('finally')division by zerofinally 在try的时候遇到错误，就把错误跑出来，终止try错误语句下面所有语句的运行，来到了except，最后来到了finally。 可以匹配多个except 语句，符合哪个，就执行哪个，总是从上往下匹配的： 12345678In [3]: try: ...: 3/0 ...: except SyntaxError as e: ...: print(e) ...: except ZeroDivisionError as e: ...: print(e)division by zero 当我们try的时候遇到错误，就去试第一个except，发现不是SyntaxError异常，所以再去找第二个except，发现符合ZeroDivisionError异常，就输出division by zero。 因为是从上往下匹配的，所以，异常总是把子类异常写在前面，父类异常写在后面，要不只会运行父类，不会运行子类了，后面的代码就没有意义了，也不知道具体的异常是什么（细化的异常，而不是一个大类的异常）。（下面例子中ZeroDivisionError是Exception的子类）： 12345678In [4]: try: ...: 3/0 ...: except Exception: ...: print('Exception') ...: except ZeroDivisionError: ...: print('ZeroDivisonError')Exception 下面例子说明，finally一定会执行，即使前面是return语句： 12345678910111213In [5]: def p(): ...: print('ha ha ha') ...:In [6]: def main(): ...: try: ...: return p() ...: finally: ...: print('finally')In [7]: main()ha ha hafinally finally通常用在try打开文件、连接后，运行中出现异常后，退出关闭用，例如： 比如： 123456789In [11]: try: ....: f = open(./Untitled.ipynb') ....: 3/0 ....: except: ....: print('eeee') ....: finally: ....: f.close()eeee 抛出异常（raise exceptions）123456789101112131415161718In [12]: def fn(i): ....: if i &lt; 0: ....: raise Exception('i&lt;0') ....:In [13]: fn(-2)---------------------------------------------------------------------------Exception Traceback (most recent call last)&lt;ipython-input-13-aaa95363b839&gt; in &lt;module&gt;()----&gt; 1 fn(-2)&lt;ipython-input-12-3d515a291510&gt; in fn(i) 1 def fn(i): 2 if i &lt; 0:----&gt; 3 raise Exception('i&lt;0') 4Exception: i&lt;0 未处理异常，会向顶层抛出，直到最顶层： 1234567891011121314151617181920212223242526272829303132333435In [17]: def main(): ....: def fn(): ....: def fn2(): ....: 3/0 ....: return fn2() ....: return fn() ....:In [18]: main()---------------------------------------------------------------------------ZeroDivisionError Traceback (most recent call last)&lt;ipython-input-18-58ca95c5b364&gt; in &lt;module&gt;()----&gt; 1 main()&lt;ipython-input-17-25d5853cd075&gt; in main() 4 3/0 5 return fn2()----&gt; 6 return fn() 7&lt;ipython-input-17-25d5853cd075&gt; in fn() 3 def fn2(): 4 3/0----&gt; 5 return fn2() 6 return fn() 7&lt;ipython-input-17-25d5853cd075&gt; in fn2() 2 def fn(): 3 def fn2():----&gt; 4 3/0 5 return fn2() 6 return fn()ZeroDivisionError: division by zero 我们可以在运行时候处理：比如上面的例子，我们用try...except...来处理： 123456In [19]: try: ....: main() ....: except Exception as e: ....: print(e) ....:division by zero 异常的继承层次BaseException：最顶层的异常，基异常，下面四中都是BaseException的子类 Exception：除了下面三种特殊的，异常一般都继承自Exception。 GeneratorExit：生成器退出的异常。 KeyboardInterrupt：键盘中断，运行程序中&lt;Ctrl-C&gt;就会抛出这个异常。 SystemExit：在解释器中sys.exit()出抛出这个异常，解释器就会退出。（在python自带的IDE和IDLE解释器中exit()就可以， ipython中，exit就可以） 让我们用代码来理解后面三种异常。GeneratorExit： 123456789101112131415161718192021222324252627282930In [21]: def gen(): ....: c = 0 ....: while True: ....: yield c ....: c += 1 ....: if c &gt; 3: ....: raise GeneratorExit() ....:In [22]: for x in gen(): ....: print(x) ....:0123---------------------------------------------------------------------------GeneratorExit Traceback (most recent call last)&lt;ipython-input-22-19e03e2de58a&gt; in &lt;module&gt;()----&gt; 1 for x in gen(): 2 print(x) 3&lt;ipython-input-21-15634e9f6ed8&gt; in gen() 5 c += 1 6 if c &gt; 3:----&gt; 7 raise GeneratorExit() 8GeneratorExit: KeyboardInterrupt： 12345678910111213141516171819202122In [25]: try: ....: while True: ....: print('ha ha ha') ....: except KeyboardInterrupt: ....: print('exit...') ....: ha ha haha ha haha ha haha ha haha ha haha ha haha ha haha ha haha ha haha ha haha ha haha ha haha ha haha ha haexit... #运行时候按&lt;CTRl-C&gt; 中断后会输出exit。。。 SystemExit： 123456[yulongjun@MBP python3.6 ]$ pythonPython 3.6.1 (default, Mar 24 2016, 18:14:05)[GCC 4.2.1 Compatible Apple LLVM 7.0.2 (clang-700.1.81)] on darwinType "help", "copyright", "credits" or "license" for more information.&gt;&gt;&gt; import sys&gt;&gt;&gt; sys.exit() # 或者用'exit()', &lt;Ctrl-d&gt; 1234567891011121314[yulongjun@MBP python3.6 ]$ ipythonWARNING: IPython History requires SQLite, your history will not be savedPython 3.5.1 (default, Mar 24 2016, 18:14:05)Type "copyright", "credits" or "license" for more information.IPython 4.1.2 -- An enhanced Interactive Python.? -&gt; Introduction and overview of IPython's features.%quickref -&gt; Quick reference.help -&gt; Python's own help system.object? -&gt; Details about 'object', use 'object??' for extra details.In [1]: exit() # 或者用'exit', 'quit', &lt;Ctrl-D&gt;[yulongjun@MBP python3.6 ]$ 除了上面三种，其他的异常都是Excption和Excption的派生类（子类） 自定义异常当一个类继承自Exception及其派生类，那么就是自定义的异常。下面举两个简单的例子，都是Exception的自定义子类异常： 1234567891011In [1]: class MyException(Exception): ...: pass ...:In [4]: raise MyException('my exception')---------------------------------------------------------------------------MyException Traceback (most recent call last)&lt;ipython-input-4-d9d6f87445e1&gt; in &lt;module&gt;()----&gt; 1 raise MyException('my exception')MyException: my exception 12345678910111213141516171819202122In [5]: class InputLessZeroException(Exception): ...: pass ...:In [6]: def fn(i): ...: if i &lt; 0: ...: raise InputLessZeroException() ...:In [7]: fn(-2)---------------------------------------------------------------------------InputLessZeroException Traceback (most recent call last)&lt;ipython-input-7-aaa95363b839&gt; in &lt;module&gt;()----&gt; 1 fn(-2)&lt;ipython-input-6-862835565304&gt; in fn(i) 1 def fn(i): 2 if i &lt; 0:----&gt; 3 raise InputLessZeroException() 4InputLessZeroException:]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Exception</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[魔术方法/特殊方法(Magic Methods)]]></title>
    <url>%2Fpython%2F20170512-04-magic-method%2F</url>
    <content type="text"><![CDATA[总是以双下划线开始，双下划线结束的方法，就叫做魔术方法（magic methods）。 init可以读作dunder init 对象的创建与销毁 __new__：创建对象的方法（用到很少，只有元编程的时候用到） __init__：初始化对象（用到比较多） __del__：当销毁对象的时候调用（用的也不多，但是也会用到）（比如程序里打开了一些资源，在python运行时，并没有释放，只有等程序运行完了才释放，这时候就可以用del来提前释放） 看个例子： 可视化对象在我们打印类A的实例a时候，并不能输出可视化： 我们可以用__repr__、 __str__、__bytes__这三种来加强可视化： print(a)就相当于先调用a的__repr_ 方法， 即相当于print(repr(a))。类似的 str(a)，就是调用a的__str__方法。法；bytes(a)，就是调用a的__bytes__方法。 比较运算符重载(reload)例子： 这里我们不能比较p1和p2的大小，但是如果我们想比较呢，用什么方法？ 可以采用下面的方法，就可以比较了： 我们分别比较下： bool函数12345678910111213141516171819202122232425262728In [79]: bool([]) # 空列表是FlaseOut[79]: FalseIn [80]: bool(0) # 数字0是FalseOut[80]: FalseIn [81]: bool(None) # None是FalseOut[81]: FalseIn [82]: bool(p1) # 上一节的p1实例是TrueOut[82]: TrueIn [85]: class Grok: ....: def __init__(self, val): ....: self.val = val ....: def __bool__(self): ....: return not self.val ....:In [86]: grok1 = Grok(True)In [87]: bool(grok1) #grok1是True，定义中bool是返回not True，也就是FalseOut[87]: FalseIn [88]: grok2 = Grok(False)In [89]: bool(grok2) #grok2是False，定义中bool是返回not False，也就是TrueOut[89]: True 我们随便dir([])，发现其实类默认是没有__bool__方法的，那么是如何使用bool()函数的呢？——其实使用__len__方法的值，值如果是0，就是False，值如果是非0，就是True： 1234567891011121314151617181920212223In [91]: class List: ....: def __init__(self,*args): ....: self.val = args ....: ....: def __len__(self): ....: return len(self.val) ....:In [92]: lst = List(1, 2, 3)In [93]: len(lst)Out[93]: 3In [94]: bool(lst)Out[94]: TrueIn [95]: lst2 = list()In [96]: len(lst2)Out[96]: 0In [97]: bool(lst2)Out[97]: False 如果我们定义了__bool__方法，那么就按照__bool__方法的定义来： 123456789101112131415In [98]: class List: ....: def __init__(self,*args): ....: self.val = args ....: ....: def __bool__(self): ....: return True ....: ....: def __len__(self): ....: return len(self.val) ....:In [99]: lst3 = List()In [100]: bool(lst3)Out[100]: True hash() 与可hash对象 当我们重写了__hash__后，变为pass，那么就用hash就会抛出异常 系统如果是64位的，hash值是64位的 可调用对象函数是可调用对象： 123456789In [106]: class Function: .....: def __call__(self,name): .....: print('I am callable, my name is &#123;0&#125;'.format(name)) .....:In [107]: func = Function()In [109]: func('magedu')I am callable, my name is magedu callable函数经常用在装饰器上： 单例（singleton)：单例模式可以保证系统中一个类只有一个实例而且该实例易于外界访问，从而方便对实例个数的控制并节约系统资源。如果希望在系统中某个类的对象只能存在一个，单例模式是最好的解决方案。 下面写一个单例，用到可调用对象： （后面会详细讲单例，这里不做赘述） 针对反射的方法12345678910111213class Grok: X = 1 Y = 2 Z = 3 def __init__(self, x, y, z): self.x = x self.y = y self.z = z def method(self): passgrok = Grok(1, 2, 3) __dict__反射： 12In [112]: grok.__dict__Out[112]: &#123;'x': 1, 'y': 2, 'z': 3&#125; __class__反射： 12In [113]: grok.__class__Out[113]: __main__.Grok __dir__反射： 12345678910111213141516171819202122232425262728293031323334In [113]: grok.__dir__Out[113]:['Y', '__repr__', 'Z', '__eq__', '__getattribute__', '__str__', '__reduce__', '__delattr__', '__ne__', '__le__', '__dir__', '__hash__', '__sizeof__', '__weakref__', 'z', '__class__', '__setattr__', '__format__', '__lt__', '__new__', '__dict__', '__reduce_ex__', 'y', '__module__', 'method', 'X', '__gt__', '__doc__', '__ge__', 'x', '__init__', '__subclasshook__'] __getattr__、__setattr__、__delattr__反射： with语句与 __enter__ 、__exit__一般打开文件，连接数据库，连接socket等，结束后都要close()退出操作： 1234567891011f = open('./notes.adoc')f.readline()f.close()pymysql.connect()...pymysq.close()socket.connect().....socket.close() 但是如果用with，就不用写close()，在离开with段后会自动退出： 12with open('./notes.adoc') as f: f.readline() 这是利用的什么原理呢？就是__enter__ 、__exit__： 12345678910111213141516171819In [145]: class Resouce: def __init__(self): print('init') def __enter__(self): print('enter') print(self) return self def __exit__(self, *args, **kwargs): print('exit')In [146]: with Resouce() as res: print(res)Out[146]:initenter&lt;__main__.Resouce object at 0x7f00d443f588&gt;&lt;__main__.Resouce object at 0x7f00d443f588&gt;exit 看上面代码，用with语法后，先执行了__init__，然后进入__enter__，最后进入__exit__自动退出。 with语法可以自动清理不用的资源，如果一段程序老是打开不关闭，打开的多了，就会造成资源的浪费，最终导致系统崩溃，所以要养成用with语法的习惯。 描述器（descriptor）只要能实现getter、setter、deleter方法的类就叫描述器。 用代码来说明。 point表示平面坐标上的一个点： 1234In [110]: class Point: .....: def __init__(self, x, y): .....: self.x = x .....: self.y = y 上面代码只是一个简单的定义，x可以是数字也可以是字符串，如何能保证坐标点是数字呢？可以用描述器来实现： point的getter和setter方法都可以实现，而且当setter的时候是非数值，就会报TypeError错误，并提示&quot;excepted int or float&quot; 可以看之前继承那里的property、setter、getter、deleter来理解。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>OOP</tag>
        <tag>Encapsulate</tag>
        <tag>Inheritance</tag>
        <tag>Polymorphism</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[03-多继承、MRO算法]]></title>
    <url>%2Fpython%2F20170512-03-multi-inheritance-mro%2F</url>
    <content type="text"><![CDATA[多继承 举个例子，有一个人有亲爹有干爹，可以继承亲爹的，也可以继承干爹的一些东西，这就是多继承的概念。 用代码来理解： 123456789101112131415161718192021In [23]: class A: ....: def method_from_a(self): ....: print('I am method of a') ....:In [24]: class B: ....: def method_from_b(self): ....: print('I am method of b') ....:In [25]: class C(A,B): ....: pass ....:In [26]: c = C()In [28]: c.method_from_a()I am method of aIn [29]: c.method_from_b()I am method of b 如果多继承里面，两个父类有相同的方法，怎么办呢，我们用代码来验证下： 123456789101112131415161718192021222324252627In [30]: class A: ....: def method(self): ....: print('method of A') ....:In [31]: class B: ....: def method(self): ....: print('method of B') ....:In [33]: class C(A,B): ....: pass ....:In [34]: c = C()In [35]: c.method()method of AIn [33]: class C(B,A): ....: pass ....:In [34]: c = C()In [35]: c.method()method of B 看上面代码可以看到，如果继承的方法名字相同，就继承前面那个。 但是如果B继承自A，又是另外一种情况，C继承A和B会报错： 12345678910111213141516171819202122In [30]: class A: ....: def method(self): ....: print('method of A') ....:In [36]: class B(A): ....: def method(self): ....: print('method of B') ....:In [37]: class C(A,B): ....: pass ....:---------------------------------------------------------------------------TypeError Traceback (most recent call last)&lt;ipython-input-37-779918bf027e&gt; in &lt;module&gt;()----&gt; 1 class C(A,B): 2 pass 3TypeError: Cannot create a consistent method resolutionorder (MRO) for bases A, B 但如果是C(B,A)呢？那就没问题了： 123456789101112In [38]: class C(B,A): ....: pass ....:In [38]: class C(B,A): ....: pass ....:In [39]: c=C()In [41]: c.method()method of B 这是什么原理呢?其实是遵循一种MRO（method resolution order）原理： MROMRO详解：你真的理解Python中MRO算法吗？ 本地优先级：根据声明顺序从左往右查找 单调性：所有子类中，也应该满足其查找顺序 MRO通过C3算法计算出来。 C3算法： 12class B: --&gt; mro(B) =[B,O] #这里的O相当于Object，最顶级的类class B(A1,A2,...) --&gt; mro(B)+merge(mro(A1), mro(A2), ... , [A1, A2, ...]) C3算法merge步骤： 顺序遍历列表 首元素满足以下条件，否则遍历下一个序列 在其他序列也是首元素 在其他序列里不存在 从所有序列中移除此元素，合并到MRO序列中 重复执行，直到所有序列为空或无法执行下去 下面看上面四中情况的MRO算法： 12345678C(A,B) --&gt; mro(C(A, B)) =[C] + merge(mro(A), mro(B), [A, B]) =[C] + merge([A, O], [B, O], [A, B]) =[C,A] + merge([O], [B,O], [B]) =[C, A, B] + merge([O], [O]) =[C, A, B, O] 12345678C(B, A) -&gt; mro(C(A, B)) =[C] + merge(mro(B), mro(A), [B, A]) =[C] + merge([B, O], [A, O], [B, A]) =[C, B] + merge([O], [A, O], [A]) =[C, B, A] + merge([O], [O]) =[C, B, A, O] 123456789C(A, B), B(A) -&gt; mro(C(A, B)) =[C] + merge(mro(A), mro(B), [A, B]) =[C] + merge([A, O], ([B] + merge(mro(A), [A]), [A, B]) =[C] + merge([A, O], ([B] + merge([A, O], [A])), [A, B]) =[C] + merge([A, O], ([B, A] + merge([O])), [A, B]) =[C] + merge([A, O], [B, A, O], [A, B]) raise TypeError 12345678C(B, A), B(A) -&gt; mro(C(B, A)) =[C] + merge(mro(B), mro(A), [B, A]) =[C] + merge([B, A, O], [A, O], [B, A]) =[C, B] + merge([A, O], [A, O], [A]) =[C, B, A] + merge([O], [O]) =[C, B, A, O] 第三段如果难以理解，可以拆分一下，如下： 1234567891011121314B(A) -&gt; //先算出mro(B(A)) mro(B(A)) =[B] + merge(mro(A), [A]) =[B] + merge([A, O], [A]) =[B, A] + merge([O]) =[B, A, O]C(A, B), B(A) -&gt; //把mro(B(A))的结果带入下面公式 mro(C(A,B)) =[C] + merge(mro(A), mro(B), [A, B]) =[C] + merge([A, O], [B, A, O], [A, B]) raise TypeError 其实可以找出一个简单规律，比如这样： 1234class Aclass B(A)class C(B)class D(C) 那么就可以用下面几种多继承都是正确的： 123456789class E(D,C,B,A)class E(D,C,B)class E(D,C,A)class E(D,B,A)class E(D,B)class E(D,A)class E(C,B,A)class E(C,A)class E(B,A) 相当于一个层级的多继承，先继承底层的类，再继承高层的类，这样就不会抛出 TypeError。 所有类都有__mro__方法 12In [54]: C.__mro__Out[54]: (__main__.C, __main__.B, __main__.A, object) Python的多继承是一剂毒药，容易让人上瘾，确实有让人爽的地方 我们看下面一个代码例子，Document是文档，Word和Excel是Document的格式，输出模式有两个，一个是屏幕Monitor，一个是HP打印机HP。 如果是单继承模式，我们对一个文档的输出模式有m(文档格式)_n(输出模式)种，要一个个写太累了。就比如上面写了2_2=4种单继承的类（WordWithMonitor,ExcelWithMonitor,WordWithHP,ExcelWithHP）。如果我们有10种格式，4种输出模式，难道我们要写40种单继承的类吗？这里就可以用到多继承了： 我们创建Monitor类和HP类，如果有另外的输出模式，就再新建一个类就可以了，然后都可以用多继承来调用。如果是Monitor类有变化，我们只要修改Monoitor类就可以了，而不会影响其他的代码。 一个新类，组合两个类，成为一个新类，在Python中就叫MixIn。两个类，一个存数据，一个存方法，单独调用方法是没用的，组合起来就有组合的效果。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>multi-inheritance</tag>
        <tag>MRO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[02-OOP的三大特征：封装、继承、多态]]></title>
    <url>%2Fpython%2F20170512-02-oop-three-principles%2F</url>
    <content type="text"><![CDATA[oop的三大特性： 封装（Encapsulate） 继承（Inheritance） 多态（Polymorphism） 下面三个小节详细说明了这三个特性。 封装（Encapsulate）封装有两种划分方法： 按可见范围分类划分： 类级（class level）：（类和实例都可以访问，所有实例共享） 类变量（class variable） ：类定义时确定的，没在__init__初始化实例方法里面的 类方法 （class method） 实例级（instance level）： （只有实例可以访问） 实例变量（instance variable）：被定义在__init__初始化实例方法里面的，实例初始化的后的变量 实例方法（instance method） 按私有与公有划分： 私有（private）：只有类内部可以访问。 私有类变量（private class variable） 私有类方法（private class method） 私有实例变量（private instance variable） 私有实例方法（private instance method） 公有（public）：类外可以访问。 公有类变量（public class variable） 公有类方法（public class method） 公有实例变量（public instance variable） 公有实例方法（ public instance method） 定义规则： 私有（private）的变量和方法，通常在变量和方法前面加__。 类变量（class variable）通常在定义类后定义类变量；实例变量（instance variable）是定义在__init__方法里面的。 实例方法是直接def(self)创建；类方法通常使用装饰器@classmethod后，再def ClassMethod(cls)创建。 下面让我们用代码来理解下以上概念：（代码有点多，可以看后面注释一步步理解，看懂这一波代码你就就能懂封装了,后面继承也能用到这段代码） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465class A: # 定义类名后定义类变量 __private_class_var = 'private class var' # 定义私有类变量 public_class_var = 'public class var' # 定义公有类变量 def __init__(self): # 用__init__定义实例变量 self.__private_instance_var = 'private instance var' # 定义私有实例变量 self.public_instance_var = 'public instance var' # 定义公有实例变量 def __private_instance_method(self): # 定义私有实例方法，尝试打印出所有的变量 try: print(self.__private_class_var) # 尝试打印私有类变量 except: pass try: print(self.public_class_var) # 尝试打印公有类变量 except: pass try: print(self.__private_instance_var) # 尝试打印私有实例变量 except: pass try: print(self.public_instance_var) # 尝试打印私有实例变量 except: pass def public_instance_method(self): # 定义公有实例方法，尝试打印所有的变量 try: print(self.__private_class_var) # 尝试打印私有类变量 except: pass try: print(self.public_class_var) # 尝试打印公有类变量 except: pass try: print(self.__private_instance_var) # 尝试打印私有实例变量 except: pass try: print(self.public_instance_var) # 尝试打印私有实例变量 except: pass @classmethod def __private_class_method(cls): # 使用@classmethod创建私有类方法 try: print(cls.__private_class_var) # 尝试打印私有类变量 except: pass try: print(cls.public_class_var) # 尝试打印公有类变量 except: pass @classmethod def public_class_method(cls): # 使用@classmethod创建公有类方法 try: print(cls.__private_class_var) # 尝试打印私有类变量 except: pass try: print(cls.public_class_var) # 尝试打印公有类变量 except: pass 上面代码： 行号 定义类型 英文 1 定义类名 class name 2-3 定义类变量 class variable(private &amp; public) 5-7 定义实例变量 instance variable(private &amp; public) 9-25 定义私有实例方法 private instance method 27-43 定义公有实例方法 public instance method 45-54 定义私有类方法 private class method 56-65 定义公有类方法 public class method 下面我们验证下类和实例的变量和方法的互访情况：(a=A()，a是类A的实例) 由上图可以得出结论： 类私有变量、类私有方法、实例私有变量和实例私有方法，类和实例都不能直接访问。 类可以访问类级的公有类变量和公有类方法，但是不能访问实例级的的公有实例变量和公有实例方法。 实例可以访问类级的公有类变量和公有类方法，也能访问实例级的的公有实例变量和公有实例方法。 类可以用公有类方法调用私有类变量和公有类变量，但是不能调用私有实例变量和公有实例变量。 实例可以用公有实例方法调用私有类变量和公有类变量，也能调用私有实例变量和公有实例变量。 —- 类能否访问 实例能否访问 类是否能够通过公有类方法调用私有变量 实例是否能够通过公有实例方法调用私有变量 私有类变量 × × √ √ 私有类方法 × × - - 私有实例变量 × × × √ 私有实例方法 × × - - 公有类变量 √ √ √ √ 公有类方法 √ √ - - 公有实例变量 × √ × √ 公有实例方法 × √ - - property函数、 getter、setter、deleter方法让我们看一段代码： 1234567891011121314151617class A: def __init__(self, input_x): self.__x = input_x def getx(self): print('inside the getter') return self.__x def setx(self, input_x): print('inside the setter') self.__x = input_x def delx(self): print('inside the deleter') del self.__x x = property(getx, setx, delx, "I'm the 'x' property") 上面代码中： __x是一个隐藏的变量，我们通常不会直接去调用隐藏的变量，而是用getter方法getx，相应的，我们改变隐藏的变量，也用相应的setter方法setx，还有删除隐藏变量的deleter方法delx。 property函数调用了上述三种方法，property函数的用法是：property(fget=None, fset=None, fdel=None, doc=None)，这里的fget是getx，fset是setx，fdel是delx，doc是&quot;I&#39;m the &#39;x&#39; property.&quot;。下面是使用的代码： 当然也可以有更简便的方法： property函数的代码还可以装饰器来写，更加简洁,和上面实现的功能是一样的： 12345678910111213141516171819class A: def __init__(self, input_x): self.__x = input_x @property def x(self): "I am the 'x' property." print("inside the getter") return self.__x @x.setter def x(self, value): print("inside the setter") self.__x = value @x.deleter def x(self): print("inside the deleter") del self.__x 继承（Inheritance）继承的多种方法 继承（inheritance）是一种实现代码复用的一个好方法。 当我们定义的新类用到之前定义过的旧类的一些属性和方法的时候，我们可以重写一个新类（比较笨拙的方法），也可以用继承的方法，来获得旧类的变量和方法。 新类可以保留部分旧类变量和方法（使用super()函数），可以重写（也说覆盖，override）旧类的部分变量和方法，可以新增（add）变量和方法。 在继承中，原始的旧类叫做父类（parent class）、超类（super class）、基类（base class），继承得到的新类叫做孩子类（child class），子类（sub class），衍生类（derived class）。 用代码来说明 前面有定义过一个Door的类，下面是类Door的定义： 12345678910class Door: def __init__(self,number,status): self.number=number self.status=status def open(self): self.status='openning' def close(self): self.status='closed' 我们重新定义一个新类叫LockableDoor（可锁的门） 1234567891011121314151617181920class LockableDoor: def __init__(self,number,status,is_lockked): self.number = number self.status = status self.is_locked = is_locked def open(self): if not self.is_locked: self.status = 'openning' else: print('is locked') def close(self): self.status = 'closed' def lock(self): if self.status == 'closed': self.is_locked = True else: print('is openning') 定义新类是笨方法，尤其是当旧类的属性和方法很多的时候，不能全部去重写一遍吧！ 我们看到这两个类有很多相似的部分，所以可以用Door当做父类，用LockableDoor当做Door的子类，继承Door： 123456789101112131415161718class LockableDoor(Door): # 定义Door的子类LockableDoor def __init__(self,number,status,is_locked):# 新增了一个is_locked属性（attritube） super(LockableDoor,self).__init__(number,status) # number，status可以直接继承Door的这两个属性，是相同的，用super（）函数来继承 self.is_locked = is_locked # 新加的is_locked属性的定义，新的属性 def open(self): # 覆盖（override）open方法 if not self.is_locked: # 如果门没锁，LockableDoor的门可以像Door一样调用open方法 super(LockableDoor,self).open() #此处为像超类Door一样调用open方法 else: # 如果们锁了，门就打不开了 print("It is locked, can't open.")# 只能输出“它锁住了，不能打开” #LockableDoor和Door的close方法都一样，没必要重写close方法，就可以省略了，直接继承 def lock(self):# 新增一个lock方法，这个超类中完全没有，下面是lock方法的定义 if self.status == 'closed':# 如果门关了 self.is_locked = True # is_locked属性就是真值 else: # 如果门开着 print('It is openning')# 就输出“它开着" 上面代码用到了继承的很多方法： 单继承：close方法都一样，是直接继承的，所以不用写，省略就可以，直接继承过来。 重写（override）：LockableDoor的open方法是属于重写了原来的Door的open方法。 新增（add）：is_lock属于新增的变量，lock方法属于新增的方法。 调用父类（super()）：super(LockableDoor,self).__init__(number,status)调用了父类的number和status变量，super(LockableDoor,self).open()调用了父类的open方法。 继承与可见性继承可以继承父类的那些东西呢?这里与之前的封装有关系，我们可以封装那一节里定义的那个特别长的函数A来说明:之前的那个类是A，太长就不复制黏贴了。我们定义一个新类B，继承自父类A，b是类B的实例： 12345678910111213141516171819202122232425262728293031323334353637383940In [69]: def B(ClassName): passIn [70]: b=B()In [71]: dir(b)out[71]:['_A__private_class_method', '_A__private_class_var', '_A__private_instance_method', '_A__private_instance_var', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'public_class_method', 'public_class_var', 'public_instance_method', 'public_instance_var'] dir(b)可以查看b的属性和方法，中间那些我们都用不上，我们可以切片精简下： In [72]: dir(b)[:4]+dir(b)[:-5:-1] Out[72]: ['_A__private_class_method', '_A__private_class_var', '_A__private_instance_method', '_A__private_instance_var', 'public_instance_var', 'public_instance_method', 'public_class_var', 'public_class_method'] 我们运行下面代码： 以上代码说明：1. 私有的方法、变量（无论类还是实例的）是不可继承的2. 公有的方法、变量（无论类还是实例）是可以继承的3. 子类的公有的方法（包括类和实例）是可以访问父类的私有变量的 继承后重写私有变量和公有变量，私有变量不变，公有变量变为重写后的变量 看一段代码： 类C我们继承A并重写（override）私有变量和公有变量我们发现私有变量没有变化，而公有变量变了，说明重写（override）只能重写公有变量，不能重写私有变量，私有变量还是父类A的私有变量。（dir(c)后我们看到，私有变量有_A前缀，也有_C前缀，默认会先使用父类的_A前缀的私有变量。） 继承后重写公有方法和私有方法，公有方法改变，私有方法也改变 看一段代码理解： 重写公有方法后，公有方法改变（变为调用两次__method())；重写私有方法后，公有方法调用的私有方法也改变（改变为输出method of B) 多态（Polymorphism）不同的操作对不同的对象有多种表现形式。重写（override）就是多态的一种表现形式。 在讲继承的时候，已经把多态讲过了，这里就略过了。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>OOP</tag>
        <tag>Encapsulate</tag>
        <tag>Inheritance</tag>
        <tag>Polymorphism</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[01-类（Class）的定义]]></title>
    <url>%2Fpython%2F20170512-01-define-class%2F</url>
    <content type="text"><![CDATA[Python中对象由两大部分组成： 数据（data）（也可以称之为变量（variable）或者属性（attribute））（下文类的理解中中有时候用变量，有时候用属性，其实说的是一个东西） 行为（behavior）（也可以称之为函数（functions）或者方法（methods））（下文类的理解中大部分用方法来表示） 类（class）和实例（instance）类和实例都是对象，但是类是一类对象的对象，实例是调用类后产生的对象。 实例是调用类后的产物，每次调用类，都会产生一个新实例。类相当于工厂，实例就是工厂生产的一个个产品，看个例子： 12345class A: #定义类A passa1=A() #实例化类A，a1就是类A的一个实例a2=A() #实例化类A，a2是类A的另一个实例 看上面代码，实现了定义一个类A（注意类名一般大写），调用类后产生两个实例a1和a2（调用类：在类后面加一对小括号）。 定义一个类我们定义了一个类Door，这个门有号码属性，有状态属性（打开状态或者关闭状态），还有两种方法（打开方法和关闭方法）number和status是属性（或者称之为变量），open()和close()是门的两种方法: 12345678class Door: def __init__(self, number, status): self.number = number self.status = status def open(self): self.status = 'openning' def close(self): self.status = 'closed' 解读代码： class Door：定义一个类Door，这是一个简写的定义类的语句，其实要写全应该是class Door(object):，object是最Python中最顶级的类，由object构造出一切类，Door就是object的子类。当然，定义出来的类还可以构造出子类，比如再定义一个类:class LockableDoor(Door):， 这里就定义了Door的一个子类LockableDoor，LockableDoor继承了Door的属性和行为。 构造函数：__init__，第一个参数是self（是约定俗成的，当类实例化后，self代表实例本身），后面的是参数number和status，这两个参数会赋值给实例变量（instance variable）self.number和self.status。 定义类的两个方法，open()和close()。在类实例化后，实例就有两个方法：打开和关闭。调用方法后，会把实例的status变量变为openning或者closed 下面是实例化后的效果： 123456789101112131415161718192021222324252627In [2]: door1 = Door(1, 'closed') # 实例化Door为door1实例In [3]: door2 = Door(1, 'openning') #实例化Door为door2实例In [4]: door1.status # 查看door1的状态Out[4]: 'closed'In [5]: door2.status # 查看door2的状态Out[5]: 'openning'In [6]: door1.open() # 运行door1实例的open()方法In [7]: door1.status # 查看door1的状态，发现变成'openning'Out[7]: 'openning'In [8]: door1.close() # 运行door1实例的close()方法In [9]: door1.status # 查看door1的状态，变为了'closed'Out[9]: 'closed'In [10]: door2.number = 222 # 变更door2的号码为222In [11]: door2.number # door2实例的号码就变为了222Out[11]: 222In [12]: door1.number # door1实例的号码不变，还是1Out[12]: 1]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[装饰器(Decorators)]]></title>
    <url>%2Fpython%2F20170511-08-decoractors%2F</url>
    <content type="text"><![CDATA[装饰器是给已有的函数加上一些小装饰（即一些小功能，这些小功能可能好多函数都会用到），但是不会让这个小装饰（小功能）侵入到原有的模块代码中。 ——引用于CoolShell.cn的文章：《Python修饰器的函数式编程》(下面部分内容摘抄自上述文章) 1 不带参数的装饰器先看一个没有用到装饰器的代码： 12345678910In [1]: import time ...: ...: def sleep(n): ...: time.sleep(n) ...: ...: start = time.time() ...: sleep(3) ...: print(time.time()-start) ...: 3.0056068897247314 上述代码的作用就是算出sleep(3)这个的执行时间。 我们可以改写代码，使得计算函数执行时间的代码作为一个函数，接收一个函数，然后计算这个函数的执行时间。 123456789101112import timedef timeit(fn, *args, **kwargs): start = time.time() ret = fn(*args,**kwargs) print(time.time()-start) return retdef sleep(n): time.sleep(n)timeit(sleep,3) 上面的代码，必须用timeit来传入sleep函数和sleep的参数来运行，我们可不可以提前装饰下要被装饰的函数，然后调用呢？可以的，如下： 1234567891011121314151617In [2]: import time ...: ...: def timeit(fn): ...: def wrapper(*args, **kwargs): ...: start = time.time() ...: ret = fn(*args, **kwargs) ...: print(time.time()-start) ...: return ret ...: return wrapper ...: ...: def sleep(n): ...: time.sleep(n) ...: ...: sleep = timeit(sleep) #提前把sleep函数装饰了。 ...: sleep(3) # 再调用函数的时候，就是调用被装饰过的sleep函数了。 ...: 3.000748872756958 Python提供了一种装饰器的语法糖，可以把这三行： 1234def sleep(n): time.sleep(n)sleep = timeit(sleep) 改为下面这三行: 123@timeitdef sleep(n): time.sleep(n) 完整版语法糖版的装饰器示例如下： 1234567891011121314151617In [3]: import time ...: ...: def timeit(fn): ...: def wrapper(*args, **kwargs): ...: start = time.time() ...: ret = fn(*args,**kwargs) ...: print(time.time()-start) ...: return ret ...: return wrapper ...: ...: @timeit ...: def sleep(n): ...: time.sleep(n) ...: ...: sleep(3) ...: 3.004680871963501 装饰器的本质是高阶函数，接受一个函数作为参数，并且返回一个函数。 装饰器通常会返回一个封装函数（上述代码中的wrapper），这个封装函数在传入的函数前后做一些事情。 详解上述代码： 我们在timeit装饰器里定义了一个封装函数wrapper，这个wrapper函数在我们真正传入的函数fn的前后做了一些操作，计算出了fn运行的时间差，并且把函数返回回去，然后把这个封装函数wrapper返回回去，替换原来的fn。 @timeit 然后定义的函数sleep，意味着sleep = timeit(sleep)，即sleep即为传入的函数，然后经过wrapper的封装，返回回来，替换原来的sleep。 2 装饰器里的@wraps用法我们看这样一个例子： 1234567891011121314151617181920212223In [3]: def timeit(fn): ...: def wrapper(*args, **kwargs): ...: start = time.time() ...: ret = fn(*args, **kwargs) ...: print(time.time() - start) ...: return ret ...: return wrapper ...: ...: @timeit ...: def add(x, y): ...: '''x + y''' ...: return x + y ...: In [4]: help(add)Help on function wrapper in module __main__:wrapper(*args, **kwargs)In [5]: add.__name__Out[5]: 'wrapper' 我们本意是求add的用法，和add的名字，结果给的不是我们想要的，是因为我们调用add的帮助和名字，实际上调用的是wrapper，所以我们返回的都是wrapper的help和name。 这里就可以在装饰器timeit里面用@wraps(fn)方法，这个方法在标准库functools里面。这样我们就可以得到想要的结果了，查看帮助是add的帮助,name是add的name： 1234567891011121314151617181920212223242526In [6]: from functools import wraps ...: ...: def timeit(fn): ...: @wraps(fn) # 下面的函数wrapper就集成了传入的函数的属性。 ...: def wrapper(*args, **kwargs): ...: start = time.time() ...: ret = fn(*args, **kwargs) ...: print(time.time() - start) ...: return ret ...: return wrapper ...: ...: @timeit ...: def add(x, y): ...: '''x + y''' ...: return x + y ...: In [7]: help(add)Help on function add in module __main__:add(x, y) x + y In [8]: add.__name__Out[8]: 'add' 3 带参数的装饰器一个程序占用的时间分为用户时间（包括sleep等待的时间），和cpu时间（cpu时间不包括sleep等待的时间）。下面是cpu时间的例子： 12345678910n [12]: import time ...: ...: def sleep(n): ...: time.sleep(3) ...: ...: start = time.clock() ...: sleep(3) ...: time.clock() - start ...: Out[12]: 0.0009540000000001214 我们想写一个装饰器，既可以返回用户时间，又可以返回cpu时间，默认返回的是用户时间（可以用一个开关作为参数，来控制返回的是什么时间），这时候我们就用到了带参数的装饰器： 12345678910111213141516171819202122232425262728293031In [13]: import time ...: ...: def timeit(cpu_time = False): ...: # 根据传入的参数，来决定是用time.clock还是time.time ...: time_func = time.clock if cpu_time else time.time ...: def dec(fn): ...: @wraps(fn) ...: def wrapper(*args, **kwargs): ...: start = time_func() ...: ret = fn(*args, **kwargs) ...: print(time_func() - start) ...: return ret ...: return wrapper ...: return dec ...: ...: # 下面注释，等同于@timeit()那段 ...: # def fun(n): ...: # time.sleep(n) ...: # return n ...: # fun = timeit()(fun) ...: # 其实上面这行，用柯里化就非常好理解了。 ...: ...: @timeit() # 参数为空，但也是带了参数了，空参数，传入的参数为默认参数，等同于@timeit(cpu_time = False） ...: def fun(n): ...: time.sleep(n) ...: return n ...: In [14]: fun(3)3.0001399517059326Out[14]: 3 上面是返回用户时间的装饰器。 如果后面几行像下面这样写，就是输出cpu时间了： 123456789In [15]: @timeit(cpu_time = True) # 传入cpu_time的参数为True，覆盖掉False默认参数 ...: def fun(n): ...: time.sleep(n) ...: return n ...: In [16]: fun(3)0.0007150000000000212Out[16]: 3 带参数的装饰器本质是一个函数，传入参数，返回一个新的装饰器。 带参数的装饰器只允许一层，如果像这样@xxx()()多层了，就会报错。 多个装饰器装饰的时候，采用就近原则，然后一层层装饰，比如： 123456@a@b@cdef fn(): pass# 上述等效于a(b(c(fn))) 4 装饰器的应用4.1 给函数调用做缓存1234567891011121314151617181920from functools import wrapsdef memo(fn): cache = &#123;&#125; miss = object() @wraps(fn) def wrapper(*args): result = cache.get(args, miss) if result is miss: result = fn(*args) cache[args] = result return result return wrapper @memodef fib(n): if n &lt; 2: return n return fib(n - 1) + fib(n - 2) 上面这个例子中，是一个斐波拉契数例的递归算法。我们知道，这个递归是相当没有效率的，因为会重复调用。比如：我们要计算fib(5)，于是其分解成fib(4) + fib(3)，而fib(4)分解成fib(3)+fib(2)，fib(3)又分解成fib(2)+fib(1)…… 你可看到，基本上来说，fib(3), fib(2), fib(1)在整个递归过程中被调用了两次。 而我们用decorator，在调用函数前查询一下缓存，如果没有才调用了，有了就从缓存中返回值。一下子，这个递归从二叉树式的递归成了线性的递归。 4.2 给函数打日志下面这个示例演示了一个logger的decorator，这个decorator输出了函数名，参数，返回值，和运行时间。 12345678910111213141516171819202122232425262728from functools import wrapsdef logger(fn): @wraps(fn) def wrapper(*args, **kwargs): ts = time.time() result = fn(*args, **kwargs) te = time.time() print("function = &#123;0&#125;".format(fn.__name__)) print(" arguments = &#123;0&#125; &#123;1&#125;".format(args, kwargs)) print(" return = &#123;0&#125;".format(result)) print(" time = %.6f sec" % (te-ts)) return result return wrapper @loggerdef multipy(x, y): return x * y @loggerdef sum_num(n): s = 0 for i in xrange(n+1): s += i return s print(multipy(2, 10))print(sum_num(100))print(sum_num(10000000)) 上面那个打日志还是有点粗糙，让我们看一个更好一点的（带log level参数的）： 1234567891011121314151617181920import inspectdef get_line_number(): return inspect.currentframe().f_back.f_back.f_lineno def logger(loglevel): def log_decorator(fn): @wraps(fn) def wrapper(*args, **kwargs): ts = time.time() result = fn(*args, **kwargs) te = time.time() print "function = " + fn.__name__, print " arguments = &#123;0&#125; &#123;1&#125;".format(args, kwargs) print " return = &#123;0&#125;".format(result) print " time = %.6f sec" % (te-ts) if (loglevel == 'debug'): print " called_from_line : " + str(get_line_number()) return result return wrapper return log_decorator 但是，上面这个带log level参数的有两具不好的地方，1） loglevel不是debug的时候，还是要计算函数调用的时间。2） 不同level的要写在一起，不易读。 我们再接着改进： 12345678910111213141516171819202122232425262728293031323334import inspect def advance_logger(loglevel): def get_line_number(): return inspect.currentframe().f_back.f_back.f_lineno def _basic_log(fn, result, *args, **kwargs): print "function = " + fn.__name__, print " arguments = &#123;0&#125; &#123;1&#125;".format(args, kwargs) print " return = &#123;0&#125;".format(result) def info_log_decorator(fn): @wraps(fn) def wrapper(*args, **kwargs): result = fn(*args, **kwargs) _basic_log(fn, result, args, kwargs) return wrapper def debug_log_decorator(fn): @wraps(fn) def wrapper(*args, **kwargs): ts = time.time() result = fn(*args, **kwargs) te = time.time() _basic_log(fn, result, args, kwargs) print " time = %.6f sec" % (te-ts) print " called_from_line : " + str(get_line_number()) return wrapper if loglevel is "debug": return debug_log_decorator else: return info_log_decorator 你可以看到两点，1）我们分了两个log level，一个是info的，一个是debug的，然后我们在外尾根据不同的参数返回不同的decorator。2）我们把info和debug中的相同的代码抽到了一个叫_basic_log的函数里，DRY原则。 以上例子来自于：http://coolshell.cn/articles/11265.html其他装饰器例子参考：https://wiki.python.org/moin/PythonDecoratorLibrary 英文不错的也可以参考英文文章，比如这篇https://qxf2.com/blog/python-decorators/，文章开头图片来自于此文章。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>function</tag>
        <tag>decorators</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高阶函数、闭包、偏函数、柯里化、匿名函数]]></title>
    <url>%2Fpython%2F20170511-07-higher-order-function%2F</url>
    <content type="text"><![CDATA[1 高阶函数 一个函数可以接收另一个函数作为参数，这种函数就称之为高阶函数。 如下面的add函数就是一个高阶函数，他接收一个函数作为参数：12345In [1]: def add(x, y, fn): ...: return fn(x) + fn(y) ...: In [5]: add(10, -20, abs) Out[5]: 30 在上述例子中，我们传入的x 为10， y 为 -20 ，传入的函数为abs函数，返回abs(10) + abs(20)。 上述高阶函数例子，我们也可以传入其他的函数，比如我们定义一个square（平方）函数，然后把这个平方函数传入到add高阶函数 123456In [8]: def square(x): ...: return x*x ...: In [9]: add(10, -20, square)Out[9]: 500 其实add(10, -20, square)就相当于 square(10) + square(20)，即10*10 + 20*20。 其他好多语言是无法直接传递函数作为参数到另外一个函数，要用到函数指针，而Python可以直接传递一个函数进来。 我们可以完善下上述程序，当没有指定传入参数fn的时候，就调用默认的default_add函数，即默认把传入的x和y相加后返回；如果指定了fn函数，就返回fn(x) + fn(y)的值。如下： 12345678910111213141516In [17]: def add(x, y, fn=None): ...: def default_add(a, b): ...: return a + b ...: if fn is None: ...: add = default_add ...: return add(x, y) ...: else: ...: return fn(x) + fn(y) ...: In [18]: add(10, -20) # 不指定默认函数，默认返回x + yOut[18]: -10In [19]: add(10, -20, abs) # 指定了默认函数为abs，就返回abs(x) + abs(y)Out[19]: 30 2 闭包 一个函数的返回值里有函数，就是闭包闭包也是高阶函数。 下面的这样的一个函数就是一个闭包。此函数的作用是做一个计数器，可以增加减少和重置的计数器：123456789101112131415161718192021222324252627282930313233In [1]: def make_counter(init): #给计数器一个初始值 ...: counter = [init] ...: def inc(): ...: counter[0] += 1 ...: def dec(): ...: counter[0] -= 1 ...: def get(): ...: return counter[0] ...: def reset(): ...: counter[0] = init ...: return inc, dec, get, reset ...: In [2]: inc, dec, get, reset = make_counter(0)In [3]: inc() # 增加In [4]: inc()In [5]: inc()In [7]: get() # 获取Out[7]: 3In [8]: dec() # 减少In [9]: get()Out[9]: 2In [10]: reset() # 重置In [11]: get()Out[11]: 0 上述还可以用nolocal的形式来写(nolocal方式可选学习)： 123456789101112131415In [12]: def make_counter(init=0): ...: counter = init ...: def inc(): ...: nonlocal counter ...: counter += 1 ...: def dec(): ...: nonlocal counter ...: counter -= 1 ...: def get(): ...: nonlocal counter ...: return counter ...: def reset(): ...: nonlocal counter ...: counter = init ...: return inc, dec, get, reset 总结一下： 参数是函数。 返回值是函数。满足以上两点任意一点的函数,就称之为高阶函数 3 偏函数偏函数英文叫partital，从functools模块导入。用法： partial(func, *args, **keywords) - new function with partial application of the given arguments and keywords. 意思为给func函数传入参数，并固定下来，即可以固定一个或多个参数。 123456789101112In [1]: from functools import partialIn [2]: help(partial)In [3]: partial(int,base=16)Out[3]: functools.partial(&lt;class 'int'&gt;, base=16)In [4]: hex_to_int = partial(int,base=16)In [6]: hex_to_int('0xaaaa')Out[6]: 43690 12345678910In [9]: lst = [ 3, 1, 2 , 5, 4]In [10]: sorted(lst)Out[10]: [1, 2, 3, 4, 5]In [15]: sorted_desc = partial(sorted, reverse = True) # sorted_desc即为降序排序，固话参数reverse为TrueIn [16]: sorted_desc(lst)Out[16]: [5, 4, 3, 2, 1] 来一个实际应用：比如我们经常创建数据库连接，而数据的某些信息是固定的，就可以用partial函数。 123from functools import partitalmy_connect = partital(connect, port=3000) #端口是固定的3000，就可以用偏函数固化。 4 柯里化柯里化是闭包的一种。 f(x, y , z) =&gt; g(x)(y)(z) 123456789101112In [17]: def add(x,y): #正常的函数 ...: return x + y ...: In [18]: def add(x): # 柯里化的函数 ...: def inner_add(y): ...: return x + y ...: return inner_add ...: In [19]: add(3)(5)Out[19]: 8 5 匿名函数 lambda parameters : expression 只能写在一行上。 前面是参数，后面是表达式。表达式作为返回值。1234567In [16]: lambda x, y : x + yOut[16]: &lt;function __main__.&lt;lambda&gt;&gt;In [17]: add = lambda x, y : x + yIn [18]: add(3, 5)Out[18]: 8 lambda函数也可以给默认值、可变参数、可变关键字参数，keyword-only参数 12345678910111213141516171819In [19]: add = lambda x, y = 1: x + yIn [20]: add(5)Out[20]: 6In [21]: add = lambda *x : sum(x) # 支持可变参数In [22]: add(1,2,3,4)Out[22]: 10In [39]: f = lambda **kw: kw # 支持可变关键字参数In [40]: f(a=0, b=1)Out[40]: &#123;'a': 0, 'b': 1&#125;In [41]: f = lambda x, *, y: x + y # 支持keyword-onlyIn [42]: f(1,y=3)Out[42]: 4 匿名函数通常和高阶函数配合使用，作为参数传入，或者作为返回值返回 一些短小的函数，我们就可以写匿名函数，而不用写好几行代码，一行匿名函数就够了。 1234In [2]: fib = lambda n: 1 if n==0 or n==1 else fib(n-1)+fib(n-2)In [3]: fib(10)Out[3]: 89 但是匿名函数最好不要定义递归的，匿名函数通常用来定义一些简单的函数。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>function</tag>
        <tag>higher order function</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[生成器函数]]></title>
    <url>%2Fpython%2F20170511-06-generator-function%2F</url>
    <content type="text"><![CDATA[1 定义之前有说过生成器解析式。这里我们来写一下生成器的函数，生成器函数就是在函数体里写yield 12345678910111213141516171819In [85]: def gen(): ...: yield 0 ...: In [86]: g = gen()In [87]: type(g)Out[87]: generatorIn [89]: next(g)Out[89]: 0In [90]: next(g)------------------------------------------------------------StopIteration Traceback (most recent call last)&lt;ipython-input-90-5f315c5de15b&gt; in &lt;module&gt;()----&gt; 1 next(g)StopIteration: 我们写一个复杂点的：12345678910111213141516171819In [91]: def gen(): ...: while True: ...: yield 0 ...: print('.....') ...: In [98]: g = gen()In [99]: next(g)Out[99]: 0In [100]: next(g).....Out[100]: 0In [101]: next(g).....Out[101]: 0 我们可以看出，一执行next，就到yield那条语句执行完返回后面的值，然后暂停，等待下一次next，下一次再next就先执行剩下的部分，然后执行到下一次循环，到yield那条语句，返回yield后面的值，然后又暂停。 生成器的定义和函数类似，但是有yield语句。 生成器执行到yield的时候会暂停，再次的时候，next会从暂停的地方继续执行到下一次yield。 我们再写一个： 1234567891011121314151617181920In [107]: def gen(x): ...: for i in range(x): ...: yield i ...: In [108]: g = gen(10)In [109]: for x in g: ...: print(x) ...: 0123456789 2 yield和returnyield 弹出值，暂停函数return返回值，并结束函数 yied可以和return并用： 12345678910111213141516171819In [111]: def gen(x): ...: for i in range(10): ...: yield i ...: return 'ok'In [112]: g = gen(10)In [113]: for x in g: ...: print(x) ...: 012456789 从上我们可以看出，当yield和return同时存在的时候，return的返回值会被忽略，但是return依然可以中断生成器。 3 协程协程是用户空间的轻量线程，泡在一个线程内，由用户空间调度。 生成器就可以实现协程。 1234567891011121314151617181920212223In [118]: def gen1(): ...: while True: ...: yield 'gen 1' ...: In [121]: def gen2(g): ...: while True: ...: yield 'gen 2' ...: print(next(g)) ...: In [122]: g = gen2(gen1())In [123]: next(g)Out[123]: 'gen 2'In [124]: next(g)gen 1Out[124]: 'gen 2'In [125]: next(g)gen 1Out[125]: 'gen 2' 4 生成器的应用 下面是一个计数器（counter），如果在单线程环境下，没有意义，可视用在多线程下，就有意义了。 1234567891011121314151617In [134]: def counter(init): ...: c = init ...: while True: ...: yield c ...: c +=1 ...: In [135]: c = counter(0)In [136]: next(c)Out[136]: 0In [137]: next(c)Out[137]: 1In [138]: next(c)Out[138]: 2 惰性求值(由于函数是在yield处暂停的，所以，可以用到时，才去计算) 比如下面的阶乘函数：12345678910111213141516171819202122232425262728In [147]: def factorial(): ...: ret = 1 ...: idx =0 ...: while True: ...: yield ret ...: idx +=1 ...: ret *= idx ...: In [148]: g = factorial()In [149]: next(g)Out[149]: 1In [150]: next(g)Out[150]: 1In [151]: next(g)Out[151]: 2In [152]: next(g)Out[152]: 6In [153]: next(g)Out[153]: 24In [154]: next(g)Out[154]: 120 我们可以使用生成器来替换递归。 所有的递归，都可以用生成器来替换。(这样就没有深度限制了) 12345678910111213141516In [159]: def g(n): ...: def fact(): ...: ret = 1 ...: idx = 0 ...: while True: ...: yield ret ...: idx += 1 ...: ret += idx ...: gen = factorial() ...: for _ in range(n): ...: next(gen) ...: return next(gen) ...: In [160]: g(10)Out[160]: 3628800 5 yield from用法1234In [161]: def gen(lst): ...: for x in lst: ...: yield x ...: 上面的我们迭代一个列表，用循环来yield，其实可以用yield from 可迭代对象的简写方法： 123In [163]: def gen(lst): ...: yield from lst ...: yield from我们也可用在元组、字符串、文件对象等可迭代对象。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>function</tag>
        <tag>generator</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[递归函数]]></title>
    <url>%2Fpython%2F20170511-05-recursive-function%2F</url>
    <content type="text"><![CDATA[我们来看一个斐波那契数列的定义： fn(0) = 1fn(1) = 1fn(n) = f(n-1) + f(n-2) 例如：1 1 2 3 5 8 13 21 34 我们用函数来定义就是： 123456789101112131415161718In [35]: def fib(n): ...: if n == 0: ...: return 1 ...: if n == 1: ...: return 1 ...: return fib(n-1) + fib(n-2)In [40]: fib(1)Out[40]: 1In [41]: fib(5)Out[41]: 8In [42]: fib(10)Out[42]: 89In [44]: fib(19)/fib(20)Out[44]: 0.618033985017358 # 0.618黄金分割比例 我们再看一个简单的： 阶乘（factorial）:fact(0) = 1fact(1) = 1fact(n) = n*fact(n-1) 用函数来写就是： 1234567891011121314151617In [51]: def fact(n): ...: if n == 0: ...: return 1 ...: if n == 1: ...: return 1 ...: return n * fact(n-1) ...: ...: In [52]: fact(1)Out[52]: 1In [53]: fact(5)Out[53]: 120In [54]: fact(10)Out[54]: 3628800 fact(5)的实际执行过程就是这样： ===&gt; fact(5)===&gt; 5 fact(4)===&gt; 5 (4 fact(3))===&gt; 5 (4 (3 fact(2)))===&gt; 5 (4 (3 (2 fact(1))))===&gt; 5 (4 (3 (2 1)))===&gt; 5 (4 (3 2))===&gt; 5 (4 6)===&gt; 5 24===&gt; 120 在Python中，递归深度是有限制的， 默认深度是1000， 我们可以更改默认深度，但是如果太大, 而且可能让服务器的cpu冲高。12345678In [55]: import sysIn [56]: sys.getrecursionlimit() # 默认递归深度为1000Out[56]: 1000In [66]: sys.setrecursionlimit(10000) # 更改递归深度为10000In [71]: fib(1000) # 这个要跑很久，cpu 100%,普通的电脑跑一两分钟跑不出来，服务器去跑很快，貌似因为服务器的指令集不同，感觉运算很快。 递归在Python中非常慢，而且有深度限制，所以尽量避免使用递归。 比如上面的阶乘函数，我们就可以用普通函数来写。12345In [73]: def fact(n): ...: ret = 1 ...: for x in range(1,n+1): ...: ret *= x ...: return ret 在Python当中我们可以完全不使用递归。 但是在写某些函数的时候，如果递归写起来非常简单，那么也可以写递归，但是递归层数最好不要太多。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>function</tag>
        <tag>recursive</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[函数注解（类型示意）]]></title>
    <url>%2Fpython%2F20170511-04-function-annotation%2F</url>
    <content type="text"><![CDATA[我们说过，Python是一种强类型的动态语言。但是也有类型示意，但是不是强制性质的，没有强制指定类型。 123456789101112In [14]: def add(x:int, y:int) -&gt; int: ...: return x+y ...: In [15]: add(1,2)Out[15]: 3In [16]: add(1.0, 2.0)Out[16]: 3.0In [17]: add('x', 'y')Out[17]: 'xy' 从上面代码而已看出，类型示意没有任何类型检查，仅仅只是一个示意而已。我们可以用help来查看类型示意： 123In [19]: help(add)Help on function add in module __main__:add(x:int, y:int) -&gt; int Python是一种自文档的语言，很多时候，我们需要自己来写用法示意，以前都是用三引号引起来，来说明函数的用法： 123456789101112131415161718In [21]: def add(x, y): ...: ''' ...: @param x int ...: @param y int ...: @return int ...: ''' ...: return x+y Help on function add in module __main__:In [24]: help(add)Help on function add in module __main__:add(x, y) @param x int @param y int @return int 有了上面的类型示意后，很多时候简单的就不用写了，类型示意就能明白 用处： 一种更清晰的自文档。（很多时候就不用写docstrings了，写个类型示意简单明了） 帮助IDE做检查（像PyCharm做检查时候） 可以通过这种机制，做类型检查（可以在装饰器里来限制传入参数的类型，装饰器里会讲）。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>function</tag>
        <tag>annotation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[函数的参数]]></title>
    <url>%2Fpython%2F20170511-03-function-argument%2F</url>
    <content type="text"><![CDATA[1. 函数定义时的参数(parameter)1.1 普通参数init是普通参数： 123456789In [1]: def inc(init): ...: return init + 1 ...: In [2]: inc(3)Out[2]: 4In [3]: inc(4)Out[3]: 5 1.1 默认参数下面step = 1，是默认参数： 123456789101112In [4]: def inc(init, step=1): ...: return init + step ...: In [5]: inc(3, 2) # 覆盖掉默认参数Out[5]: 5In [6]: inc(3) # 不填默认参数，默认用默认参数1Out[6]: 4In [7]: inc(3, 1) # 效果和上面等同Out[7]: 4 使用默认参数，一时可以让api更简洁，又不失灵活性，可以用通用性的默认参数，也可以自定义参数值，比较灵活。 还有，当我们对旧函数重构功能时候，用默认参数，可以保持函数的向下兼容性。 默认参数要在非默然参数后面： 允许有多个默认参数，但是默认参数要放在参数列表的最后面，否则会报语法错误： 123456In [15]: def inx(step=1, x): ...: return x + step File "&lt;ipython-input-15-f03eeca5f89a&gt;", line 1 def inx(step=1, x): ^SyntaxError: non-default argument follows default argument 默认参数的值，如果是可变的，在函数体里不要修改： 12345678910 In [16]: def append(x, lst =[]): ...: lst.append(x) ...: return lst ...: In [17]: append(1)Out[17]: [1]In [18]: append(2)Out[18]: [1, 2] 我们可以看到，lst属于调用者的全局变量，这样的话重复调用函数会有问题。 如果实在要用，，可以采用下面的方式：1234567891011In [19]: def append(x, lst=None): ...: if lst is None: ...: lst = [] ...: lst.append(x) ...: return lstIn [28]: append(1)Out[28]: [1]In [29]: append(2)Out[29]: [2] 1.2 可变位置参数可变位置参数用*来定义，在函数体内，可变位置参数是一个元组。 123456789101112In [1]: def fn(*args): ...: print(args) ...: In [2]: fn()()In [3]: fn(1)(1,)In [5]: fn(1, 2, 3, 4, 5, 6)(1, 2, 3, 4, 5, 6) 1.3 可变关键字参数可变关键字参数用**来定义，在函数体内，可变位置参数是一个字典。 可变关键字参数的key都是字符串，并且符合标识符定义规范。123456In [6]: def fn(**kwargs): ...: print(kwargs) ...: In [7]: fn(a=5, b=6)&#123;'b': 6, 'a': 5&#125; 可变位置参数只能以位置参数的额形式调用 可变关键字参数只能以关键字参数的形式调用 1.4 可变关键字参数和可变关键字参数混用两者可以混用，但是可变位置参数必须在可变关键字参数前面。 1234567891011121314151617In [1]: def fn(*args, **kwargs): ...: print(args) ...: print(kwargs) ...: In [2]: fn(1, 2, 3, a=1, b=2)(1, 2, 3)&#123;'a': 1, 'b': 2&#125;In [3]: def fn(**kwargs, *args): #可变位置参数必须在可变关键字参数前面 ...: print(kwargs) ...: print(args) ...: File "&lt;ipython-input-3-ff68f43fac13&gt;", line 1 def fn(**kwargs, *args): ^SyntaxError: invalid syntax 1.5 普通参数，可变位置参数，可变关键字参数混用123456789101112In [4]: def fn(x, y, *args, **kwargs): ...: print(x) ...: print(y) ...: print(args) ...: print(kwargs) ...: In [5]: fn(1, 2, 3, 4, 5, 6, 7, a=1, b=2)12(3, 4, 5, 6, 7)&#123;'a': 1, 'b': 2&#125; 2. 函数调用时的参数(argument)首先定义一个函数：123In [23]: def minus(x, y): ...: return x-y ...: 下面是调用（传参）的情况： 2.1 位置参数（位置传参）按照对应的位置传入： 12345In [24]: minus(5, 3)Out[24]: 2In [25]: minus(3, 5)Out[25]: -2 2.2 关键字参数（关键字传参）按照关键字传参，无所谓位置12345In [26]: minus(x=3 , y=5)Out[26]: -2In [27]: minus(y=5, x=3)Out[27]: -2 2.3 位置参数和关键字参数混用混用的话，关键字参数要在位置参数后面，否则会报错。 12345678In [30]: minus(3 , y=5)Out[30]: -2In [31]: minus(x=3 , 5) File "&lt;ipython-input-31-37ba1a10f555&gt;", line 1 minus(x=3 , 5) ^SyntaxError: positional argument follows keyword argument 2.7 使用规则 可变参数后置 可变参数不和默认参数一起出现。 编写代码，通常遵循上面两条规则，否则容易混乱。 2.8 参数解构参数解构发生在函数调用的时候。 *可以把线性结构解包成位置参数。 1234567891011In [12]: def fn(a, b, c): ....: print(a, b, c) ....: In [13]: lst = [1, 2, 3]In [14]: fn(lst[0],lst[1], lst[2])1 2 3In [15]: fn(*lst) # 参数解构，fn(*lst)等价于fn(lst[0],lst[1], lst[2])1 2 3 **可以把字典解构成关键字参数。 1234567In [12]: def fn(a, b, c): ....: print(a, b, c) ....: In [16]: d = &#123;'a':1, 'b':2, 'c':3&#125;In [17]: fn(**d) 如果传入的参数解构的元素太多，可以在函数里采用*args的形式，来去掉多余的参数。 12345678In [22]: def fn(a, b, c, *args): ....: print(a, b, c) ....: In [23]: lst = [1, 2, 3, 4, 5]In [24]: fn(*lst)1 2 3 也可以用**kwargs，去掉多余的参数。 12345678In [25]: d = &#123;'a':1, 'b':2, 'c':3, 'd':4, 'e':5&#125;In [26]: def fn(a, b, c, *args, **kwargs): ....: print(a, b, c ) ....: In [27]: fn(**d)1 2 3 2.9 传参的一个顺序位置参数，线性结构解构，关键字参数，字典解构 解构的时候，线性结构的解构后是位置参数，字典结构成关键字参数。 在传入时候注意冲突。 尽量不要同时使用两种结构，除非你真的知道在做什么。 2.10 参数槽（keyword-only）*之后的参数，必须以关键字参数的形式传递，称之为参数槽（又叫keyword-only）。 1234567891011121314151617In [4]: def fn(a, b, *, c): ...: print(a, b ,c) ...: In [6]: fn(1, 2, c=3)1 2 3In [7]: fn(a=1, b=2, c=3)1 2 3In [22]: fn(1, 2, 3)---------------------------------------------------------------------------TypeError Traceback (most recent call last)&lt;ipython-input-22-9ab6b0a400c3&gt; in &lt;module&gt;()----&gt; 1 fn(1, 2, 3)TypeError: fn() takes 2 positional arguments but 3 were given 参数槽通常和默认参数搭配使用 参数槽通常在我们认为一些参数通常不会改变的情况下使用，如果需要使用，必须要用关键字参数来调用。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>function</tag>
        <tag>argument</tag>
        <tag>parameter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[函数执行过程]]></title>
    <url>%2Fpython%2F20170511-02-function-process%2F</url>
    <content type="text"><![CDATA[在学习函数初期，我们可以用pythontutor来分析函数的执行过程，帮助理解函数: 123456789def inc(x): return x + 1def inc_add(x, y): return inc(x) + inc(y) x = 1y = 2z = inc_add(x, y)]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>function</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[函数基本定义和函数调用]]></title>
    <url>%2Fpython%2F20170511-01-function-define%2F</url>
    <content type="text"><![CDATA[定义函数（define）简单的定义一个函数的格式： 12def function_name(parameter_list): statements 结构为def，后面接函数名(function name)，然后括号括起来的参数列表（parameter list），参数以逗号分隔，然后再接冒号:，下面是函数语句(statements)。 函数语句里通常包含一个return语句，或者是yield语句，或者是二者都有。 写一个简单的函数： 123In [18]: def add(x, y): ....: return x+y ....: 函数调用（call）函数调用格式：参数名加括号括起来的传入参数（argument），传入参数以逗号分隔。 1function_name(argument_list) 例如上面的add函数调用： 12In [19]: add(1, 2)Out[19]: 3 作用域（scope）LGB原则： Built-in（内置作用域：open，range） Global（全局作用域：模块（或文件）最外层，或者在函数内里声明了global） Local（函数内的作用域） 在函数内搜索变量时候，先从函数本地作用域查找，如果没有，再去全局作用域查找，然后再去内置作用域查找: Local–&gt;Global –&gt; Built-in 当然，函数内可以有多层嵌套函数或匿名函数，以层级从内（inner）到外（outer）查找。 让我们看两个例子： 12345678910In [20]: def append(lst,x): ....: lst.append(x) ....: In [21]: lst = [1, 2, 3]In [22]: append(lst, 4)In [23]: lstOut[23]: [1, 2, 3, 4] 上面append(lst, 4)，在函数内没有找到lst的定义，所以去全局再找，在全局找到了lst，这时候给lst添加4后，改变了全局的lst值，我们可以看到lst变成了[1, 2, 3, 4] 下面这个例子比较绕，大家需要仔细体会： 1234567891011121314151617In [24]: def swap(x,y): ....: x, y = y, x ....: print(x, y) ....: In [25]: x = 3In [26]: y = 4In [27]: swap(x, y)4 3In [28]: xOut[28]: 3In [29]: yOut[29]: 4 上面这个例子是这样：我们运行swap(x, y)是在global作用域，是传入的全局的x 和 y的值，也就相当于运行swap(3, 4)，在函数内部，把4，3的值赋给了函数本地作用域里的x和y，也就是说函数本地的x = 4, y = 3。而我们最后运行查看x和y是在global作用域运行的，所以查看的是global作用域里的x和y 换一种表现形式大家更能明白： 1234567891011121314151617In [30]: def swap(globalx, globaly): ....: localx, localy = globaly, globalx ....: print(localx, localy) ....: In [31]: globalx = 3In [32]: globaly = 4In [33]: swap(globalx, globaly)4 3In [34]: globalxOut[34]: 3In [35]: globalyOut[35]: 4 返回值在函数里可以用return来定义函数的返回值。如果没有定义return语句，默认会返回一个None。 例如： 12345678In [43]: def add(x,y): ....: return x + y ....: In [44]: ret = add(1, 2)In [45]: print(ret)3 12345678In [39]: def fn(): ....: pass ....: In [40]: ret = fn()In [42]: print(ret)None 如果return后面跟多个值，会把多个值隐式封装成一个元组。 我们可以对return回来的元组进行解包操作，也是可以的。 12345678910111213141516171819In [46]: def unpack(lst): ....: head, *tail = lst ....: return head, tail ....: In [47]: lst1 = [1, 2, 3, 4]In [48]: all = unpack(lst1)In [49]: all # 我们看到返回的多个值被封装成元组Out[49]: (1, [2, 3, 4])In [50]: head, tail = all # 可以对返回值进行解包操作In [51]: headOut[51]: 1In [52]: tailOut[52]: [2, 3, 4] 一个函数可以有任意多个return语句，但是始终只会执行一个return语句，执行完return语句后，会返回到调用方作用域。原函数作用域里的其他语句都不执行，直接跳出来。如果在多层循环里，会跳出所有循环并跳出函数作用域。 12345678910111213141516In [56]: lst1Out[56]: [1, 2, 3, 4]In [57]: def append(lst,x): ....: return "No Operation" ....: lst.append(x) ....: return "Have Operation" ....: In [58]: ret = append(lst1, 5)In [59]: ret # 只返回了执行到的第一个return语句Out[59]: 'No Operation'In [60]: lst1 # return后面的语句都没有被执行Out[60]: [1, 2, 3, 4] 跳出多层循环的例子： 1234567891011121314In [4]: def loop(lst1, lst2): ...: for x in lst1: ...: for y in lst2: ...: print(x, y) ...: if y == 3: ...: return ...: ...: In [5]: loop(range(10), range(10))0 00 10 20 3]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>function</tag>
        <tag>define</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[详解 可迭代对象(Iterables)、迭代器(Iterators)、生成器(Generators)]]></title>
    <url>%2Fpython%2F20170510-07-iterables-interators-generators-verbose%2F</url>
    <content type="text"><![CDATA[英文原文：http://nvie.com/posts/iterators-vs-generators/ 翻译：（译者：于龙君，严禁未经本人同意的转载，如要转载，请联系本人，转载也请注明出处。） 有时我会混淆Python中的几个概念： 容器（container） 可迭代对象（iterable） 迭代器（iterator） 生成器（generator） 生成器表达式（generator expression） 列表、集合、字典解析式（{list, set, dict} comprehension） 故写下这个帖子作为袖珍指南。 容器（Containers）容器是指存有元素的数据结构，支持成员测试。容器是存在内存里的数据结构，通常它们的值也在内存里。在Python里内置的容器有： list, deque, … set, frozensets, … dict, defaultdict, OrderedDict, Counter, … tuple, namedtuple, … str 容器易于掌握，因为您可以将其视为现实生活中的容器：盒子，立方体，房屋，船舶等。 从技术上讲，一个对象是一个容器，可以询问它是否包含某个元素。您可以对列表，集合或元组执行这样的成员关系测试： 123456&gt;&gt;&gt; assert 1 in [1, 2, 3] # lists&gt;&gt;&gt; assert 4 not in [1, 2, 3]&gt;&gt;&gt; assert 1 in &#123;1, 2, 3&#125; # sets&gt;&gt;&gt; assert 4 not in &#123;1, 2, 3&#125;&gt;&gt;&gt; assert 1 in (1, 2, 3) # tuples&gt;&gt;&gt; assert 4 not in (1, 2, 3) 字典是检查keys： 1234&gt;&gt;&gt; d = &#123;1: 'foo', 2: 'bar', 3: 'qux'&#125;&gt;&gt;&gt; assert 1 in d&gt;&gt;&gt; assert 4 not in d&gt;&gt;&gt; assert 'foo' not in d # 'foo' is not a _key_ in the dict 你也可以查看一个字符串是否包含一个子字符串： 1234&gt;&gt;&gt; s = 'foobar'&gt;&gt;&gt; assert 'b' in s&gt;&gt;&gt; assert 'x' not in s&gt;&gt;&gt; assert 'foo' in s # a string "contains" all its substrings 最后一个例子有一点奇怪，不过它展示了容器接口如何隐式呈现对象。一个字符串不会将所有子字符串的副本存储在内存中，但是可以这样来使用。 注意：尽管大多数容器数据结构提供了生成包含的每个元素的方法，但他们并不一定生成一个容器，也可能是一个可迭代对象（稍后会说到）。 并不是所有的容器都必须是可迭代的。一个例子是Bloom filter。是一种概率性的数据结构，我们可以问他是否包含某个元素，但是不能返回其中的任何元素。 可迭代对象（Iterables ）如上所述，大多数容器也是iterable，但是还有更多的东西是iterable，比如说打开的文件，打开的套接字（sockets）等。容器通常是有限的；iterable可以是有限的，也可以表示无限的数据源。 iterable不只可以是数据结构，也可以是能返回迭代器（Iterator）的任何对象（目的是为了返回其中的元素）。听起来有一点绕，但iterable和iterator有一个重要的不同，我们来看例子更明了： 12345678910111213&gt;&gt;&gt; x = [1, 2, 3]&gt;&gt;&gt; y = iter(x)&gt;&gt;&gt; z = iter(x)&gt;&gt;&gt; next(y)1&gt;&gt;&gt; next(y)2&gt;&gt;&gt; next(z)1&gt;&gt;&gt; type(x)&lt;class 'list'&gt;&gt;&gt;&gt; type(y)&lt;class 'list_iterator'&gt; 从例子可以看出, x 是 iterable, y 和 z 是两个单独的iterator实例，这两个实例从iterablex生成值。 y 和 z 都保存各自的状态。在例子里， x 是一个数据结构 (list列表), y是list_iterator(列表迭代器）。 注意：Often, for pragmatic reasons, iterable classes will implement both __iter__() and __next__() in the same class, and have __iter__() return self, which makes the class both an iterable and its own iterator. It is perfectly fine to return a different object as the iterator, though. 最后，当你写下： 123 x = [1, 2, 3]for elem in x: ... 这是实际发生的： 当您反汇编此Python代码时，您可以看到显式调用GET_ITER, 这实际上就像调用 iter(x)。 FOR_ITER 是一个指令，它将相当于重复调用next()以获取每个元素，但是这不会从字节码指令中显示，因为它在解释器中针对速度进行了优化。 123456789101112&gt;&gt;&gt; import dis&gt;&gt;&gt; x = [1, 2, 3]&gt;&gt;&gt; dis.dis('for _ in x: pass') 1 0 SETUP_LOOP 14 (to 17) 3 LOAD_NAME 0 (x) 6 GET_ITER &gt;&gt; 7 FOR_ITER 6 (to 16) 10 STORE_NAME 1 (_) 13 JUMP_ABSOLUTE 7 &gt;&gt; 16 POP_BLOCK &gt;&gt; 17 LOAD_CONST 0 (None) 20 RETURN_VALUE 迭代器（Iterators）那么什么是 iterator 呢？它是一个有状态的帮助对象，当您调用 next() 时将生成下一个值。因此，任何具有__next__()方法的对象都是iterator，如何生成一个价值是无关紧要的。 所以迭代器是一个生产值的工厂。每次你要求它的“下一个”值，它知道如何计算它，因为它保存内部状态。 有无数的迭代器例子。所有的itertools函数都返回iterator。 有些生成无限序列(infinite sequences)： 123456&gt;&gt;&gt; from itertools import count&gt;&gt;&gt; counter = count(start=13)&gt;&gt;&gt; next(counter)13&gt;&gt;&gt; next(counter)14 有些生成从有限序列（finite sequences）生成无限序列： 12345678910&gt;&gt;&gt; from itertools import cycle&gt;&gt;&gt; colors = cycle(['red', 'white', 'blue'])&gt;&gt;&gt; next(colors)'red'&gt;&gt;&gt; next(colors)'white'&gt;&gt;&gt; next(colors)'blue'&gt;&gt;&gt; next(colors)'red' 有些从无限序列生成有限序列： 123456789&gt;&gt;&gt; from itertools import islice&gt;&gt;&gt; colors = cycle(['red', 'white', 'blue']) # infinite&gt;&gt;&gt; limited = islice(colors, 0, 4) # finite&gt;&gt;&gt; for x in limited: # so safe to use for-loop on... print(x)redwhitebluered 为了更好地了解interator的内部结构，我们来构建一个产生斐波那契数的interator： 1234567891011121314151617&gt;&gt;&gt; class fib:... def __init__(self):... self.prev = 0... self.curr = 1... ... def __iter__(self):... return self... ... def __next__(self):... value = self.curr... self.curr += self.prev... self.prev = value... return value...&gt;&gt;&gt; f = fib()&gt;&gt;&gt; list(islice(f, 0, 10))[1, 1, 2, 3, 5, 8, 13, 21, 34, 55] 请注意，这个类即是一个iterable（因为它运行一个__iter__() 方法），也是迭代器（因为它有一个__next__()方法）。 这个iterator中的状态完全保存在内部的prev和curr实例变量中，并用于后续调用迭代器。每一次调用next()都要做两件重要的事情： 修改状态，为了下一次调用next()做准备。 生成当前调用的结果。 中心思想：一个懒惰的工厂从外面看，interator就像一个懒惰的工厂，平常是空闲的，除非你向它请求一个值，他才会产生一个单个的值，然后再次进入空闲状态，直到你下次再调用，这样循环往复。 生成器（Generators）最后，我们终于要说generator了！generator是我最爱的Python语言功能。一个generator就是一个特殊的迭代器——优雅的那种。 一个生成器允许你像上面的斐波纳契序列迭代器示例一样，来编写迭代器，但是使用了一个优雅的简洁语法，避免在类里写__iter__()和__next__()方法。 让我们明确的说一下： 任何generator也是一个iterator（反之亦然！）; 因此，任何generator也是一个惰性生成值的工厂。 下面也是一个斐波那契序列工厂，但是是用generator写的： 123456789&gt;&gt;&gt; def fib():... prev, curr = 0, 1... while True:... yield curr... prev, curr = curr, prev + curr...&gt;&gt;&gt; f = fib()&gt;&gt;&gt; list(islice(f, 0, 10))[1, 1, 2, 3, 5, 8, 13, 21, 34, 55] 哇，是不是很优雅？注意美丽的魔法关键字： yield 让我们分解一下这里发生的一切：首先要注意的fib是一个普通的Python函数，没什么特别的。但是，请注意，在函数体里没有return关键字。函数的返回值将是一个generator（心中默念：一个iterator，一个懒惰的工厂，一个有状态的帮助对象）。 现在，当f = fib()被调用时，genrator（懒惰的工厂）被实例化并返回，此时不会执行任何代码：只是启动了一个初始化状态的空闲generator。要明白一点：prev, curr = 0, 1这行代码还没有被执行。 然后，这个generator实例被包在一个islice()函数里。lslice(f,0,10)本身也是一个迭代器，最初是空闲的。还是什么都没有发生。 然后，这个迭代器被包装在一个list()函数里，它将消耗它的所有参数，并从它构建一个列表。为了做到这一点，它将开始在islice()实例里调用next() ，这其实是转向f实例里调用next()。 但是一次只有一步。在第一次调用时，代码会最终运行一点：prev, curr = 0, 1这行执行了，然后再到while True循环开始，然后遇到yield curr语句。然后会生成一个值，这个是就是当前curr变量里的值，然后再次进入空闲状态。 这个产生的值传入到islice()，list()函数可以把第一次生成的值1加入到列表里。 因为还没到第10个，这时会要求islice()下一个值，然后传递到要求f下一个值，它将f从之前的状态“取消暂停” ，接着运行prev, curr = curr, prev + curr。然后再次进入while循环的下一次迭代，并且命中yield curr语句，返回下一个curr的值2。 直到输出列表为10个元素长度，这时list()要求 islice()第11个值时，islice()会引发StopIteration异常，表示已到达结束，并且列表将返回结果：10个项目的列表，其中包含了前10个斐波纳契数。请注意，generator不接收第十一个next()的调用。实际上，它不会再被使用了，之后会被垃圾回收。 生成器类型（Types of Generators）Python中有两种类型的generator：generator函数（function）和generator表达式(expression)。只要yield在其函数体内出现，就叫generator函数。我们刚才还看了一个例子就是这样的。关键字的yield的出现足以使函数成为generator函数。 假设你用下面的列表解析式（list comprehension）语法来构建一个平方数列表： 123&gt;&gt;&gt; numbers = [1, 2, 3, 4, 5, 6]&gt;&gt;&gt; [x * x for x in numbers][1, 4, 9, 16, 25, 36] 你可以用集合解析式(set comprehension)来做相同的事情：You could do the same thing with a set comprehension: 12&gt;&gt;&gt; &#123;x * x for x in numbers&#125;&#123;1, 4, 36, 9, 16, 25&#125; 或者是一个字典解析式(dict comprehension)： 12&gt;&gt;&gt; &#123;x: x * x for x in numbers&#125;&#123;1: 1, 2: 4, 3: 9, 4: 16, 5: 25, 6: 36&#125; 但是您也可以使用生成器表达式（generator expression）（注意：这不是一个元组解析式(tuple comprehension），没有元组解析式这种东西） 1234567&gt;&gt;&gt; lazy_squares = (x * x for x in numbers)&gt;&gt;&gt; lazy_squares&lt;generator object &lt;genexpr&gt; at 0x10d1f5510&gt;&gt;&gt;&gt; next(lazy_squares)1&gt;&gt;&gt; list(lazy_squares)[4, 9, 16, 25, 36] 需要注意的是，因为我们用next()方法从lazy_squares读入第一个值，状态目前在第二个item上，所以，当我们通过调用list()来消费所有元素时，只会从第二个开始读入，因为我们已经用next()消费了一个了。（这也向我们展示了惰性求值行为）。这也是一个和上面例子一样的generator（当然了，也是iterator） 总结generator是一个不可思议的强大的编程结构。它们允许您编写具有较少中间变量和数据结构的流式代码。除此之外，它们具有更高的内存和CPU效率，他们也用更少的代码行来书写。 开始使用generator。 在代码中找到如下位置： 12345def something(): result = [] for ... in ...: result.append(x) return result 并替换为： 1234567def iter_something(): for ... in ...: yield x# def something(): # 当你真的需要一个列表结构时：# return list(iter_something())]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>Iterables</tag>
        <tag>Iterators</tag>
        <tag>Generators</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简单了解 可迭代对象(Iterables)、迭代器(Iterators)、生成器(Generators)]]></title>
    <url>%2Fpython%2F20170510-06-iterables-interators-generators-simple%2F</url>
    <content type="text"><![CDATA[##可迭代对象（iterable） 列表、元组、集合、字典、字符串、bytes、bytearray、生成器（generator）、range等，都是可迭代对象（iterable）。 简单的可以这样理解：能用for...in循环来迭代、能用in成员运算符的，都是可迭代对象。 迭代器（iterator）通过iter函数，可以把可迭代对象（iterable）封装成为迭代器（iterator）。 123456789In [11]: r = range(3)In [12]: it = iter(r)In [13]: type(r)Out[13]: rangeIn [14]: type(it)Out[14]: range_iterator 迭代器的本质是一种封装。很多地方都隐式的调用了迭代器。for…in循环和成员运算符隐式的调用了iter函数。 next函数可以迭代迭代器。 当迭代器没有下一个元素的时候，next函数会抛出StopIteration异常。 没有下一个元素的时候，如果设置了默认返回值，迭代结束就不会抛出异常，而是返回默认返回值。 12345678910111213141516171819In [15]: next(it)Out[15]: 0In [16]: next(it)Out[16]: 1In [17]: next(it)Out[17]: 2In [18]: next(it)---------------------------------------------------------------------------StopIteration Traceback (most recent call last)&lt;ipython-input-18-2cdb14c0d4d6&gt; in &lt;module&gt;()----&gt; 1 next(it)StopIteration: In [19]: next(it,3)Out[19]: 3 生成器（generator）生成器（generator）是迭代器的子集（iterator），迭代器中包含了生成器。 生成器可以用上节的生成器解析式来生成。 由于生成器也是迭代器，所以也可以使用next方法。 123456789101112131415161718192021222324In [35]: g = (x for x in range(3))In [36]: gOut[36]: &lt;generator object &lt;genexpr&gt; at 0x10e6c0e08&gt;In [37]: next(g)Out[37]: 0In [38]: next(g)Out[38]: 1In [39]: next(g)Out[39]: 2In [40]: next(g)---------------------------------------------------------------------------StopIteration Traceback (most recent call last)&lt;ipython-input-40-5f315c5de15b&gt; in &lt;module&gt;()----&gt; 1 next(g)StopIteration: In [41]: next(g,-1)Out[41]: -1 非生成器的迭代器的用处其他迭代器不如生成器那样能节省内存，还让可迭代对象只能next往后。那其他迭代器到底有什么用呢？ iter的一种使用场景，用的最少的一种场景。 123456789101112131415In [47]: lst = [ ....: ['温度', 28, 29, 32, 35, 30, 29, 27], ....: ['湿度', 30, 35, 45, 50, 39, 35, 30] ....: ]In [48]: for seq in lst: ....: it = iter(seq) ....: name = next(it) ....: print(name) ....: for x in it: ....: print(x, end=' ') ....: print() 温度28 29 32 35 30 29 27 湿度30 35 45 50 39 35 30 help(iter)我们可以看到第二种用法：iter(callable, sentinel) -&gt; iterator iter(…)iter(iterable) -&gt; iteratoriter(callable, sentinel) -&gt; iterator Get an iterator from an object. In the first form, the argument mustsupply its own iterator, or be a sequence.In the second form, the callable is called until it returns the sentinel. 第二种用法我们用的比较多，鉴于目前所学的知识还不够，后续会讲到。(可以实现非阻塞io）]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>Iterables</tag>
        <tag>Iterators</tag>
        <tag>Generators</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解析式（Comprehensions)]]></title>
    <url>%2Fpython%2F20170510-05-comprehensions%2F</url>
    <content type="text"><![CDATA[解析式是用一个或多个迭代器来快速建立数据结构的一种方法。可以将for循环和if判断结合，创造出一种简单快捷的语法糖，更加Pythonic。 分为几种解析式： 列表解析式（list comprehensions） 集合解析式（set comprehensions） 字典解析式（dict comprehensions） 生成器解析式（generator comprehensions） 1. 列表解析式（list comprehensions）1.1 最基本语法[ expression for item in iterable ] 用正常的for循环来建立一个列表： 12345678In [2]: list1=[]In [3]: for i in range(6): ...: list1.append(i) ...: In [4]: list1Out[4]: [0, 1, 2, 3, 4, 5] 用列表解析式来建立： 1234In [5]: list1=[i for i in range(6)]In [6]: list1Out[6]: [0, 1, 2, 3, 4, 5] 1.2加上if条件表达式[ expression for item in iterable if condition ] 下面看示例： 1234In [8]: list2=[i for i in range(5) if i % 2 == 1]In [9]: list2Out[9]: [1, 3, 5] 上面代码用传统方法来写就是： 123456789In [10]: list2=[]In [11]: for i in range(6): ....: if i % 2 == 1: ....: list2.append(i) ....: In [12]: list2Out[12]: [1, 3, 5] 1.3 多个if条件表达式1234In [24]: list3=[i for i in range(6) if i % 2 == 1 if i &gt; 2]In [25]: list3Out[25]: [3, 5] 传统方法来写就是： 12345678910In [28]: list3=[]In [29]: for i in range(6): ....: if i%2 == 1: ....: if i &gt; 2: ....: list3.append(i) ....:In [30]: list3Out[30]: [3, 5] 1.4 笛卡尔积（多个for的嵌套循环）[ (expression1,expression2 for item1 in iterable1 for item2 in iterable2 ] 12345678In [1]: list1=[1,3,4]In [2]: list2=[2,4,6]In [3]: list3=[(x,y) for x in list1 for y in list2]In [4]: list3Out[4]: [(1, 2), (1, 4), (1, 6), (3, 2), (3, 4), (3, 6), (4, 2), (4, 4), (4, 6)] 用传统方法来写就是： 12345678910111213In [5]: list1=[1,3,5]In [6]: list2=[2,4,6]In [7]: list3=[]In [8]: for x in list1: ...: for y in list2: ...: list3.append((x,y)) ...:In [9]: list3Out[9]: [(1, 2), (1, 4), (1, 6), (3, 2), (3, 4), (3, 6), (5, 2), (5, 4), (5, 6)] 1.5 列表解析式加上zip()函数（可以不看，延伸部分）先理解zip()函数，zip()函数可以对多个序列进行并行迭代 1234567891011In [20]: uppers = ['A','B','C']In [21]: lowers = ['a','b','c']In [22]: nums = [1,2,3]In [23]: zip(uppers,lowers,nums)Out[23]: &lt;zip at 0x17c62a1c9c8&gt;In [24]: list(zip(uppers,lowers,nums))Out[24]: [('A', 'a', 1), ('B', 'b', 2), ('C', 'c', 3)] 下面两个是不一样的，第一个是笛卡尔积，第二个是zip()函数,结果是不一样的。笛卡尔积： 12345678910111213In [25]: list1=[(u,l,n) for u in uppers for l in lowers for n in lowers]In [26]: list1Out[26]:[('A', 'a', 'a'), ('A', 'a', 'b'), ('A', 'a', 'c'), ('A', 'b', 'a'), ('A', 'b', 'b'), ('A', 'b', 'c'), ('A', 'c', 'a'), ('A', 'c', 'b'), ('A', 'c', 'c'), ('B', 'a', 'a'), ('B', 'a', 'b'), ('B', 'a', 'c'), ('B', 'b', 'a'), ('B', 'b', 'b'), ('B', 'b', 'c'), ('B', 'c', 'a'), ('B', 'c', 'b'), ('B', 'c', 'c'), ('C', 'a', 'a'), ('C', 'a', 'b'), ('C', 'a', 'c'), ('C', 'b', 'a'), ('C', 'b', 'b'), ('C', 'b', 'c'), ('C', 'c', 'a'), ('C', 'c', 'b'), ('C', 'c', 'c')] zip()函数: 1234In [30]: list2=[(u,l,n) for u,l,n in zip(uppers,lowers,nums)]In [31]: list2Out[31]: [('A', 'a', 1), ('B', 'b', 2), ('C', 'c', 3)] 2. 集合解析式（set comprehensions）类似于列表解析，只是中括号[]变成大括号{}.集合有个区别是，是集合里面不重复元素: 1234In [18]: set1=&#123;2,2,2&#125;In [19]: &#123;x+1 for x in set1&#125;Out[19]: &#123;3&#125; 3. 字典解析式（dict comprehensions）{_keyexp : _valueexp for expresion in iterable} 通常是keys和values一起解析： 12345678In [1]: letters=['A','B','C','D']In [2]: nums=[1,2,3,4]In [3]: dict1=&#123; k : v for k,v in zip(letters,nums)&#125;In [4]: dict1Out[4]: &#123;'A': 1, 'B': 2, 'C': 3, 'D': 4&#125; 还有一种，values是keys的调用后的值，这种情况只解析keys就可以了： 123456In [7]: name = 'yulongjun'In [8]: counts=&#123;letter: name.count(letter) for letter in set(name)&#125;In [9]: countsOut[9]: &#123;'g': 1, 'j': 1, 'l': 1, 'n': 2, 'o': 1, 'u': 2, 'y': 1&#125; 当然，由于name字符串里面有重复的字母，name.count计算了多遍重复的字母，可以有更pythonic的用法，如下，set(name)就把name中重复的字母去掉了： 1counts=&#123;letter: name.count(letter) for letter in set(name)&#125; 4. 生成器解析式（generator comprehensions）生成器解析式和列表解析式用法差不多，只是把中括号[]变成小括号()，很多人会认为()生成的是元组（tuple），但其实是生成器（generator）: 1234567In [17]: gen1=(i for i in range(6))In [18]: gen1Out[18]: &lt;generator object &lt;genexpr&gt; at 0x0000028944C86570&gt;In [19]: type(gen1)Out[19]: generator 生成的生成器只能迭代完一次，再次从头迭代就不可用了: 123456789In [20]: list2=list(gen1)In [21]: list2Out[21]: [0, 1, 2, 3, 4, 5]In [22]: list1=list(gen1)In [23]: list1Out[23]: []]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>comprehension</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[byte和bytearray]]></title>
    <url>%2Fpython%2F20170510-04-bytes-bytearrays%2F</url>
    <content type="text"><![CDATA[bytesPython 3 特有的，Python2是不区分bytes和str。 bytes是不可变的。 Python 2 中： 12345type(b'xxxx')&lt;type 'str'&gt;&gt;&gt;&gt; type('xxxx')&lt;type 'str'&gt; Python 3 中： 12345In [1]: type(b'xxxx')Out[1]: bytesIn [3]: type('xxxx')Out[3]: str bytes 和 str 的区别在于，bytes是byte的序列，而str是unicode的序列。 str可使用encode的方法转化为bytes。 bytes使用decode的方法转化为str。 (默认的encode和decode的编码方式为utf-8）。 1234567891011121314151617181920212223242526272829In [4]: s = '于龙君'In [5]: b = s.encode()In [6]: bOut[6]: b'\xe4\xba\x8e\xe9\xbe\x99\xe5\x90\x9b'In [7]: b.decode()Out[7]: '于龙君'In [8]: for x in s: ...: print(x) ...: 于龙君In [9]: for x in b: ...: print(x) ...: 228186142233190153229144155 bytearraybytearray和bytes不一样的地方在于，bytearray是可变的。 1234567891011121314151617In [10]: s = '于龙君'In [11]: ba = bytearray(s.encode())In [12]: baOut[12]: bytearray(b'\xe4\xba\x8e\xe9\xbe\x99\xe5\x90\x9b')In [13]: ba.decode()Out[13]: '于龙君'In [14]: ba[:3] = bytearray('王'.encode())In [15]: baOut[16]: bytearray(b'\xe7\x8e\x8b\xe9\xbe\x99\xe5\x90\x9b')In [17]: ba.decode()Out[17]: '王龙君']]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>byte</tag>
        <tag>bytearray</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[字典（Dictionarys）]]></title>
    <url>%2Fpython%2F20170510-03-dicts%2F</url>
    <content type="text"><![CDATA[字典是一种key-value结构。字典的key必须是可hash的值，并且是唯一的，value可以是任意值。 字典初始化12345678In [1]: d = dict()In [2]: d = &#123;&#125;In [3]: d = &#123;'a':1, 'b':2&#125;In [4]: dOut[4]: &#123;'a': 1, 'b': 2&#125; 字典的下标操作12345678910111213141516171819202122In [3]: d=&#123;'a':1, 'b':2&#125;In [4]: d['a']Out[4]: 1In [5]: d['a'] = 123In [6]: dOut[6]: &#123;'a': 123, 'b': 2&#125;In [7]: d['c']---------------------------------------------------------------------------KeyError Traceback (most recent call last)&lt;ipython-input-7-3e4d85f12902&gt; in &lt;module&gt;()----&gt; 1 d['c']KeyError: 'c'In [8]: d['c'] = 345In [9]: dOut[9]: &#123;'a': 123, 'b': 2, 'c': 345&#125; 增updateupdate的参数可以是以下几种情况： 字典 由二元组构成的可迭代对象 关键字参数 12345678910111213141516171819202122232425262728293031323334353637383940In [9]: dOut[9]: &#123;'a': 123, 'b': 2, 'c': 345&#125;In [10]: d.update(&#123;'f':111, 'e':222&#125;)In [11]: dOut[11]: &#123;'a': 123, 'b': 2, 'c': 345, 'e': 222, 'f': 111&#125;In [12]: d.update([('g',333),('h',444)])In [13]: dOut[13]: &#123;'a': 123, 'b': 2, 'c': 345, 'e': 222, 'f': 111, 'g': 333, 'h': 444&#125;In [14]: d.update([1, 2, 3])---------------------------------------------------------------------------TypeError Traceback (most recent call last)&lt;ipython-input-14-8f8690e9b692&gt; in &lt;module&gt;()----&gt; 1 d.update([1, 2, 3])TypeError: cannot convert dictionary update sequence element #0 to a sequenceIn [15]: d.update((1, 2, 3))---------------------------------------------------------------------------TypeError Traceback (most recent call last)&lt;ipython-input-15-78ef53cee86d&gt; in &lt;module&gt;()----&gt; 1 d.update((1, 2, 3))TypeError: cannot convert dictionary update sequence element #0 to a sequenceIn [16]: d.update(&#123;1, 2, 3&#125;)---------------------------------------------------------------------------TypeError Traceback (most recent call last)&lt;ipython-input-16-0c35aaa27a8f&gt; in &lt;module&gt;()----&gt; 1 d.update(&#123;1, 2, 3&#125;)TypeError: cannot convert dictionary update sequence element #0 to a sequenceIn [17]: d.update(i=555)In [18]: dOut[18]: &#123;'a': 123, 'b': 2, 'c': 345, 'e': 222, 'f': 111, 'g': 333, 'h': 444, 'i': 555&#125; update如果key相同的话，第二个的value会覆盖第一个的value，算是一个改的功能了。 1234In [19]: d.update(a=456)In [20]: dOut[20]: &#123;'a': 456, 'b': 2, 'c': 345, 'e': 222, 'f': 111, 'g': 333, 'h': 444, 'i': 555&#125; setdefaultdefaultdict设置字典的默认值。参数为一个函数。 删pop pop(…) method of builtins.dict instanceD.pop(k[,d]) -&gt; v, remove specified key and return the corresponding value.If key is not found, d is returned if given, otherwise KeyError is raised popitem随机删除并返回一个k-v对。（用得不多） 123456789101112131415161718192021In [26]: dOut[26]: &#123;'a': 456, 'b': 2, 'c': 345, 'e': 222, 'f': 111, 'g': 333, 'h': 444, 'i': 555&#125;In [27]: d.pop('i')Out[27]: 555In [28]: d.pop('g',333)Out[28]: 333In [29]: d.popitem()Out[29]: ('c', 345)In [30]: del d['f']In [31]: dOut[31]: &#123;'a': 456, 'b': 2, 'e': 222, 'h': 444&#125;In [32]: d.clear()In [33]: dOut[33]: &#123;&#125; 访问（查）keys12345678910111213141516171819202122232425262728In [45]: dOut[45]: &#123;'a': 1, 'b': 2, 'c': 123&#125;In [46]: d.keys()Out[46]: dict_keys(['b', 'c', 'a'])In [47]: for k in d.keys(): ....: print('&#123;&#125; =&gt; &#123;&#125;'.format(k,d[k]) ....: ....: ) ....: b =&gt; 2c =&gt; 123a =&gt; 1In [53]: dk = d.keys()In [54]: dk -&#123;'a', 'b'&#125;Out[54]: &#123;'c'&#125;In [55]: dk &amp; &#123;'a','b'&#125;Out[55]: &#123;'a', 'b'&#125;In [56]: dk | &#123;'a', 'b'&#125;Out[56]: &#123;'a', 'b', 'c'&#125;In [57]: dk ^ &#123;'b', 'c', 'd'&#125;Out[57]: &#123;'a', 'd'&#125; values1234567In [58]: d.values()Out[58]: dict_values([2, 123, 1])In [59]: dv = d.values()In [60]: len(dv)Out[60]: 3 items1234567891011121314151617181920In [61]: d.items()Out[61]: dict_items([('b', 2), ('c', 123), ('a', 1)])In [62]: for k, v in d.items(): ....: print('&#123;&#125; =&gt;&#123;&#125;'.format(k, v)) ....: b =&gt;2c =&gt;123a =&gt;1In [63]: di = d.items()In [64]: di &amp; &#123;'d','e'&#125;Out[64]: set()In [65]: di | &#123;'d','e'&#125;Out[65]: &#123;'d', ('a', 1), ('c', 123), ('b', 2), 'e'&#125;In [68]: di^&#123;'d','e'&#125;Out[68]: &#123;'d', ('a', 1), ('c', 123), ('b', 2), 'e'&#125; 附加：OrderedDictOrderedDict，有序的字典 12345678910111213141516171819202122In [71]: from collections import OrderedDictIn [72]: od = OrderedDict()In [73]: od['a'] = 1In [74]: od['b'] = 2In [75]: od['c'] = 3In [76]: odOut[76]: OrderedDict([('a', 1), ('b', 2), ('c', 3)])In [77]: od.keys()Out[77]: odict_keys(['a', 'b', 'c'])In [78]: for k,v in od.items(): ....: print(k,v) ....: a 1b 2c 3 其他几个函数copyfromkeys1234d.fromkeys([1, 2, 3])d.fromkeys([1, 2, 3], False)hosts = [1, 2, 3]d.fromkeys(hosts, False) 3.9 字典（Dictionarys）@(Learning-Python3(2016下半年))[dict] 字典是一种key-value结构。字典的key必须是可hash的值，并且是唯一的，value可以是任意值。 字典初始化12345678In [1]: d = dict()In [2]: d = &#123;&#125;In [3]: d = &#123;'a':1, 'b':2&#125;In [4]: dOut[4]: &#123;'a': 1, 'b': 2&#125; 字典的下标操作12345678910111213141516171819202122In [3]: d=&#123;'a':1, 'b':2&#125;In [4]: d['a']Out[4]: 1In [5]: d['a'] = 123In [6]: dOut[6]: &#123;'a': 123, 'b': 2&#125;In [7]: d['c']---------------------------------------------------------------------------KeyError Traceback (most recent call last)&lt;ipython-input-7-3e4d85f12902&gt; in &lt;module&gt;()----&gt; 1 d['c']KeyError: 'c'In [8]: d['c'] = 345In [9]: dOut[9]: &#123;'a': 123, 'b': 2, 'c': 345&#125; 增updateupdate的参数可以是以下几种情况： 字典 由二元组构成的可迭代对象 关键字参数 12345678910111213141516171819202122232425262728293031323334353637383940In [9]: dOut[9]: &#123;'a': 123, 'b': 2, 'c': 345&#125;In [10]: d.update(&#123;'f':111, 'e':222&#125;)In [11]: dOut[11]: &#123;'a': 123, 'b': 2, 'c': 345, 'e': 222, 'f': 111&#125;In [12]: d.update([('g',333),('h',444)])In [13]: dOut[13]: &#123;'a': 123, 'b': 2, 'c': 345, 'e': 222, 'f': 111, 'g': 333, 'h': 444&#125;In [14]: d.update([1, 2, 3])---------------------------------------------------------------------------TypeError Traceback (most recent call last)&lt;ipython-input-14-8f8690e9b692&gt; in &lt;module&gt;()----&gt; 1 d.update([1, 2, 3])TypeError: cannot convert dictionary update sequence element #0 to a sequenceIn [15]: d.update((1, 2, 3))---------------------------------------------------------------------------TypeError Traceback (most recent call last)&lt;ipython-input-15-78ef53cee86d&gt; in &lt;module&gt;()----&gt; 1 d.update((1, 2, 3))TypeError: cannot convert dictionary update sequence element #0 to a sequenceIn [16]: d.update(&#123;1, 2, 3&#125;)---------------------------------------------------------------------------TypeError Traceback (most recent call last)&lt;ipython-input-16-0c35aaa27a8f&gt; in &lt;module&gt;()----&gt; 1 d.update(&#123;1, 2, 3&#125;)TypeError: cannot convert dictionary update sequence element #0 to a sequenceIn [17]: d.update(i=555)In [18]: dOut[18]: &#123;'a': 123, 'b': 2, 'c': 345, 'e': 222, 'f': 111, 'g': 333, 'h': 444, 'i': 555&#125; update如果key相同的话，第二个的value会覆盖第一个的value，算是一个改的功能了。 1234In [19]: d.update(a=456)In [20]: dOut[20]: &#123;'a': 456, 'b': 2, 'c': 345, 'e': 222, 'f': 111, 'g': 333, 'h': 444, 'i': 555&#125; setdefaultdefaultdict设置字典的默认值。参数为一个函数。 删pop pop(…) method of builtins.dict instanceD.pop(k[,d]) -&gt; v, remove specified key and return the corresponding value.If key is not found, d is returned if given, otherwise KeyError is raised popitem随机删除并返回一个k-v对。（用得不多） 123456789101112131415161718192021In [26]: dOut[26]: &#123;'a': 456, 'b': 2, 'c': 345, 'e': 222, 'f': 111, 'g': 333, 'h': 444, 'i': 555&#125;In [27]: d.pop('i')Out[27]: 555In [28]: d.pop('g',333)Out[28]: 333In [29]: d.popitem()Out[29]: ('c', 345)In [30]: del d['f']In [31]: dOut[31]: &#123;'a': 456, 'b': 2, 'e': 222, 'h': 444&#125;In [32]: d.clear()In [33]: dOut[33]: &#123;&#125; 访问（查） 遍历keys12345678910111213141516171819202122232425262728In [45]: dOut[45]: &#123;'a': 1, 'b': 2, 'c': 123&#125;In [46]: d.keys()Out[46]: dict_keys(['b', 'c', 'a'])In [47]: for k in d.keys(): ....: print('&#123;&#125; =&gt; &#123;&#125;'.format(k,d[k]) ....: ....: ) ....: b =&gt; 2c =&gt; 123a =&gt; 1In [53]: dk = d.keys()In [54]: dk -&#123;'a', 'b'&#125;Out[54]: &#123;'c'&#125;In [55]: dk &amp; &#123;'a','b'&#125;Out[55]: &#123;'a', 'b'&#125;In [56]: dk | &#123;'a', 'b'&#125;Out[56]: &#123;'a', 'b', 'c'&#125;In [57]: dk ^ &#123;'b', 'c', 'd'&#125;Out[57]: &#123;'a', 'd'&#125; values1234567In [58]: d.values()Out[58]: dict_values([2, 123, 1])In [59]: dv = d.values()In [60]: len(dv)Out[60]: 3 items1234567891011121314151617181920In [61]: d.items()Out[61]: dict_items([('b', 2), ('c', 123), ('a', 1)])In [62]: for k, v in d.items(): ....: print('&#123;&#125; =&gt;&#123;&#125;'.format(k, v)) ....: b =&gt;2c =&gt;123a =&gt;1In [63]: di = d.items()In [64]: di &amp; &#123;'d','e'&#125;Out[64]: set()In [65]: di | &#123;'d','e'&#125;Out[65]: &#123;'d', ('a', 1), ('c', 123), ('b', 2), 'e'&#125;In [68]: di^&#123;'d','e'&#125;Out[68]: &#123;'d', ('a', 1), ('c', 123), ('b', 2), 'e'&#125; 附加：OrderedDictOrderedDict，有序的字典 12345678910111213141516171819202122In [71]: from collections import OrderedDictIn [72]: od = OrderedDict()In [73]: od['a'] = 1In [74]: od['b'] = 2In [75]: od['c'] = 3In [76]: odOut[76]: OrderedDict([('a', 1), ('b', 2), ('c', 3)])In [77]: od.keys()Out[77]: odict_keys(['a', 'b', 'c'])In [78]: for k,v in od.items(): ....: print(k,v) ....: a 1b 2c 3 其他几个函数copyfromkeys1234d.fromkeys([1, 2, 3])d.fromkeys([1, 2, 3], False)hosts = [1, 2, 3]d.fromkeys(hosts, False)]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>dict</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[集合（Sets）]]></title>
    <url>%2Fpython%2F20170510-02-sets%2F</url>
    <content type="text"><![CDATA[增add增加一个元素到集合，如果元素已经存在，则没有任何操作。 add(…)Add an element to a set.This has no effect if the element is already present. update增加一个集合 update(…)Update a set with the union of itself and others. 删remove删除不存在的会抛出异常 remove(…)Remove an element from a set; it must be a member. If the element is not a member, raise a KeyError. discard删除不存在的不会抛出异常。 discard(…)Remove an element from a set if it is a member.If the element is not a member, do nothing. pop 删除并返回一个任意元素。 pop(…)Remove and return an arbitrary set element.Raises KeyError if the set is empty. clear删除所有元素 clear(…)Remove all elements from this set. 改、查没有一个方法可以直接的修改集合中的某个具体元素，因为没有一个方法，可以查找定位其中的某个具体元素。 集合的集合运算并集（union==|） union(…) Return the union of sets as a new set.(i.e. all elements that are in either set.) 交集（intersection==&amp;、intersection_update） intersection(…)Return the intersection of two sets as a new set.(i.e. all elements that are in both sets.) intersection_update(…)Update a set with the intersection of itself and another. 差集（difference==-、difference_update） difference(…)Return the difference of two or more sets as a new set. (i.e. all elements that are in this set but not the others.) difference_update(…)Remove all elements of another set from this set. 对称差集（symmetric_difference==^、symmetric_difference_update）对称差集，把a.difference(b)和b.difference(a)的值union起来 symmetric_difference(…)Return the symmetric difference of two sets as a new set.(i.e. all elements that are in exactly one of the sets.) symmetric_difference_update(…)Update a set with the symmetric difference of itself and another. 是否超集（isuperset） issuperset(…)Report whether this set contains another set. 是否子集(issubset) issubset(…)Report whether another set contains this set. 是否相交（isdisjoint） isdisjoint(…)Return True if two sets have a null intersection. 复制（copy） copy(…) Return a shallow copy of a set. 集合的应用 元素需要唯一而对顺序没有要求添加主机，要求不重复 1hosts = set(user_input.splitlines()) 我们需要集合运算时求未完成添加的主机（主机-已完成添加的主机） 1hosts - complete_hosts 求多个地方输入的一个并集hosts = input_a | input_b | input_c]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>set</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[格式化（Formatting）]]></title>
    <url>%2Fpython%2F20170510-01-formatting%2F</url>
    <content type="text"><![CDATA[printf style 老式的类似c语言的printf风格的格式化输出。 用百分号%来作为占位符。 12345678910111213In [16]: 'I am %s'%('yulongjun',) # 可以采用元组的方式Out[16]: 'I am yulongjun'In [18]: 'I am %(name)s'%&#123;'name':'yulongjun'&#125; # 可以采用字典的方式Out[18]: 'I am yulongjun'In [19]: 'I am %(name)s, my name is %(name)s'%&#123;'name':'yulongjun'&#125; # 多次出现，可以采用字典的方式Out[19]: 'I am yulongjun, my name is yulongjun'In [21]: name = "yulongjun"In [22]: 'I am %s'%name #只有一个元素可以直接跟在百分号后面，这里解释器自动做了一个封包，把name封包为元组（语法糖）Out[22]: 'I am yulongjun' 前面字符串中占位符后面的type，以下为常用的几个： type 说明 d、i、u 十进制整数 o、 八进制整数 x、X 十六进制整数（x的话数字里的字母为小写，X的话为大写） e、E 科学计数法（e的话科学计数的e为小写，E的话为大写） f、F 浮点数（默认保留6位小数) g、G 自动选择最优表示法（整数、浮点数或科学计数法） c 单个字符或整数转化为字符 s 用str()转化为字符串 r 用repr()转化为字符串 a 用ascii()转化为字符串 其中的str()和repr()调用的是__str__和__repr__的魔术方法，有个了解就可以，后续会讲到。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647In [48]: 'The number is %d'%56789Out[48]: 'The number is 56789'In [49]: 'The number is %i'%56789Out[49]: 'The number is 56789'In [50]: 'The number is %u'%56789Out[50]: 'The number is 56789'In [51]: 'The number is %o'%56789Out[51]: 'The number is 156725'In [52]: 'The number is %x'%56789Out[52]: 'The number is ddd5'In [53]: 'The number is %X'%56789Out[53]: 'The number is DDD5'In [54]: 'The number is %e'%56789Out[54]: 'The number is 5.678900e+04'In [55]: 'The number is %E'%56789Out[55]: 'The number is 5.678900E+04'In [56]: 'The number is %f'%0.123456789Out[56]: 'The number is 0.123457'In [57]: 'The number is %F'%0.123456789Out[57]: 'The number is 0.123457'In [58]: 'The number is %g'%0.123456789Out[58]: 'The number is 0.123457'In [60]: 'The number is %g'%0.0000000123456789Out[60]: 'The number is 1.23457e-08'In [61]: 'The number is %G'%123456789Out[61]: 'The number is 1.23457E+08'In [78]: 'The string is %s'%'yulongjun'Out[78]: 'The string is yulongjun'In [79]: 'The string is %r'%'yulongjun'Out[79]: "The string is 'yulongjun'"In [80]: 'The string is %a'%'于龙君'Out[80]: "The string is '\\u4e8e\\u9f99\\u541b'" 数字的位数和对齐的操作 -左对齐 +正负号 0补零 123456789101112131415161718In [86]: '%0.3f'%1.23456789 # 小数位为3位Out[86]: '1.235'In [87]: '%10.3f'%1.23456789 # 小数位为3位，总位数为10位，不够的左边补空格Out[87]: ' 1.235'In [88]: '%-10.3f'%1.23456789 # 加上-号，左对齐，右边补空格Out[88]: '1.235 'In [89]: '%+10.3f'%1.23456789 # 加上正负号Out[89]: ' +1.235'In [90]: '%+10.3f'%-1.23456789Out[90]: ' -1.235'In [91]: '%010.3f'%1.23456789 # 前面加0，算补零Out[91]: '000001.235' format Python3推荐format格式的格式化输出，功能更强大。 str.format(_args,*_kwargs) 字符串中的占位符用{}或者带索引的{INDEX}，或者更详细的格式（索引后面加冒号），如{0:10.3f}等。 format括号里可以跟位置参数，也可以跟关键字参数。 1234567891011121314151617In [97]: 'I am &#123;&#125;'.format('yulongjun')Out[97]: 'I am yulongjun'In [98]: 'I am &#123;&#125;, my age is &#123;&#125;'.format('yulongjun',18)Out[98]: 'I am yulongjun, my age is 18'In [99]: 'I am &#123;1&#125;, my age is &#123;0&#125;'.format(18,'yulongjun')Out[99]: 'I am yulongjun, my age is 18'In [100]: 'I am &#123;name&#125;, my age is &#123;age&#125;'.format(name='yulongjun', age=18)Out[100]: 'I am yulongjun, my age is 18'In [101]: 'I am &#123;name&#125;, my name is &#123;name&#125;'.format(name='yulongjun')Out[101]: 'I am yulongjun, my name is yulongjun'In [102]: 'I am &#123;0&#125;, my name is &#123;0&#125;'.format('yulongjun')Out[102]: 'I am yulongjun, my name is yulongjun' 可以在{}占位符中用字典和列表的下标操作，还可以用模块的子模块或子属性。 1234567891011121314151617181920In [105]: 'My &#123;config[spam]&#125; runs &#123;sys.platform&#125;'.format(sys=sys, config = &#123;'spam': 'laptop'&#125;)Out[105]: 'My laptop runs darwin'In [106]: lst = list('yulongjun')In [107]: 'first=&#123;0[0]&#125;, third=&#123;0[3]&#125;'.format(lst)Out[107]: 'first=y, third=o'In [108]: lst = list('yulongjun')In [109]: 'first=&#123;0[0]&#125;, third=&#123;0[2]&#125;'.format(lst)Out[109]: 'first=y, third=l'In [110]: 'first=&#123;0&#125;, last=&#123;1&#125;'.format(lst[0],lst[-1])Out[110]: 'first=y, last=n'In [113]: parts = lst[0], lst[-1], lst[1:-1]In [115]: 'first=&#123;0&#125;, last=&#123;1&#125;, middle=&#123;2&#125;'.format(*parts)Out[115]: "first=y, last=n, middle=['u', 'l', 'o', 'n', 'g', 'j', 'u']" sys.platform调用的sys的platform config[spam]是用的字典的下标操作 {0[1]使用的是列表的下标操作 *part调用的是位置参数 字符串也有具体的格式化，如字段宽度、对齐方式、补零、小数点精度，填充字符等。 字段宽度：整数部分大小 对齐方式：&gt;右对齐，&lt;左对齐，^居中对齐（和printf style有所不同） 补零：资源宽度的数字前面加0，默认为右对齐 小数点精度：宽度后面加.数字f，f处也可以用g，e 填充字符需要和对齐方式一起使用。 12345678910111213141516171819202122232425In [2]: 'the Number is &#123;:10f&#125;'.format(123.4567)Out[2]: 'the Number is 123.456700'In [3]: 'the Number is &#123;:10&#125;'.format(123.4567)Out[3]: 'the Number is 123.4567'In [4]: 'the Number is &#123;:&lt;10&#125;'.format(123.4567)Out[4]: 'the Number is 123.4567 'In [5]: 'the Number is &#123;:^10&#125;'.format(123.4567)Out[5]: 'the Number is 123.4567 'In [7]: 'the Number is &#123;:010&#125;'.format(123.4567)Out[7]: 'the Number is 00123.4567'In [13]: 'the Number is &#123;:.2f&#125;'.format(123.4567)Out[13]: 'the Number is 123.46'In [15]: 'the Number is &#123;:#^20.2f&#125;'.format(123.4567) ....: Out[15]: 'the Number is #######123.46#######'In [16]: 'the Number is &#123;:#&gt;20.2f&#125;'.format(123.4567) ....: Out[16]: 'the Number is ##############123.46']]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>formatting</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解包（Unpacking）]]></title>
    <url>%2Fpython%2F20170509-06-unpacking%2F</url>
    <content type="text"><![CDATA[以下内容部分内容摘选自《Python Cookbook》第一章 第一节，部分内容为自己书写和总结。 任何序列（或者可迭代对象（iterable））都可以通过一个简单的赋值操作来分解为单独的变量。 12345678910111213141516171819202122232425262728293031In [1]: x,y = (1, 3)In [2]: xOut[2]: 1In [3]: yOut[3]: 3In [4]: data = ['ACME', 50, 90.1, (2012,12,21)]In [5]: name, share, price, date = dataIn [6]: nameOut[6]: 'ACME'In [7]: dateOut[7]: (2012, 12, 21)In [8]: name, shares, price, (year, month, day) = dataIn [9]: nameOut[9]: 'ACME'In [10]: yearOut[10]: 2012In [11]: monthOut[11]: 12In [12]: dayOut[12]: 21 如果元素个数不匹配，将会抛出一个ValueError： 123456789101112131415In [13]: x, y, z = (4,5) #变量多于要解包的元素个数---------------------------------------------------------------------------ValueError Traceback (most recent call last)&lt;ipython-input-13-6ff7f0410c3e&gt; in &lt;module&gt;()----&gt; 1 x, y, z = (4,5)ValueError: not enough values to unpack (expected 3, got 2)In [14]: x, y = (4, 5, 6) # 变量少于要解包的元素个数---------------------------------------------------------------------------ValueError Traceback (most recent call last)&lt;ipython-input-14-096cd5364eca&gt; in &lt;module&gt;()----&gt; 1 x, y = (4, 5, 6)ValueError: too many values to unpack (expected 2) 解包操作可以作用在各种内置结构上，只要对枪恰好是可迭代的：列表、元组、字符串、迭代器、生成器等。 有时候我们分解操作时候，有可能想丢弃某些值，我们可以选用一个用不到的变量名，比如_，来作为要丢弃的值的名称。 123456789In [5]: data = ['ACME', 50, 90.1, (2012,12,21)]In [6]: _, shares, price, _ = dataIn [7]: sharesOut[7]: 50In [8]: priceOut[8]: 90.1 *expressions来分解包，可以对任意长度的可迭代对象（iterable）中分解元素。 12345678910111213141516171819202122232425262728293031323334In [9]: head,*tail = (1,2,3,4)In [10]: headOut[10]: 1In [11]: tailOut[11]: [2, 3, 4]In [12]: first, *middle, last = [1,2,3,4,5,6,7] In [13]: firstOut[13]: 1In [14]: middleOut[14]: [2, 3, 4, 5, 6]In [15]: lastOut[15]: 7In [16]: lst = [1, [2, 3, 6, 7, 8, 10], 4]In [17]: a, (b, *_, c), d = lstIn [18]: aOut[18]: 1In [19]: bOut[19]: 2In [20]: cOut[20]: 10In [21]: dOut[21]: 4]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>unpacking</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[切片（Slice）]]></title>
    <url>%2Fpython%2F20170509-05-slice%2F</url>
    <content type="text"><![CDATA[切片基本操作取一个list、tuple、strings的部分元素我们经常遇到的操作，我们经常用一种切片（slice）的方法。 用法： seq[start:stop:step]：start为起始索引（包含），stop为结束索引(不包含)，step为步长，省略step的话表示默认值为1，步长可为负数，表示倒序取元素。 start和stop可以省略不写，start不写，表示从头（step为正数）或尾巴（step为负数）开始，stop不写表示从尾（step为正数）或头（step为负数）开始，而且省略的那个位置也包含在内。 如果start和stop同时省略，步长为正数，就是从头到尾，步长为负数，就是从尾到头。 正数超过索引长度的话，表示包含末尾，超过的就不算了；负数超过索引长度的话，表示包含开头，超过的就不算了。 长话短说，实践最重要，我们以list为例（tuple和string和此类似）： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758In [1]: lst = list(range(100)) # 创建一个从0到99的列表In [2]: lstOut[2]: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]In [3]: lst[0:8] # 包含0，不包含8，切片Out[3]: [0, 1, 2, 3, 4, 5, 6, 7]In [4]: lst[:8] # 省略开头，切片效果同上Out[4]: [0, 1, 2, 3, 4, 5, 6, 7]In [5]: lst[90:99] # 包含90，不包含99，切片Out[5]: [90, 91, 92, 93, 94, 95, 96, 97, 98]In [6]: lst[90:-1] # -1表示最后一个元素，切片效果同上Out[6]: [90, 91, 92, 93, 94, 95, 96, 97, 98]In [7]: lst[-10:-1] # -10表示倒数第10个元素，切片效果同上Out[7]: [90, 91, 92, 93, 94, 95, 96, 97, 98]In [8]: lst[90:10000] # 10000超出最大索引99，直接到最后一位（包含）Out[8]: [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]In [9]: lst[90:] # 省略stop，直接到末尾（包含末尾）Out[9]: [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]In [12]: lst[-10000:10] # 负索引超出范围，从头开始(包含头)Out[12]: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]In [13]: lst[:10] # 省略start，就从头开始Out[13]: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]In [18]: lst[0:20:2] # 步长为2，表示每两个取元素Out[18]: [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]In [19]: lst[:20:2] # 同样可以省略开头Out[19]: [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]In [20]: lst[-1:-20:-2] # start比stop大的时候，step为负数才能取到值，否则取不到，为空Out[20]: [99, 97, 95, 93, 91, 89, 87, 85, 83, 81]In [21]: lst[-1:80:-2] # 正数负数可以结合Out[21]: [99, 97, 95, 93, 91, 89, 87, 85, 83, 81]In [22]: lst[::10] # 可以同时省略start和stopOut[22]: [0, 10, 20, 30, 40, 50, 60, 70, 80, 90]In [23]: lst[::-10] # 同上，步长变为负数，表示倒序切片Out[23]: [99, 89, 79, 69, 59, 49, 39, 29, 19, 9]In [24]: lst[:] # 原样复制Out[24]: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]In [25]: lst[::-1] # 反转Out[25]: [99, 98, 97, 96, 95, 94, 93, 92, 91, 90, 89, 88, 87, 86, 85, 84, 83, 82, 81, 80, 79, 78, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 66, 65, 64, 63, 62, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0] 以上切片操作同样适用于元组和字符串（字符串在后面讲，字符串就不讲切片了，和列表的切片用法类似）。 对切片赋值 对连续切片赋值，如果所赋值的内容是可迭代的（iterable），会替换切片原来的元素，元素个数可以不相同。 对非连续的切片赋值，赋值的元素个数要和切片切出来的元素的个数相同。 1234567891011121314151617181920212223242526272829303132333435363738394041In [11]: lst = list(range(10))In [12]: lstOut[12]: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]In [13]: lst[3:5] = ['x', 'y'] #个数相同的情况In [14]: lstOut[14]: [0, 1, 2, 'x', 'y', 5, 6, 7, 8, 9]In [15]: lst = list(range(10))In [16]: lst[3:5] = ['x', 'y','z'] #赋值个数比切片多的情况In [17]: lstOut[17]: [0, 1, 2, 'x', 'y', 'z', 5, 6, 7, 8, 9]In [18]: lst = list(range(10)) In [19]: lst[3:5] = ['x'] # 赋值个数比切片少的情况In [20]: lstOut[20]: [0, 1, 2, 'x', 5, 6, 7, 8, 9]In [21]: lst = list(range(10))In [22]: lst[3:8:2] # 不连续的切片Out[22]: [3, 5, 7]In [23]: lst[3:8:2]=['x'] # 不连续的切片，个数不同就抛出异常---------------------------------------------------------------------------ValueError Traceback (most recent call last)&lt;ipython-input-23-1242dfd11688&gt; in &lt;module&gt;()----&gt; 1 lst[3:8:2]=['x']ValueError: attempt to assign sequence of size 1 to extended slice of size 3In [24]: lst[3:5] = ['x', 'y', 'z'] # 不连续的切片，个数相同就能赋值上。In [25]: lstOut[25]: [0, 1, 2, 'x', 'y', 'z', 5, 6, 7, 8, 9] 附加：成员操作符in 和not in可以用在列表、元组、字符串、字典、元组等。12345678910111213In [1]: lst = list(range(10))In [2]: lstOut[2]: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]In [3]: 3 in lstOut[3]: TrueIn [4]: 10 in lstOut[4]: FalseIn [5]: 10 not in lstOut[5]: True]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>slice</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[字符串（Strings）]]></title>
    <url>%2Fpython%2F20170509-04-strings%2F</url>
    <content type="text"><![CDATA[在Python3中，字符串是一个unicode的序列，在Python2中一个byte的序列。字符串的很多特性和元组类似，字符串也是不可变的。 定义字符串 &#39; &quot; &#39;&#39;&#39; &quot;&quot;&quot; Python中单引号和双引号的效果是一样的。 三个单引号或双引号表通常用在字符串为多行的情况下。 123456789In [1]: s = 'yulongjun'In [2]: s = "yulongjun"In [3]: s = ''' My name is YuLongjun. ...: My age is 18.'''In [4]: s = """ My name is YuLongjun. ...: My age is 18.""" 连接字符串12345678910In [1]: list1=['I','love','Python']In [2]: ' '.join(list1) #用空格连接Out[2]: 'I love Python'In [3]: ','.join(list1) #用逗号连接Out[3]: 'I,love,Python'In [5]: 'Yu' + 'Longjun'Out[5]: 'YuLongjun' 字符串分割split()函数，从左边开始分割 1234567891011121314151617181920212223242526272829In [9]: s='I love Python'In [10]: s.split() #默认是以空格为分隔符分割Out[10]: ['I', 'love', 'Python']In [11]: s.split('o') # 指定分隔符为oOut[11]: ['I l', 've Pyth', 'n']In [12]: s.split(' ',1) # 以空格为分隔符，最大分割次数为1Out[12]: ['I', 'love Python']In [13]: s='root:x:0:0:root:/root:/bin/bash'In [14]: s.split(':',1) # 以冒号为分隔符，最大分割次数为1Out[14]: ['root', 'x:0:0:root:/root:/bin/bash']In [16]: username,_=s.split(':',1)In [17]: usernameOut[17]: 'root'In [18]: line ='url:http://www.google.com'In [19]: key,value=line.split(':',1)In [20]: keyOut[20]: 'url'In [21]: valueOut[21]: 'http://www.google.com' rsplit()：和split()相反，是从右往左分割的 123In [18]: line='url:http://www.google.com'In [22]: line.rsplit(':',1)Out[22]: ['url:http', '//www.google.com'] splitlines：分割段 12345678910111213In [24]: s =''' ....: I love Python ....: I also love Linux ....: '''In [25]: s.splitlines()Out[25]: ['', 'I love Python', 'I also love Linux']In [26]: s.splitlines(True) #默认是False，即去掉换行符\n,True的话即保留换行符Out[26]: ['\n', 'I love Python\n', 'I also love Linux\n']In [27]: s.splitlines(False)Out[27]: ['', 'I love Python', 'I also love Linux'] partition分割 有点像split之后接了一个参数1，但是还会保留分隔符。 123456789101112131415161718192021222324252627In [29]: help(s.partition)# Help on built-in function partition:#partition(...) method of builtins.str instance #S.partition(sep) -&gt; (head, sep, tail) # Search for the separator sep in S, and return the part before it,the separator itself, and the part after it. If the separator is not found, return S and two empty strings.In [30]: s='root:x:0:0:root:/root:/bin/bash'In [31]: s.partition(':')Out[31]: ('root', ':', 'x:0:0:root:/root:/bin/bash')In [32]: h,_,t=s.partition(':')In [33]: tOut[33]: 'x:0:0:root:/root:/bin/bash'In [34]: h,_,t=t.partition(':')In [35]: tOut[35]: '0:0:root:/root:/bin/bash'In [36]: h,_,t=t.partition(':')In [37]: tOut[37]: '0:root:/root:/bin/bash' rpartition：和partition相反，是从右向左分割 字符串修改-大小写12345678910111213141516In [40]: s='I love Python'In [41]: s.capitalize() #首字母大写Out[41]: 'I love python'In [42]: s.title() #所有单词首字母大写Out[42]: 'I Love Python'In [43]: s.lower() #所有字母小写Out[43]: 'i love python'In [44]: s.upper() #所有字母大写Out[44]: 'I LOVE PYTHON'In [46]: s.swapcase() #所有字母大小写反转Out[46]: 'i LOVE pYTHON' 字符串修改-填充（对齐）、清除（修剪）1234567891011121314151617181920212223242526272829303132333435363738In [2]: s = 'Python'In [3]: s.center(30) #中间填充Out[3]: ' Python 'In [4]: s.center(30,'*') #中间填充，用*填充Out[4]: '************Python************'In [5]: s.ljust(30) #字符串在左边，右边填充Out[5]: 'Python 'In [6]: s.ljust(30,'*') #字符串在左边，右边用*填充Out[6]: 'Python************************'In [7]: s.rjust(30,'*') #字符串在左边，左边用*填充Out[7]: '************************Python'In [16]: s='root:x::0:0:root:/root:/bin/bash\n'In [17]: s.strip() #去掉两边的空白符（space、制表符tab、换行符\n)Out[17]: 'root:x::0:0:root:/root:/bin/bash'In [18]: s.lstrip() #去掉左边的空白符Out[18]: 'root:x::0:0:root:/root:/bin/bash\n'In [19]: s.rstrip() #去掉右边的空白符 Out[19]: 'root:x::0:0:root:/root:/bin/bash'In [20]: s = '##test##'In [21]: s.strip('#')Out[22]: 'test'In [22]: s.lstrip('#')Out[22]: 'test##'In [23]: s.rstrip('#')Out[23]: '##test' 字符串判断12345678910111213141516171819In [74]: poem='''There was a Young Lady of Norway,who casually sat in a doorway;when the door squeezed her flat,She exclaimed, "What of that?"this courageous Young Lady of Norway.'''In [76]: poem[:13]Out[76]: 'There was a Y'In [77]: len(poem) #字符串长度Out[77]: 166In [78]: poem.startswith('There') #以'There'开头Out[78]: TrueIn [79]: poem.endswith('Norway.') #以'Norway.'结尾Out[79]: TrueIn [80]: poem.isalnum() #所有字符都是字母或数字吗？is*还有很多用法，可以自己查看Out[80]: False 字符串查找12345678910111213141516In [81]: poem.count('a') #字符串'a'出现了多少次Out[81]: 16In [82]: poem.index('a') #字符串'a'出现的第一次的位置Out[82]: 7In [82]: poem.rindex('a') #字符串'a'从右边开始出现的第一次的位置Out[82]: 7In [83]: poem.find('a') #查找第一次出现'a'的位置Out[83]: 7In [83]: poem.find('a'，50,100) #查找从50到100，第一次出现'a'的位置Out[83]: 54In [84]: poem.rfind('a',50,100) #查找从50到100，从右开始找，第一次出现'a'的位置Out[84]: 94 replace()替换s.replace(old,new[,count]) 12345678910111213141516In [27]: s='root:x::0:0:root:/root:/bin/bash\n'In [28]: s.replace('root','yulongjun') #默认替换所有Out[28]: 'yulongjun:x::0:0:yulongjun:/yulongjun:/bin/bash\n'In [29]: s.replace('root','yulongjun',1) #只替换第一个Out[29]: 'yulongjun:x::0:0:root:/root:/bin/bash\n'In [30]: s.replace('root','yulongjun',-1) #负数还是替换所有Out[30]: 'yulongjun:x::0:0:yulongjun:/yulongjun:/bin/bash\n'In [31]: s.replace('root','yulongjun',-2) #负数还是替换所有Out[31]: 'yulongjun:x::0:0:yulongjun:/yulongjun:/bin/bash\n'In [32]: s.replace('root','yulongjun',1000) #超过最大个数也是替换所有Out[32]: 'yulongjun:x::0:0:yulongjun:/yulongjun:/bin/bash\n' Python3使用str类型，底层实现是用unicode编码str –&gt; encode –&gt; bytes bytes –&gt; decode –&gt; str 123456789101112In [12]: s='于龙君'In [13]: sOut[13]: '于龙君'In [14]: s.encode() #编码（不填参数默认utf-8）Out[14]: b'\xe4\xba\x8e\xe9\xbe\x99\xe5\x90\x9b'In [15]: d=s.encode()In [16]: d.decode() #解码（不填参数默认utf-8）Out[16]: '于龙君']]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[元组]]></title>
    <url>%2Fpython%2F20170509-03-tuples%2F</url>
    <content type="text"><![CDATA[元组和列表很像，包括索引查询、查找统计元素操作都很类似。但是元组是不可变的，无法改改元素，所以没有增删改操作。 初始化元组元组是不可变的，所以初始化后元组内的元素不可改变。1234t = tuple() # 初始化一个空元组t = () 也是初始化一个空元组t = (1,) 初始化一个元素的元组t = (1, 2, 3) # 初始化三个元素的元组 下标/索引查询 元组中的索引，也是从前往后，索引也是从0开始，从后往前，索引是从-1开始。 如果索引超出范围，将引发IndexError异常。 元组中，是无法更改元素的值的，更改会抛出TypeError的异常。 示例： 12345678910111213141516171819202122232425262728293031In [1]: t = (1, 2, 3)In [2]: t[0] # 索引0的值Out[2]: 1In [3]: t[1] # 索引1的值 Out[3]: 2In [4]: t[-1] # 索引-1，即最后一个的值Out[4]: 3In [5]: t[-2] # 索引-2，即倒数第二个值Out[5]: 2In [6]: t[3] # 索引3，超出范围，报错---------------------------------------------------------------------------IndexError Traceback (most recent call last)&lt;ipython-input-6-7d5cf04057c5&gt; in &lt;module&gt;()----&gt; 1 t[3]IndexError: tuple index out of rangeIn [7]: t[3] = 5 # 元组无法更改索引的元素，抛出TypeError---------------------------------------------------------------------------TypeError Traceback (most recent call last)&lt;ipython-input-8-241a76bcd075&gt; in &lt;module&gt;()----&gt; 1 t[3] = 5TypeError: 'tuple' object does not support item assignment 查找/统计元素index查找某值的第一个索引，可以指定索引的开始和结束位置。（包含start，不包含stop） 如果值没有找到，则抛出ValueError。 index(…)T.index(value, [start, [stop]]) -&gt; integer – return first index of value.Raises ValueError if the value is not present. 1234567891011121314151617181920212223242526In [9]: t = tuple('abcdb')In [10]: tOut[10]: ('a', 'b', 'c', 'd', 'b')In [11]: t.index('b') # 查找'b'第一次出现的索引位置Out[11]: 1In [12]: t.index('b', 2) # 从索引2开始查找，找到第一次出现'b'的位置Out[12]: 4In [13]: t.index('x') # 没找到'x'---------------------------------------------------------------------------ValueError Traceback (most recent call last)&lt;ipython-input-13-616584d1b884&gt; in &lt;module&gt;()----&gt; 1 tuple.index('x')ValueError: 'x' is not in tupleIn [14]: t.index('b', 2, 4) # 'b'没在2-4索引范围内出现---------------------------------------------------------------------------ValueError Traceback (most recent call last)&lt;ipython-input-14-fa3eb33afd79&gt; in &lt;module&gt;()----&gt; 1 tuple.index('b', 2, 4)ValueError: 'b' is not in tuple count计数，返回值出现的次数。 count(...)T.count(value) -&gt; integer – return number of occurrences of value 12345In [21]: tOut[21]: ('a', 'b', 'c', 'd', 'b')In [22]: t.count('b')Out[22]: 2 len函数len函数可以用在列表、元组、字符串、字典、集合等上面，输出容器中元素的个数。 len(obj, /)Return the number of items in a container. 12345In [24]: tOut[24]: ('a', 'b', 'c', 'd', 'b')In [25]: len(t)Out[25]: 5]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>tuple</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[列表（Lists）]]></title>
    <url>%2Fpython%2F20170509-02-lists%2F</url>
    <content type="text"><![CDATA[初始化列表：123lst = list() # 初始化一个空列表lst = [] # 也是初始化一个空列表lst = [1, 2, 3] # 初始化三个元素 下标/索引操作 Python中的索引，从前往后，索引是从0开始，从后往前，索引是从-1开始。 如果索引超出范围，将引发IndexError异常。 更改列表中元素的值，采用lst[index] = new_value，索引可用正数，也可用负数，但是不能超出范围，否则也会抛出IndexError异常。 示例： 123456789101112131415161718192021222324252627282930313233343536373839In [2]: lst = [1, 2, 3]In [3]: lst[0] #索引0的值Out[3]: 1In [4]: lst[1] # 索引1的值Out[4]: 2In [5]: lst[-1] # 索引-1，即最后一个的值Out[5]: 3In [6]: lst[-2] # 索引-2，即倒数第二个值Out[6]: 2In [7]: lst[3] # 索引3，超出范围，报错--------------------------------------------------------------------------IndexError Traceback (most recent call last)&lt;ipython-input-7-298ffefac8cf&gt; in &lt;module&gt;()----&gt; 1 lst[3]IndexError: list index out of rangeIn [8]: lst[0] = 5 # 把索引为0的元素更改为5In [9]: lstOut[9]: [5, 2, 3]In [10]: lst[-1] = 10 # 索引为负数也可更改In [11]: lstOut[11]: [5, 2, 10]In [12]: lst[-4] = 12 # 超出索引范围，报错---------------------------------------------------------------------------IndexError Traceback (most recent call last)&lt;ipython-input-12-8f011d505efa&gt; in &lt;module&gt;()----&gt; 1 lst[-4] = 12IndexError: list assignment index out of range 给list增加元素append在列表最后增加一个对象，返回值为None 。 append(…)L.append(object) -&gt; None – append object to end 示例： 1234567In [14]: lstOut[14]: [5, 2, 10]In [15]: lst.append(12)In [16]: lstOut[16]: [5, 2, 10, 12] insert在索引之前插入一个对象。 insert操作索引超出范围是：如果是正索引，等效append，如果是负索引，等效于insert(0,object)。 insert(…) L.insert(index, object) – insert object before index 示例： 12345678910111213141516171819202122232425262728In [22]: lstOut[22]: [5, 2, 10, 12]In [23]: lst.insert(0, 7) # 在索引0之前插入7In [24]: lstOut[24]: [7, 5, 2, 10, 12]In [25]: lst.insert(3, 0) # 在索引3之前插入0In [26]: lstOut[26]: [7, 5, 2, 0, 10, 12]In [27]: lst.insert(7,13) # 超出范围，索引为正，就在最后面添加In [28]: lstOut[28]: [7, 5, 2, 0, 10, 12, 13]In [29]: lst.insert(100,76) # 超出范围，索引为正，就在最后面添加In [30]: lstOut[30]: [7, 5, 2, 0, 10, 12, 13, 76]In [31]: lst.insert(-100, 8) # 超出范围，索引为负，就在最前面In [32]: lstOut[32]: [8, 7, 5, 2, 0, 10, 12, 13, 76] extend通过添加一个可迭代对象（iterable）中的元素来扩展列表。 extend(…)L.extend(iterable) -&gt; None – extend list by appending elements from the iterable 示例： 123456789101112131415In [38]: lst1 = [1, 2, 3]In [39]: lst2 = [4, 5, 6]In [40]: lst1.extend(lst2) # lst2是一个可迭代对象（iterable），可给lst1做扩展In [41]: lst1Out[41]: [1, 2, 3, 4, 5, 6]In [43]: tuple1 = ('a', 'b', 'c')In [44]: lst2.extend(tuple1) # tuple1(元组后面会讲)是一个可迭代对象（iterable，会面会讲），可给lst2做扩展In [45]: lst2Out[45]: [4, 5, 6, 'a', 'b', 'c'] 删除元素pop删除并返回索引所在的元素（默认不填索引是指-1，最后一个）。 如果index超出索引范围，会抛出IndexError异常。 pop(…)L.pop([index]) -&gt; item – remove and return item at index (default last).Raises IndexError if list is empty or index is out of range. 1234567891011121314151617181920212223242526272829303132333435In [47]: lst = [1, 2, 3, 4, 5, 6]In [48]: lst.pop() # 不填索引，默认删除最后一个Out[48]: 6In [49]: lstOut[49]: [1, 2, 3, 4, 5]In [50]: lst.pop(3) # 删除索引为3的元素Out[50]: 4In [51]: lstOut[51]: [1, 2, 3, 5]In [52]: lst.pop(100) # 超出索引范围，抛出IndexError异常---------------------------------------------------------------------------IndexError Traceback (most recent call last)&lt;ipython-input-52-795b88347eea&gt; in &lt;module&gt;()----&gt; 1 lst.pop(100)IndexError: pop index out of rangeIn [53]: lst.pop(-1) # 删除索引为负数的元素Out[53]: 5In [54]: lstOut[54]: [1, 2, 3]In [55]: lst.pop(-100) # 超过索引范围，抛出IndexError异常---------------------------------------------------------------------------IndexError Traceback (most recent call last)&lt;ipython-input-54-d93c61a62a8e&gt; in &lt;module&gt;()----&gt; 1 lst.pop(-100)IndexError: pop index out of range remove删除第一次发现的值。 如果值不存在则抛出ValueError。 remove(…)L.remove(value) -&gt; None – remove first occurrence of value.Raises ValueError if the value is not present. 1234567891011121314In [57]: lst = [1, 2, 3, 1, 2, 3]In [58]: lst.remove(1) # 删除第一次查找到的1，第二个1没有删除In [59]: lstOut[59]: [2, 3, 1, 2, 3]In [60]: lst.remove(5) # 没有找到，抛出ValueError---------------------------------------------------------------------------ValueError Traceback (most recent call last)&lt;ipython-input-60-29e61bbce0d4&gt; in &lt;module&gt;()----&gt; 1 lst.remove(5)ValueError: list.remove(x): x not in list clear清空列表。 clear(…)L.clear() -&gt; None – remove all items from L 123456In [1]: lst = [1, 2, 3]In [2]: lst.clear()In [3]: lstOut[3]: [] 查找/统计元素index查找某值的第一个索引，可以指定索引的开始和结束位置。（包含start，不包含stop） 如果值没有找到，则抛出ValueError。 index(…)L.index(value, [start, [stop]]) -&gt; integer – return first index of value.Raises ValueError if the value is not present. 1234567891011121314151617181920212223242526In [9]: lst = list('abcdb')In [10]: lstOut[10]: ['a', 'b', 'c', 'd', 'b']In [11]: lst.index('b') # 查找'b'第一次出现的索引位置Out[11]: 1In [12]: lst.index('b', 2) # 从索引2开始查找，找到第一次出现'b'的位置Out[12]: 4In [13]: lst.index('x') # 没找到'x'---------------------------------------------------------------------------ValueError Traceback (most recent call last)&lt;ipython-input-13-616584d1b884&gt; in &lt;module&gt;()----&gt; 1 lst.index('x')ValueError: 'x' is not in listIn [14]: lst.index('b', 2, 4) # 'b'没在2-4索引范围内出现---------------------------------------------------------------------------ValueError Traceback (most recent call last)&lt;ipython-input-14-fa3eb33afd79&gt; in &lt;module&gt;()----&gt; 1 lst.index('b', 2, 4)ValueError: 'b' is not in list count计数，返回值出现的次数。 count(...)L.count(value) -&gt; integer – return number of occurrences of value 12345In [21]: lstOut[21]: ['a', 'b', 'c', 'd', 'b']In [22]: lst.count('b')Out[22]: 2 len函数len函数可以用在列表、元组、字符串、字典、集合等上面，输出容器中元素的个数。 len(obj, /)Return the number of items in a container. 12345In [24]: lstOut[24]: ['a', 'b', 'c', 'd', 'b']In [25]: len(lst)Out[25]: 5 修改列表sort原地排序，有两个参数，一个是key，表示排序用的函数，默认为None没有。一个是reverse（反向，降序排列），默认是False。 sort(…)L.sort(key=None, reverse=False) -&gt; None – stable sort “IN PLACE” 1234567891011121314In [30]: lst = list("yulongjun")In [31]: lstOut[31]: ['y', 'u', 'l', 'o', 'n', 'g', 'j', 'u', 'n']In [32]: lst.sort()In [33]: lstOut[33]: ['g', 'j', 'l', 'n', 'n', 'o', 'u', 'u', 'y']In [34]: lst.sort(reverse=True)In [35]: lstOut[35]: ['y', 'u', 'u', 'o', 'n', 'n', 'l', 'j', 'g'] reverse原地反转。 reverse(…)L.reverse() – reverse “IN PLACE” 123456In [37]: lst = [3, 1, 2, 5]In [38]: lst.reverse()In [39]: lstOut[39]: [5, 2, 1, 3] 其他copy采用赋值方法创建新列表，是指向原来的列表的那块内存，当进行更改时候，新老列表一起改变。 12345678910111213141516171819In [44]: lst = [1, 2, 3, 4, 5]In [45]: lst2 = lstIn [46]: lst2.remove(2)In [47]: lst2Out[47]: [1, 3, 4, 5]In [48]: lst1---------------------------------------------------------------------------NameError Traceback (most recent call last)&lt;ipython-input-48-f3e10dd48749&gt; in &lt;module&gt;()----&gt; 1 lst1NameError: name &apos;lst1&apos; is not definedIn [49]: lstOut[49]: [1, 3, 4, 5] 采用copy方法，就是复制出一块相同的内存(影子复制)。新旧列表互不影响。 copy(…)L.copy() -&gt; list – a shallow copy of L 1234567891011121314Out[49]: [1, 3, 4, 5]In [50]: lstOut[50]: [1, 3, 4, 5]In [51]: lst2 = lst.copy()In [52]: lst2.remove(3)In [53]: lst2Out[53]: [1, 4, 5]In [54]: lstOut[54]: [1, 3, 4, 5]]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>list</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数字（Numbers）]]></title>
    <url>%2Fpython%2F20170509-01-numbers%2F</url>
    <content type="text"><![CDATA[整理出Python3的数字类型，数字分为多种： 整数（int） 浮点数（float） 二进制数（binary） 八进制数（octal） 十六进制数（hex） 复数（complex number） 小数（decimal） 分数（fraction） 数字类型整数（integer)1234， −24， +42， 0 1234567891011121314&gt;&gt;&gt; int(9.1) #取整数9&gt;&gt;&gt; int('1111',2) #二进制转化十进制15&gt;&gt;&gt; int('0b1111',2) #二进制转化十进制15&gt;&gt;&gt; int('177',8) #八进制转化十进制127&gt;&gt;&gt; int('0o177',8) #八进制转化十进制127&gt;&gt;&gt; int('9ff',16) #十六进制转化十进制2559&gt;&gt;&gt; int('0x9ff',16) #十六进制转化十进制2559 浮点数（float）1.23，-1.23， 1.， .1， -1.， -.1， 3.14e-10， 4E210， 4.0e+210 float(9)， float(43210)，float(‘4e210’) 二进制整数（binary）0b1111 bin(15) 八进制整数（octal）0o177 oct(127) 十六进制（hex）0x9ff hex(2559) 复数（complex number）3+4j， 3.0+4.0j， 3j complex(3,4) 小数（decimal）精度高，比float更准确。 123&gt;&gt;&gt; from decimal import Decimal&gt;&gt;&gt; Decimal('1.1')-Decimal('.1')Decimal('1.0') 分数（fraction）123&gt;&gt;&gt; from fractions import Fraction&gt;&gt;&gt; Fraction(1,3)+Fraction(7,6)Fraction(3,2) 运算符+：加法：5+8=13 -：减法：90-10=80 *：乘法：4*7=28 /：浮点数除法：7/2=3.5 //：整数除法（地板除）：7//2=3 %：模（求余数）7%3=1 **：幂：3**4=81]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>number</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[程序控制结构]]></title>
    <url>%2Fpython%2F20170508-03-control%2F</url>
    <content type="text"><![CDATA[2.3.1 顺序结构从上到下顺序执行： 123a = 0a += 1print(a) 2.3.2 分支结构(1) 单分支结构[ 123x = 6if x &gt; 5: print("x is larger than 5") (2) 双分支结构[ 12345x = 6if x &gt; 5: print("x is larger than 5")else: print("x ls not larger than 5") (3) 多分支结构[ 1234567 x = 6if x &gt; 5: print("x is larger than 5")elif x &lt; 5: print("x ls smaller than 5")else: print("x is equal to 5") 2.3.3 循环结构（1） while循环结构[ 1234567891011In [1]: x = 0In [2]: while x &lt; 5: ...: print("&#123;&#125; is smaller than 5".format(x)) ...: x += 1 ...: 0 is smaller than 51 is smaller than 52 is smaller than 53 is smaller than 54 is smaller than 5 (2) for循环结构[ 12345678910111213In [3]: for i in range(10): ...: print(i) ...: 0123456789 (3) 循环体重不要修改可迭代对象不要出现下面的用法： 123 lst = range(10)for i in lst: lst.append(i) (4) 控制结构可以互相嵌套if elif else 、for、 while三种控制结构可以相互嵌套。 123for i in range(10): if i% 2 == 0: print(i) (5) break提前结束整个循环12345678In [8]: for i in range(10): ...: if i == 3: ...: break ...: print(i) ...: 012 (6) continue跳到下次循环开始1234567891011121314In [7]: for i in range(10): ...: if i == 3: ...: continue ...: print(i) ...: 012456789 (7) 循环外使用else123456789In [10]: a = 7In [11]: for i in range(2, a): ....: if a % i ==0: ....: break ....: else: ....: print('yes') ....: yes 循环结构中else子句是用来判断循环有没有提前退出，如果提前退出了，else子句不执行，如果没有提前退出，执行else子句。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>control</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[运算符]]></title>
    <url>%2Fpython%2F20170508-02-operator%2F</url>
    <content type="text"><![CDATA[运算符分为以下几种类型： 算术运算符 逻辑运算符 比较运算符 位运算符 其他运算符 赋值运算符 成员运算符 身份运算符 2.2.1 算术运算符 算术运算符 说明 示例 + 加法 5+8=13 - 减法 90-10=80 * 乘法 4*7=28 / 浮点数除法 7/2=3.5 // 整除，或叫地板除 7//2=3 % 模，即求余数 7%3=1 ** 幂 3**4=81 2.2.2 比较运算符 比较运算符 说明 示例 &gt; 大于 3 &gt; 2 为True &lt; 小于 3 &lt; 2 为False == 等于 3 == 3为True != 不等于 3 != 3为False &gt;= 大于等于 5&gt;=4为True &lt;= 小于等于 6&lt;=3为False 2.2.3 逻辑运算符 比较运算符 说明 示例 and 与。两边都是真值，返回后面那个值,否则返回False 3 and 5 返回5，5 and 0返回False，True and False 返回False or 或 。两边有一个真值，返回那个真值，否则返回False 5 and 0返回5，True and False返回False not 非。非真为假，非假为真 not 5为True，not 0为False，not True为False，Not False为True 2.2.4 位运算符(用到很少，可以暂时理解下就好) [ [ 2.2.5 其他运算符赋值运算符 =：把右边赋值给左边，例如a = 5 a += b、a -= b、a *= b、a /=b、a //=b、a %= b、a **= b：相当于a = a + b、a = a - b… 成员运算符 in 和not in：一个元素是否存在于一组元素中。后续会讲到，略 身份运算符 is和not is：两者是否是指向同一个内存对象。 123456In [8]: x = 20In [9]: y = 20In [10]: x is yOut[10]: True]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>operator</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[变量与命名规则(PEP8)]]></title>
    <url>%2Fpython%2F20170508-01-variable%2F</url>
    <content type="text"><![CDATA[2.1.1 写一个Hello world一个语言刚开始一般写一个hello world： 1print(&quot;Hello, world!&quot;) 2.1.2 变量 Python没有严格意义上的常量，都是可变的，可以随意改变数据的类型。 但是对与一个变量内的元素来说，分为可改变和不可改变的，可改变内部元素的如列表、字典、集合，不可改变内部元素的如元组、字符串。（本章后面小节会讲到。） 举个例子： 12345678910111213141516171819202122In [1]: var = 5In [2]: var = &quot;Python3&quot;In [3]: var = [1,2,3,4]In [4]: lst = [1,2,3,4]In [5]: lst[2] = &quot;c&quot;In [6]: lstOut[6]: [1, 2, &apos;c&apos;, 4]In [7]: strings = &quot;yulongjun&quot;In [8]: strings[0] = &quot;Y&quot;---------------------------------------------------------------------------TypeError Traceback (most recent call last)&lt;ipython-input-8-824d19b519c0&gt; in &lt;module&gt;()----&gt; 1 strings[0] = &quot;Y&quot;TypeError: &apos;str&apos; object does not support item assignment | 2.1.3 命名规则变量名只能包含以下字符： 小写字母（a-z） 大写字母（A-Z） 数字（0-9） 下划线（_） Python中以下划线开头的名字有特殊含义： -：单独的下划线。临时的名称使用，后面不会再次用到它。 _private：单下划线接一个名称。表明该名称的属性为私有。 __attr__：两组双下划线中间加一个名称。Python中系统属性名称，如__init__，__doc__。 更详细的命名约定可参照pep8规范，里面约定了Python中的命名的常用方法：PEP8规范中文版]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>variables</tag>
        <tag>PEP8</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开发环境（vim/Jupyter Notebook/Pycharm）]]></title>
    <url>%2Fpython%2F20170507-03-ide%2F</url>
    <content type="text"><![CDATA[vimvim是一款非常好用的编辑器，学习曲线比较陡峭，但是当你学会并熟练应用的时候，绝对非常好用。这里不详细介绍vim的用法，感兴趣的可以看这本书《vim实用技巧》： 京东：http://item.jd.com/11445638.html 网上也有电子版的下载，请自行搜索。 jupyter notebookjupyter notebook，是一个强大的工具，可以一边测试代码，一边用markdown写标题和文字，算的上是一个在线编辑器+交互式IDE，使用pip可以安装 ：pip install jupyter如果访问pypi安装不是特别快可以更改pip的设置linux下是修改~/.pip/pip.conf： 123[global]index-url = http://mirrors.aliyun.com/pypi/simple/trusted-host = mirrors.aliyun.com MacOS下如果是用brew来安装的话，需要手动创建~/.pip目录，然后创建pip.conf文件，加入下面内容： 123[global]index-url = http://mirrors.aliyun.com/pypi/simple/trusted-host = mirrors.aliyun.com jupyter notebook使用指南 如果仅在所在的那台主机上使用 ：jupyter notebook这样会在所在的那台主机开启一个服务并打开主机的默认浏览器。我们在服务器里输入http://localhost:888或者http://127.0.0.1:8888就可以登录 如果用其他机器的浏览器访问的话：jupyter notebook --ip 0.0.0.0 --port 8888 --no-browser0.0.0.0表示全网可以访问；port后面跟的是端口，可以自定义；no-browser是指不打开本机的浏览器。 jupyter notebook经常用到的快捷方式 可参考http://blog.csdn.net/lawme/article/details/51034543 PyCharmPyCharm简介Pycharm 是 Jetbrains 公司出品的一款商业化的针对Python开发者开发的一款IDE产品，功能十分强大。分为两个版本， Community 和 Professional 版本,下面是两个版本的功能和区别： Features PyCharm Community Edition PyCharm Professional Edition 智能 Python 编辑器 ✔ ✔ 图形化的调试程序和测试运行程序 ✔ ✔ 导航和重构 ✔ ✔ 代码检查 ✔ ✔ VCS 支持 ✔ ✔ 科学化的工具 ✔ ✔ Web 开发 ✔ Python web 框架 ✔ Python 分析器 ✔ 远程开发功能 ✔ 数据库 &amp; SQL 支持 ✔ 你要想用做Web开发（ html，jss，JavaScript 等），或者用到Python的web框架如 Tornado，Django， Flask 等等高级功能，还是选择 Professional 版本吧。如果只是想了解 Python 的基本语法，Community 版足够你用了。（当然，如果只是了解基本语法，可以用 ipython ，还有从ipython中独立出来的 jupyter notebook）。 下载地址为：https://www.jetbrains.com/pycharm/download/ 安装后初始化 双击打开。第一次安装，点ok就可以了；如果之前装过PyCharm，或者有自定义的配置，可以选择上面一条。 这里我们点试用30天（Evaluate for free 30 days） 长期用可以选择付费，支持支付宝的哦，购买地址：https://www.jetbrains.com/pycharm/buy/ 。 IDE主题和编辑器的代码风格： 这里我一般都选Darcula，暗色风格。这个后续都是可以自行更改的。 重启，让主题生效。 创建项目 双击打开，界面如图： Create New Project：创建新项目。 Open： 打开项目或文件。 Check out from Version Control：从版本控制如GitHub，Git等， checkout 项目。 Register：是注册用，关于注册这里不涉及。 Configure：是配置PyCharm，这里面有Pycharm所有的配置项。 Get Help：获取帮助。 我们点击Create New Project，能看到很多项目模板 有纯粹的Python模板，Django，Flaskweb框架的模板等等，我们先选择Pure Python进行初步了解，纯粹的Python模板。右边栏位，Location是项目存放的位置，Interpreter是解释器版本选择，我们可以选择项目要使用的Python版本（新的 Pycharm 2016 已经支持pyenv了，笔者这里用的pyenv来控制Python版本)然后点击create创建。 第一次启动项目时候回进行索引，这时候可能你电脑的cpu和内存占用会很高，甚至风扇狂装，都是正常现象，一会儿就结束，如果使用macbook的话，由于是ssd的，速度会很快，半分钟差不多，索引期间最好不要操作Pycharm，等索引完了再说： 在左下角会提示你接入Tools Windows，包括Mac自带的终端，Python自带的解释器，还有一个TODO，这样，你可以完全沉浸在一个界面就可以了，基本上不用切换桌面或切换程序了，编程变得更专注： 如果想了解更多Pycharm的使用方法，可以看这个：IntelliJ IDEA 使用教程，IDEA是IntelliJ公司的旗舰产品，包含了PyCharm的所有功能。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>pyenv</tag>
        <tag>pyenv-virtualenv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS下Python多版本控制软件的安装：pyenv、pyenv-virtualenv]]></title>
    <url>%2Fpython%2F20170507-02-pyenv-centos%2F</url>
    <content type="text"><![CDATA[pyenv安装1. 安装依赖包1yum -y install git gcc make patch zlib-devel gdbm-devel openssl-devel sqlite-devel bzip2-devel readline-devel 2. 安装pyenv1curl -L https://raw.githubusercontent.com/pyenv/pyenv-installer/master/bin/pyenv-installer | bash 3. 设置环境变量1234567cat &gt;&gt; .bash_profile &lt;&lt; EOF# pyenv settingsexport PATH="~/.pyenv/bin:\$PATH"eval "\$(pyenv init -)"eval "\$(pyenv virtualenv-init -)"EOF 4. 使之生效. .bash_profile或者source .bash_profile 这时候pyenv就可以使用了 pyenv使用指南1、 pyenv versions查看系统的上安装的Python版本。 其中前面的*表示当前工作目录正在使用的版本,其中 的 system表示系统自带的 Python 版本： 12$ pyenv versions* system (set by /Users/yulongjun/.pyenv/version) 2、 pyenv install &lt;version&gt;安装其他版本的Python。例如安装3.6.2和2.7.13版本： 1234567891011121314151617181920212223$ pyenv install 3.6.2 # 安装3.6.2版本的Python$ pyenv install 2.7.13 # 安装2.7.13版本的Python$ pyenv versions # 可以看到3个版本，system为系统自带的版本* system (set by /root/.pyenv/version) 2.7.13 3.6.2$ cd # 到家目录$ mkdir Python36 # 创建Python3.6的工作目录$ cd Python36$ pyenv local 3.6.2 # 使当前工作目录使用Python3.6.2版本$ python -V # 查看一下当前目录用Python的版本，确实是3.6.2Python3.6.2$ pip -V # 查看一下pip版本,是3.6的pippip 9.0.1 from /root/.pyenv/versions/3.6.2/lib/python3.6/site-packages (python 3.6) $ cd # 回到家目录$ mkdir Python27 # 创建python2.7的工作目录$ cd Python27$ pyenv local 2.7.13 # 使当前工作目录使用Python2.7.13版本$ python -V # 查看一下当前目录用Python的版本，确实是2.7.13Python 2.7.13$ pip -V # 查看一下pip版本，是2.7的pippip 9.0.1 from /root/.pyenv/versions/2.7.13/lib/python2.7/site-packages (python 2.7) pyenv-virtualenv的使用方法pyenv-virtualenv是用来创建一个干净的虚拟Python环境的命令，通常在创建干净的新项目时候使用。使用方法如下: 1、创建虚拟环境–pyenv virtualenv 版本号 虚拟环境名。 1$ pyenv virtualenv 3.6.2 venv-3.6.2 2、创建项目，让项目使用干净的Python3.6.2的虚拟环境： 123456[yulongjun@yulongjun ~]$ mkdir Learning-Python3[yulongjun@yulongjun ~]$ cd Learning-Python3/[yulongjun@yulongjun Learning-Python3]$ pyenv local venv-3.6.2(venv-3.6.2) [yulongjun@yulongjun Learning-Python3]$ cd ..[yulongjun@yulongjun ~]$ cd Learning-Python3/(venv-3.6.2) [yulongjun@yulongjun Learning-Python3]$ 我们会发现：只要我们进入Learning-Python3目录，就会自动激活virtualenv，退出Learning-Python3目录，就会关闭virtualenv。 如果要关闭自动激活，可以运行命令pyenv deactivate，要重新启用的话，运行pyenv activate 虚拟环境名。 国内网络环境如果下载不下来的话，可以把显示的下载地址的文件用自己电脑的迅雷下载下来，然后传到~/.pyenv/cache里(cache文件夹没有的话手动创建一个），然后执行pyenv install x.x.x就可以了。也可以使用阿里云来加速下载： vim ~/.pip/pip.conf 12345[global]index-url=http://mirrors.aliyun.com/pypi/simple/[install]trusted-host=mirrors.aliyun.com]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>pyenv</tag>
        <tag>pyenv-virtualenv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[macOS下Python多版本控制软件的安装：pyenv、pyenv-virtualenv]]></title>
    <url>%2Fpython%2F20170507-01-pyenv-macos%2F</url>
    <content type="text"><![CDATA[软件简介： pyenv，是一款特别好用的Python版本管理器，程序员可以建立不同的目录，在不同的目录里分别运行不同版本的Python， 并且互不影响，安装的包也互不影响。github项目地址：https://github.com/yyuu/pyenv pyenv-virtualenv， 是pyenv的一个plugin（插件），可以用来创建基于不同Python版本的干净的虚拟环境。github项目地址：https://github.com/yyuu/pyenv-virtualenv 安装思路：先安装macOS的软件包管理器brew，然后用brew安装pyenv和pyenv-virtualenv 1. 安装brew软件包管理器brew全名Homebrew，是macOS下的一款软件包管理器(macOS没有自己的软件包管理器)，类似于CentOS下面的yum，Ubuntu下的apt-get命令。 1/usr/bin/ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)" 2. 用brew命令安装pyenv、pyenv-virtualenv12brew install pyenvbrew install pyenv-virtualenv 会先安装autoconf, pkg-config, openssl, readline 安装过程中我们可以看到一些Caveats（警告），需要我们手动处理一下。首先link readline到系统lib：1brew link readline --force 然后根据Caveats的提示修改环境变量，vim ~/.bash_profile添加下面内容： 123456#pyenv settingsexport PYENV_ROOT=/usr/local/var/pyenvif which pyenv &gt; /dev/null; then eval &quot;$(pyenv init -)&quot;; fi#pyenv-virtualenv settingsif which pyenv-virtualenv-init &gt; /dev/null; then eval &quot;$(pyenv virtualenv-init -)&quot;; fi 上面的两处设置让pyenv和pyenv-virtualenv更好用，用命令的时候可以补全。 设置完关闭终端，然后重启终端，即可生效。 3. pyenv的使用方法 **警告：pyenv安装Python是编译安装的，在使用之前要先安装zlib和SQLite3，要不然安装会报错。 安装zlib和SQLite3并链接： 1234brew install zlibbrew install sqlite3brew link zlib --forcebrew link sqlite3 --force 然后根据Caveats的提示修改环境变量，vim ~/.bash_profile添加下面内容： 12#sqlite3 settingsexport PATH="/usr/local/opt/sqlite/bin:$PATH" 用pyenv --help可以查看pyenv的使用帮助： 常用的几个pyenv命令： pyenv install x.y.z：安装Python，x.y.z是Python的版本，如pyenv install 3.6.2。 pyenv local x.y.z：设置当前目录的Python版本为x.y.z, 如pyenv local 3.6.2。 pyenv versions：查看安装的版本，前面带*号的表示当前目录下正在使用的版本。系统自带的Python是System，后安装的版本的都是版本号。 下面给出使用的例子：示例： 12345678910111213141516171819202122232425$ pyenv install 3.6.2 # 安装3.6.2版本的Python$ pyenv install 2.7.13 # 安装2.7.13版本的Python$ pyenv versions # 可以看到3个版本，system为系统自带的版本* system (set by /usr/local/var/pyenv/version) 2.7.13 3.6.2$ cd # 到家目录$ mkdir Python36 # 创建Python3.6的工作目录$ cd Python36$ pyenv local 3.6.2 # 使当前工作目录使用Python3.6.2版本$ python -V # 查看一下当前目录用Python的版本，确实是3.6.2Python3.6.2$ pip -V # 查看一下pip版本,是3.6的pippip 9.0.1 from /usr/local/var/pyenv/versions/3.6.2/lib/python3.6/site-packages $ cd # 回到家目录$ mkdir Python27 # 创建python2.7的工作目录$ cd Python27$ pyenv local 2.7.13 # 使当前工作目录使用Python2.7.13版本$ python -V # 查看一下当前目录用Python的版本，确实是2.7.13Python 2.7.13$ pip -V # 查看一下pip版本，是2.7的pippip 9.0.1 from /usr/local/var/pyenv/versions/2.7.13/lib/python2.7/site-packages (python 2.7) 4. pyenv-virtualenv的使用方法pyenv-virtualenv是用来创建一个干净的虚拟Python环境的命令，通常在创建干净的新项目时候使用。使用方法如下: 1.创建虚拟环境–pyenv virtualenv 版本号 虚拟环境名。 1$ pyenv virtualenv 3.6.2 venv-3.6.2 创建项目，让项目使用干净的Python3.6.2的虚拟环境： 123456[yulongjun@yulongjun ~]$ mkdir Learning-Python3[yulongjun@yulongjun ~]$ cd Learning-Python3/[yulongjun@yulongjun Learning-Python3]$ pyenv local venv-3.6.2(venv-3.6.2) [yulongjun@yulongjun Learning-Python3]$ cd ..[yulongjun@yulongjun ~]$ cd Learning-Python3/(venv-3.6.2) [yulongjun@yulongjun Learning-Python3]$ 我们会发现：只要我们进入Learning-Python3目录，就会自动激活virtualenv，退出Learning-Python3目录，就会关闭virtualenv。 如果要关闭自动激活，可以运行命令pyenv deactivate，要重新启用的话，运行pyenv activate 虚拟环境名。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>pyenv</tag>
        <tag>pyenv-virtualenv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Service Pack for ProLiant (SPP) Version 2016.10.0 -- HP服务器软件、驱动、固件汇总ISO（包含几乎所有操作系统和Gen6到9的机型）]]></title>
    <url>%2Fserver%2F20170408-01-hp-spp%2F</url>
    <content type="text"><![CDATA[简介：英文介绍页面： http://h17007.www1.hpe.com/us/en/enterprise/servers/products/service_pack/spp/index.aspx Service Pack for ProLiant (SPP)是一个全面的系统软件、驱动和固件更新解决方案，作为单个ISO映像提供。此解决方案使用HP Smart Update Manager（HP SUM）作为部署工具，并可以在所有HPE ProLiant Gen9、Gen8、Gen7、Gen6服务器上使用。 2016.10版本，增加了对下面几个系统的支持： Microsoft Windows Server 2016 Red Hat Enterprise 6.8 VMware vSphere 6.0 U2 使用方法：1. 安装Chrome浏览器并设置为默认浏览器。这里装Chrome浏览器的原因是因为SSP对低IE版本不支持，有些低版本的IE在启动web安装界面时候会有问题。Linux使用的Firefox没有这个问题，可以省略这步。 2. 解压iso并运行hpsumWindows下运行lauch_hpsum.bat，Linux下运行launch_hpsum.sh。 3. 进入浏览器web界面系统会自动弹出IE浏览器窗口，进入SPP界面，刷新固件、安装驱动和相应软件程序请点击Localhost引导式更新(Localhost Guided Update) 4. 选择部署模式 交互式—交互式安装 自动—自动更新全部的驱动、固件等 本次就交互式为例，单击正常（若选自动更新，选择之后则无需继续手动操作，直至自动更新完毕后重启服务器即可） 5. 清点步骤1：释放镜像中的文件并且清点，清点过程中Next按键为灰色不可点击，清点完成后点击下一步。 6. 安装清单步骤2：可升级的固件、驱动和应用软件清单列表已选定，表示现在的SPP里面的版本与已经安装的版本更高强制，表示现在的SPP里面的版本与已经安装的版本相同或者更低就ILO为例可以看到，当前的固件版本为3.10，SPP中最新的版本为3.30，建议更新 注意：可以根据需求强制选中强制或者已选定按钮标识，滑动条会滑动到另一侧.点击部署进入步骤3 7. 开始安装步骤3：开始安装。 8. 重启 安装完成后，方便停机的情况下选择重启重启服务器，固件以及部分驱动更新升效 下载地址这里提供百度网盘下载地址： Service Pack for ProLiant (SPP) Version 2016.10.0 (大小：6.52 GB) MD5 Checksum: 3e93873632c5758666c5b1c305d557ea 链接： http://pan.baidu.com/s/1mhTMZva 密码: bthq]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>HP SSP</tag>
        <tag>Service Pack for ProLiant</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[目前所用操作系统版本汇总（持续更新）]]></title>
    <url>%2Fserver%2F20170404-server-operation-system%2F</url>
    <content type="text"><![CDATA[截止目前为止，运维主要用到下面几大类的操作系统。操作系统全用64位版本。Linux一般用小版本号为偶数版的，比较稳定，奇数版据统计不是特别稳定。 在传统企业当中，大部分系统还是用的红帽，但是最近两年，用CentOS和OEL的逐渐多了起来。CentOS方便安装和更新，OEL在Oracle数据库方面配套使用比较好用。 RHEL（Red Hat Enterprise Linux)传统企业中用的最多的版本 RHEL 5.8 （5中用的最多，历史遗留） RHEL 5.10 （新搭建的5，用此版本） RHEL 6.6 （6中用的比较多的版本） RHEL 6.8 （推荐后续安装的6用此版本，在5时代，8是时间最长，用的最多的版本，在6中也会延续） RHEL 7.2 （偶数较为稳定） RHEL 7.3 OEL（Oracle Enterprise Linux）通常与Oracle数据库一起配套安装，针对Oracle做了一些优化。 OEL 6.8 OEL 7.2 CentOS（等同于RHEL，可联网yum更新）CentOS现在传统企业开始用起来，互联网企业很久之前就已经开始用了。 CentOS 6.8 CentOS 7.2 CentOS 7.3 Windows ServerWindows Server 2003 版不再使用，目前主流用的 2008 R2 比较多，没有历史包袱的项目也开始使用 2012 R2 。 Windows Server 2008 R2 Enterprise SP1 VL版 Windows Server 2012 R2 Enterprise with Update VL版 Windows Desktop目前桌面版主用的两大系统，xp、8、8.1 已被摒弃。 Windows 7 Pro SP1 VL版（文件后缀为677816的版本可用，此版之后的版本不易激活） Windows 10 Enterprise 2016 LTSB版（目前最新的企业长期支持版） Windows 激活工具以前一直用的 HEU KMS 激活工具，用了三四年，去年发现一个 microKMS，能激活的系统更全。因此把这两个都贡献出来。 百度网盘下载地址（持续更新）链接: https://pan.baidu.com/s/1c12ZFtI 密码: mgcb]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>Windows</tag>
        <tag>CentOS</tag>
        <tag>RHEL</tag>
        <tag>OEL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[新的开始]]></title>
    <url>%2Fcloud%2F20170404-03-start-cloud%2F</url>
    <content type="text"><![CDATA[全新的开始，敬请期待!]]></content>
      <categories>
        <category>cloud</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[新的开始]]></title>
    <url>%2Fsoftware%2F20170404-04-start-software%2F</url>
    <content type="text"><![CDATA[全新的开始，敬请期待!]]></content>
      <categories>
        <category>software</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[新的开始]]></title>
    <url>%2Flinux%2F20170404-01-start%2F</url>
    <content type="text"><![CDATA[全新的开始，敬请期待!]]></content>
  </entry>
</search>
